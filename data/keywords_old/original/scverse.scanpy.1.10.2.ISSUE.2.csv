id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1481:648,Testability,log,logging,648,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:257,Usability,guid,guide,257,- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1482:677,Security,hash,hashsolo,677,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-207-326a4b3ee327> in <module>(); 1 sce.pp.hashsolo(adata, sample_to_column.keys(),; 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',; ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace); 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]); 250 for cluster_feature in unique_cluster_features:; --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:883,Security,hash,hashsolo,883,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-207-326a4b3ee327> in <module>(); 1 sce.pp.hashsolo(adata, sample_to_column.keys(),; 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',; ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace); 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]); 250 for cluster_feature in unique_cluster_features:; --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1323,Testability,log,logging,1323,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-207-326a4b3ee327> in <module>(); 1 sce.pp.hashsolo(adata, sample_to_column.keys(),; 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',; ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace); 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]); 250 for cluster_feature in unique_cluster_features:; --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-207-326a4b3ee327> in <module>(); 1 sce.pp.hashsolo(adata, sample_to_column.keys(),; 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',; ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace); 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]); 250 for cluster_feature in unique_cluster_features:; --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1484:503,Testability,test,tests,503,"Hi!. I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```; > raise SyntaxError(msg, (filename, lineno, 2, text)); E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9; E > <; E ^; E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`’s docstring should start with one-line description:; E ; E ␣␣␣␣""""""\; E ␣␣␣␣My one-line␣description.; E ; E ␣␣␣␣…; E ␣␣␣␣""""""; scanpy/tests/test_docs.py:38: SyntaxError; ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1485:1351,Testability,log,logfoldchanges,1351,"enes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python; print(set(noncycling_adult.obs.class_1)); #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),; (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),; (6.991276 ,), (6.952865 ,)],; dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),; ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],; dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),; (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),; (10.144425 ,), ( 5.6517367,)],; dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),; (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),; (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),; (3.57940624e-12,)],; dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),; (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),; (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),; (8.76739764e-09,)],; dtype=[('T-cell', '<f8')])}; """"""; ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2212,Usability,learn,learn,2212,"ups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python; print(set(noncycling_adult.obs.class_1)); #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),; (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),; (6.991276 ,), (6.952865 ,)],; dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),; ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],; dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),; (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),; (10.144425 ,), ( 5.6517367,)],; dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),; (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),; (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),; (3.57940624e-12,)],; dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),; (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),; (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),; (8.76739764e-09,)],; dtype=[('T-cell', '<f8')])}; """"""; ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1486:527,Availability,error,error,527,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2591,Deployability,update,updated,2591,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 4.12.0; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; retrying NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.1; storemagic NA; tables 3.6.1; tornado 6.0.4; traitlets 5.0.5; wcwidth 0.2.5; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2020-11-05 17:47; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2539,Testability,log,logical,2539,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 4.12.0; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; retrying NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.12.1; storemagic NA; tables 3.6.1; tornado 6.0.4; traitlets 5.0.5; wcwidth 0.2.5; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2020-11-05 17:47; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:570,Usability,guid,guide,570,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],; jitter=0.4, multi_panel=True). ```. ```pytb; /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.4; appnope 0.1.0; attr 20.2.0; backcall 0.2.0; cffi 1.14.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.9; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.34.0; matplotlib 3.3.2; mpl_toolkits NA; natsort 7.0.1; nbformat 5.0.8; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.4; pandas 1.1.2; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1487:286,Availability,error,error,286,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:262,Testability,log,log,262,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:266,Testability,log,log,266,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:703,Testability,log,log,703,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:707,Testability,log,log,707,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:845,Testability,log,log,845,"This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\; max_out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/inde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1140,Testability,log,log,1140,"out_group_fraction=max_out_group_fraction,; min_fold_change=min_fold_change,use_raw=use_raw,; min_in_group_fraction=0.25,log=log)`. But got this error:. ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-91-d477dca208af> in <module>; 2 max_out_group_fraction=max_out_group_fraction,; 3 min_fold_change=min_fold_change,use_raw=use_raw,; ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 725 var_names,; 726 groupby='__is_in_cluster__',; --> 727 use_raw=use_raw,; 728 ); 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1808 matrix = adata.raw[:, var_names].X; 1809 else:; -> 1810 matrix = adata[:, var_names].X; 1811 ; 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/pull/1488:385,Usability,simpl,simply,385,"Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python; df1 = sc.queries.enrich(['KLF4', 'PAX5']); df2 = sc.queries.enrich(['SOX2', 'NANOG']); ...concat...; ```. we can now do. ```python; df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}); ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1489:263,Modifiability,variab,variables,263,"As explained in plotting docs; > The color map can also be set individually for each value in adata.obs and adata.var, by setting `adata.uns[""{var}_cmap""]`. The individual values overwrite `color_map`. I think it's very useful when plotting multiple .obs or .var variables using ""color"", as the cmaps can then be defined for each embedding individually.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1490:120,Availability,error,error,120,"Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```; >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'); WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; ranking genes; consider 'louvain_resolution_3.0' groups:; with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups; method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics; for group_index, scores, pvals in generate_test_results:; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test; self._basic_stats(); File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats; self.means[imask], self.vars[imask] = _get_mean_var(X_mask); File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var; var *= X.shape[axis] / (X.shape[axis] - 1); ZeroDivisionError: division by zero; ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:251,Testability,test,test,251,"Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```; >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'); WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; ranking genes; consider 'louvain_resolution_3.0' groups:; with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups; method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics; for group_index, scores, pvals in generate_test_results:; File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test; self._basic_stats(); File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats; self.means[imask], self.vars[imask] = _get_mean_var(X_mask); File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var; var *= X.shape[axis] / (X.shape[axis] - 1); ZeroDivisionError: division by zero; ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1493:20,Deployability,update,updates,20,"Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:98,Deployability,install,installed,98,"Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:32,Testability,test,tests,32,"Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1494:86,Deployability,patch,patch,86,Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist.; This patch will check for existence of 'add_adj_list' in the object before; calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/issues/1495:354,Testability,test,test,354,"the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering; 1. why; 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1496:293,Deployability,install,install,293,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas?. ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install -e .; ```. ```pytb; File ""/tmp/tmp7fu14tjf"", line 280, in <module>; main(); File ""/tmp/tmp7fu14tjf"", line 263, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:313,Deployability,install,install,313,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas?. ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install -e .; ```. ```pytb; File ""/tmp/tmp7fu14tjf"", line 280, in <module>; main(); File ""/tmp/tmp7fu14tjf"", line 263, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:709,Deployability,install,install,709,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas?. ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install -e .; ```. ```pytb; File ""/tmp/tmp7fu14tjf"", line 280, in <module>; main(); File ""/tmp/tmp7fu14tjf"", line 263, in main; json_out['return_val'] = hook(**hook_input['kwargs']); File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel; return hook(metadata_directory, config_settings); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finaliz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2245,Deployability,integrat,integration,2245,"-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3115,Deployability,install,installation,3115,"ine 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 20.0.2 . ubuntu; 20.04. pip list; Package Version Location ; ------------------------- -------------------- -----------------------------; analysaurus 0.0.1 /home/ubuntu/code/analysaurus; anndata 0.7.5 ; ansi2html 1.5.2 ; appdirs 1.4.4 ; argon2-cffi 20.1.0 ; astroid 2.4.2 ; async-generator 1.10 ; attrs 20.3.0 ; autopep8 1.5.4 ; backcall 0.2.0 ; biopython 1.78 ; black 20.8b1 ; bleach 3.2.1 ; bokeh 2.2.3 ; botocore 1.19.18 ; Brotli 1.0.9 ; cellforest 0.0.2 /home/ubuntu/code/cellforest ; certifi 2019.11.28 ; cffi 1.14.3 ; chardet 3.0.4 ; click 7.1.2 ; colorama 0.4.4 ; commonmark 0.9.1 ; cycler 0.10.0 ; dash 1.17.0 ; dash-building-blocks 0.1.2 ; dash-core-components 1.13.0 ; dash-html-components 1.1.1 ; dash-renderer 1.8.3 ; dash-table 4.11.0 ; dataclasses 0.6 ; dataforest 0.0.2 /home/ubuntu/code/dataforest ; dbus-python 1.2.16 ; decorator 4.4.2 ; defusedxml 0.6.0 ; distr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6767,Deployability,upgrade,upgrades,6767,lite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-server 0.4.0 ; python-language-server 0.36.1 ; pytoml 0.1.21 ; pytz 2020.4 ; PyYAML 5.3.1 ; pyzmq 20.0.0 ; regex 2020.11.13 ; requests 2.22.0 ; requests-unixsocket 0.2.0 ; retrying 1.3.3 ; rich 9.2.0 ; rope 0.18.0 ; scikit-learn 0.23.2 ; scikit-misc 0.1.3 ; scipy 1.5.4 ; scriptedforms 0.10.1 ; scvi-tools 0.7.1 ; seaborn 0.11.0 ; Send2Trash 1.5.0 ; setuptools 50.3.2 ; setuptools-scm 4.1.2 ; sinfo 0.3.1 ; six 1.14.0 ; smmap 3.0.4 ; snowballstemmer 2.0.0 ; SQLAlchemy 1.3.20 ; statsmodels 0.12.1 ; stdlib-list 0.7.0 ; tables 3.6.1 ; termcolor 1.1.0 ; terminado 0.9.1 ; testpath 0.4.4 ; threadpoolctl 2.1.0 ; toml 0.10.2 ; torch 1.7.0 ; tornado 6.1 ; tqdm 4.51.0 ; traitlets 5.0.5 ; typed-ast 1.4.1 ; typeguard 2.10.0 ; typing-extensions 3.7.4.3 ; ujson 4.0.1 ; umap-learn 0.4.6 ; unattended-upgrades 0.1 ; urllib3 1.25.8 ; watchdog 0.10.3 ; wcwidth 0.2.5 ; webencodings 0.5.1 ; Werkzeug 1.0.1 ; wheel 0.35.1 ; widgetsnbextension 3.5.1 ; wrapt 1.12.1 ; xeus-python 0.8.3 ; xlrd 1.2.0 ; yapf 0.30.0 ; zipp 3.4.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2245,Integrability,integrat,integration,2245,"-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4982,Integrability,wrap,wrap,4982,.11.0 ; dataclasses 0.6 ; dataforest 0.0.2 /home/ubuntu/code/dataforest ; dbus-python 1.2.16 ; decorator 4.4.2 ; defusedxml 0.6.0 ; distro-info 0.23ubuntu1 ; entrypoints 0.3 ; fastcore 1.3.5 ; flake8 3.8.4 ; Flask 1.1.2 ; Flask-Compress 1.8.0 ; future 0.18.2 ; get-version 2.1 ; gitdb 4.0.5 ; GitPython 3.1.11 ; h5py 3.1.0 ; hyperopt 0.1.2 ; idna 2.8 ; importlib-metadata 2.0.0 ; iniconfig 1.1.1 ; ipdb 0.13.4 ; ipykernel 5.3.4 ; ipympl 0.5.8 ; ipython 7.19.0 ; ipython-genutils 0.2.0 ; ipywidgets 7.5.1 ; isort 5.6.4 ; itsdangerous 1.1.0 ; jedi 0.17.2 ; Jinja2 2.11.2 ; jmespath 0.10.0 ; joblib 0.17.0 ; json5 0.9.5 ; jsonschema 3.2.0 ; jupyter-client 6.1.7 ; jupyter-core 4.6.3 ; jupyter-dash 0.3.1 ; jupyter-lsp 0.9.2 ; jupyterlab 2.2.9 ; jupyterlab-code-formatter 1.3.6 ; jupyterlab-git 0.23.1 ; jupyterlab-latex 2.0.0 ; jupyterlab-pygments 0.1.2 ; jupyterlab-server 1.2.0 ; jupyterlab-sql 0.3.3 ; jupyterlab-templates 0.2.5 ; jupytext 1.6.0 ; kiwisolver 1.3.1 ; lazy-object-proxy 1.4.3 ; legacy-api-wrap 1.2 ; llvmlite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-ser,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6913,Integrability,wrap,wrapt,6913,lite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-server 0.4.0 ; python-language-server 0.36.1 ; pytoml 0.1.21 ; pytz 2020.4 ; PyYAML 5.3.1 ; pyzmq 20.0.0 ; regex 2020.11.13 ; requests 2.22.0 ; requests-unixsocket 0.2.0 ; retrying 1.3.3 ; rich 9.2.0 ; rope 0.18.0 ; scikit-learn 0.23.2 ; scikit-misc 0.1.3 ; scipy 1.5.4 ; scriptedforms 0.10.1 ; scvi-tools 0.7.1 ; seaborn 0.11.0 ; Send2Trash 1.5.0 ; setuptools 50.3.2 ; setuptools-scm 4.1.2 ; sinfo 0.3.1 ; six 1.14.0 ; smmap 3.0.4 ; snowballstemmer 2.0.0 ; SQLAlchemy 1.3.20 ; statsmodels 0.12.1 ; stdlib-list 0.7.0 ; tables 3.6.1 ; termcolor 1.1.0 ; terminado 0.9.1 ; testpath 0.4.4 ; threadpoolctl 2.1.0 ; toml 0.10.2 ; torch 1.7.0 ; tornado 6.1 ; tqdm 4.51.0 ; traitlets 5.0.5 ; typed-ast 1.4.1 ; typeguard 2.10.0 ; typing-extensions 3.7.4.3 ; ujson 4.0.1 ; umap-learn 0.4.6 ; unattended-upgrades 0.1 ; urllib3 1.25.8 ; watchdog 0.10.3 ; wcwidth 0.2.5 ; webencodings 0.5.1 ; Werkzeug 1.0.1 ; wheel 0.35.1 ; widgetsnbextension 3.5.1 ; wrapt 1.12.1 ; xeus-python 0.8.3 ; xlrd 1.2.0 ; yapf 0.30.0 ; zipp 3.4.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2328,Modifiability,config,config,2328,"ocals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 20.0.2 . ubuntu; 20.04. pip list; Package Version Location ; ------------------------- --------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2465,Modifiability,config,config,2465,"ckages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 20.0.2 . ubuntu; 20.04. pip list; Package Version Location ; ------------------------- -------------------- -----------------------------; analysaurus 0.0.1 /home/ubuntu/code/analysaurus; anndata 0.7.5 ; ansi2html 1.5.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2155,Performance,load,load,2155,"un_setup(); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup; exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>; setup(; File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup; return distutils.core.setup(**attrs); File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup; _setup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2633,Safety,detect,detect,2633,"etup_distribution = dist = klass(attrs); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__; _Distribution.__init__(self, {; File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__; self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options; ep(self); File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 20.0.2 . ubuntu; 20.04. pip list; Package Version Location ; ------------------------- -------------------- -----------------------------; analysaurus 0.0.1 /home/ubuntu/code/analysaurus; anndata 0.7.5 ; ansi2html 1.5.2 ; appdirs 1.4.4 ; argon2-cffi 20.1.0 ; astroid 2.4.2 ; async-generator 1.10 ; attrs 20.3.0 ; autopep8 1.5.4 ; backcall 0.2.0 ; biopython 1.78 ; black 20.8b1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3139,Testability,log,logging,3139,"eywords; ep.load()(self, ep.name, value); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword; dist.metadata.version = _get_version(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version; parsed_version = _do_parse(config); File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(; LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work.; ; For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```; ```; #### Versions. <details>. scanpy; problem is with installation, so scanpy.logging.print_versions(); commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python; 3.8.5. pip; 20.0.2 . ubuntu; 20.04. pip list; Package Version Location ; ------------------------- -------------------- -----------------------------; analysaurus 0.0.1 /home/ubuntu/code/analysaurus; anndata 0.7.5 ; ansi2html 1.5.2 ; appdirs 1.4.4 ; argon2-cffi 20.1.0 ; astroid 2.4.2 ; async-generator 1.10 ; attrs 20.3.0 ; autopep8 1.5.4 ; backcall 0.2.0 ; biopython 1.78 ; black 20.8b1 ; bleach 3.2.1 ; bokeh 2.2.3 ; botocore 1.19.18 ; Brotli 1.0.9 ; cellforest 0.0.2 /home/ubuntu/code/cellforest ; certifi 2019.11.28 ; cffi 1.14.3 ; chardet 3.0.4 ; click 7.1.2 ; colorama 0.4.4 ; commonmark 0.9.1 ; cycler 0.10.0 ; dash 1.17.0 ; dash-building-blocks 0.1.2 ; dash-core-components 1.13.0 ; dash-html-components 1.1.1 ; dash-renderer 1.8.3 ; dash-table 4.11.0 ; dataclasses 0.6 ; dataforest 0.0.2 /home/ubuntu/code/dataforest ; dbus-python 1.2.16 ; decorator 4.4.2 ; defusedxml 0.6.0 ; distro-info 0.23ubuntu1 ; entrypo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6545,Testability,test,testpath,6545,lite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-server 0.4.0 ; python-language-server 0.36.1 ; pytoml 0.1.21 ; pytz 2020.4 ; PyYAML 5.3.1 ; pyzmq 20.0.0 ; regex 2020.11.13 ; requests 2.22.0 ; requests-unixsocket 0.2.0 ; retrying 1.3.3 ; rich 9.2.0 ; rope 0.18.0 ; scikit-learn 0.23.2 ; scikit-misc 0.1.3 ; scipy 1.5.4 ; scriptedforms 0.10.1 ; scvi-tools 0.7.1 ; seaborn 0.11.0 ; Send2Trash 1.5.0 ; setuptools 50.3.2 ; setuptools-scm 4.1.2 ; sinfo 0.3.1 ; six 1.14.0 ; smmap 3.0.4 ; snowballstemmer 2.0.0 ; SQLAlchemy 1.3.20 ; statsmodels 0.12.1 ; stdlib-list 0.7.0 ; tables 3.6.1 ; termcolor 1.1.0 ; terminado 0.9.1 ; testpath 0.4.4 ; threadpoolctl 2.1.0 ; toml 0.10.2 ; torch 1.7.0 ; tornado 6.1 ; tqdm 4.51.0 ; traitlets 5.0.5 ; typed-ast 1.4.1 ; typeguard 2.10.0 ; typing-extensions 3.7.4.3 ; ujson 4.0.1 ; umap-learn 0.4.6 ; unattended-upgrades 0.1 ; urllib3 1.25.8 ; watchdog 0.10.3 ; wcwidth 0.2.5 ; webencodings 0.5.1 ; Werkzeug 1.0.1 ; wheel 0.35.1 ; widgetsnbextension 3.5.1 ; wrapt 1.12.1 ; xeus-python 0.8.3 ; xlrd 1.2.0 ; yapf 0.30.0 ; zipp 3.4.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6198,Usability,learn,learn,6198,lite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-server 0.4.0 ; python-language-server 0.36.1 ; pytoml 0.1.21 ; pytz 2020.4 ; PyYAML 5.3.1 ; pyzmq 20.0.0 ; regex 2020.11.13 ; requests 2.22.0 ; requests-unixsocket 0.2.0 ; retrying 1.3.3 ; rich 9.2.0 ; rope 0.18.0 ; scikit-learn 0.23.2 ; scikit-misc 0.1.3 ; scipy 1.5.4 ; scriptedforms 0.10.1 ; scvi-tools 0.7.1 ; seaborn 0.11.0 ; Send2Trash 1.5.0 ; setuptools 50.3.2 ; setuptools-scm 4.1.2 ; sinfo 0.3.1 ; six 1.14.0 ; smmap 3.0.4 ; snowballstemmer 2.0.0 ; SQLAlchemy 1.3.20 ; statsmodels 0.12.1 ; stdlib-list 0.7.0 ; tables 3.6.1 ; termcolor 1.1.0 ; terminado 0.9.1 ; testpath 0.4.4 ; threadpoolctl 2.1.0 ; toml 0.10.2 ; torch 1.7.0 ; tornado 6.1 ; tqdm 4.51.0 ; traitlets 5.0.5 ; typed-ast 1.4.1 ; typeguard 2.10.0 ; typing-extensions 3.7.4.3 ; ujson 4.0.1 ; umap-learn 0.4.6 ; unattended-upgrades 0.1 ; urllib3 1.25.8 ; watchdog 0.10.3 ; wcwidth 0.2.5 ; webencodings 0.5.1 ; Werkzeug 1.0.1 ; wheel 0.35.1 ; widgetsnbextension 3.5.1 ; wrapt 1.12.1 ; xeus-python 0.8.3 ; xlrd 1.2.0 ; yapf 0.30.0 ; zipp 3.4.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6742,Usability,learn,learn,6742,lite 0.34.0 ; markdown-it-py 0.5.6 ; MarkupSafe 1.1.1 ; matplotlib 3.3.3 ; mccabe 0.6.1 ; mistune 0.8.4 ; mypy-extensions 0.4.3 ; natsort 7.0.1 ; nbclient 0.5.1 ; nbconvert 6.0.7 ; nbdime 2.1.0 ; nbformat 5.0.8 ; nbresuse 0.3.6 ; nest-asyncio 1.4.3 ; networkx 2.5 ; notebook 6.1.5 ; numba 0.51.2 ; numexpr 2.7.1 ; numpy 1.19.4 ; packaging 20.4 ; pandas 1.1.4 ; pandocfilters 1.4.3 ; parso 0.7.1 ; path 15.0.0 ; pathspec 0.8.1 ; pathtools 0.1.2 ; patsy 0.5.1 ; peepdis 0.1.13 ; pexpect 4.8.0 ; pickleshare 0.7.5 ; Pillow 8.0.1 ; pip 20.0.2 ; plotly 4.12.0 ; pluggy 0.13.1 ; prometheus-client 0.8.0 ; prompt-toolkit 3.0.8 ; psutil 5.7.3 ; ptvsd 4.3.2 ; ptyprocess 0.6.0 ; py 1.9.0 ; pycodestyle 2.6.0 ; pycparser 2.20 ; pydocstyle 5.1.1 ; pyflakes 2.2.0 ; Pygments 2.7.2 ; PyGObject 3.36.0 ; pylint 2.6.0 ; pymongo 3.11.0 ; pyparsing 2.4.7 ; pyrsistent 0.17.3 ; pytest 6.1.2 ; python-apt 2.0.0+ubuntu0.20.4.1 ; python-dateutil 2.8.1 ; python-debian 0.1.36ubuntu1 ; python-jsonrpc-server 0.4.0 ; python-language-server 0.36.1 ; pytoml 0.1.21 ; pytz 2020.4 ; PyYAML 5.3.1 ; pyzmq 20.0.0 ; regex 2020.11.13 ; requests 2.22.0 ; requests-unixsocket 0.2.0 ; retrying 1.3.3 ; rich 9.2.0 ; rope 0.18.0 ; scikit-learn 0.23.2 ; scikit-misc 0.1.3 ; scipy 1.5.4 ; scriptedforms 0.10.1 ; scvi-tools 0.7.1 ; seaborn 0.11.0 ; Send2Trash 1.5.0 ; setuptools 50.3.2 ; setuptools-scm 4.1.2 ; sinfo 0.3.1 ; six 1.14.0 ; smmap 3.0.4 ; snowballstemmer 2.0.0 ; SQLAlchemy 1.3.20 ; statsmodels 0.12.1 ; stdlib-list 0.7.0 ; tables 3.6.1 ; termcolor 1.1.0 ; terminado 0.9.1 ; testpath 0.4.4 ; threadpoolctl 2.1.0 ; toml 0.10.2 ; torch 1.7.0 ; tornado 6.1 ; tqdm 4.51.0 ; traitlets 5.0.5 ; typed-ast 1.4.1 ; typeguard 2.10.0 ; typing-extensions 3.7.4.3 ; ujson 4.0.1 ; umap-learn 0.4.6 ; unattended-upgrades 0.1 ; urllib3 1.25.8 ; watchdog 0.10.3 ; wcwidth 0.2.5 ; webencodings 0.5.1 ; Werkzeug 1.0.1 ; wheel 0.35.1 ; widgetsnbextension 3.5.1 ; wrapt 1.12.1 ; xeus-python 0.8.3 ; xlrd 1.2.0 ; yapf 0.30.0 ; zipp 3.4.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1497:223,Availability,error,error,223,"It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:843,Availability,Error,Error,843,"It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:849,Integrability,message,message,849,"It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:2118,Security,hash,hash,2118,"e: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```; adata.obs['seurat_clusters'].cat.categories; ```; `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:; ```; sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'); ```. Error message:; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-327-1f686f2dc40b> in <module>(); ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0); 474 or (c in var_names); 475 ); --> 476 for c in colors; 477 ]; 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key); 4069 False; 4070 """"""; -> 4071 hash(key); 4072 try:; 4073 return key in self._engine. TypeError: unhashable type: 'dict'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1500:999,Availability,down,downstream,999,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: ; - Cluster cells based on endogenes; - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. ; I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:; ```; sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ?; ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: ; - Cluster cells based on endogenes; - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. ; I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:; ```; sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ?; ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1502:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1503:156,Safety,predict,prediction,156,"Hi everyone,. Thank you for scanpy! I use it very frequently for my research. I am getting started with spatial data, and would like to ask if there is any prediction for when IMC data will be supported? You mention this in the [spatial transcriptomics tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html) so I suppose it's coming soon -- but how soon?; If you have started something and need an extra pair of hands to get it done, I would be happy to contribute! . Thanks,; Pedro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1504:623,Availability,error,error,623,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python; sc.pp.highly_variable_genes(; adata,; flavor = ""seurat_v3"",; n_top_genes = 7000,; layer = ""counts"",; batch_key = ""combined"",; subset = True; ); ```. I get the following error:. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-3748de5bacdc> in <module>; 5 layer = ""counts"",; 6 batch_key = ""combined"",; ----> 7 subset = True; 8 ); 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 420 span=span,; 421 subset=subset,; --> 422 inplace=inplace,; 423 ); 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3514,Deployability,update,updated,3514,"4 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; SCCAF NA; anndata 0.7.4; backcall 0.1.0; cffi 1.14.3; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.0; importlib_metadata 1.7.0; ipykernel 5.1.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.16.0; joblib 0.17.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.31.0; louvain 0.6.1; matplotlib 3.1.3; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.6.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.3; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.1; rich NA; ruamel NA; scanpy 1.6.0; scipy 1.5.4; scvi 0.7.1; seaborn 0.10.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.11.1; storemagic NA; tables 3.6.1; texttable 1.6.2; threadpoolctl 2.1.0; torch 1.6.0; tornado 6.0.3; tqdm 4.32.2; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth NA; yaml 5.3.1; zipp NA; zmq 19.0.0; -----; IPython 7.12.0; jupyter_client 6.0.0; jupyter_core 4.6.3; jupyterlab 1.2.5; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-11-23 09:17. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:711,Modifiability,variab,variable,711,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python; sc.pp.highly_variable_genes(; adata,; flavor = ""seurat_v3"",; n_top_genes = 7000,; layer = ""counts"",; batch_key = ""combined"",; subset = True; ); ```. I get the following error:. ```pytb; If you pass `n_top_genes`, all cutoffs are ignored.; extracting highly variable genes; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-19-3748de5bacdc> in <module>; 5 layer = ""counts"",; 6 batch_key = ""combined"",; ----> 7 subset = True; 8 ); 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 420 span=span,; 421 subset=subset,; --> 422 inplace=inplace,; 423 ); 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 82 x = np.log10(mean[not_const]); 83 model = loess(x, y, span=span, degree=2); ---> 84 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <deta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3460,Testability,log,logical,3460,"4 model.fit(); 85 estimat_var[not_const] = model.outputs.fitted_values; 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'; ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; SCCAF NA; anndata 0.7.4; backcall 0.1.0; cffi 1.14.3; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.0; importlib_metadata 1.7.0; ipykernel 5.1.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.16.0; joblib 0.17.0; kiwisolver 1.1.0; legacy_api_wrap 1.2; leidenalg 0.8.2; llvmlite 0.31.0; louvain 0.6.1; matplotlib 3.1.3; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.6.1; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.3; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.1; rich NA; ruamel NA; scanpy 1.6.0; scipy 1.5.4; scvi 0.7.1; seaborn 0.10.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; statsmodels 0.11.1; storemagic NA; tables 3.6.1; texttable 1.6.2; threadpoolctl 2.1.0; torch 1.6.0; tornado 6.0.3; tqdm 4.32.2; traitlets 4.3.3; typing_extensions NA; umap 0.3.10; wcwidth NA; yaml 5.3.1; zipp NA; zmq 19.0.0; -----; IPython 7.12.0; jupyter_client 6.0.0; jupyter_core 4.6.3; jupyterlab 1.2.5; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]; Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid; 24 logical CPU cores, x86_64; -----; Session information updated at 2020-11-23 09:17. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/pull/1506:159,Availability,avail,available,159,Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets.; This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:39,Modifiability,extend,extended,39,Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets.; This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1507:35,Availability,down,downloading,35,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:230,Availability,down,download,230,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:319,Availability,down,downloaded,319,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:423,Integrability,depend,dependency,423,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:810,Usability,progress bar,progress bar,810,"This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc..; Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency.; However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:; - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:; My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/issues/1508:2542,Deployability,update,updated,2542,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour?. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.settings.figdir = ""./""; sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""); ```. ```pytb; FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; IPython 7.19.0; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; flufl NA; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0rc3; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; ruamel NA; scanpy 1.6.0; scipy 1.5.4; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.3; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zc NA; -----; Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]; Linux-5.4.0-54-generic-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-11-25 11:03. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1112,Safety,avoid,avoid,1112,"sts on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour?. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.settings.figdir = ""./""; sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""); ```. ```pytb; FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; IPython 7.19.0; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; flufl NA; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0rc3; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2488,Testability,log,logical,2488,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour?. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.settings.figdir = ""./""; sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""); ```. ```pytb; FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; IPython 7.19.0; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; flufl NA; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0rc3; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; ruamel NA; scanpy 1.6.0; scipy 1.5.4; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; storemagic NA; tables 3.6.1; texttable 1.6.3; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zc NA; -----; Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]; Linux-5.4.0-54-generic-x86_64-with-glibc2.29; 8 logical CPU cores, x86_64; -----; Session information updated at 2020-11-25 11:03. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1509:73,Deployability,release,released,73,It'd be good to make sure everything works with umap 0.5 before it get's released.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1510:260,Availability,error,error,260,"Hi, . Thanks for the awesome tool!. May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, ; Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:588,Deployability,install,install,588,"Hi, . Thanks for the awesome tool!. May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, ; Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/pull/1512:4,Testability,log,logic,4,"fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/issues/1513:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1515:235,Deployability,update,updated,235,"`sc.datasets.moignard15()` results in a 404. The previous link http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx seems to not be working anymore. It looks like supp info is still there, so links probably just need to be updated: https://www.nature.com/articles/nbt.3154#Sec24. Alternatively, maybe springer needs the 10k in publishing fees to keep their servers running.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1515
https://github.com/scverse/scanpy/pull/1517:65,Deployability,pipeline,pipelines,65,"I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:28,Testability,test,test,28,"I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:126,Testability,test,tests,126,"I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/issues/1519:677,Deployability,update,update,677,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:340,Performance,perform,performs,340,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:956,Performance,load,load,956,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:377,Testability,test,testing,377,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1137,Testability,test,test,1137,"y.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1261,Testability,log,logfc,1261,"groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1303,Testability,log,logfc,1303,"groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1315,Testability,log,logfc,1315,"groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1377,Testability,log,logfoldchanges,1377,"sting. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.786",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1478,Testability,test,test,1478,"l give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1).; However, the current function still compares to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1662,Testability,log,logfc,1662,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1674,Testability,log,logfc,1674,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1736,Testability,log,logfoldchanges,1736,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1856,Testability,log,logfcs,1856,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2185,Testability,test,test,2185,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2274,Testability,test,test,2274,"to all other clusters (see below). ; Is that the intention? If so, we should update the readthedocs I think.; If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. # load data; adata = sc.datasets.pbmc68k_reduced(); # cluster; sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5); print(""Clusters:"", sorted(set(adata.obs[""clusters""]))); # do test with groups=""all""; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""); # store results, sorting genes by logfc; genes_cluster_0_vs_all = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # do test with groups=[""0"",""1""], i.e. only a subset of the clusters; sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]); # store result; genes_cluster_0_vs_1 = [; (name, logfc); for logfc, name in sorted(; zip(; adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],; adata.uns[""rank_genes_groups""][""names""][""0""],; ),; reverse=True,; ); ]; # print top 5 genes and logfcs for both,; # they're the same and should not be; print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]); print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]); ```. ```pytb; Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; Top genes cluster 0 versus all:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]; Top genes cluster 0 versus cluster 1:; [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1521:1688,Availability,down,down,1688,"info using `.uns[""dendrogram_['groups']""]`; WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; Storing dendrogram info using `.uns['dendrogram_groups']`; ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3568,Deployability,update,updated,3568,"the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pendulum 2.1.2; pexpect 4.8.0; pheno_tools 0.0.1; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; pytzdata NA; s3fs 0.4.2; scanorama 1.7; scanpy 1.6.0; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; tqdm 4.52.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.25.11; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.1.5; -----; Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]; Linux-4.4.0-1106-aws-x86_64-with-glibc2.10; 36 logical CPU cores, x86_64; -----; Session information updated at 2020-12-02 22:22. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1301,Security,access,access,1301,"y data). ```python; np.random.seed(seed=0); df = pd.DataFrame(np.random.randn(50,50)); fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50); fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""); sc.pl.dendrogram(fake, groupby = ""groups""); ```. ```pytb; using data matrix X directly; Storing dendrogram info using `.uns[""dendrogram_['groups']""]`; WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; Storing dendrogram info using `.uns['dendrogram_groups']`; ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1515,Testability,log,logic,1515,"""category""). sc.tl.dendrogram(fake, groupby = ""groups""); sc.pl.dendrogram(fake, groupby = ""groups""); ```. ```pytb; using data matrix X directly; Storing dendrogram info using `.uns[""dendrogram_['groups']""]`; WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently.; using data matrix X directly; Storing dendrogram info using `.uns['dendrogram_groups']`; ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2521,Testability,log,logzero,2521,"the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pendulum 2.1.2; pexpect 4.8.0; pheno_tools 0.0.1; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; pytzdata NA; s3fs 0.4.2; scanorama 1.7; scanpy 1.6.0; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; tqdm 4.52.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.25.11; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.1.5; -----; Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]; Linux-4.4.0-1106-aws-x86_64-with-glibc2.10; 36 logical CPU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3514,Testability,log,logical,3514,"the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior?. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; OpenSSL 19.1.0; PIL 8.0.1; anndata 0.7.5; annoy NA; autoreload NA; backcall 0.2.0; botocore 1.19.22; brotli NA; certifi 2020.11.08; cffi 1.14.3; colorama 0.4.3; cryptography 3.2.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.6.0; fbpca NA; fsspec 0.8.4; get_version 2.1; h5py 3.1.0; igraph 0.8.3; intervaltree NA; invoke 1.4.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; jmespath 0.10.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; logzero 1.6.3; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.0.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; parso 0.7.1; pendulum 2.1.2; pexpect 4.8.0; pheno_tools 0.0.1; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; pytzdata NA; s3fs 0.4.2; scanorama 1.7; scanpy 1.6.0; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; tqdm 4.52.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.25.11; wcwidth 0.2.5; xlrd 1.2.0; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; jupyterlab 2.2.9; notebook 6.1.5; -----; Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]; Linux-4.4.0-1106-aws-x86_64-with-glibc2.10; 36 logical CPU cores, x86_64; -----; Session information updated at 2020-12-02 22:22. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/pull/1524:9,Deployability,install,installed,9,… if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1527:29,Deployability,install,install,29,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:53,Deployability,install,install,53,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:73,Deployability,install,install,73,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:109,Deployability,install,install,109,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:158,Deployability,install,install,158,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:202,Deployability,install,install,202,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:264,Deployability,install,installation,264,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:322,Deployability,install,install,322,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:364,Deployability,install,install,364,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:384,Deployability,install,installs,384,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:505,Deployability,install,install,505,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:824,Deployability,configurat,configuration,824,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:824,Modifiability,config,configuration,824,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:545,Security,password,password,545,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:459,Usability,simpl,simple,459,"What stays the same:. - `pip install scanpy`; - `pip install . `; - `pip install git+https://...`; - you can install your deps with conda; - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:; - `pip install -e .[every,single,extra]` → `flit install -s` for dev installs; - `beni pyproject.toml > environment.yml` for conda; - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to.; - `flit build` doesn’t clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`.; - No more obscure stuff nobody understands (MANIFEST.in, package_data, …); - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1528:141,Integrability,depend,dependent,141,"This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:43,Testability,test,tests,43,"This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:125,Testability,test,test,125,"This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope that’s OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1529:415,Testability,log,log,415,This PR adds the following to `rank_genes_groups_*` plots:; * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster.; * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a ; given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for; the given genes.; * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/issues/1530:282,Testability,log,logreg,282,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:296,Testability,log,logfoldchanges,296,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:504,Testability,log,logreg,504,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:750,Testability,log,logfoldchanges,750,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:915,Testability,log,logfoldchanges,915,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:991,Testability,log,logging,991,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is; required by `sc.get.rank_genes_groups_df`. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'); sc.get.rank_genes_groups_df(adata, 'Dendritic'); ```. ```pytb; /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols); 56 d = pd.DataFrame(); 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:; ---> 58 d[k] = adata.uns[key][k][group]; 59 if pval_cutoff is not None:; 60 d = d[d[""pvals_adj""] < pval_cutoff]; KeyError: 'logfoldchanges'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1531:360,Performance,load,load,360,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy.; While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat.; After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:; 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs?; 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy?; 3. How to be sure we did not undercluster and miss some smaller cell populations?. I would be glad for any feedback or input, and of course if someone knows the answers, that's great!. Best wishes,; Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:255,Testability,log,log-norm,255,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy.; While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat.; After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:; 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs?; 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy?; 3. How to be sure we did not undercluster and miss some smaller cell populations?. I would be glad for any feedback or input, and of course if someone knows the answers, that's great!. Best wishes,; Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:495,Testability,log,log-norm,495,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy.; While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat.; After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:; 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs?; 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy?; 3. How to be sure we did not undercluster and miss some smaller cell populations?. I would be glad for any feedback or input, and of course if someone knows the answers, that's great!. Best wishes,; Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1173,Usability,feedback,feedback,1173,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy.; While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat.; After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:; 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs?; 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy?; 3. How to be sure we did not undercluster and miss some smaller cell populations?. I would be glad for any feedback or input, and of course if someone knows the answers, that's great!. Best wishes,; Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/pull/1533:52,Deployability,integrat,integrate,52,"This PR aims to add more GPU functionalities and to integrate more an exisiting one:; * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework.; * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:425,Deployability,integrat,integrate,425,"This PR aims to add more GPU functionalities and to integrate more an exisiting one:; * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework.; * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:52,Integrability,integrat,integrate,52,"This PR aims to add more GPU functionalities and to integrate more an exisiting one:; * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework.; * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:425,Integrability,integrat,integrate,425,"This PR aims to add more GPU functionalities and to integrate more an exisiting one:; * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework.; * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/issues/1534:2880,Usability,learn,learn,2880,"1.],; [1., 0., 1., 0., 1., 0., 0., 0., 0.],; [1., 1., 0., 1., 1., 1., 0., 0., 0.],; [1., 0., 1., 0., 0., 1., 0., 0., 0.],; [1., 1., 1., 0., 0., 0., 1., 1., 0.],; [1., 0., 1., 1., 0., 0., 0., 1., 1.],; [1., 0., 0., 0., 1., 0., 0., 1., 0.],; [1., 0., 0., 0., 1., 1., 1., 0., 1.],; [1., 0., 0., 0., 0., 1., 0., 1., 0.]]); a = ad.AnnData(arr); a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}; a.obsp['spatial_connectivities'] = conn; a.obsm['coords'] = arr.copy(); a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'); print('coords', a.obsm['coords']); sc.pl.embedding(a, 'spatial'); print('spatial no edges', a.obsm['spatial']); sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'); print('spatial edges', a.obsm['spatial']); ```. produces following output:. - expected (when plotting ""coords""); ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png); ```; coords [[96 55]; [95 54]; [96 54]; [97 54]; [95 55]; [97 55]; [95 56]; [96 56]; [97 56]]; ```. - when plotting ""spatial"" without edges (obsm is not modified); ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png); ```; spatial no edges [[96 55]; [95 54]; [96 54]; [97 54]; [95 55]; [97 55]; [95 56]; [96 56]; [97 56]]; ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png); ```; spatial edges [[ 96 255]; [ 95 254]; [ 96 254]; [ 97 254]; [ 95 255]; [ 97 255]; [ 95 0]; [ 96 0]; [ 97 0]]; ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/pull/1538:839,Security,expose,exposed,839,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1369,Security,expose,exposed,1369,"onents` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour; - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:721,Testability,test,testing,721,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:758,Testability,test,tests,758,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1582,Testability,test,test,1582,"onents` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour; - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:15,Usability,simpl,simplify,15,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:88,Usability,simpl,simplifying,88,"Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do?. * Let's us delete `_get_data_points`, an awful function; * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element; * Move spatial specific code to spatial specific functions; * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated?. I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed?; * Isn't it the same amount of keystrokes?; * How useful is `""all""`?. I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented?. We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement?. ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>; <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-931",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/issues/1539:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/pull/1540:106,Performance,throughput,throughput,106,"The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1543:66,Deployability,release,released,66,Restricting umap to below `0.5` so we can fix changes before it's released (see #1509).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1543
https://github.com/scverse/scanpy/pull/1544:125,Deployability,release,release,125,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:772,Deployability,Release,Release,772,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:722,Testability,test,testing,722,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:593,Usability,guid,guide,593,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:680,Usability,Guid,Guidelines,680,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:712,Usability,Guid,Guide,712,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:733,Usability,Guid,Guide,733,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:792,Usability,guid,guides,792,"This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html); * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools; * Guide for testing; * Guide for writing and building docs; * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/issues/1545:855,Deployability,update,updated,855,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:331,Testability,log,logarithmized,331,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:516,Testability,log,logarithmized,516,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:698,Testability,log,logspace,698,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:910,Testability,log,logarithmized,910,"- [X ] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1546:0,Availability,Ping,Ping,0,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1588,Availability,error,error,1588,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1603,Availability,error,error,1603,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:253,Testability,Assert,AssertionError,253,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:491,Testability,log,log,491,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1249,Testability,assert,assert,1249,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1377,Testability,Assert,AssertionError,1377,"Ping @fidelram. ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ); ```. ```pytb; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-7-594171c15db1> in <module>; ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 710 ; 711 if groupby is not None:; --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw); 713 if kwds.get('palette', None) is None:; 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 200 # add var values; 201 if len(var_names) > 0:; --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw); 203 if use_raw:; 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp); 341 return adata.obsp[obsp]; 342 else:; --> 343 assert False, (; 344 ""That was unexpected. Please report this bug at:\n\n\t""; 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues; ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/pull/1548:143,Availability,error,error,143,"Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test; 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case).; 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:174,Testability,test,test,174,"Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test; 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case).; 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/issues/1549:383,Modifiability,variab,variable,383,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy.; Latest on pip at least scanpy-1.6.0; ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python; hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]; ```; then; ```python; [sum(hvgene) for hvgene in hvegene_sets]; ```; outputs:; [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then ; ```python; dendro1 = sc.tl.dendrogram(adata, ; var_names=adata.var_names[hvegene_sets[1]].values, ; optimal_ordering=True,; cor_method=""spearman"", linkage_method=""complete"", inplace=False,; groupby=""Annotation""); dendro2 = sc.tl.dendrogram(adata, ; var_names=adata.var_names[hvegene_sets[5]].values, ; optimal_ordering=True,; cor_method=""spearman"", linkage_method=""complete"", inplace=False,; groupby=""Annotation""); [dendro1[key] ==dendro2[key] for key in dendro1.keys()] ; ```; outputs: ; ```code; [array([[ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True],; [ True, True, True, True]]),; Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4772,Safety,detect,detect,4772,"True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True]])]; ```; At first I was creating all dendrograms in a list comprehension and it did the same. ; I also directly inputted a list of my own and I obtained the same result....; I guess dendrogram don't detect the genes. When running functions such as ; ```python ; ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :; categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby); mean_df = obs_tidy.groupby(level=0).mean(); ; return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :; z_var = linkage(corr_matrix, method=linkage); return dendrogram(z_var, labels=mean_df.index); ``` ; Everything works fine ! . Thanks by advance, ; C. #### Versions. 1.6.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4838,Testability,Test,Testing,4838,"True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True],; [ True, True, True, True, True, True, True, True, True,; True, True, True, True, True, True, True, True, True,; True, True]])]; ```; At first I was creating all dendrograms in a list comprehension and it did the same. ; I also directly inputted a list of my own and I obtained the same result....; I guess dendrogram don't detect the genes. When running functions such as ; ```python ; ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :; categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby); mean_df = obs_tidy.groupby(level=0).mean(); ; return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :; z_var = linkage(corr_matrix, method=linkage); return dendrogram(z_var, labels=mean_df.index); ``` ; Everything works fine ! . Thanks by advance, ; C. #### Versions. 1.6.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/pull/1551:619,Testability,test,tests,619,"Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python; import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata); sc.pp.scale(adata); genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']; sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'); ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/issues/1556:506,Availability,error,error,506,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:527,Availability,down,downgraded,527,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:721,Deployability,pipeline,pipeline,721,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it!; ```python; import numpy as np; import pandas as pd; from sklearn.datasets import load_iris; from sklearn.pipeline import make_pipeline; from sklearn.preprocessing import StandardScaler, Normalizer; from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'); samples = df.iloc[:, 2:7].values[:42]; country_names = df.iloc[:, 1].values[:42]; mergings = linkage(samples, method='single'). # Plot the dendrogram; plt.figure(figsize=(15, 5)); dendrogram(mergings,; labels=country_names,; leaf_rotation=90, ; leaf_font_size=6);; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-185-e360a70857f0> in <module>; 9 # Plot the dendrogram; 10 plt.figure(figsize=(15, 5)); ---> 11 dendrogram(mergings, ; 12 labels=companies,; 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color); 3275 ""'bottom', or 'right'""); 3276 ; -> 3277 if labels and Z.shape[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/pull/1557:14,Testability,test,testing,14,sklearn.utils.testing is deprecated in scikit-learn 0.24: https://github.com/scikit-learn/scikit-learn/pull/17133,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1557
https://github.com/scverse/scanpy/pull/1557:46,Usability,learn,learn,46,sklearn.utils.testing is deprecated in scikit-learn 0.24: https://github.com/scikit-learn/scikit-learn/pull/17133,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1557
https://github.com/scverse/scanpy/pull/1557:84,Usability,learn,learn,84,sklearn.utils.testing is deprecated in scikit-learn 0.24: https://github.com/scikit-learn/scikit-learn/pull/17133,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1557
https://github.com/scverse/scanpy/pull/1557:97,Usability,learn,learn,97,sklearn.utils.testing is deprecated in scikit-learn 0.24: https://github.com/scikit-learn/scikit-learn/pull/17133,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1557
https://github.com/scverse/scanpy/issues/1559:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; mito_genes = adata.var_names.str.startswith('mt-'); # for each cell compute fraction of counts in mito genes vs. all genes; # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing); adata.obs['percent_mito'] = np.sum(; adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; # add the total counts per cell as observations-annotation to adata; adata.obs['n_counts'] = adata.X.sum(axis=1).A1. print(sum(mito_genes)); ```. ```pytb; AttributeError Traceback (most recent call last); <ipython-input-18-7f1a7fee3beb> in <module>; 2 # for each cell compute fraction of counts in mito genes vs. all genes; 3 # the `.A1` is only necessary as X is sparse (to transform to a dense array after summing); ----> 4 adata.obs['percent_mito'] = np.sum(; 5 adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1; 6 # add the total counts per cell as observations-annotation to adata. ```. #### Versions. <details>; AttributeError: 'ArrayView' object has no attribute 'A1'. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1559
https://github.com/scverse/scanpy/issues/1560:1524,Availability,robust,robust,1524,"t having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bins_to_cuts(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered); 399 if len(unique_bins) < len(bins) and len(bins) != 2:; 400 if duplicates == ""raise"":; --> 401 raise ValueError(; 402 f""Bin edges must be unique: {repr(bins)}.\n""; 403 f""You can drop duplicate edges by setting the 'duplicates' kwarg"". ValueError: Bin edges must be unique: array([ -inf, 1.00000000e-12, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:604,Modifiability,variab,variable,604,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:893,Modifiability,variab,variable,893,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:2820,Testability,log,logging,2820,"e genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bins_to_cuts(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered); 399 if len(unique_bins) < len(bins) and len(bins) != 2:; 400 if duplicates == ""raise"":; --> 401 raise ValueError(; 402 f""Bin edges must be unique: {repr(bins)}.\n""; 403 f""You can drop duplicate edges by setting the 'duplicates' kwarg"". ValueError: Bin edges must be unique: array([ -inf, 1.00000000e-12, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 1.00000000e-12,; 1.00000000e-12, 1.11241045e-04, 2.44672419e-04, 5.69339462e-04,; 1.35840576e-03, 3.49938189e-03, 1.02259867e-02, 2.97723795e-02,; 7.22420720e-02, 1.46845240e-01, 2.97005969e-01, 3.42389128e+00,; inf]).; You can drop duplicate edges by setting the 'duplicates' kwarg; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/issues/1560:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-46-616fc10e63ff> in <module>; ----> 1 sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=4000); 2 print('\n','Number of highly variable genes: {:d}'.format(np.sum(adata.var['highly_variable']))). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 424 ; 425 if batch_key is None:; --> 426 df = _highly_variable_genes_single_batch(; 427 adata,; 428 layer=layer,. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py in _highly_variable_genes_single_batch(adata, layer, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor); 242 from statsmodels import robust; 243 ; --> 244 df['mean_bin'] = pd.cut(; 245 df['means'],; 246 np.r_[-np.inf, np.percentile(df['means'], np.arange(10, 105, 5)), np.inf],. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered); 273 raise ValueError(""bins must increase monotonically.""); 274 ; --> 275 fac, bins = _bins_to_cuts(; 276 x,; 277 bins,. ~\anaconda3\lib\site-packages\pandas\core\reshape\tile.py in _bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1560
https://github.com/scverse/scanpy/pull/1561:941,Integrability,wrap,wrapper,941,"@dkobak @ivirshup @Koncopd This is a first stab #1233. Features. - [X] Construct t-SNE embeddings; - [ ] Recipes; - [ ] Ingest functionality. As discussed, this PR currently implements t-SNE with uniform affinity kernels, making it fit in nicely with the existing `sc.pp.neighbors` architecture. While this isn't technically t-SNE per se, it's visually almost impossible to tell them apart. It would also make sense to add a `tsne` option to `sc.pp.neighbors`, but from what I can tell, there's no direct way to change the existing code to do this. It looks like `sc.pp.neighbors` calls UMAP to calculate the nearest neighbors directly, calculating the UMAP weights. We'd probably have to do something similar to the `gauss` option and just overwrite the UMAP weights after the fact. Does this sound reasonable?. I like the API of calling `sc.tl.tsne.recipe_X(adata)`. Adding the recipes would be simple here; we can just add a simple class wrapper around `_tsne` which which would `__call__` tsne, and a bunch of static methods to the wrapper for recipes. This is kind-of messy and probably not something you guys do anywhere else throughout the code base, so I'd appreciate your feedback on this. Do you like this, or should we do it in a different way?. The `ingest` functionality should be fairly straightforward as well, just adding a `tsne` option to `embedding_method`. All of these things should be pretty easy to do, but I'd like to see that this is moving in a direction you like first.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1036,Integrability,wrap,wrapper,1036,"@dkobak @ivirshup @Koncopd This is a first stab #1233. Features. - [X] Construct t-SNE embeddings; - [ ] Recipes; - [ ] Ingest functionality. As discussed, this PR currently implements t-SNE with uniform affinity kernels, making it fit in nicely with the existing `sc.pp.neighbors` architecture. While this isn't technically t-SNE per se, it's visually almost impossible to tell them apart. It would also make sense to add a `tsne` option to `sc.pp.neighbors`, but from what I can tell, there's no direct way to change the existing code to do this. It looks like `sc.pp.neighbors` calls UMAP to calculate the nearest neighbors directly, calculating the UMAP weights. We'd probably have to do something similar to the `gauss` option and just overwrite the UMAP weights after the fact. Does this sound reasonable?. I like the API of calling `sc.tl.tsne.recipe_X(adata)`. Adding the recipes would be simple here; we can just add a simple class wrapper around `_tsne` which which would `__call__` tsne, and a bunch of static methods to the wrapper for recipes. This is kind-of messy and probably not something you guys do anywhere else throughout the code base, so I'd appreciate your feedback on this. Do you like this, or should we do it in a different way?. The `ingest` functionality should be fairly straightforward as well, just adding a `tsne` option to `embedding_method`. All of these things should be pretty easy to do, but I'd like to see that this is moving in a direction you like first.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:897,Usability,simpl,simple,897,"@dkobak @ivirshup @Koncopd This is a first stab #1233. Features. - [X] Construct t-SNE embeddings; - [ ] Recipes; - [ ] Ingest functionality. As discussed, this PR currently implements t-SNE with uniform affinity kernels, making it fit in nicely with the existing `sc.pp.neighbors` architecture. While this isn't technically t-SNE per se, it's visually almost impossible to tell them apart. It would also make sense to add a `tsne` option to `sc.pp.neighbors`, but from what I can tell, there's no direct way to change the existing code to do this. It looks like `sc.pp.neighbors` calls UMAP to calculate the nearest neighbors directly, calculating the UMAP weights. We'd probably have to do something similar to the `gauss` option and just overwrite the UMAP weights after the fact. Does this sound reasonable?. I like the API of calling `sc.tl.tsne.recipe_X(adata)`. Adding the recipes would be simple here; we can just add a simple class wrapper around `_tsne` which which would `__call__` tsne, and a bunch of static methods to the wrapper for recipes. This is kind-of messy and probably not something you guys do anywhere else throughout the code base, so I'd appreciate your feedback on this. Do you like this, or should we do it in a different way?. The `ingest` functionality should be fairly straightforward as well, just adding a `tsne` option to `embedding_method`. All of these things should be pretty easy to do, but I'd like to see that this is moving in a direction you like first.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:928,Usability,simpl,simple,928,"@dkobak @ivirshup @Koncopd This is a first stab #1233. Features. - [X] Construct t-SNE embeddings; - [ ] Recipes; - [ ] Ingest functionality. As discussed, this PR currently implements t-SNE with uniform affinity kernels, making it fit in nicely with the existing `sc.pp.neighbors` architecture. While this isn't technically t-SNE per se, it's visually almost impossible to tell them apart. It would also make sense to add a `tsne` option to `sc.pp.neighbors`, but from what I can tell, there's no direct way to change the existing code to do this. It looks like `sc.pp.neighbors` calls UMAP to calculate the nearest neighbors directly, calculating the UMAP weights. We'd probably have to do something similar to the `gauss` option and just overwrite the UMAP weights after the fact. Does this sound reasonable?. I like the API of calling `sc.tl.tsne.recipe_X(adata)`. Adding the recipes would be simple here; we can just add a simple class wrapper around `_tsne` which which would `__call__` tsne, and a bunch of static methods to the wrapper for recipes. This is kind-of messy and probably not something you guys do anywhere else throughout the code base, so I'd appreciate your feedback on this. Do you like this, or should we do it in a different way?. The `ingest` functionality should be fairly straightforward as well, just adding a `tsne` option to `embedding_method`. All of these things should be pretty easy to do, but I'd like to see that this is moving in a direction you like first.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/pull/1561:1181,Usability,feedback,feedback,1181,"@dkobak @ivirshup @Koncopd This is a first stab #1233. Features. - [X] Construct t-SNE embeddings; - [ ] Recipes; - [ ] Ingest functionality. As discussed, this PR currently implements t-SNE with uniform affinity kernels, making it fit in nicely with the existing `sc.pp.neighbors` architecture. While this isn't technically t-SNE per se, it's visually almost impossible to tell them apart. It would also make sense to add a `tsne` option to `sc.pp.neighbors`, but from what I can tell, there's no direct way to change the existing code to do this. It looks like `sc.pp.neighbors` calls UMAP to calculate the nearest neighbors directly, calculating the UMAP weights. We'd probably have to do something similar to the `gauss` option and just overwrite the UMAP weights after the fact. Does this sound reasonable?. I like the API of calling `sc.tl.tsne.recipe_X(adata)`. Adding the recipes would be simple here; we can just add a simple class wrapper around `_tsne` which which would `__call__` tsne, and a bunch of static methods to the wrapper for recipes. This is kind-of messy and probably not something you guys do anywhere else throughout the code base, so I'd appreciate your feedback on this. Do you like this, or should we do it in a different way?. The `ingest` functionality should be fairly straightforward as well, just adding a `tsne` option to `embedding_method`. All of these things should be pretty easy to do, but I'd like to see that this is moving in a direction you like first.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1561
https://github.com/scverse/scanpy/issues/1562:15,Testability,test,test,15,"@fidelram. The test `test_matrixplot_obj` fails if `pandas>1.2.0` as the groups order changes. These groups are meant to be sorted with `plot.add_totals(sort='descending')`. All groups have the same value here, so my assumption is this is fine. I'm going to change the test for now, but it'd be good to hear back from you on whether this is a bug or not. It would probably be good if we could ensure a stable sort was used so this won't change in future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1562:269,Testability,test,test,269,"@fidelram. The test `test_matrixplot_obj` fails if `pandas>1.2.0` as the groups order changes. These groups are meant to be sorted with `plot.add_totals(sort='descending')`. All groups have the same value here, so my assumption is this is fine. I'm going to change the test for now, but it'd be good to hear back from you on whether this is a bug or not. It would probably be good if we could ensure a stable sort was used so this won't change in future.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1562
https://github.com/scverse/scanpy/issues/1563:530,Deployability,install,installing,530,"I'd like to start using [pre-commit](https://pre-commit.com) with scanpy and anndata. Pre-commit is essentially a tool that manages scripts we'd like to run before each commit, e.g. linting and formatting, so it becomes essentially impossible to forget these. I think this can allow PRs to progress faster since it gives us a way to codify formatting requirements – so we don't have to remember them – and have these checks happen locally – so we don't have to wait on CI. Of course, having these checks run depends on developers installing pre-commit, so we can also run these checks on CI ([example ci script](https://github.com/pandas-dev/pandas/blob/master/.github/workflows/pre-commit.yml), [example run](https://github.com/pandas-dev/pandas/pull/38745/checks?check_run_id=1624558250)). There is a question of what things we'd like to add here. For sure: `black`. I think import checks (e.g. no unused imports) and `flake8` would be good too. We can also add custom checks for things like slow imports. I think this would be a good time to run `black` over the whole codebase so we don't have exempted files any more. My questions for the dev team:. * Does this sound good?; * Do you have more ideas for checks/ tools?. @michalk8, I saw you added this to [`squidpy`](https://github.com/theislab/squidpy/pull/203). How's the experience been there – that is, any major foot guns we should look out for? Also, are there any tools you're using (beyond the basic `black`, `isort`, `flake8`) you'd especially recommend?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/issues/1563:508,Integrability,depend,depends,508,"I'd like to start using [pre-commit](https://pre-commit.com) with scanpy and anndata. Pre-commit is essentially a tool that manages scripts we'd like to run before each commit, e.g. linting and formatting, so it becomes essentially impossible to forget these. I think this can allow PRs to progress faster since it gives us a way to codify formatting requirements – so we don't have to remember them – and have these checks happen locally – so we don't have to wait on CI. Of course, having these checks run depends on developers installing pre-commit, so we can also run these checks on CI ([example ci script](https://github.com/pandas-dev/pandas/blob/master/.github/workflows/pre-commit.yml), [example run](https://github.com/pandas-dev/pandas/pull/38745/checks?check_run_id=1624558250)). There is a question of what things we'd like to add here. For sure: `black`. I think import checks (e.g. no unused imports) and `flake8` would be good too. We can also add custom checks for things like slow imports. I think this would be a good time to run `black` over the whole codebase so we don't have exempted files any more. My questions for the dev team:. * Does this sound good?; * Do you have more ideas for checks/ tools?. @michalk8, I saw you added this to [`squidpy`](https://github.com/theislab/squidpy/pull/203). How's the experience been there – that is, any major foot guns we should look out for? Also, are there any tools you're using (beyond the basic `black`, `isort`, `flake8`) you'd especially recommend?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1563
https://github.com/scverse/scanpy/pull/1564:335,Deployability,pipeline,pipelines,335,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564
https://github.com/scverse/scanpy/pull/1564:0,Testability,Test,Testing,0,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564
https://github.com/scverse/scanpy/pull/1564:39,Testability,test,test,39,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564
https://github.com/scverse/scanpy/pull/1564:145,Testability,test,test,145,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564
https://github.com/scverse/scanpy/pull/1564:380,Testability,test,test,380,"Testing some azure stuff for better CI test results. Mainly:. * I don't like what `pytest-azurepipelines` does with warnings; * I'd like to have test coverage; * Azure's is a bit meh (no diffs), maybe we should use codecovs ([example usage](https://github.com/codecov/example-python/blob/74883884e480b523e0db9e92e97264908ecb9b8f/azure-pipelines.yml#L32-L34)); * I like having the test results be easy to read",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1564
https://github.com/scverse/scanpy/issues/1566:500,Performance,Perform,Perform,500,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; #Perform a clustering for scran normalization in clusters; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps=15); sc.pp.neighbors(adata_pp); sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5); ```. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-785c54721f17> in <module>; 8 sc.pp.pca(adata_pp, n_comps=15); 9 sc.pp.neighbors(adata_pp); ---> 10 sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5). ~\anaconda3\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566
https://github.com/scverse/scanpy/issues/1566:1536,Testability,log,logging,1536,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; #Perform a clustering for scran normalization in clusters; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps=15); sc.pp.neighbors(adata_pp); sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5); ```. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-785c54721f17> in <module>; 8 sc.pp.pca(adata_pp, n_comps=15); 9 sc.pp.neighbors(adata_pp); ---> 10 sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5). ~\anaconda3\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566
https://github.com/scverse/scanpy/issues/1566:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; #Perform a clustering for scran normalization in clusters; adata_pp = adata.copy(); sc.pp.normalize_per_cell(adata_pp, counts_per_cell_after=1e6); sc.pp.log1p(adata_pp); sc.pp.pca(adata_pp, n_comps=15); sc.pp.neighbors(adata_pp); sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5); ```. ```pytb; ModuleNotFoundError Traceback (most recent call last); <ipython-input-11-785c54721f17> in <module>; 8 sc.pp.pca(adata_pp, n_comps=15); 9 sc.pp.neighbors(adata_pp); ---> 10 sc.tl.louvain(adata_pp, key_added='groups', resolution=0.5). ~\anaconda3\lib\site-packages\scanpy\tools\_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, neighbors_key, obsp, copy); 135 weights = None; 136 if flavor == 'vtraag':; --> 137 import louvain; 138 if partition_type is None:; 139 partition_type = louvain.RBConfigurationVertexPartition. ModuleNotFoundError: No module named 'louvain'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1566
https://github.com/scverse/scanpy/issues/1567:97,Availability,error,error,97,"Hi there. Everytime I run the code _sc.pp.neighbors_ the kernel dies. Unfortunately, there is no error message or error code. It just dies while computing neighbors. Other scanpy codes like _sc.pp.filter_cells_ and _sc.pp.filter_genes_ work without a problem. I'm using:. - windows 10 64-bit 24 gb ram; - python 3.8.5 in jupyter notebook; - numpy 1.19.4; - scanpy 1.6.0. Is there someone who would be able to solve this issue?; Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567
https://github.com/scverse/scanpy/issues/1567:114,Availability,error,error,114,"Hi there. Everytime I run the code _sc.pp.neighbors_ the kernel dies. Unfortunately, there is no error message or error code. It just dies while computing neighbors. Other scanpy codes like _sc.pp.filter_cells_ and _sc.pp.filter_genes_ work without a problem. I'm using:. - windows 10 64-bit 24 gb ram; - python 3.8.5 in jupyter notebook; - numpy 1.19.4; - scanpy 1.6.0. Is there someone who would be able to solve this issue?; Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567
https://github.com/scverse/scanpy/issues/1567:103,Integrability,message,message,103,"Hi there. Everytime I run the code _sc.pp.neighbors_ the kernel dies. Unfortunately, there is no error message or error code. It just dies while computing neighbors. Other scanpy codes like _sc.pp.filter_cells_ and _sc.pp.filter_genes_ work without a problem. I'm using:. - windows 10 64-bit 24 gb ram; - python 3.8.5 in jupyter notebook; - numpy 1.19.4; - scanpy 1.6.0. Is there someone who would be able to solve this issue?; Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1567
https://github.com/scverse/scanpy/issues/1568:168,Usability,simpl,simple,168,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Add parameter for setting embedding/UMAP colour when the ""color"" parameter is not used - e.g. set one colour for all points. Currently, the only option to set colour for all cells seems to be to add additional constant obs feature and modify uns to set the colour for the new feature.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1568
https://github.com/scverse/scanpy/pull/1569:53,Deployability,release,release,53,To find all PRs that have been merged since the last release: `repo:theislab/scanpy closed:>YYYY-MM-DD is:pr is:merged` where the date is the date of last release. Boy were there a lot. There should be some automation here.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1569
https://github.com/scverse/scanpy/pull/1569:155,Deployability,release,release,155,To find all PRs that have been merged since the last release: `repo:theislab/scanpy closed:>YYYY-MM-DD is:pr is:merged` where the date is the date of last release. Boy were there a lot. There should be some automation here.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1569
https://github.com/scverse/scanpy/issues/1570:66,Deployability,release,releases,66,We'd like to be able to back port So that we can do actual bugfix releases. We can use some tooling (https://meeseeksbox.github.io) to make this easier. I need to document this process so that we can get back ports going as soon as we make the next release (turns out it get's harder to back port when the PR was merged a few months ago).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1570
https://github.com/scverse/scanpy/issues/1570:249,Deployability,release,release,249,We'd like to be able to back port So that we can do actual bugfix releases. We can use some tooling (https://meeseeksbox.github.io) to make this easier. I need to document this process so that we can get back ports going as soon as we make the next release (turns out it get's harder to back port when the PR was merged a few months ago).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1570
https://github.com/scverse/scanpy/issues/1573:474,Deployability,integrat,integrating,474,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:512,Deployability,integrat,integrated,512,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:954,Deployability,integrat,integrated,954,"eature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc_clust[i], 0.6, bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:474,Integrability,integrat,integrating,474,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:512,Integrability,integrat,integrated,512,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:954,Integrability,integrat,integrated,954,"eature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc_clust[i], 0.6, bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1573:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; I am integrating multiple datasets. In the integrated object I wanted to see for each cluster the percentage of each dataset it consisted of (also see [this question](https://scanpy.discourse.group/t/cluster-statistics/134) in the scanpy discourse group). I wrote code for it on my own, but am not sure which part of `sc.pl` you want it to go to, so here is the code for your consideration:. ```python; import matplotlib.pyplot as plt; import scanpy as sc; import numpy as np. # given integrated object adata, clustered via the leiden algorithm and; # with the batch ID in the 'batch' slot, and a collection of batch_names:. # count the number of occurrences of each batch ID for each cluster ID; count_series = adata.obs.groupby(['leiden', 'batch']).size(); new_df = count_series.to_frame(name = 'size').reset_index(); # convert from multi index to pivot; constitution = new_df.pivot(index='leiden', columns='batch')['size']; # convert to %batch (but could be modified to show different things instead; perc_clust = np.array((constitution.T / np.sum(constitution.T, axis=0))); # keep track of the batch, cluster IDs so we can use them for plotting; clusters = adata.obs.leiden.cat.categories; batches = adata.obs.batch.cat.categories. # actual plotting; basically stacked barplots; # replace styling with scanpy defaults probably?; fig, ax = plt.subplots(); ax.grid(False); ax.bar(clusters, perc_clust[0], 0.6, yerr=0, label=platy_names[0]); bottom = np.zeros(clusters.shape); for i, b in enumerate(batches):; ax.bar(clusters, perc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1573
https://github.com/scverse/scanpy/issues/1574:114,Deployability,integrat,integration,114,Hi!. I am wondering if you could add https://github.com/BayraktarLab/cell2location to your list of scRNA->spatial integration methods (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html). Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574
https://github.com/scverse/scanpy/issues/1574:193,Deployability,integrat,integration-scanorama,193,Hi!. I am wondering if you could add https://github.com/BayraktarLab/cell2location to your list of scRNA->spatial integration methods (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html). Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574
https://github.com/scverse/scanpy/issues/1574:114,Integrability,integrat,integration,114,Hi!. I am wondering if you could add https://github.com/BayraktarLab/cell2location to your list of scRNA->spatial integration methods (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html). Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574
https://github.com/scverse/scanpy/issues/1574:193,Integrability,integrat,integration-scanorama,193,Hi!. I am wondering if you could add https://github.com/BayraktarLab/cell2location to your list of scRNA->spatial integration methods (https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html). Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1574
https://github.com/scverse/scanpy/pull/1577:21,Deployability,pipeline,pipeline,21,Added MiCV as a full pipeline in the external ecosystem docs. We recently built this tool and hope it will be useful to others trying to jump into this analysis space. Please let me know if there are any questions or issues with including this in the docs. Thank you for all that you're doing with this project!. For extra information:; https://micv.works; https://github.com/Cai-Lab-at-University-of-Michigan/MiCV; https://www.biorxiv.org/content/10.1101/2020.07.02.184549v2. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1577
https://github.com/scverse/scanpy/pull/1577:549,Usability,guid,guidelines,549,Added MiCV as a full pipeline in the external ecosystem docs. We recently built this tool and hope it will be useful to others trying to jump into this analysis space. Please let me know if there are any questions or issues with including this in the docs. Thank you for all that you're doing with this project!. For extra information:; https://micv.works; https://github.com/Cai-Lab-at-University-of-Michigan/MiCV; https://www.biorxiv.org/content/10.1101/2020.07.02.184549v2. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1577
https://github.com/scverse/scanpy/pull/1577:580,Usability,guid,guide,580,Added MiCV as a full pipeline in the external ecosystem docs. We recently built this tool and hope it will be useful to others trying to jump into this analysis space. Please let me know if there are any questions or issues with including this in the docs. Thank you for all that you're doing with this project!. For extra information:; https://micv.works; https://github.com/Cai-Lab-at-University-of-Michigan/MiCV; https://www.biorxiv.org/content/10.1101/2020.07.02.184549v2. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1577
https://github.com/scverse/scanpy/issues/1578:61,Availability,down,downstream,61,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1578:269,Deployability,integrat,integrating,269,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1578:269,Integrability,integrat,integrating,269,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1578:38,Modifiability,variab,variable,38,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1578:176,Modifiability,variab,variable,176,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1578:225,Modifiability,variab,variable,225,"Hi,; Is it necessary to use only high variable genes for the downstream analysis ?; If an examperiment includes many batches, then each batch will give a different set of high variable genes, how to determine the shared high variable genes (intersection or union) when integrating the batches ? Does scany have any fucntion to get the shared genes ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1578
https://github.com/scverse/scanpy/issues/1579:518,Deployability,Integrat,Integrating,518,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:609,Deployability,integrat,integrating-data-using-ingest,609,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:518,Integrability,Integrat,Integrating,518,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:609,Integrability,integrat,integrating-data-using-ingest,609,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:493,Usability,learn,learning,493,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/issues/1579:1605,Usability,learn,learn,1605,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am learning the example of [Integrating data using ingest and BBKNN](https://scanpy-tutorials.readthedocs.io/en/latest/integrating-data-using-ingest.html). When I run code ; ```python; sc.tl.umap(adata_ref); ```; I get; ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-13-0e548e19df3a> in <module>; 1 sc.pp.pca(adata_ref); 2 sc.pp.neighbors(adata_ref); ----> 3 sc.tl.umap(adata_ref). ~/miniconda3/envs/tf/lib/python3.6/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 171 neigh_params.get('metric', 'euclidean'),; 172 neigh_params.get('metric_kwds', {}),; --> 173 verbose=settings.verbosity > 3,; 174 ); 175 elif method == 'rapids':. TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.5 umap==0.5.0 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1579
https://github.com/scverse/scanpy/pull/1580:108,Deployability,update,update,108,"Some changes to @giovp #1512, just pushing here so they are visible. Still needs going through the tests to update offsets, and some doc tweaks (behaviour of `na_color`, what `spot_size` is, move `scale_factor` to be `spatial` only).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1580
https://github.com/scverse/scanpy/pull/1580:99,Testability,test,tests,99,"Some changes to @giovp #1512, just pushing here so they are visible. Still needs going through the tests to update offsets, and some doc tweaks (behaviour of `na_color`, what `spot_size` is, move `scale_factor` to be `spatial` only).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1580
https://github.com/scverse/scanpy/pull/1583:914,Testability,test,test,914,"I simplified the `_prepare_dataframe code` by using `sc.get.df`. However, this change uncovered two issues with `sc.get.obs_df` that I have now addressed in this PR. . The most relevant is the case when the call to `sc.get.obs_df` contains keys with duplicates (e.g. `keys=['gene1', 'gene1']`). This case is not rare as for example in `sc.pl.dotplot` the same gene can be visualized several times, which requires calling `sc.get.obs_df` with keys that contain duplications. An example is when `sc.pl.rank_genes_groups_dotplot` is called and, frequently, the same gene appears as top up-regulated for more than one category. To address this, `sc.get.obs_df` removes all duplicates (which correspond to DataFrame columns) and after the DataFrame is complete, the duplicates are added back. A second problem was for non-unique adata.obs indices which should be a rare situation. However, it turns out that one of the test adata object used in `test_plotting` have this issue. Also, for the goal of this PR (allow adata.obs.index as groupby option) it could be expected that the index may not be unique. . In general, non unique obs indices are ok as long as `.obs` DataFrame is not joined or merge based on index. However, because internally in `sc.get.obs_df` the DataFrames are merged using `adata.obs.index` this non-unique indices caused an increase in rows due to multiple matching. To fix this, the code now checks for unique index, and if it is not unique then a temporary index is added to allow proper join operations and then the non-unique index is put back.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583
https://github.com/scverse/scanpy/pull/1583:2,Usability,simpl,simplified,2,"I simplified the `_prepare_dataframe code` by using `sc.get.df`. However, this change uncovered two issues with `sc.get.obs_df` that I have now addressed in this PR. . The most relevant is the case when the call to `sc.get.obs_df` contains keys with duplicates (e.g. `keys=['gene1', 'gene1']`). This case is not rare as for example in `sc.pl.dotplot` the same gene can be visualized several times, which requires calling `sc.get.obs_df` with keys that contain duplications. An example is when `sc.pl.rank_genes_groups_dotplot` is called and, frequently, the same gene appears as top up-regulated for more than one category. To address this, `sc.get.obs_df` removes all duplicates (which correspond to DataFrame columns) and after the DataFrame is complete, the duplicates are added back. A second problem was for non-unique adata.obs indices which should be a rare situation. However, it turns out that one of the test adata object used in `test_plotting` have this issue. Also, for the goal of this PR (allow adata.obs.index as groupby option) it could be expected that the index may not be unique. . In general, non unique obs indices are ok as long as `.obs` DataFrame is not joined or merge based on index. However, because internally in `sc.get.obs_df` the DataFrames are merged using `adata.obs.index` this non-unique indices caused an increase in rows due to multiple matching. To fix this, the code now checks for unique index, and if it is not unique then a temporary index is added to allow proper join operations and then the non-unique index is put back.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1583
https://github.com/scverse/scanpy/pull/1584:54,Deployability,update,updated,54,This PR addresses #1562; A test requiring sorting was updated such that it works the same with pandas<1.2.0 or pandas>=1.2.0. The issue was caused by the test having identical values to sort.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1584
https://github.com/scverse/scanpy/pull/1584:27,Testability,test,test,27,This PR addresses #1562; A test requiring sorting was updated such that it works the same with pandas<1.2.0 or pandas>=1.2.0. The issue was caused by the test having identical values to sort.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1584
https://github.com/scverse/scanpy/pull/1584:154,Testability,test,test,154,This PR addresses #1562; A test requiring sorting was updated such that it works the same with pandas<1.2.0 or pandas>=1.2.0. The issue was caused by the test having identical values to sort.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1584
https://github.com/scverse/scanpy/issues/1585:226,Availability,error,error,226,"`twine check` is not great at telling you why it's failing. It would be easier to figure out what caused the break if we were continuously checking for this. Inspired by finding out that `authors` can't have new lines, via an error that says `long_description` can't have section headings (which definitely isn't true).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585
https://github.com/scverse/scanpy/issues/1585:126,Deployability,continuous,continuously,126,"`twine check` is not great at telling you why it's failing. It would be easier to figure out what caused the break if we were continuously checking for this. Inspired by finding out that `authors` can't have new lines, via an error that says `long_description` can't have section headings (which definitely isn't true).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1585
https://github.com/scverse/scanpy/pull/1586:23,Deployability,release,release,23,"Ran into issues making release (PyPi didn't like the upload), trying again",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1586
https://github.com/scverse/scanpy/pull/1587:626,Modifiability,plugin,plugin,626,"If plots fail on CI, this should let us see the expected, actual, and diff through azure. ~~Hopefully~~ It works!. I think this could make debugging plotting issues much easier. Here's an example of what the results look like:. <img width=""1090"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104561575-b5814680-569b-11eb-8d1e-a9971affc645.png"">. Current issue, if tests are run in parallel, this does not work (https://github.com/pytest-dev/pytest-nunit/issues/40), which is not an immediate problem for CI, but limits applicability for local usage. I believe this is an issue with this particular pytest plugin, not necessarily this strategy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587
https://github.com/scverse/scanpy/pull/1587:385,Testability,test,tests,385,"If plots fail on CI, this should let us see the expected, actual, and diff through azure. ~~Hopefully~~ It works!. I think this could make debugging plotting issues much easier. Here's an example of what the results look like:. <img width=""1090"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/104561575-b5814680-569b-11eb-8d1e-a9971affc645.png"">. Current issue, if tests are run in parallel, this does not work (https://github.com/pytest-dev/pytest-nunit/issues/40), which is not an immediate problem for CI, but limits applicability for local usage. I believe this is an issue with this particular pytest plugin, not necessarily this strategy.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1587
https://github.com/scverse/scanpy/pull/1589:299,Usability,learn,learn,299,"@Koncopd, this seems to work as a bare minimum for making `sc.tl.umap` work for `umap-0.5`. `ingest` still does not work, and that definitely looks complicated to fix. What would you say to adding a line like. ```python; if umap.__version__ >= 0.5:; raise ImportError(""Ingest currently require umap-learn < 0.5""); ```. We could then remove the pin, and free up user's environments.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1589
https://github.com/scverse/scanpy/issues/1590:446,Availability,error,error,446,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590
https://github.com/scverse/scanpy/issues/1590:482,Modifiability,variab,variable,482,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590
https://github.com/scverse/scanpy/issues/1590:631,Modifiability,variab,variable,631,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590
https://github.com/scverse/scanpy/issues/1590:1704,Testability,log,logical,1704,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ```python; sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True, chunked=True, chunk_size=1000); ```. ```pytb; TypeError: unsupported operand type(s) for -: 'datetime.datetime' and 'int'; ```. I believe the error is due overwriting of `start` variable.; It is declared in [line 116](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L116) but is overwritten by loop variable of same name in [line 172](https://github.com/theislab/scanpy/blob/master/scanpy/preprocessing/_pca.py#L172). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; asciitree NA; cffi 1.14.3; cloudpickle 1.6.0; constants NA; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; fasteners NA; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.0; numba 0.52.0; numcodecs 0.7.2; numexpr 2.7.2; numpy 1.19.4; packaging 20.8; pandas 1.2.0; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.0; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.0; sparse 0.11.2; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; typing_extensions NA; yaml 5.3.1; zarr 2.6.1; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1062.4.1.el7.x86_64-x86_64-with-glibc2.10; 2 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1590
https://github.com/scverse/scanpy/issues/1591:1825,Availability,down,downwards,1825," the left (fig. 1); sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) # see the tb (if there's only 1 category, in the group, it doesn't crash). a.X[:16, :] = 10 + np.random.RandomState(42).normal(size=(16, 50)); a.X[16:32, :] = -10 + np.random.RandomState(42).normal(size=(16, 50)); a.obs['foo'].iloc[:16, :] = 0; a.obs['foo'].iloc[16:32, :] = 1; a.obs['foo'].iloc[32:, :] = 2; # wrong label-color mapping; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 2; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 3. # but not when there are colors in `.uns; a.uns['foo_colors'] = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 4; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 5; # xlabels are not centered + horizntal lines are slightly shifted downwards (really have to zoom in); sc.pl.heatmap(a, var_names=a.var_names, groupby=""foo"", swap_axes=False, figsize=(50, 50)); ```; If you look closely (e.g. between fig. 2 and fig.3, or fig. 4 and fig. 5), the within group order is also broken. ```pytb; TypeError Traceback (most recent call last); <ipython-input-56-f1ba710dac43> in <module>; 9 ; 10 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=None, swap_axes=True) # is shifted to the left (fig. 1); ---> 11 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) ; 12 ; 13 a.X[:16, :] = 0. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1220 groupby_cmap,; 1221 norm,; -> 1222 ) = _plot_categories_as_colorblocks(; 1223 groupby_ax, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591
https://github.com/scverse/scanpy/issues/1591:5747,Deployability,update,updated,5747,"d-bb115cd014aa.png); Fig. 3; ![f2](https://user-images.githubusercontent.com/46717574/104822452-d9cb5780-5842-11eb-8606-f4a9a5c97893.png); Fig. 4; ![f3](https://user-images.githubusercontent.com/46717574/104822453-dcc64800-5842-11eb-827c-90db0525d4d4.png); Fig. 5; ![f4](https://user-images.githubusercontent.com/46717574/104822455-dfc13880-5842-11eb-9286-655b2210b182.png); Fig. 6; ![f6](https://user-images.githubusercontent.com/46717574/104822796-958d8680-5845-11eb-82e2-4b30597c6722.png). #### Versions. <details>; -----; anndata 0.7.5; scanpy 1.7.0rc2.dev1+g2a123065; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; coverage 5.3; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.8; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygments 2.7.3; pyparsing 2.4.7; pytz 2020.5; ruamel NA; scanpy 1.7.0rc2.dev1+g2a123065; scipy 1.5.4; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sparse 0.11.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zarr 2.6.1; zmq 20.0.0; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; notebook 6.1.5; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.10.0-1-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2021-01-16 21:28; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591
https://github.com/scverse/scanpy/issues/1591:2527,Testability,log,log,2527,"_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 5; # xlabels are not centered + horizntal lines are slightly shifted downwards (really have to zoom in); sc.pl.heatmap(a, var_names=a.var_names, groupby=""foo"", swap_axes=False, figsize=(50, 50)); ```; If you look closely (e.g. between fig. 2 and fig.3, or fig. 4 and fig. 5), the within group order is also broken. ```pytb; TypeError Traceback (most recent call last); <ipython-input-56-f1ba710dac43> in <module>; 9 ; 10 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=None, swap_axes=True) # is shifted to the left (fig. 1); ---> 11 sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) ; 12 ; 13 a.X[:16, :] = 0. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, **kwds); 1220 groupby_cmap,; 1221 norm,; -> 1222 ) = _plot_categories_as_colorblocks(; 1223 groupby_ax, obs_tidy, colors=groupby_colors, orientation='bottom'; 1224 ). ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _plot_categories_as_colorblocks(groupby_ax, obs_tidy, colors, orientation, cmap_name); 2361 if len(labels) > 1:; 2362 groupby_ax.set_xticks(ticks); -> 2363 if max([len(x) for x in labels]) < 3:; 2364 # if the labels are small do not rotate them; 2365 rotation = 0. ~/.miniconda3/envs/cellrank/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in <listcomp>(.0); 2361 if len(labels) > 1:; 2362 groupby_ax.set_xticks(ticks); -> 2363 if max([len(x) for x in labels]) < 3:; 2364 # if the labels are small do not rotate them; 2365 rotation = 0. TypeError: object of type 'int' has no len(); ```; #### Figures; Fig. 1; ![f0](https://user-images.githubusercontent.com/46717574/104822526-6544e880-5843-11eb-8324-261e8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591
https://github.com/scverse/scanpy/issues/1591:5701,Testability,log,logical,5701,"d-bb115cd014aa.png); Fig. 3; ![f2](https://user-images.githubusercontent.com/46717574/104822452-d9cb5780-5842-11eb-8606-f4a9a5c97893.png); Fig. 4; ![f3](https://user-images.githubusercontent.com/46717574/104822453-dcc64800-5842-11eb-827c-90db0525d4d4.png); Fig. 5; ![f4](https://user-images.githubusercontent.com/46717574/104822455-dfc13880-5842-11eb-9286-655b2210b182.png); Fig. 6; ![f6](https://user-images.githubusercontent.com/46717574/104822796-958d8680-5845-11eb-82e2-4b30597c6722.png). #### Versions. <details>; -----; anndata 0.7.5; scanpy 1.7.0rc2.dev1+g2a123065; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; asciitree NA; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; coverage 5.3; cycler 0.10.0; cython_runtime NA; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; future_fstrings NA; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.0.1; numba 0.51.2; numcodecs 0.7.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.8; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pygments 2.7.3; pyparsing 2.4.7; pytz 2020.5; ruamel NA; scanpy 1.7.0rc2.dev1+g2a123065; scipy 1.5.4; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sparse 0.11.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zarr 2.6.1; zmq 20.0.0; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; notebook 6.1.5; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.10.0-1-amd64-x86_64-with-glibc2.10; 8 logical CPU cores; -----; Session information updated at 2021-01-16 21:28; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591
https://github.com/scverse/scanpy/issues/1591:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; from anndata import AnnData. a = AnnData(np.random.RandomState(42).normal(size=(50, 50)),; obs={""foo"": pd.Categorical(np.random.choice([0, 1, 2], size=50))}). sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=None, swap_axes=True) # is shifted to the left (fig. 1); sc.pl.heatmap(a, var_names=a.var_names[:5], groupby=""foo"", swap_axes=True) # see the tb (if there's only 1 category, in the group, it doesn't crash). a.X[:16, :] = 10 + np.random.RandomState(42).normal(size=(16, 50)); a.X[16:32, :] = -10 + np.random.RandomState(42).normal(size=(16, 50)); a.obs['foo'].iloc[:16, :] = 0; a.obs['foo'].iloc[16:32, :] = 1; a.obs['foo'].iloc[32:, :] = 2; # wrong label-color mapping; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 2; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 3. # but not when there are colors in `.uns; a.uns['foo_colors'] = [(1, 0, 0), (0, 1, 0), (0, 0, 1)]; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=True) # fig. 4; sc.pl.heatmap(a, var_names=a.var_names[:50], groupby=""foo"", swap_axes=False, dendrogram=False) # fig. 5; # xlabels are not centered + horizntal lines are slightly shifted downwards (really have to zoom in); sc.pl.heatmap(a, var_names=a.var_names, groupby=""foo"", swap_axes=False, figsize=(50, 50)); ```; If you look closely (e.g. between fig. 2 and",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1591
https://github.com/scverse/scanpy/pull/1592:16,Testability,test,tests,16,Fixes #1590 and tests that chunked pca works,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1592
https://github.com/scverse/scanpy/pull/1595:32,Deployability,release,release,32,"Supersedes #1540, just adding a release note. (I didn't want to push to your master branch @atarashansky)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1595
https://github.com/scverse/scanpy/pull/1596:265,Testability,benchmark,benchmarking,265,"If values of color dict are not unique, `categorical.map(non_unique)` returns a string array, which caused `to_hex` to be called on each element, not just the categories. This was quite slow. Using a dataset of 13million cells, with 38 clusters but only 20 colors, benchmarking the following line . ```python; sc.pl.umap(adata, color=""louvain""); ```. On master:. ```; CPU times: user 12.3 s, sys: 187 ms, total: 12.4 s; Wall time: 12.4 s; ```. This pr:. ```; CPU times: user 6.82 s, sys: 149 ms, total: 6.97 s; Wall time: 6.97 s; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1596
https://github.com/scverse/scanpy/pull/1597:19,Deployability,Update,Update,19,Backport PR #1595: Update sam params,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1597
https://github.com/scverse/scanpy/issues/1599:512,Availability,error,error,512,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello everyone, I am trying to calculate cell cycle score for my mouse data and encountering this error. I have already converted the gene name to upper case letters to read from the cell cycle genes. please help me to resolve this issue. Thank you very much. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens); ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-63-57c51b3902c0> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens). ~\anaconda3\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599
https://github.com/scverse/scanpy/issues/1599:5179,Testability,log,logging,5179,"indices."". KeyError: ""Values ['USP1', 'NSUN3', 'PHTF2', 'CCDC84', 'NUP160', 'RRM1', 'CENPM', 'SLC38A2', 'ABCC5', 'REEP1', 'DYNC1LI2', 'BMI1', 'RBBP8', 'MYCBP2', 'NFE2L2', 'GCLM', 'DNA2', 'OSGIN2', 'MAP3K2', 'BLM', 'PRIM1', 'RSRC2', 'CREBZF', 'E2F8', 'CDKN2AIP', 'ASF1B', 'CCDC150', 'BRIP1', 'MAN1A2', 'ZWINT', 'PKMYT1', 'ZBED5', 'PHTF1', 'ATAD2', 'CASP2', 'BRCA1', 'HELLS', 'CALD1', 'ORC3', 'SVIP', 'ABHD10', 'SAP30BP', 'RAD51', 'TTLL7', 'UBL3', 'DNAJB4', 'NEAT1', 'KAT2A', 'OGT', 'CENPQ', 'RAD51AP1', 'TOP2A', 'CDC7', 'CRLS1', 'DEPDC7', 'EZH2', 'CDCA5', 'TYMS', 'FANCA', 'PTAR1', 'RMI1', 'CDC45', 'UBE2T', 'POLA1', 'FANCI', 'KAT2B', 'MCM8', 'SRSF5', 'COQ9', 'NT5DC1', 'BIVM', 'RHOBTB3', 'CHML', 'CALM2', 'NAB1', 'LMO4', 'SP1', 'INTS7', 'RFC2', 'ESCO2', 'MASTL', 'DHFR', 'FEN1', 'DSCC1', 'CCDC14', 'MBD4', 'LYRM7', 'NRD1', 'RAD18', 'EXO1', 'PHIP', 'RPA2', 'BBS2', 'CERS6', 'CPNE8', 'RRM2', 'DONSON', 'H1F0', 'EIF4EBP2'], from ['USP1', 'NSUN3', 'PHTF2', 'CCDC84', 'NUP160', 'RRM1', 'CENPM', 'SLC38A2', 'ABCC5', 'REEP1', 'DYNC1LI2', 'BMI1', 'RBBP8', 'MYCBP2', 'NFE2L2', 'GCLM', 'DNA2', 'OSGIN2', 'MAP3K2', 'BLM', 'PRIM1', 'RSRC2', 'CREBZF', 'E2F8', 'CDKN2AIP', 'ASF1B', 'CCDC150', 'BRIP1', 'MAN1A2', 'ZWINT', 'PKMYT1', 'ZBED5', 'PHTF1', 'ATAD2', 'CASP2', 'BRCA1', 'HELLS', 'CALD1', 'ORC3', 'SVIP', 'ABHD10', 'SAP30BP', 'RAD51', 'TTLL7', 'UBL3', 'DNAJB4', 'NEAT1', 'KAT2A', 'OGT', 'CENPQ', 'RAD51AP1', 'TOP2A', 'CDC7', 'CRLS1', 'DEPDC7', 'EZH2', 'CDCA5', 'TYMS', 'FANCA', 'PTAR1', 'RMI1', 'CDC45', 'UBE2T', 'POLA1', 'FANCI', 'KAT2B', 'MCM8', 'SRSF5', 'COQ9', 'NT5DC1', 'BIVM', 'RHOBTB3', 'CHML', 'CALM2', 'NAB1', 'LMO4', 'SP1', 'INTS7', 'RFC2', 'ESCO2', 'MASTL', 'DHFR', 'FEN1', 'DSCC1', 'CCDC14', 'MBD4', 'LYRM7', 'NRD1', 'RAD18', 'EXO1', 'PHIP', 'RPA2', 'BBS2', 'CERS6', 'CPNE8', 'RRM2', 'DONSON', 'H1F0', 'EIF4EBP2'], are not valid obs/ var names or indices.""; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599
https://github.com/scverse/scanpy/issues/1599:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello everyone, I am trying to calculate cell cycle score for my mouse data and encountering this error. I have already converted the gene name to upper case letters to read from the cell cycle genes. please help me to resolve this issue. Thank you very much. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens); ```. ```pytb; KeyError Traceback (most recent call last); <ipython-input-63-57c51b3902c0> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens). ~\anaconda3\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 247 ctrl_size = min(len(s_genes), len(g2m_genes)); 248 # add s-score; --> 249 score_genes(adata, gene_list=s_genes, score_name='S_score', ct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1599
https://github.com/scverse/scanpy/pull/1602:88,Testability,test,testing,88,"Dear everyone,. This PR adds; 1. Python 3.8 to the build matrix. We were currently only testing vs 3.6 and 3.7. 3.10 is already coming up in April, so it is in my opinion time to use the more latest Python versions. If you feel like this adds too much to the Azure/CI bill, then I would suggest to remove 3.6. ; 2. Solves #1585 . Signed-off-by: Zethson <lukas.heumos@posteo.net>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1602
https://github.com/scverse/scanpy/pull/1603:37,Availability,error,error,37,This PR resolves the issues with:. * error when the type of a category is not `str`; * inconsistent color assigned to categories; * white space ; * horizontal lines not well aligned. Missing. - [x] Tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1603
https://github.com/scverse/scanpy/pull/1603:198,Testability,Test,Tests,198,This PR resolves the issues with:. * error when the type of a category is not `str`; * inconsistent color assigned to categories; * white space ; * horizontal lines not well aligned. Missing. - [x] Tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1603
https://github.com/scverse/scanpy/issues/1606:2677,Integrability,wrap,wrap,2677,"s. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 548 . ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in _raise_linalgerror_singular(err, flag); 86 ; 87 def _raise_linalgerror_singular(err, flag):; ---> 88 raise LinAlgError(""Singular matrix""); 89 ; 90 def _raise_linalgerror_nonposdef(err, flag):. LinAlgError: Singular matrix; ```; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. scanpy==1.7.0rc2.dev7+g57ec8a7e anndata==0.7.3 umap==0.4.6 numpy==1.19.5 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:868,Modifiability,variab,variables,868,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata.obs['sex'].cat.categories.tolist(); ```. ```pytb; ['F', 'M', 'U']; ```. ```python; adata.obs['age_groups'].cat.categories.tolist(); ```. ```pytb; ['Old', 'YoungAdult', 'Pediatric', 'Fetal', 'NewBorn']; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:904,Modifiability,variab,variables,904,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata.obs['sex'].cat.categories.tolist(); ```. ```pytb; ['F', 'M', 'U']; ```. ```python; adata.obs['age_groups'].cat.categories.tolist(); ```. ```pytb; ['Old', 'YoungAdult', 'Pediatric', 'Fetal', 'NewBorn']; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:1385,Modifiability,variab,variables,1385," for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata.obs['sex'].cat.categories.tolist(); ```. ```pytb; ['F', 'M', 'U']; ```. ```python; adata.obs['age_groups'].cat.categories.tolist(); ```. ```pytb; ['Old', 'YoungAdult', 'Pediatric', 'Fetal', 'NewBorn']; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:1427,Modifiability,variab,variables,1427,"imal code sample (that we can copy&paste without having any data). ```python; adata.obs['sex'].cat.categories.tolist(); ```. ```pytb; ['F', 'M', 'U']; ```. ```python; adata.obs['age_groups'].cat.categories.tolist(); ```. ```pytb; ['Old', 'YoungAdult', 'Pediatric', 'Fetal', 'NewBorn']; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). ~/.local/lib/python3.8/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:1775,Testability,log,logg,1775,"ython; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:3069,Testability,log,logging,3069,"s. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 548 . ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in _raise_linalgerror_singular(err, flag); 86 ; 87 def _raise_linalgerror_singular(err, flag):; ---> 88 raise LinAlgError(""Singular matrix""); 89 ; 90 def _raise_linalgerror_nonposdef(err, flag):. LinAlgError: Singular matrix; ```; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. scanpy==1.7.0rc2.dev7+g57ec8a7e anndata==0.7.3 umap==0.4.6 numpy==1.19.5 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:260,Usability,guid,guide,260,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata.obs['sex'].cat.categories.tolist(); ```. ```pytb; ['F', 'M', 'U']; ```. ```python; adata.obs['age_groups'].cat.categories.tolist(); ```. ```pytb; ['Old', 'YoungAdult', 'Pediatric', 'Fetal', 'NewBorn']; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['sex']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	sex. Found 0 numerical variables:; 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/sinhar/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py:340: RuntimeWarning: divide by zero encountered in true_divide; (abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max(); Adjusting data; ```. ```python; sc.pp.combat(adata, key='384plate', covariates=['age_group']); ```. ```pytb; Standardizing Data across genes. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/issues/1606:3258,Usability,learn,learn,3258,"s. Found 34 batches. Found 1 categorical variables:; 	age_group. Found 0 numerical variables:; 	. ---------------------------------------------------------------------------; LinAlgError Traceback (most recent call last); <timed eval> in <module>. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace); 204 # standardize across genes using a pooled variance estimator; 205 logg.info(""Standardizing Data across genes.\n""); --> 206 s_data, design, var_pooled, stand_mean = _standardize_data(model, data, key); 207 ; 208 # fitting the parameters on the standardized data. ~/.local/lib/python3.8/site-packages/scanpy/preprocessing/_combat.py in _standardize_data(model, data, batch_key); 102 ; 103 # compute pooled variance estimator; --> 104 B_hat = np.dot(np.dot(la.inv(np.dot(design.T, design)), design.T), data.T); 105 grand_mean = np.dot((n_batches / n_array).T, B_hat[:n_batch, :]); 106 var_pooled = (data - np.dot(design, B_hat).T) ** 2. <__array_function__ internals> in inv(*args, **kwargs). ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in inv(a); 544 signature = 'D->D' if isComplexType(t) else 'd->d'; 545 extobj = get_linalg_error_extobj(_raise_linalgerror_singular); --> 546 ainv = _umath_linalg.inv(a, signature=signature, extobj=extobj); 547 return wrap(ainv.astype(result_t, copy=False)); 548 . ~/.local/lib/python3.8/site-packages/numpy/linalg/linalg.py in _raise_linalgerror_singular(err, flag); 86 ; 87 def _raise_linalgerror_singular(err, flag):; ---> 88 raise LinAlgError(""Singular matrix""); 89 ; 90 def _raise_linalgerror_nonposdef(err, flag):. LinAlgError: Singular matrix; ```; #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. scanpy==1.7.0rc2.dev7+g57ec8a7e anndata==0.7.3 umap==0.4.6 numpy==1.19.5 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1606
https://github.com/scverse/scanpy/pull/1608:111,Integrability,depend,depend,111,"scvelo docs have been changed so the url for the sphinx inventory is different. We also probably don't want to depend on scvelo's documentation for our doc builds, especially since it's pre 1.0, and we weren't really doing much with it. Should fix current doc build problems.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1608
https://github.com/scverse/scanpy/pull/1609:26,Integrability,depend,dependency,26,Backport PR #1608: Remove dependency on scvelo for doc builds,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1609
https://github.com/scverse/scanpy/issues/1612:3039,Deployability,update,updated,3039,"ad(""adata2.h5ad""); check_equal_adata_X(adata_run1_concat, adata_run2_concat); adata_run1_concat.X = adata_run1_concat.X.astype(np.float64); adata_run2_concat.X = adata_run2_concat.X.astype(np.float64); sc.pp.normalize_total(adata_run1_concat); sc.pp.normalize_total(adata_run2_concat); check_equal_adata_X(adata_run1_concat, adata_run2_concat); ```. Output:; ```pytb; True; True; True; True; True; True; ```. Like I said, we tested also the ""internal"" `scanpy` 10x 3k PBMC dataset. ```python; sc.datasets.pbmc3k(); pbmc3k_1 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); pbmc3k_2 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); check_equal_adata_X(pbmc3k_1, pbmc3k_2); sc.pp.normalize_total(pbmc3k_1); sc.pp.normalize_total(pbmc3k_2); check_equal_adata_X(pbmc3k_1, pbmc3k_2); ```. ```pytb; True; True; True; True; True; True; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; anndata 0.7.5; backcall 0.1.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; importlib_metadata 1.6.0; ipykernel 5.2.1; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 0.14.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.31.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.18.2; packaging 20.3; pandas 1.0.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2019.3; scanpy 1.6.1; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.22.2.post1; storemagic NA; tables 3.6.1; tornado 6.0.4; tqdm 4.45.0; traitlets 4.3.3; wcwidth NA; zipp NA; zmq 19.0.0; -----; IPython 7.13.0; jupyter_client 6.1.3; jupyter_core 4.6.3; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) [GCC 7.3.0]; Linux-3.10.0-1127.18.2.el7.x86_64-x86_64-with-centos-7.8.2003-Core; 36 logical CPU cores; -----; Session information updated at 2021-01-27 17:16; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1612
https://github.com/scverse/scanpy/issues/1612:1503,Testability,test,tested,1503,"nt(np.array_equal(tmp1, tmp2)); print((tmp1 == tmp2).all()). adata_run1_concat = sc.read_h5ad(""adata1.h5ad""); adata_run2_concat = sc.read_h5ad(""adata2.h5ad""); check_equal_adata_X(adata_run1_concat, adata_run2_concat); sc.pp.normalize_total(adata_run1_concat); sc.pp.normalize_total(adata_run2_concat); check_equal_adata_X(adata_run1_concat, adata_run2_concat); ```; Output:; ```pytb; True; True; True; False; False; False; ```. Here is the code that fixes this bug. ```python; adata_run1_concat = sc.read_h5ad(""adata1.h5ad""); adata_run2_concat = sc.read_h5ad(""adata2.h5ad""); check_equal_adata_X(adata_run1_concat, adata_run2_concat); adata_run1_concat.X = adata_run1_concat.X.astype(np.float64); adata_run2_concat.X = adata_run2_concat.X.astype(np.float64); sc.pp.normalize_total(adata_run1_concat); sc.pp.normalize_total(adata_run2_concat); check_equal_adata_X(adata_run1_concat, adata_run2_concat); ```. Output:; ```pytb; True; True; True; True; True; True; ```. Like I said, we tested also the ""internal"" `scanpy` 10x 3k PBMC dataset. ```python; sc.datasets.pbmc3k(); pbmc3k_1 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); pbmc3k_2 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); check_equal_adata_X(pbmc3k_1, pbmc3k_2); sc.pp.normalize_total(pbmc3k_1); sc.pp.normalize_total(pbmc3k_2); check_equal_adata_X(pbmc3k_1, pbmc3k_2); ```. ```pytb; True; True; True; True; True; True; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; anndata 0.7.5; backcall 0.1.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; importlib_metadata 1.6.0; ipykernel 5.2.1; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 0.14.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.31.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.18.2; packaging 20.3; pandas 1.0.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; ptyprocess 0.6.0; pygments 2.6.1; pypars",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1612
https://github.com/scverse/scanpy/issues/1612:2993,Testability,log,logical,2993,"ad(""adata2.h5ad""); check_equal_adata_X(adata_run1_concat, adata_run2_concat); adata_run1_concat.X = adata_run1_concat.X.astype(np.float64); adata_run2_concat.X = adata_run2_concat.X.astype(np.float64); sc.pp.normalize_total(adata_run1_concat); sc.pp.normalize_total(adata_run2_concat); check_equal_adata_X(adata_run1_concat, adata_run2_concat); ```. Output:; ```pytb; True; True; True; True; True; True; ```. Like I said, we tested also the ""internal"" `scanpy` 10x 3k PBMC dataset. ```python; sc.datasets.pbmc3k(); pbmc3k_1 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); pbmc3k_2 = sc.read_h5ad(""data/pbmc3k_raw.h5ad""); check_equal_adata_X(pbmc3k_1, pbmc3k_2); sc.pp.normalize_total(pbmc3k_1); sc.pp.normalize_total(pbmc3k_2); check_equal_adata_X(pbmc3k_1, pbmc3k_2); ```. ```pytb; True; True; True; True; True; True; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; anndata 0.7.5; backcall 0.1.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; importlib_metadata 1.6.0; ipykernel 5.2.1; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.0; joblib 0.14.1; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.31.0; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.0.1; numba 0.48.0; numexpr 2.7.1; numpy 1.18.2; packaging 20.3; pandas 1.0.3; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2019.3; scanpy 1.6.1; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.22.2.post1; storemagic NA; tables 3.6.1; tornado 6.0.4; tqdm 4.45.0; traitlets 4.3.3; wcwidth NA; zipp NA; zmq 19.0.0; -----; IPython 7.13.0; jupyter_client 6.1.3; jupyter_core 4.6.3; notebook 6.0.3; -----; Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20) [GCC 7.3.0]; Linux-3.10.0-1127.18.2.el7.x86_64-x86_64-with-centos-7.8.2003-Core; 36 logical CPU cores; -----; Session information updated at 2021-01-27 17:16; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1612
https://github.com/scverse/scanpy/issues/1613:75,Deployability,upgrade,upgraded,75,"Hi,. Thank you for the great tool. I think this is not a bug. . Recently I upgraded some packages and found my results were different from the previous runs. I figured out that it is caused by different versions of `pynndescent` (0.4.7 vs 0.5.1), which is recommended to use in UMAP. So I think `pynndescent` should be included in the output of `sc.logging.print_header()`. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.1; pkg_resources NA; pynndescent 0.5.1; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.1; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; statsmodels 0.12.1; tables 3.6.1; texttable 1.6.3; umap 0.4.6; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 40 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613
https://github.com/scverse/scanpy/issues/1613:349,Testability,log,logging,349,"Hi,. Thank you for the great tool. I think this is not a bug. . Recently I upgraded some packages and found my results were different from the previous runs. I figured out that it is caused by different versions of `pynndescent` (0.4.7 vs 0.5.1), which is recommended to use in UMAP. So I think `pynndescent` should be included in the output of `sc.logging.print_header()`. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.1; pkg_resources NA; pynndescent 0.5.1; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.1; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; statsmodels 0.12.1; tables 3.6.1; texttable 1.6.3; umap 0.4.6; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 40 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613
https://github.com/scverse/scanpy/issues/1613:1174,Testability,log,logical,1174,"Hi,. Thank you for the great tool. I think this is not a bug. . Recently I upgraded some packages and found my results were different from the previous runs. I figured out that it is caused by different versions of `pynndescent` (0.4.7 vs 0.5.1), which is recommended to use in UMAP. So I think `pynndescent` should be included in the output of `sc.logging.print_header()`. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.1; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 3.1.0; highs_wrapper NA; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.1; pkg_resources NA; pynndescent 0.5.1; pyparsing 2.4.7; pytz 2020.5; scanpy 1.6.1; scipy 1.6.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; statsmodels 0.12.1; tables 3.6.1; texttable 1.6.3; umap 0.4.6; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 40 logical CPU cores, x86_64. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1613
https://github.com/scverse/scanpy/pull/1614:591,Availability,ping,ping,591,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; The PR uses `1-correlation` as distance matrix to compute the dendrogram as suggested in #1288 and mentioned in https://github.com/theislab/squidpy/pull/236. I opted for the minimal changes to the code. Other solution would be to use `scipy.spatial.distance.pdist` that allows a larger number of distance metrics. I am open for a discussion on this topic (ping @michalk8),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1614
https://github.com/scverse/scanpy/pull/1614:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; The PR uses `1-correlation` as distance matrix to compute the dendrogram as suggested in #1288 and mentioned in https://github.com/theislab/squidpy/pull/236. I opted for the minimal changes to the code. Other solution would be to use `scipy.spatial.distance.pdist` that allows a larger number of distance metrics. I am open for a discussion on this topic (ping @michalk8),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1614
https://github.com/scverse/scanpy/pull/1614:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; The PR uses `1-correlation` as distance matrix to compute the dendrogram as suggested in #1288 and mentioned in https://github.com/theislab/squidpy/pull/236. I opted for the minimal changes to the code. Other solution would be to use `scipy.spatial.distance.pdist` that allows a larger number of distance metrics. I am open for a discussion on this topic (ping @michalk8),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1614
https://github.com/scverse/scanpy/pull/1615:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1615
https://github.com/scverse/scanpy/pull/1615:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1615
https://github.com/scverse/scanpy/issues/1619:59,Usability,learn,learn,59,This seems related to the new Densmap feature https://umap-learn.readthedocs.io/en/latest/densmap_demo.html (see https://www.biorxiv.org/content/10.1101/2020.05.12.077776v1). Would be cool to support it in scanpy. _Originally posted by @gokceneraslan in https://github.com/theislab/scanpy/issues/1509#issuecomment-748156450_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1619
https://github.com/scverse/scanpy/pull/1620:88,Deployability,pipeline,pipelines,88,Should speed up CI. Based on [these docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/release/caching?view=azure-devops#pythonpip),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1620
https://github.com/scverse/scanpy/pull/1620:98,Deployability,release,release,98,Should speed up CI. Based on [these docs](https://docs.microsoft.com/en-us/azure/devops/pipelines/release/caching?view=azure-devops#pythonpip),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1620
https://github.com/scverse/scanpy/pull/1621:33,Deployability,update,updates,33,"Addendum to #1583, realized some updates hadn't been propagated to `var_df` so I've added those. Made it harder to forget these in the future by sharing the code. Additionally cleaned up the `get` namespace.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1621
https://github.com/scverse/scanpy/pull/1624:19,Deployability,Release,Release,19,Backport PR #1623: Release note for #1583 and update release date,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1624
https://github.com/scverse/scanpy/pull/1624:46,Deployability,update,update,46,Backport PR #1623: Release note for #1583 and update release date,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1624
https://github.com/scverse/scanpy/pull/1624:53,Deployability,release,release,53,Backport PR #1623: Release note for #1583 and update release date,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1624
https://github.com/scverse/scanpy/issues/1625:298,Availability,down,down,298,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:5558,Availability,avail,available,5558,".1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_O",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:6293,Availability,error,errors,6293,"as the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:414,Deployability,install,installed,414,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:735,Deployability,install,installed,735,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:5374,Deployability,install,installing,5374,"1=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:722,Integrability,depend,dependencies,722,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:1451,Integrability,depend,dependencies,1451,"ed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins-base=1.14.0=h8213a91_2; - gstreamer=1.14.0=h28cd5cc_2; - icu=58.2=he6710b0_3; - importlib_metadata=2.0.0=1; - ipykernel=5.3.4=py37h5ca1d4c_0; - ipython=7.20.0=py37hb070fc8_1; - ipython_genutils=0.2.0=pyhd3eb1b0_1; - ipywidgets=7.6.3=pyhd3eb1b0_1; - jedi=0.17.0=py37_0; - jinja2=2.11.3=pyhd3eb1b0_0; - jpeg=9b=h024ee3a_2; - jsonschema=3.2.0=py_2; - jupyter=1.0.0=py37_7; - jupyter_client=6.1.7=py_0; - jupyter_console=6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:4621,Integrability,wrap,wrap,4621,"sing=2.4.7=pyhd3eb1b0_0; - pyqt=5.9.2=py37h05f1152_2; - pyrsistent=0.17.3=py37h7b6447c_0; - python=3.7.9=h7579374_0; - python-dateutil=2.8.1=pyhd3eb1b0_0; - pyzmq=20.0.0=py37h2531618_1; - qt=5.9.7=h5867ecd_1; - qtconsole=4.7.7=py_0; - qtpy=1.9.0=py_0; - readline=8.1=h27cfd23_0; - send2trash=1.5.0=pyhd3eb1b0_1; - setuptools=52.0.0=py37h06a4308_0; - sip=4.19.8=py37hf484d3e_0; - six=1.15.0=py37h06a4308_0; - sqlite=3.33.0=h62c20be_0; - terminado=0.9.2=py37h06a4308_0; - testpath=0.4.4=pyhd3eb1b0_0; - tk=8.6.10=hbc83047_0; - tornado=6.1=py37h27cfd23_0; - traitlets=5.0.5=pyhd3eb1b0_0; - wcwidth=0.2.5=py_0; - webencodings=0.5.1=py37_1; - wheel=0.36.2=pyhd3eb1b0_0; - widgetsnbextension=3.5.1=py37_0; - xz=5.2.5=h7b6447c_0; - zeromq=4.3.3=he6710b0_3; - zipp=3.4.0=pyhd3eb1b0_0; - zlib=1.2.11=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:5400,Integrability,depend,dependency,5400,"1=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:1994,Modifiability,plugin,plugins-base,1994,a==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins-base=1.14.0=h8213a91_2; - gstreamer=1.14.0=h28cd5cc_2; - icu=58.2=he6710b0_3; - importlib_metadata=2.0.0=1; - ipykernel=5.3.4=py37h5ca1d4c_0; - ipython=7.20.0=py37hb070fc8_1; - ipython_genutils=0.2.0=pyhd3eb1b0_1; - ipywidgets=7.6.3=pyhd3eb1b0_1; - jedi=0.17.0=py37_0; - jinja2=2.11.3=pyhd3eb1b0_0; - jpeg=9b=h024ee3a_2; - jsonschema=3.2.0=py_2; - jupyter=1.0.0=py37_7; - jupyter_client=6.1.7=py_0; - jupyter_console=6.2.0=py_0; - jupyter_core=4.7.1=py37h06a4308_0; - jupyterlab_pygments=0.1.2=py_0; - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1; - ld_impl_linux-64=2.33.1=h53a641e_7; - libedit=3.1.20191231=h14c3975_1; - libffi=3.3=he6710b0_2; - libgcc-ng=9.1.0=hdf63c60_0; - libpng=1.6.37=hbc83047_0; - libsodium=1.0.18=h7b6447c_0; - libstdcxx-ng=9.1.0=hdf63c60_0; - libuuid=1.0.3=h1bed415_2; - libxcb=1.14=h7b6447c_0; - libxml2=2.9.10=hb55368b_3; - markupsafe=1.1.1=py37h14c3975_1; - mistune=0.8.4=py37h14c3975_1001; - nb_conda=2.2.1=py37_0; - nb_conda_kernels=2.3.1=py37h06a4308_0; - nbclient,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:4448,Performance,cache,cached-property,4448,"yhd3eb1b0_0; - prompt-toolkit=3.0.8=py_0; - prompt_toolkit=3.0.8=0; - ptyprocess=0.7.0=pyhd3eb1b0_2; - pycparser=2.20=py_2; - pygments=2.7.4=pyhd3eb1b0_0; - pyparsing=2.4.7=pyhd3eb1b0_0; - pyqt=5.9.2=py37h05f1152_2; - pyrsistent=0.17.3=py37h7b6447c_0; - python=3.7.9=h7579374_0; - python-dateutil=2.8.1=pyhd3eb1b0_0; - pyzmq=20.0.0=py37h2531618_1; - qt=5.9.7=h5867ecd_1; - qtconsole=4.7.7=py_0; - qtpy=1.9.0=py_0; - readline=8.1=h27cfd23_0; - send2trash=1.5.0=pyhd3eb1b0_1; - setuptools=52.0.0=py37h06a4308_0; - sip=4.19.8=py37hf484d3e_0; - six=1.15.0=py37h06a4308_0; - sqlite=3.33.0=h62c20be_0; - terminado=0.9.2=py37h06a4308_0; - testpath=0.4.4=pyhd3eb1b0_0; - tk=8.6.10=hbc83047_0; - tornado=6.1=py37h27cfd23_0; - traitlets=5.0.5=pyhd3eb1b0_0; - wcwidth=0.2.5=py_0; - webencodings=0.5.1=py37_1; - wheel=0.36.2=pyhd3eb1b0_0; - widgetsnbextension=3.5.1=py37_0; - xz=5.2.5=h7b6447c_0; - zeromq=4.3.3=he6710b0_3; - zipp=3.4.0=pyhd3eb1b0_0; - zlib=1.2.11=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:1662,Security,certificate,certificates,1662,"g the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins-base=1.14.0=h8213a91_2; - gstreamer=1.14.0=h28cd5cc_2; - icu=58.2=he6710b0_3; - importlib_metadata=2.0.0=1; - ipykernel=5.3.4=py37h5ca1d4c_0; - ipython=7.20.0=py37hb070fc8_1; - ipython_genutils=0.2.0=pyhd3eb1b0_1; - ipywidgets=7.6.3=pyhd3eb1b0_1; - jedi=0.17.0=py37_0; - jinja2=2.11.3=pyhd3eb1b0_0; - jpeg=9b=h024ee3a_2; - jsonschema=3.2.0=py_2; - jupyter=1.0.0=py37_7; - jupyter_client=6.1.7=py_0; - jupyter_console=6.2.0=py_0; - jupyter_core=4.7.1=py37h06a4308_0; - jupyterlab_pygments=0.1.2=py_0; - jupyterlab_widgets=1.0.0=pyhd3eb1b0_1; - ld_impl_linux-64=2.33.1=h53a641e_7; - libedit=3.1.20191231=h14c3975_1; - libffi=3.3=he6710b0_2; - libgcc-ng=9.1.0=hd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:5484,Security,access,access,5484,".1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_O",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:4087,Testability,test,testpath,4087,b0_1; - nest-asyncio=1.4.3=pyhd3eb1b0_0; - notebook=6.2.0=py37h06a4308_0; - openssl=1.1.1i=h27cfd23_0; - packaging=20.9=pyhd3eb1b0_0; - pandoc=2.11=hb0f4dca_0; - pandocfilters=1.4.3=py37h06a4308_1; - parso=0.8.1=pyhd3eb1b0_0; - pcre=8.44=he6710b0_0; - pexpect=4.8.0=pyhd3eb1b0_3; - pickleshare=0.7.5=pyhd3eb1b0_1003; - pip=20.3.3=py37h06a4308_0; - prometheus_client=0.9.0=pyhd3eb1b0_0; - prompt-toolkit=3.0.8=py_0; - prompt_toolkit=3.0.8=0; - ptyprocess=0.7.0=pyhd3eb1b0_2; - pycparser=2.20=py_2; - pygments=2.7.4=pyhd3eb1b0_0; - pyparsing=2.4.7=pyhd3eb1b0_0; - pyqt=5.9.2=py37h05f1152_2; - pyrsistent=0.17.3=py37h7b6447c_0; - python=3.7.9=h7579374_0; - python-dateutil=2.8.1=pyhd3eb1b0_0; - pyzmq=20.0.0=py37h2531618_1; - qt=5.9.7=h5867ecd_1; - qtconsole=4.7.7=py_0; - qtpy=1.9.0=py_0; - readline=8.1=h27cfd23_0; - send2trash=1.5.0=pyhd3eb1b0_1; - setuptools=52.0.0=py37h06a4308_0; - sip=4.19.8=py37hf484d3e_0; - six=1.15.0=py37h06a4308_0; - sqlite=3.33.0=h62c20be_0; - terminado=0.9.2=py37h06a4308_0; - testpath=0.4.4=pyhd3eb1b0_0; - tk=8.6.10=hbc83047_0; - tornado=6.1=py37h27cfd23_0; - traitlets=5.0.5=pyhd3eb1b0_0; - wcwidth=0.2.5=py_0; - webencodings=0.5.1=py37_1; - wheel=0.36.2=pyhd3eb1b0_0; - widgetsnbextension=3.5.1=py37_0; - xz=5.2.5=h7b6447c_0; - zeromq=4.3.3=he6710b0_3; - zipp=3.4.0=pyhd3eb1b0_0; - zlib=1.2.11=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:6343,Testability,log,logging,6343,"itionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfoldchange > 2) & (marker_table.pval_adj < 0.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:6380,Testability,log,logging,6380," the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfoldchange > 2) & (marker_table.pval_adj < 0.05)].copy(); print(marker_table.shape)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:7298,Testability,log,logfoldchange,7298,"ms(vector_friendly = True, dpi=300). sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3); sc.logging.print_version_and_date(); sc.logging.print_header(). adata = sc.read(""/data/190924_Recreated_Virus_Object_regressed.h5ad""); #adata.write(folder + ""190924_Recreated_Virus_Object_regressed.h5ad""). sc.tl.louvain(adata, resolution = 4, key_added = ""louvain_2""); sc.tl.louvain(adata, resolution = 5, key_added = ""louvain_3""); sc.tl.louvain(adata, resolution = 6, key_added = ""louvain_4""); sc.tl.louvain(adata, resolution = 7, key_added = ""louvain_5""). sc.pl.umap(adata, color = [""louvain_2"", ""louvain_3"", ""louvain_4"", ""louvain_5""], wspace = 0.45). #select resolution; print(adata.obs[""louvain_5""].value_counts()). sc.tl.rank_genes_groups(adata, groupby = ""louvain_5""). # read all arkers table from known annotated data; marker_folder = ""/marker/""; marker_table = pd.read_csv(marker_folder + ""Particle_AllMarkers.txt"", sep = ""\t"", index_col = None); marker_table.head(2). ## Restrict to Foldchange and P value; marker_table = marker_table[(marker_table.logfoldchange > 2) & (marker_table.pval_adj < 0.05)].copy(); print(marker_table.shape). marker = dict(); for ct in marker_table[""cluster""].unique():; tmp = marker_table[marker_table[""cluster""] == ct]; marker[ct] = tmp.gene.values. ## Look at a predefined list of cell types and the corresponding marker genes in order to annotate our clusters; cell_annotation = sc.tl.marker_gene_overlap(adata, marker, key = 'rank_genes_groups', normalize = 'reference'). fig, ax = plt.subplots(figsize = (30, 10)); sb.heatmap(cell_annotation, cbar = False, annot = True). fig.savefig('/data/heatmap.png'); ```. Everything works smoothly and the results look fine until the marker_gene_overlap. A similar issue was observed by another ICB member who is trying to verify that their new environment still works. Any pointers strongly appreciated, since we consider this a severe issue blocking new analyses with the most recent packages.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:1060,Usability,learn,learn,1060,"ported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; # Introduction. Hi,. so this is a weird one and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins-base=1.14.0=h8213a91_2; - gstreamer=1.14.0=h28cd5cc_2; - i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:1273,Usability,learn,learn,1273,"and I could not track it down yet.; The Schillerlab people have a workstation known as ""agando"". On this workstation the full environment is installed globally and shared by all users. I am looking to change that. # The issue. When calculating the `sc.tl.marker_gene_overlap` I get the expected and reasonable results on the agando environment, but completely rubbish results when running the same code with a fresh Conda environment and the latest dependencies installed. ![image](https://user-images.githubusercontent.com/21954664/106739402-659dfb80-6619-11eb-84f1-e75abfa6167d.png). Top = new, trash results; Bottom = old=agando expected results. The old environment has:. ```; scanpy==1.6.1.dev110+gb4234d81 anndata==0.7.4 umap==0.4.6 numpy==1.19.0 scipy==1.5.1 pandas==1.1.5 scikit-learn==0.23.1 statsmodels==0.12.1 python-igraph==0.8.0 louvain==0.6.1 leidenalg==0.8.3; ```. The new environment has ; ```; scanpy==1.6.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3; ```; Full new conda environment:; ```; name: single_cell_analysis; channels:; - defaults; dependencies:; - _libgcc_mutex=0.1=main; - argon2-cffi=20.1.0=py37h7b6447c_1; - async_generator=1.10=py37h28b3542_0; - attrs=20.3.0=pyhd3eb1b0_0; - backcall=0.2.0=pyhd3eb1b0_0; - bleach=3.3.0=pyhd3eb1b0_0; - ca-certificates=2021.1.19=h06a4308_0; - certifi=2020.12.5=py37h06a4308_0; - cffi=1.14.4=py37h261ae71_0; - dbus=1.13.18=hb2f20db_0; - decorator=4.4.2=pyhd3eb1b0_0; - defusedxml=0.6.0=py_0; - entrypoints=0.3=py37_0; - expat=2.2.10=he6710b0_2; - fontconfig=2.13.0=h9420a91_0; - freetype=2.10.4=h5ab3b9f_0; - glib=2.66.1=h92f7085_0; - gst-plugins-base=1.14.0=h8213a91_2; - gstreamer=1.14.0=h28cd5cc_2; - icu=58.2=he6710b0_3; - importlib_metadata=2.0.0=1; - ipykernel=5.3.4=py37h5ca1d4c_0; - ipython=7.20.0=py37hb070fc8_1; - ipython_genutils=0.2.0=pyhd3eb1b0_1; - ipywidgets=7.6.3=pyhd3eb1b0_1; - jedi=0.17.0=py37_0; - ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:4957,Usability,learn,learn,4957,"6a4308_0; - sip=4.19.8=py37hf484d3e_0; - six=1.15.0=py37h06a4308_0; - sqlite=3.33.0=h62c20be_0; - terminado=0.9.2=py37h06a4308_0; - testpath=0.4.4=pyhd3eb1b0_0; - tk=8.6.10=hbc83047_0; - tornado=6.1=py37h27cfd23_0; - traitlets=5.0.5=pyhd3eb1b0_0; - wcwidth=0.2.5=py_0; - webencodings=0.5.1=py37_1; - wheel=0.36.2=pyhd3eb1b0_0; - widgetsnbextension=3.5.1=py37_0; - xz=5.2.5=h7b6447c_0; - zeromq=4.3.3=he6710b0_3; - zipp=3.4.0=pyhd3eb1b0_0; - zlib=1.2.11=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1625:5224,Usability,learn,learn,5224," - webencodings=0.5.1=py37_1; - wheel=0.36.2=pyhd3eb1b0_0; - widgetsnbextension=3.5.1=py37_0; - xz=5.2.5=h7b6447c_0; - zeromq=4.3.3=he6710b0_3; - zipp=3.4.0=pyhd3eb1b0_0; - zlib=1.2.11=h7b6447c_3; - pip:; - anndata==0.7.5; - cached-property==1.5.2; - click==7.1.2; - cycler==0.10.0; - get-version==2.1; - h5py==3.1.0; - importlib-metadata==3.4.0; - joblib==1.0.0; - kiwisolver==1.3.1; - legacy-api-wrap==1.2; - leidenalg==0.8.3; - llvmlite==0.35.0; - loompy==3.0.6; - louvain==0.7.0; - matplotlib==3.3.4; - natsort==7.1.1; - networkx==2.5; - numba==0.52.0; - numexpr==2.7.2; - numpy==1.20.0; - numpy-groupies==0.9.13; - pandas==1.2.1; - patsy==0.5.1; - pillow==8.1.0; - python-igraph==0.8.3; - pytz==2021.1; - scanpy==1.6.1; - scikit-learn==0.24.1; - scipy==1.6.0; - scvelo==0.2.2; - seaborn==0.11.1; - setuptools-scm==5.0.1; - sinfo==0.3.1; - statsmodels==0.12.1; - stdlib-list==0.8.0; - tables==3.6.1; - texttable==1.6.3; - threadpoolctl==2.1.0; - tqdm==4.56.0; - typing-extensions==3.7.4.3; - umap-learn==0.4.6; ```. I can reproduce the issue with a Docker container that only has the minimal conda environment above. Additionally, I already tried installing the exact same dependency versions in the new environment, but got the same results. ; If you need access to the data and the container please contact me and I will make it available to you.; The data is already at the ICB cluster. Code:. ```; from os import path; import numpy as np; import matplotlib.pyplot as plt; import scanpy as sc; import scanpy.external as sce; from os import listdir; import pandas as pd; import seaborn as sb; import datetime, time; import scvelo as scv. from matplotlib.colors import LinearSegmentedColormap. #Define a nice colour map for gene expression; from matplotlib import colors. def timestamp():; ts = time.time(); st = datetime.datetime.fromtimestamp(ts).strftime('%d-%m-%Y %H:%M:%S'); return st. # Exporting folder. folder = ""/output""; sc.settings.figdir = folder + ""Plots/""; sc.set_figure_params(vect",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1625
https://github.com/scverse/scanpy/issues/1626:33,Testability,test,test,33,"Hi,. I am specifically trying to test something with random_state in sc.tl.umap, and would like to get more info on what random number generator is used. The docs there say that np.random is used if random_state=None, but does not explicitly comment on what the random number generator is otherwise. Could you please help clarify this?. Thank you!; Byron. <!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1626
https://github.com/scverse/scanpy/pull/1628:66,Deployability,release,release,66,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:101,Deployability,release,releases,101,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:144,Deployability,release,release,144,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:250,Deployability,release,release,250,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:534,Deployability,release,release,534,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:787,Deployability,release,release-latest,787,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:903,Deployability,release,release-latest,903,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:985,Deployability,release,release,985,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/pull/1628:1068,Deployability,release,release,1068,"@flying-sheep @falexwolf this is a first stab at reorganizing the release notes to facilitate bugfix releases. Using the example of the current release cycle:. The idea is that PRs which are bug fixes would have their change added to the `1.7.1.rst` release notes. New features are added to `1.8.0.rst` (which will be added in a follow up PR, since this pr will be back ported to the `1.7.x` branch). This way we don't mix all changes on master in one file, meaning we don't have to figure out what changes are included when making a release, as this information has been collected ahead of time. What I'd like to happen, is that `latest` builds will show changes for unreleased `1.7.1` and `1.8.0`, while the the `1.7.x` branch just shows `1.7.1`. ## TODO. - [x] Figure out how exactly release-latest works. What are the latest additions for ""Latest build"" vs. ""Stable"" and how should they differ.; - `release-latest.rst` will differ between stable and dev branches.; - [x] Why isn't release latest being added right to `docs/index.rst`; - [x] Process for adding new release note files should be added to dev docs.; - [x] Fix links to PAGA website",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1628
https://github.com/scverse/scanpy/issues/1629:829,Energy Efficiency,green,green,829,"<!-- What kind of feature would you like to request? -->; - [ ] New analysis tool: Calculate enrichment of a pathway across Conditions; - [ ] New plotting function: Distribution of gene-set score across Conditions. ; <!-- Please describe your wishes below: -->. Hi, . I really like your implementation of sc.tl.score_genes, which enables to extract biological information based on prior knowledge or to follow-up on genes in the DEgene analysis. . I ran the function with different gene sets on my dataset. The Conditions (of one cell-type) are colored in the density plots below. Currently I am not sure with the interpretation of the results, here I would like to hear your thoughts and maybe some improvements. In both cases >30 genes with medium/high expression are included. . In Plot1, gene-set A is enriched in Condition „green“ compared to the other conditions by comparing the medians. The scores are slightly negative, so I assume that the background-set is higher abundant in those Conditions. Which might indicate that gene-set B is depleted in the other conditions. . ![Plot1](https://user-images.githubusercontent.com/62027756/107199676-0106e600-69f7-11eb-93de-8739ad6dd497.png). In Plot 2, we see that gene-set B is depleted in purple. There might be however a slight enrichment in the other Conditions. . ![Plot2](https://user-images.githubusercontent.com/62027756/107199686-03694000-69f7-11eb-95a8-051dd9b31aea.png). 1. Can we infer from such an analysis how much a pathway is upregulated? (e.g. by calculating the FC of the mean?) . It would be great to conclude for example, that Pathway X is 30% more active, in condition Y. ; 2. How does in your opinion class-imbalance affect the analysis? For example, Condition A has 10 samples, while for Condition B,C.. I only have 3 each? ; 3. I am happy to provide the code for the density distributions to visualise the results of the gene-set-score function. . Looking forward to hear your thoughts!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1629
https://github.com/scverse/scanpy/issues/1631:428,Availability,avail,available,428,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, . I am hoping to open a pull request soon to add [CellO](https://www.cell.com/iscience/fulltext/S2589-0042(20)31110-X), a cell type classification tool, to Scanpy's external API. I notice that there currently are no cell type classification tools available in Scanpy's external API. . I am wondering if there is an explicit reason no cell type classifiers have been added to date? For example, I noticed some debate regarding how/whether to include expression imputation into Scanpy [https://github.com/theislab/scanpy/issues/189](https://github.com/theislab/scanpy/issues/189), and I just want to make sure there is no such reason why cell type classifiers have not been included yet. Thank you!. Matt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1631
https://github.com/scverse/scanpy/pull/1632:117,Usability,simpl,simple,117,"Re #1604, @fidelram, I've got the sphinx extension working for examples (at least locally) here. You can check out a simple example for `sc.pl.embedding`. Does this solve the problem you were running into?. <details>; <summary> Functions which need examples </summary>. Functions in `sc.pl`. - [ ] Embedding plots; - [ ] `sc.pl.embedding`; - [ ] `sc.pl.draw_graph`; - [ ] `sc.pl.diffmap`; - [ ] `sc.pl.pca`; - [ ] `sc.pl.tsne`; - [ ] `sc.pl.umap`; - [ ] `sc.pl.spatial`; - [x] `sc.pl.embedding_density`; - [ ] PCA specific; - [ ] `sc.pl.pca_loadings`; - [ ] `sc.pl.pca_overview`; - [ ] `sc.pl.pca_scatter`; - [ ] `sc.pl.pca_variance_ratio`; - [ ] PAGA; - [ ] `sc.pl.paga`; - [ ] `sc.pl.paga_adjacency`; - [ ] `sc.pl.paga_compare`; - [ ] `sc.pl.paga_path`; - [ ] DPT pseudotime; - [ ] `sc.pl.dpt_groups_pseudotime`; - [ ] `sc.pl.dpt_timeseries`; - [ ] Groupby; - [x] `sc.pl.dotplot`; - [ ] `sc.pl.matrixplot`; - [ ] `sc.pl.clustermap`; - [ ] `sc.pl.heatmap`; - [ ] `sc.pl.dendrogram`; - [ ] `sc.pl.stacked_violin`; - [ ] `sc.pl.tracksplot`; - [ ] `sc.pl.violin`; - [ ] Preprocessing; - [ ] `sc.pl.filter_genes_dispersion`; - [ ] `sc.pl.highest_expr_genes`; - [ ] `sc.pl.highly_variable_genes`; - [ ] DE; - [ ] `sc.pl.rank_genes_groups`; - [ ] `sc.pl.rank_genes_groups_dotplot`; - [ ] `sc.pl.rank_genes_groups_heatmap`; - [ ] `sc.pl.rank_genes_groups_matrixplot`; - [ ] `sc.pl.rank_genes_groups_stacked_violin`; - [ ] `sc.pl.rank_genes_groups_tracksplot`; - [ ] `sc.pl.rank_genes_groups_violin`; - [ ] Misc/ to be classified; - [ ] `sc.pl.ranking`; - [ ] `sc.pl.scatter`; - [ ] `sc.pl.sim`; - [ ] `sc.pl.correlation_matrix`; - [ ] `sc.pl.matrix`; - [ ] Time series (???); - [ ] `sc.pl.timeseries`; - [ ] `sc.pl.timeseries_as_heatmap`; - [ ] `sc.pl.timeseries_subplot`. Other functions. - [x] `sc.pp.calculate_qc_metrics`; - [x] `sc.tl.embedding_density`; - [ ] `sc.get.obs_df`; - [ ] `sc.get.rank_genes_groups_df`. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1632
https://github.com/scverse/scanpy/issues/1633:1592,Availability,down,downside,1592,"lt colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://github.com/theislab/scanpydoc/blob/875b441212830678cf9fc81c52f5af29bbb8715f/scanpydoc/elegant_typehints/formatting.py#L101-L107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633
https://github.com/scverse/scanpy/issues/1633:1659,Modifiability,rewrite,rewrites,1659,"lt colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://github.com/theislab/scanpydoc/blob/875b441212830678cf9fc81c52f5af29bbb8715f/scanpydoc/elegant_typehints/formatting.py#L101-L107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633
https://github.com/scverse/scanpy/issues/1633:609,Performance,tune,tune,609,"Multiple calls to `sc.pl.Dotplot.style()` cause resetting of parameters. This issue can be observed as a change in the default colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://gith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633
https://github.com/scverse/scanpy/issues/1633:1554,Usability,clear,clearly,1554,"lt colormap shown by #1632 Other methods that set default parameters are also affected like `.add_totals()`. The following example should show the dots using the `Reds` colormap, but instead it uses the `winter` colormap because the second call sets the color map to `winter` if not given. This double call happens because when `sc.pl.dotplot()` is used (instead of `sc.pl.DotPlot`), internally a call to `.style()` is made and a subsequent explicit calls to `.style()` is required to tune the parameters as suggested in the documentation. ```python; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.DotPlot(adata, markers, groupby='bulk_labels').style(cmap='Reds').style(dot_edge_color='black').show(); ```; ![image](https://user-images.githubusercontent.com/4964309/107354555-9628de00-6ace-11eb-9eb8-c0baaa80b1f6.png). The problem is caused by the current implementation of `sc.pl.Dotplot.style()` that set the default parameters as:. ```; def style(; self,; cmap: str = DEFAULT_COLORMAP,; color_on: Optional[Literal['dot', 'square']] = DEFAULT_COLOR_ON,; dot_max: Optional[float] = DEFAULT_DOT_MAX,; dot_min: Optional[float] = DEFAULT_DOT_MIN,; .....; ```. Where DEFAULT_* are the default values defined at the beginning of the file (see https://github.com/theislab/scanpy/blob/master/scanpy/plotting/_dotplot.py#L84) . What is nice about this is that the documentation clearly shows the default values. The downside is that optional values are assigned a default value that rewrites previous calls to style. Ideally, all optional values should be `None`, then is easy to know if a new value is passed or a previous call has already set a value. But, doing so will remove the defaults from the documentation. @flying-sheep suggested to use a code he wrote to add default annotations to the documentation. https://github.com/theislab/scanpydoc/blob/875b441212830678cf9fc81c52f5af29bbb8715f/scanpydoc/elegant_typehints/formatting.py#L101-L107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1633
https://github.com/scverse/scanpy/issues/1634:65,Availability,error,error,65,"Calling `sc.get.obs_df()` without the `keys` parameter causes an error:. ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)]); ```. ```pytb; ~/scanpy/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 301 ; 302 # reorder columns to given order (including duplicates keys if present); --> 303 df = df[keys]; 304 for k, idx in obsm_keys:; 305 added_k = f""{k}-{idx}"". KeyError: (); ```. Also, if `keys` is not a list, the object returned is not a pandas dataframe but a Series object in which the last row is the obsm values. In other words, instead of adding a column to a dataframe with the obsm values, a row is added to a pandas Series. . ```python; adata = sc.datasets.pbmc68k_reduced(); sc.get.obs_df(adata, obsm_keys=[('X_umap', 0,)], keys='CST3'); ```; ```; index; AAAGCCTGGCTAAC-1 0.281; AAATTCGATGCACA-1 -0.176; AACACGTGGTCTTT-1 -0.818; AAGTGCACGTGCTA-1 -0.818; ACACGAACGGAGTG-1 0.854; ... ; TGTGAGTGCTTTAC-8 -0.069; TGTTACTGGCGATT-8 -0.818; TTCAGTACCGGGAA-8 -0.818; TTGAGGTGGAGAGC-8 0.428; X_umap-0 [-1.9918625454649166, -3.2486919412134108, -3....; Name: CST3, Length: 701, dtype: object; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1634
https://github.com/scverse/scanpy/issues/1636:2649,Modifiability,variab,variable,2649,"itle, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in <dictcomp>(.0); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). NameError: free variable 'symbols' referenced before assignment in enclosing scope; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.3.10 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:338,Testability,TEST,TEST,338,"I would like to change the var name when plotting dotplot by setting the `gene_symbols` to the desired name. But this generates the NameError. Below is an example using the scanpy built-in dataset. ```python; adata = sc.datasets.pbmc68k_reduced(); ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); ```. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-45-206578ef4fd5> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); 3 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:666,Testability,TEST,TEST,666,"I would like to change the var name when plotting dotplot by setting the `gene_symbols` to the desired name. But this generates the NameError. Below is an example using the scanpy built-in dataset. ```python; adata = sc.datasets.pbmc68k_reduced(); ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); ```. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-45-206578ef4fd5> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); 3 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:804,Testability,log,log,804,"I would like to change the var name when plotting dotplot by setting the `gene_symbols` to the desired name. But this generates the NameError. Below is an example using the scanpy built-in dataset. ```python; adata = sc.datasets.pbmc68k_reduced(); ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); ```. ```pytb; ---------------------------------------------------------------------------; NameError Traceback (most recent call last); <ipython-input-45-206578ef4fd5> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); 3 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:1324,Testability,log,log,1324,"eError Traceback (most recent call last); <ipython-input-45-206578ef4fd5> in <module>; 1 adata = sc.datasets.pbmc68k_reduced(); ----> 2 ax = sc.pl.dotplot(adata, 'C1QA', groupby=['bulk_labels'], swap_axes=False, gene_symbols='TEST'); 3 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in <dictc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:1755,Testability,log,log,1755,"mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in <dictcomp>(.0); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). NameError: free variable 'symbols' referenced before assignment in enclosing scope; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.3.10 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:2128,Testability,log,log,2128,"itle, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in <dictcomp>(.0); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). NameError: free variable 'symbols' referenced before assignment in enclosing scope; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.3.10 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/issues/1636:2838,Usability,learn,learn,2838,"itle, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 142 layer=layer,; 143 ax=ax,; --> 144 **kwds,; 145 ); 146 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, **kwds); 111 num_categories,; 112 layer=layer,; --> 113 gene_symbols=gene_symbols,; 114 ); 115 . ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). ~/anaconda3/envs/scRNA/lib/python3.6/site-packages/scanpy/plotting/_anndata.py in <dictcomp>(.0); 1837 # translate the column names to the symbol names; 1838 obs_tidy.rename(; -> 1839 columns={var_names[x]: symbols[x] for x in range(len(var_names))},; 1840 inplace=True,; 1841 ). NameError: free variable 'symbols' referenced before assignment in enclosing scope; ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.4 umap==0.3.10 numpy==1.18.4 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.8.2 louvain==0.6.1 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1636
https://github.com/scverse/scanpy/pull/1642:540,Availability,ping,pinging,540,"Hi,. I'm working with pseudocounts data (kallisto/alevin/salomon output). I think they are called ""pseudocount"": if a read is assigned to two regions (genes) , a probability is assigned (e.g. gene1=0.2, gene2=0.8). Nevertheless, they can still considered counts and so it would be cool to use the `highly_variable_genes flavour=seuratv3` . ; I added an additional argument in case users would like to enforce this, as it was similarly done/discussed in https://github.com/theislab/scvelo/issues/190. Would like to hear what you guys think, pinging @adamgayoso (thanks for the great overleaf doc! )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1642
https://github.com/scverse/scanpy/issues/1643:980,Testability,log,log,980,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->. I recently ported [SCTransform](https://github.com/ChristophH/sctransform) from R into python. Any interest in getting it onto Scanpy?. The original paper is [here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1). It's a variance-stabilizing transformation that overcomes some key drawbacks of previous, similar methods (e.g. overfitting caused by building regression models from individual genes as opposed to groups of similar genes). It also eliminates the need for pseudocounts, log transformations, or library size normalization. . My code is [here](https://github.com/atarashansky/SCTransformPy). Implementation notes (from the SCTransformPy README):; - Poisson regression is done using the `statsmodels` package and parallelized with `multiprocessing`. ; - Improved Sheather & Jones bandwidth calculation is implemented by the `KDEpy` package.; - Estimating the negative binomial dispersion factor, `theta`, using MLE was translated from the `theta.ml` function in R.; - Pearson residuals are automatically clipped to be non-negative. This ensures that sparsity structure can be preserved in the data. Practically, the results do not change much when allowing for dense, negative values. Anecdotally, it produces very similar results to the R implementation, though the code itself is still a little rough around the edges. I also have to do more formal quantitative benchmarking to ensure results are similar to those of the original package. I thought I'd gauge interest here prior to working on",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643
https://github.com/scverse/scanpy/issues/1643:1871,Testability,benchmark,benchmarking,1871,"ould you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->. I recently ported [SCTransform](https://github.com/ChristophH/sctransform) from R into python. Any interest in getting it onto Scanpy?. The original paper is [here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1). It's a variance-stabilizing transformation that overcomes some key drawbacks of previous, similar methods (e.g. overfitting caused by building regression models from individual genes as opposed to groups of similar genes). It also eliminates the need for pseudocounts, log transformations, or library size normalization. . My code is [here](https://github.com/atarashansky/SCTransformPy). Implementation notes (from the SCTransformPy README):; - Poisson regression is done using the `statsmodels` package and parallelized with `multiprocessing`. ; - Improved Sheather & Jones bandwidth calculation is implemented by the `KDEpy` package.; - Estimating the negative binomial dispersion factor, `theta`, using MLE was translated from the `theta.ml` function in R.; - Pearson residuals are automatically clipped to be non-negative. This ensures that sparsity structure can be preserved in the data. Practically, the results do not change much when allowing for dense, negative values. Anecdotally, it produces very similar results to the R implementation, though the code itself is still a little rough around the edges. I also have to do more formal quantitative benchmarking to ensure results are similar to those of the original package. I thought I'd gauge interest here prior to working on making it `scanpy`-ready.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643
https://github.com/scverse/scanpy/issues/1643:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->. I recently ported [SCTransform](https://github.com/ChristophH/sctransform) from R into python. Any interest in getting it onto Scanpy?. The original paper is [here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1). It's a variance-stabilizing transformation that overcomes some key drawbacks of previous, similar methods (e.g. overfitting caused by building regression models from individual genes as opposed to groups of similar genes). It also eliminates the need for pseudocounts, log transformations, or library size normalization. . My code is [here](https://github.com/atarashansky/SCTransformPy). Implementation notes (from the SCTransformPy README):; - Poisson regression is done using the `statsmodels` package and parallelized with `multiprocessing`. ; - Improved Sheather & Jones bandwidth calculation is implemented by the `KDEpy` package.; - Estimating the negative binomial dispersion factor, `theta`, using MLE was translated from the `theta.ml` function in R.; - Pearson residuals are automatically clipped to be non-negative. This ensures that sparsity structure can be preserved in the data. Practically, the results do not change much when allowing for dense, negative values. Anecdotally, it produces very similar results to the R implementation, though the code itself is still a little rough around the edges. I also have to do more formal quantitative benchmarking to ensure results are similar to those of the original package. I thought I'd gauge interest here prior to working on",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1643
https://github.com/scverse/scanpy/issues/1644:655,Safety,Detect,Detected,655,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.external.pp.scrublet(adata, threshold='I am ignored'); ```. ```pytb; /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.27; Detected doublet rate = 1.5%; Estimated detectable doublet fraction = 44.3%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 3.4%. ```. #### Versions. <details>. scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1644
https://github.com/scverse/scanpy/issues/1644:695,Safety,detect,detectable,695,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.external.pp.scrublet(adata, threshold='I am ignored'); ```. ```pytb; /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.27; Detected doublet rate = 1.5%; Estimated detectable doublet fraction = 44.3%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 3.4%. ```. #### Versions. <details>. scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1644
https://github.com/scverse/scanpy/issues/1644:912,Usability,learn,learn,912,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); sc.external.pp.scrublet(adata, threshold='I am ignored'); ```. ```pytb; /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.; view_to_actual(adata). Automatically set threshold at doublet score = 0.27; Detected doublet rate = 1.5%; Estimated detectable doublet fraction = 44.3%; Overall doublet rate:; 	Expected = 5.0%; 	Estimated = 3.4%. ```. #### Versions. <details>. scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1644
https://github.com/scverse/scanpy/issues/1645:464,Testability,log,logarithmized,464,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.external.pp.scrublet(adata, threshold=0.1); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; /opt/conda/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.; res = method(*args, **kwargs); Trying to set attribute `.uns` of view, copying.; /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.; view_to_actual(adata). ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-21-3dabe52b6132> in <module>; 1 import scanpy as sc; 2 adata = sc.datasets.paul15(); ----> 3 sc.external.pp.scrublet(adata, threshold=0.1). /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state); 208 expected_doublet_rate=expected_doublet_rate,; 209 stdev_doublet_rate=stdev_doublet_rate,; --> 210 random_state=random_state,; 211 ); 212 . /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in _scrublet_call_doublets(adata_obs, adata_sim, n_neighbors, expected_doublet_rate,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645
https://github.com/scverse/scanpy/issues/1645:503,Testability,log,logarithmized,503,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.paul15(); sc.external.pp.scrublet(adata, threshold=0.1); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; /opt/conda/lib/python3.7/site-packages/pandas/core/arrays/categorical.py:2487: FutureWarning: The `inplace` parameter in pandas.Categorical.remove_unused_categories is deprecated and will be removed in a future version.; res = method(*args, **kwargs); Trying to set attribute `.uns` of view, copying.; /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.; view_to_actual(adata). ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-21-3dabe52b6132> in <module>; 1 import scanpy as sc; 2 adata = sc.datasets.paul15(); ----> 3 sc.external.pp.scrublet(adata, threshold=0.1). /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state); 208 expected_doublet_rate=expected_doublet_rate,; 209 stdev_doublet_rate=stdev_doublet_rate,; --> 210 random_state=random_state,; 211 ); 212 . /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in _scrublet_call_doublets(adata_obs, adata_sim, n_neighbors, expected_doublet_rate,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645
https://github.com/scverse/scanpy/issues/1645:3079,Usability,learn,learn,3079,"ut-21-3dabe52b6132> in <module>; 1 import scanpy as sc; 2 adata = sc.datasets.paul15(); ----> 3 sc.external.pp.scrublet(adata, threshold=0.1). /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in scrublet(adata, adata_sim, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state); 208 expected_doublet_rate=expected_doublet_rate,; 209 stdev_doublet_rate=stdev_doublet_rate,; --> 210 random_state=random_state,; 211 ); 212 . /opt/conda/lib/python3.7/site-packages/scanpy/external/pp/_scrublet.py in _scrublet_call_doublets(adata_obs, adata_sim, n_neighbors, expected_doublet_rate, stdev_doublet_rate, mean_center, normalize_variance, n_prin_comps, use_approx_neighbors, knn_dist_metric, get_doublet_neighbor_parents, random_state, verbose); 349 ; 350 if mean_center and normalize_variance:; --> 351 sl.pipeline_zscore(scrub); 352 elif mean_center:; 353 sl.pipeline_mean_center(scrub). /opt/conda/lib/python3.7/site-packages/scrublet/helper_functions.py in pipeline_zscore(self); 62 def pipeline_zscore(self):; 63 gene_means = self._E_obs_norm.mean(0); ---> 64 gene_stdevs = np.sqrt(sparse_var(self._E_obs_norm)); 65 self._E_obs_norm = np.array(sparse_zscore(self._E_obs_norm, gene_means, gene_stdevs)); 66 if self._E_sim_norm is not None:. /opt/conda/lib/python3.7/site-packages/scrublet/helper_functions.py in sparse_var(E, axis); 153 ''' variance across the specified axis '''; 154 ; --> 155 mean_gene = E.mean(axis=axis).A.squeeze(); 156 tmp = E.copy(); 157 tmp.data **= 2. AttributeError: 'numpy.ndarray' object has no attribute 'A'; ```. #### Versions. <details>. scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1645
https://github.com/scverse/scanpy/issues/1646:2102,Usability,learn,learn,2102,"aster branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.blobs(); sc.pp.pca(adata). adata.obs['boolean'] = True. sc.pl.pca(adata, color='boolean'); ```. ```pytb; ... storing 'blobs' as categorical. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-11-1415b8dea7b8> in <module>; 5 adata.obs['boolean'] = True; 6 ; ----> 7 sc.pl.pca(adata, color='boolean'). /opt/conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs); 727 if not annotate_var_explained:; 728 return embedding(; --> 729 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs; 730 ); 731 else:. /opt/conda/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 257 if sort_order is True and value_to_plot is not None and categorical is False:; 258 # Higher values plotted on top, null values on bottom; --> 259 order = np.argsort(-color_vector, kind=""stable"")[::-1]; 260 elif sort_order and categorical:; 261 # Null points go on bottom. TypeError: The numpy boolean negative, the `-` operator, is not supported, use the `~` operator or the logical_not function instead.; ```. #### Versions. <details>. scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1646
https://github.com/scverse/scanpy/issues/1648:751,Modifiability,extend,extend,751,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; I was wondering, what is the intended way to temporarily set plotting parameters, e.g. figsize?. Say I want to increase the figsize just for a single UMAP plot. . I could either temporarily `set_figure_params` and reset it manually afterwards; ```python; sc.set_figure_params(figsize=(8, 8)); sc.pl.umap(adata, color=""cell_type""); sc.set_figure_params(figsize=(4, 4)) # or whatever it was before...; ```. Or create the figure separately:; ```python; _, ax = plt.subplots(figsize=(8, 8)); sc.pl.umap(adata, color=""cell_type"", ax=ax); ```; <p><br></p>. Would it make sense to extend `set_figure_params` to act as a context manager?. ```python; with sc.set_figure_params(figsize=(8, 8), frameon=False):; sc.pl.umap(adata, color=""cell_type""); ```. But maybe there's a comparable way already?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1648
https://github.com/scverse/scanpy/pull/1649:39,Testability,log,log,39,Argument to compare absolute values of log fold change with `min_fold_change`.; https://github.com/theislab/scanpy/issues/1325; I think `compare_abs` is a better name than `rankby_abs` for this.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1649
https://github.com/scverse/scanpy/issues/1650:120,Performance,perform,perform,120,"Hi @ALL,; I want that the object of annData to save the normalized expression matrix that exclude the scaling matrix to perform the pyscenic regulon analysis.but the code adata.to_df().to_csv(EXP_MTX_QC_FNAME) just save the scaling matrix that had the negative number in but just normalized d matrix.so i merely want to export the normlized matrix data and then imported to the pyscenic to analyize. So how can i do for this request?; Any advice would be appreciated.; Best,; hanhuihong",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1650
https://github.com/scverse/scanpy/issues/1651:918,Usability,learn,learn,918,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. `sc.tl.filter_rank_genes_groups()` replaces gene names with ""nan"" values, would be nice to be able to ignore these with `sc.pl.rank_genes_groups()` and instead show the top n actual non-filtered genes. ### Minimal code sample. ```python; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); sc.pl.rank_genes_groups(adata, key=""rank_genes_groups_filtered""); ```. ![image](https://user-images.githubusercontent.com/20436557/107974043-ea8bfc00-6fad-11eb-9368-1ba78336a3b2.png). #### Versions; ```; scanpy==1.7.0 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.4 pandas==1.1.5 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3; ````",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1651
https://github.com/scverse/scanpy/issues/1652:3863,Availability,error,errors,3863,"t pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> 343 def sparse_alternative_jaccard(ind1, data1, ind2, data2):; 344 num_non_zero = arr_union(ind1, ind2).shape[0]; 345 num_equal = arr_intersect(ind1, ind2).shape[0]. ~/.local/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 216 with typeinfer.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:4312,Availability,error,errors,4312,"er.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:5651,Availability,avail,available,5651,"escr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 397 if self.state.cr is not None:; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8069,Availability,error,errors,8069,"/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8923,Availability,error,error,8923,"in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = call $12load_method.4(func=$12load_method.4, args=[], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5017); D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:2040,Deployability,install,installed,2040,"use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 118 adata._init_as_actual(adata.copy()); 119 neighbors = Neighbors(adata); --> 120 neighbors.compute_neighbors(; 121 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 122 method=method, metric=metric, metric_kwds=metric_kwds,. ~/.local/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 732 X = pairwise_distances(X, metric=metric, **metric_kwds); 733 metric = 'precomputed'; --> 734 knn_indices, knn_distances, forest = compute_neighbors_umap(; 735 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds); 736 # very cautious here. ~/.local/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose); 273 # umap 0.5.0; 274 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 275 from umap.umap_ import nearest_neighbors; 276 ; 277 random_state = check_random_state(random_state). ~/.local/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. ~/.local/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 1 import pkg_resources; 2 import numba; ----> 3 from .pynndescent_ import NNDescent, PyNNDescentTransformer; 4 ; 5 # Workaround: https://github.com/numba/numba/issues/3341. ~/.local/lib/python3.9/site-packages/pynndescent/pynndescent_.py in <module>; 19 import heapq; 20 ; ---> 21 import pynndescent.sparse as sparse; 22 import pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:4818,Deployability,pipeline,pipeline,4818,"r.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:4930,Deployability,pipeline,pipeline,4930,"r.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile_core(args, return_type); 93 except errors.TypingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:5661,Deployability,pipeline,pipelines,5661,"escr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 397 if self.state.cr is not None:; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8178,Deployability,pipeline,pipeline,8178,"lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8238,Deployability,pipeline,pipeline,8238,"lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8298,Deployability,pipeline,pipeline,8298,"lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8362,Deployability,pipeline,pipeline,8362,"lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8426,Deployability,pipeline,pipeline,8426,"lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8973,Deployability,pipeline,pipeline,8973,"in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = call $12load_method.4(func=$12load_method.4, args=[], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5017); D",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8103,Energy Efficiency,reduce,reduce,8103,"/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:2015,Integrability,message,message,2015,"use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 118 adata._init_as_actual(adata.copy()); 119 neighbors = Neighbors(adata); --> 120 neighbors.compute_neighbors(; 121 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,; 122 method=method, metric=metric, metric_kwds=metric_kwds,. ~/.local/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 732 X = pairwise_distances(X, metric=metric, **metric_kwds); 733 metric = 'precomputed'; --> 734 knn_indices, knn_distances, forest = compute_neighbors_umap(; 735 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds); 736 # very cautious here. ~/.local/lib/python3.9/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose); 273 # umap 0.5.0; 274 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 275 from umap.umap_ import nearest_neighbors; 276 ; 277 random_state = check_random_state(random_state). ~/.local/lib/python3.9/site-packages/umap/umap_.py in <module>; 45 ); 46 ; ---> 47 from pynndescent import NNDescent; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. ~/.local/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 1 import pkg_resources; 2 import numba; ----> 3 from .pynndescent_ import NNDescent, PyNNDescentTransformer; 4 ; 5 # Workaround: https://github.com/numba/numba/issues/3341. ~/.local/lib/python3.9/site-packages/pynndescent/pynndescent_.py in <module>; 19 import heapq; 20 ; ---> 21 import pynndescent.sparse as sparse; 22 import pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:3262,Integrability,wrap,wrapper,3262,"nt; 48 from pynndescent.distances import named_distances as pynn_named_distances; 49 from pynndescent.sparse import sparse_named_distances as pynn_sparse_named_distances. ~/.local/lib/python3.9/site-packages/pynndescent/__init__.py in <module>; 1 import pkg_resources; 2 import numba; ----> 3 from .pynndescent_ import NNDescent, PyNNDescentTransformer; 4 ; 5 # Workaround: https://github.com/numba/numba/issues/3341. ~/.local/lib/python3.9/site-packages/pynndescent/pynndescent_.py in <module>; 19 import heapq; 20 ; ---> 21 import pynndescent.sparse as sparse; 22 import pynndescent.sparse_nndescent as sparse_nnd; 23 import pynndescent.distances as pynnd_dist. ~/.local/lib/python3.9/site-packages/pynndescent/sparse.py in <module>; 341 },; 342 ); --> 343 def sparse_alternative_jaccard(ind1, data1, ind2, data2):; 344 num_non_zero = arr_union(ind1, ind2).shape[0]; 345 num_equal = arr_intersect(ind1, ind2).shape[0]. ~/.local/lib/python3.9/site-packages/numba/core/decorators.py in wrapper(func); 216 with typeinfer.register_dispatcher(disp):; 217 for sig in sigs:; --> 218 disp.compile(sig); 219 disp.disable_compile(); 220 return disp. ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, sig); 817 self._cache_misses[sig] += 1; 818 try:; --> 819 cres = self._compiler.compile(args, return_type); 820 except errors.ForceLiteralArg as e:; 821 def folded(args, kws):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 80 return retval; 81 else:; ---> 82 raise retval; 83 ; 84 def _compile_cached(self, args, return_type):. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 90 ; 91 try:; ---> 92 retval = self._compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8764,Integrability,wrap,wrap,8764,"0 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:8805,Modifiability,extend,extending,8805,"=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in propagate(self, raise_errors); 1069 if isinstance(e, ForceLiteralArg)]; 1070 if not force_lit_args:; -> 1071 raise errors[0]; 1072 else:; 1073 raise reduce(operator.or_, force_lit_args). TypingError: Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = cal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:5338,Testability,assert,assert,5338,"ingError as e:; 94 self._failed_cache[key] = e. ~/.local/lib/python3.9/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 103 ; 104 impl = self._get_implementation(args, {}); --> 105 cres = compiler.compile_extra(self.targetdescr.typing_context,; 106 self.targetdescr.target_context,; 107 impl,. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 625 pipeline = pipeline_class(typingctx, targetctx, library,; 626 args, return_type, flags, locals); --> 627 return pipeline.compile_extra(func); 628 ; 629 . ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in compile_extra(self, func); 361 self.state.lifted = (); 362 self.state.lifted_from = None; --> 363 return self._compile_bytecode(); 364 ; 365 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_bytecode(self); 423 """"""; 424 assert self.state.func_ir is None; --> 425 return self._compile_core(); 426 ; 427 def _compile_ir(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 403 self.state.status.fail_reason = e; 404 if is_final_pipeline:; --> 405 raise e; 406 else:; 407 raise CompilerError(""All available pipelines exhausted""). ~/.local/lib/python3.9/site-packages/numba/core/compiler.py in _compile_core(self); 394 res = None; 395 try:; --> 396 pm.run(self.state); 397 if self.state.cr is not None:; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:9236,Testability,assert,assert,9236,"iled in nopython mode pipeline (step: nopython frontend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython mode backend); Failed in nopython mode pipeline (step: nopython frontend); No implementation of function Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>) found for signature:; ; >>> run_quicksort(array(int32, 1d, C)); ; There are 2 candidate implementations:; - Of which 2 did not match due to:; Overload in function 'register_jitable.<locals>.wrap.<locals>.ov_wrap': File: numba/core/extending.py: Line 150.; With argument(s): '(array(int32, 1d, C))':; Rejected as the implementation raised a specific error:; UnsupportedError: Failed in nopython mode pipeline (step: analyzing bytecode); Use of unsupported opcode (LOAD_ASSERTION_ERROR) found; ; File ""../../../../.local/lib/python3.9/site-packages/numba/misc/quicksort.py"", line 180:; def run_quicksort(A):; <source elided>; while high - low >= SMALL_QUICKSORT:; assert n < MAX_STACK; ^; ; raised from /home/gabriel/.local/lib/python3.9/site-packages/numba/core/byteflow.py:269. During: resolving callee type: Function(<function make_quicksort_impl.<locals>.run_quicksort at 0x7f455d24c280>); During: typing of call at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5007). File ""../../../../.local/lib/python3.9/site-packages/numba/np/arrayobj.py"", line 5007:; def array_sort_impl(arr):; <source elided>; # Note we clobber the return value; sort_func(arr); ^. During: lowering ""$14call_method.5 = call $12load_method.4(func=$12load_method.4, args=[], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/numba/np/arrayobj.py (5017); During: lowering ""$8call_method.3 = call $4load_method.1(arr, func=$4load_method.1, args=[Var(arr, sparse.py:28)], kws=(), vararg=None)"" at /home/gabriel/.local/lib/python3.9/site-packages/pynndescent/sparse.py (28); During: resolving callee type: type(CPUDispatche",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:6848,Usability,Simpl,SimpleTimer,6848,":; 398 break. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state); 289 mutated |= check(pss.run_initialization, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:; 293 mutated |= check(pss.run_finalizer, internal_state). ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1652:6942,Usability,Simpl,SimpleTimer,6942,"ate); 339 (self.pipeline_name, pass_desc); 340 patched_exception = self._patch_error(msg, e); --> 341 raise patched_exception; 342 ; 343 def dependency_analysis(self):. ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in run(self, state); 330 pass_inst = _pass_registry.get(pss).pass_inst; 331 if isinstance(pass_inst, CompilerPass):; --> 332 self._runPass(idx, pass_inst, state); 333 else:; 334 raise BaseException(""Legacy pass in use""). ~/.local/lib/python3.9/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state); 289 mutated |= check(pss.run_initialization, internal_state); 290 with SimpleTimer() as pass_time:; --> 291 mutated |= check(pss.run_pass, internal_state); 292 with SimpleTimer() as finalize_time:; 293 mutated |= check(pss.run_finalizer, internal_state). ~/.local/lib/python3.9/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 262 ; 263 def check(func, compiler_state):; --> 264 mangled = func(compiler_state); 265 if mangled not in (True, False):; 266 msg = (""CompilerPass implementations should return True/False. "". ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in run_pass(self, state); 90 % (state.func_id.func_name,)):; 91 # Type inference; ---> 92 typemap, return_type, calltypes = type_inference_stage(; 93 state.typingctx,; 94 state.func_ir,. ~/.local/lib/python3.9/site-packages/numba/core/typed_passes.py in type_inference_stage(typingctx, interp, args, return_type, locals, raise_errors); 68 ; 69 infer.build_constraint(); ---> 70 infer.propagate(raise_errors=raise_errors); 71 typemap, restype, calltypes = infer.unify(raise_errors=raise_errors); 72 . ~/.local/lib/python3.9/site-packages/numba/core/typeinfer.py in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1652
https://github.com/scverse/scanpy/issues/1653:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. <!-- Please describe your wishes below: -->; e.g. squares, hexagons cc @jwrth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1653
https://github.com/scverse/scanpy/pull/1654:157,Modifiability,config,configs,157,"This fixes:; ```; Traceback (most recent call last):; File ""/private/var/folders/df/6xqpqpcd7h73b6jpx9t6cwhw0000gn/T/tmpn9tl9wf0/job_working_directory/000/2/configs/tmp_r9i0cvx"", line 15, in <module>; sc.pl.dpt_timeseries(; File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 171, in dpt_timeseries; timeseries_as_heatmap(; File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_utils.py"", line 206, in timeseries_as_heatmap; pl.colorbar(shrink=0.5); File ""/Users/mvandenb/miniconda3/envs/anndata/lib/python3.8/site-packages/matplotlib/pyplot.py"", line 2188, in colorbar; raise RuntimeError('No mappable was found to use for colorbar '; RuntimeError: No mappable was found to use for colorbar creation. First define a mappable such as an image (with imshow) or a contour set (with contourf).; ```; I see that in other places plt.colobar is used in this module you're; doing the same thing. I believe this broke in; 64f04d8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1654
https://github.com/scverse/scanpy/pull/1655:174,Usability,guid,guidelines,174,This matches the else branch and fixes problem when `figsize` or `color` for instance; are passed in. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1655:205,Usability,guid,guide,205,This matches the else branch and fixes problem when `figsize` or `color` for instance; are passed in. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1655
https://github.com/scverse/scanpy/pull/1656:173,Testability,log,log,173,"Otherwise this fails with:; ```; ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1828 import IPython; 1829 IPython.embed(); -> 1830 raise ValueError(; 1831 'groupby has to be a valid observation. '; 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index""; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:617,Usability,guid,guidelines,617,"Otherwise this fails with:; ```; ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1828 import IPython; 1829 IPython.embed(); -> 1830 raise ValueError(; 1831 'groupby has to be a valid observation. '; 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index""; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1656:648,Usability,guid,guide,648,"Otherwise this fails with:; ```; ~/miniconda3/envs/anndata/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1828 import IPython; 1829 IPython.embed(); -> 1830 raise ValueError(; 1831 'groupby has to be a valid observation. '; 1832 f'Given {group}, is not in observations: {adata.obs_keys()}' + msg. ValueError: groupby has to be a valid observation. Given ['cell_type'], is not in observations: ['cell_type'] or index name ""index""; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1656
https://github.com/scverse/scanpy/pull/1657:933,Usability,simpl,simple,933,"Hi. This is a small function I have written in response to the issue #490. It takes a list of genes as an input and outputs a list cells that express (>0) those genes at the same time. The list contains values `True` and `False` and so I found it easiest to visualise by adding `groups=[True]` parameter to `plotting` functions. Then the selected cells are coloured and on top and the rest are grey in the background. However, that adds an `NA` category to the plots legend, which I'm not sure how to remove. . As it was suggested in the issue, I include an option to impute the expression values with MAGIC. It does make the results more accurate. . As evident by the the original issue and my experience I think a lot of people may find the function useful. It presents what many people would call co-expression, although I refrained from using this name, as it could suggest something more biologically significant than what this simple function really does.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1657
https://github.com/scverse/scanpy/issues/1660:705,Availability,Error,Error,705,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:728,Availability,Error,Error,728,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:863,Testability,log,logging,863,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:258,Usability,guid,guide,258,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1660:1022,Usability,learn,learn,1022,"- [ X] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; annot = sc.queries.biomart_annotations(; ""hsapiens"",; [""external_gene_name"", ""start_position"", ""end_position"", ""chromosome_name"",""gene_biotype""],).set_index(""external_gene_name""); ```. ```pytb; 500 Server Error: Internal Server Error for url: http://www.ensembl.org:80/biomart/martservice?type=registry; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; scanpy==1.7.0 anndata==0.7.4 umap==0.4.6 numpy==1.19.2 scipy==1.4.1 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.7.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1660
https://github.com/scverse/scanpy/issues/1661:522,Availability,error,error,522,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to use sc.pl.rank_genes_groups_heatmap and the main function works great. However, the columns on the top only contain cluster name, without including a bar or color bar to indicate which genes are in this cluster. The pic below is an example of the right one from example and the error one from me. . ![image](https://user-images.githubusercontent.com/16257776/108395342-af730e00-71e3-11eb-87e8-a1c65ea3d92e.png). ![image](https://user-images.githubusercontent.com/16257776/108396028-653e5c80-71e4-11eb-9bd0-ac924e94b11c.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1661
https://github.com/scverse/scanpy/issues/1662:4,Testability,test,test,4,"The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python; @pytest.fixture(autouse=True); def close_figures_on_teardown():; yield; plt.close(""all""); ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended); * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:40,Testability,test,test,40,"The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python; @pytest.fixture(autouse=True); def close_figures_on_teardown():; yield; plt.close(""all""); ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended); * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:226,Testability,test,test,226,"The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python; @pytest.fixture(autouse=True); def close_figures_on_teardown():; yield; plt.close(""all""); ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended); * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/issues/1662:663,Testability,test,test,663,"The test suite can run into issues if a test generates a matplotlib figure but does not explicitly close it. Instead of having to remember that this call has to be added after every figure, I think we should just add a global test teardown that closes open figures. I think this will look like:. ```python; @pytest.fixture(autouse=True); def close_figures_on_teardown():; yield; plt.close(""all""); ```. * [Docs for yield](https://docs.pytest.org/en/stable/fixture.html#yield-fixtures-recommended); * [Docs for autouse](https://docs.pytest.org/en/stable/fixture.html#autouse-fixtures-fixtures-you-don-t-have-to-request). This looks to have an overhead of ~50µs per test, so not a big deal.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1662
https://github.com/scverse/scanpy/pull/1663:493,Availability,avail,available,493,"While I was looking through the scanpy source code, I found a note that says `# dask doesn't do medians`. https://github.com/theislab/scanpy/blob/0c4ca5b21524c2972d514ddbd85834002ed623de/scanpy/preprocessing/_normalization.py#L17. Dask does in fact do medians, provided it's applied along an axis: https://github.com/dask/dask/pull/5575; But this feature was only merged in November 2019 (the same month the comment above was added), so I think it was too new at the time to be widely known & available. This PR attempts to remove the coercion to numpy, and allow dask arrays to propagate through the `_normalize_data` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1663
https://github.com/scverse/scanpy/pull/1665:19,Deployability,Release,Release,19,Backport PR #1628: Release notes reorganization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1665
https://github.com/scverse/scanpy/pull/1666:41,Deployability,release,release,41,Adding section to start collecting 1.8.0 release notes in,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1666
https://github.com/scverse/scanpy/pull/1667:648,Energy Efficiency,Schedul,Scheduling,648,"I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations ; - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:337,Modifiability,layers,layers,337,"I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations ; - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:393,Modifiability,layers,layers,393,"I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations ; - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1667:617,Testability,Test,Tests,617,"I was looking over normalize_total and saw some strange behaviour. Since it's such a common function, I think it's important that it has standard scanpy behaviour. To this end, this PR looks at cleanup up it's code. ### Addition. `layer` argument. A specific layer can now be normalized by itself. ### Deprecations. I've deprecated the `layers` and `layer_norm` argument. Normalizing multiple layers at once seems less useful than normalizing a specific layer. These seem like very specific use cases that are easy for user's to implement themselves, and are not common patterns in scanpy functions. ### TODO:. - [x] Tests for deprecations ; - [x] Scheduling of deprecations (deprecate in 1.8, remove in 1.9)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1667
https://github.com/scverse/scanpy/pull/1669:100,Modifiability,config,configs,100,"Fixes; ```; Traceback (most recent call last):; File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>; scale='width'); File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin; df[g] = X_col; File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item; self._ensure_valid_index(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index; value = Series(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__; data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array; raise Exception(""Data must be 1-dimensional""); Exception: Data must be 1-dimensional; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1114,Usability,guid,guidelines,1114,"Fixes; ```; Traceback (most recent call last):; File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>; scale='width'); File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin; df[g] = X_col; File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item; self._ensure_valid_index(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index; value = Series(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__; data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array; raise Exception(""Data must be 1-dimensional""); Exception: Data must be 1-dimensional; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/pull/1669:1145,Usability,guid,guide,1145,"Fixes; ```; Traceback (most recent call last):; File ""/tmp/tmptq4o33we/job_working_directory/000/50/configs/tmpe21tizb1"", line 29, in <module>; scale='width'); File ""/usr/local/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py"", line 564, in rank_genes_groups_violin; df[g] = X_col; File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3487, in __setitem__; self._set_item(key, value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3563, in _set_item; self._ensure_valid_index(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 3540, in _ensure_valid_index; value = Series(value); File ""/usr/local/lib/python3.7/site-packages/pandas/core/series.py"", line 314, in __init__; data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); File ""/usr/local/lib/python3.7/site-packages/pandas/core/internals/construction.py"", line 729, in sanitize_array; raise Exception(""Data must be 1-dimensional""); Exception: Data must be 1-dimensional; ```. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1669
https://github.com/scverse/scanpy/issues/1670:4631,Deployability,update,updated,4631," such a method in its. ValueError: provided out is the wrong size for the reduction; ```. #### Versions. <details>. ```; -----; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fcsparser 0.2.1; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; markupsafe 1.1.1; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; palantir 1.0.0; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; rpy2 3.4.2; sca NA; scanpy 1.7.0; scipy 1.4.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-19 11:23; ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4337,Integrability,wrap,wrapt,4337," such a method in its. ValueError: provided out is the wrong size for the reduction; ```. #### Versions. <details>. ```; -----; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fcsparser 0.2.1; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; markupsafe 1.1.1; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; palantir 1.0.0; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; rpy2 3.4.2; sca NA; scanpy 1.7.0; scipy 1.4.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-19 11:23; ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/issues/1670:4577,Testability,log,logical,4577," such a method in its. ValueError: provided out is the wrong size for the reduction; ```. #### Versions. <details>. ```; -----; anndata 0.7.4; scanpy 1.7.0; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 7.2.0; anndata 0.7.4; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fcsparser 0.2.1; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; markupsafe 1.1.1; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; palantir 1.0.0; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.6; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; rpy2 3.4.2; sca NA; scanpy 1.7.0; scipy 1.4.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; tzlocal NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-02-19 11:23; ```; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1670
https://github.com/scverse/scanpy/pull/1671:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/pull/1671:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Fixes #1662,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1671
https://github.com/scverse/scanpy/issues/1673:109,Usability,simpl,simple,109,"- [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/issues/1673:448,Usability,guid,guides,448,"- [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. We should add more links to scanpy's [`project_url`](https://packaging.python.org/guides/distributing-packages-using-setuptools/#project-urls) metadata. Docs, twitter, and discourse for sure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1673
https://github.com/scverse/scanpy/pull/1674:61,Integrability,rout,routines,61,Backport PR #1659: Fix passing of arguments between scrublet routines,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1674
https://github.com/scverse/scanpy/issues/1675:660,Availability,ping,pinging,660,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:355,Deployability,install,installing,355,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/issues/1675:466,Testability,benchmark,benchmarks,466,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. in the last months there's been several people raising issues about `sc.pp.neighbors` being very slow. After pointing them to installing `pynndescent` they noticed considerable improvements in run times.; pynndescent is still top of the benchmarks afaik https://github.com/lmcinnes/pynndescent. Problems are that:; - afaik there's nowhere in the docs where this is documented; - it might be a good idea to just add it as default?. pinging @Koncopd @ivirshup , happy to add a line about pynndescent, just need to know where.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1675
https://github.com/scverse/scanpy/pull/1679:378,Usability,clear,clearly,378,"fixes #1642 . I'll reply to the comments here @adamgayoso . > shouldn't both not be Optional? . I removed optional `type` from both span and `check_values`. > On another note, in this current state check_nonnegative_integers is an unused import. Do you guys check for this with flake8?. we don't have pre-commit in place, we are discussing it here #1563 . I do check flake8 but clearly didn't do it this time. > I think a bug has been introduced @ivirshup @giovp. Namely, the call to check_nonnegative_integers(X) was removed (should be here on line 61) if returns False, raise the warning. this should be fixed now. Sorry again for very sloppy handling of this, should be ready to review",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1679
https://github.com/scverse/scanpy/pull/1680:63,Availability,Ping,Pinging,63,This PR aims at closing couple of open issues related to docs. Pinging original users who opened the issues. - closes #1675 add pynndescent note (me); - closes #1434 clarify qc metric and normalize total @havardtl; - closes #827 clarify diff component indexing @veghp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1680
https://github.com/scverse/scanpy/pull/1683:20,Deployability,release,release,20,Add some straggling release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1683
https://github.com/scverse/scanpy/pull/1685:98,Usability,guid,guidelines,98,Why is nothing happening. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1685:129,Usability,guid,guide,129,Why is nothing happening. <!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1685
https://github.com/scverse/scanpy/pull/1686:19,Deployability,Update,Update,19,Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1686:26,Deployability,release,release,26,Backport PR #1683: Update release notes for 1.7.1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1686
https://github.com/scverse/scanpy/pull/1690:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1690:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1690
https://github.com/scverse/scanpy/pull/1691:128,Testability,test,test,128,"`importlib_metadata` does not have a `__version__` attribute. This breaks `sinfo`. We can just skip getting it's version. Also, test that `print_versions` works. Fixes #1437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1691
https://github.com/scverse/scanpy/issues/1694:610,Modifiability,variab,variable,610,"This will be the discussion that no one ever wants since developers like us tend to bring our mice and keyboards to fight when it comes to questions like these, but hey I thought at some point it should be had anyways haha. @ivirshup recently introduced black as the formatting standard for Scanpy. I am not a fan of blacks formatting, but the idea of consistent formatting for big open source projects is great! So +1 from me. Anyways, currently black formats with 88 characters per line, which makes, especially with black, for lots and lots of line breaks and encourages bad practices like unspecific short variable names etc. Modern Python programming is not C programming from the 80s. Have a read at Linus rant on the 80 character limit in the Linux kernel and why the Linux kernel does **not** enforce it: https://lkml.org/lkml/2020/5/29/1038 . Applying black with a 120 characters limit removes about 1500 lines. That's 1500 lines that you have to scroll less and in my opinion the result is more readable. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1694
https://github.com/scverse/scanpy/issues/1698:89,Modifiability,variab,variable,89,Could you add Moran's I calculation to Scanpy? It could be used in scIB and to also find variable genes across embedding (could be an alternative to SEMITONES that takes a while to be computed).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1698
https://github.com/scverse/scanpy/pull/1695:226,Testability,test,test,226,"Fixes #1396. Branch which I had sitting on my computer, but forgot to open a PR for (doh). Uses joblib to parallelize `regress_out` instead of `multiprocessing` in order to prevent oversubscription of threads. Not sure how to test this. Should I also allow passing more arguments to joblib?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1695
https://github.com/scverse/scanpy/issues/1696:177,Availability,error,error,177,"Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2; scanpy = 1.7.1. Does anyone encounter similar issue?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:197,Availability,ERROR,ERROR,197,"Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2; scanpy = 1.7.1. Does anyone encounter similar issue?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1696:236,Availability,error,error,236,"Hi all,. When running ""sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)"" from this [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html) , the following error arises. ""LLVM ERROR: Symbol not found: __svml_sqrtf8 error when running"". numba = 0.51.2; scanpy = 1.7.1. Does anyone encounter similar issue?. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1696
https://github.com/scverse/scanpy/issues/1697:127,Energy Efficiency,schedul,schedule,127,"Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this?. Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations); * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools); * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:551,Security,access,access,551,"Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this?. Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations); * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools); * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1697:649,Security,access,access-to-module-attributes,649,"Numpy has dropped support for python 3.6 in 1.20.0, and have recommended that packages in the pydata ecosystem adopt a similar schedule for python versions ([NEP 29](https://numpy.org/neps/nep-0029-deprecation_policy.html)). Should we follow this?. Some cool stuff we get by dropping 3.6:. * [Postponed evaluation of type annotations](https://docs.python.org/3/whatsnew/3.7.html#pep-563-postponed-evaluation-of-annotations); * [`singledispatch` can register from type annotations](https://docs.python.org/3/whatsnew/3.7.html#functools); * [Customized access to module attributes](https://docs.python.org/3/whatsnew/3.7.html#pep-562-customization-of-access-to-module-attributes). Also, users will be pinned to old versions of numpy if they're using 3.6, and maybe we don't want to deal with that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1697
https://github.com/scverse/scanpy/issues/1701:395,Availability,error,error,395,"- [ X] I have checked that this issue has not already been reported.; - [ X] I have confirmed this bug exists on the latest version of scanpy.; - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi. I'm trying to do a standard analysis of cells with `scanpy?`; however, I'm having a weird issue with plotting the results. . For instance, I get the following error when I try to visualise the cell states on my data: . ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], size = 1, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 09 57 24](https://user-images.githubusercontent.com/3297906/109481342-8882ca80-7a74-11eb-83bb-8e934b08aedb.png). As you can see, the labels are there, but somehow the colours do not make it to the UMAP. When I look for a specific subpopulation, it seems that it finds it, but somehow it doesn't display it. ```python; sc.pl.umap(combined_bbknn, color = ['scNym'], groups = ['NKT'], size = 3, legend_fontsize = 6, color_map = 'RdPu', frameon = False); ```; ![Screenshot 2021-03-01 at 10 06 21](https://user-images.githubusercontent.com/3297906/109482348-c92f1380-7a75-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2216,Availability,error,error,2216,"5-11eb-9cfb-4a348fb5ed9e.png). I checked if there was something odd with the labels, but they are there. . ```python; combined_bbknn.obs['scNym'].cat.categories. Index(['Adip1', 'B_memory', 'CD4+T_cytox', 'CD8+T_tem', 'CD14+Monocyte',; 'DOCK4+MØ1', 'EC1_cap', 'EC3_cap', 'EC4_immune', 'EC5_art', 'EC6_ven',; 'EC7_atria', 'FB1', 'FB2', 'FB3', 'FB4', 'FB5', 'Mast', 'Meso', 'MØ',; 'NC1', 'NK', 'NKT', 'PC1_vent', 'PC2_atria', 'PC3_str', 'SMC1_basic',; 'SMC2_art', 'aCM1', 'aCM3', 'vCM1', 'vCM2', 'vCM3'],; dtype='object'); ```. They even have assigned colours: . ```; ('scNym_colors', ['#FFFF00', '#1CE6FF', '#FF34FF', '#FF4A46', '#008941', '#006FA6', '#A30059', '#FFDBE5', '#7A4900', '#0000A6', '#63FFAC', '#B79762', '#004D43', '#8FB0FF', '#997D87', '#5A0007', '#809693', '#6A3A4C', '#1B4400', '#4FC601', '#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]); ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python; marker_genes = ['PERM1', 'GAB3', 'G6PD']; combined_bbknn.var_names_make_unique(); sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'); ```; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-17-3392793686cd> in <module>; 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']; 2 combined_bbknn.var_names_make_unique(); ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 949 return dp; 950 else:; --> 951",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4595,Availability,error,error,4595,"); 733 ; 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4609,Availability,down,downgraded,4609,"a/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:4645,Availability,error,error,4645,"py/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_size_legend(self, size_legend_ax); 418 # a descending range that is afterwards inverted is used; 419 # to guarantee that dot_max is in the legend.; --> 420 size_range = np.arange(self.dot_max, self.dot_min, step * -1)[::-1]; 421 if self.dot_min != 0 or self.dot_max != 1:; 422 dot_range = self.dot_max - self.dot_min. ValueError: arange: cannot compute length; ```; and this figure: . ![Screenshot 2021-03-01 at 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.14; psutil 5.8.0; ptyprocess 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6375,Deployability,update,updated,6375,"t 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.14; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.7.4; pyparsing 2.4.7; pyrsistent NA; pytz 2020.5; requests 2.23.0; ruamel NA; scanpy 1.7.1; scipy 1.4.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.22.2.post1; sniffio 1.2.0; socks 1.7.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.3.10; urllib3 1.25.8; wcwidth 0.2.5; yaml 5.3.1; zmq 21.0.1; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 3.0.5; notebook 6.2.0; -----; Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]; Linux-4.15.0-112-generic-x86_64-with-glibc2.10; 60 logical CPU cores, x86_64; -----; Session information updated at 2021-03-01 09:45. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:2833,Testability,log,log,2833,"#3B5DFF', '#4A3B53', '#FF2F80', '#61615A', '#BA0900', '#6B7900', '#00C2A0', '#FFAA92', '#FF90C9', '#B903AA', '#D16100', '#DDEFFF', '#000035'])]); ```. Then I tried to plot some markers using the dotplot function, but then I got this error: . ``` python; marker_genes = ['PERM1', 'GAB3', 'G6PD']; combined_bbknn.var_names_make_unique(); sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'); ```; ```; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-17-3392793686cd> in <module>; 1 marker_genes = ['PERM1', 'GAB3', 'G6PD']; 2 combined_bbknn.var_names_make_unique(); ----> 3 sc.pl.dotplot(combined_bbknn, marker_genes, groupby = 'scNym'). /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 949 return dp; 950 else:; --> 951 dp.make_figure(); 952 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 953 show = settings.autoshow if show is None else show. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py in make_figure(self); 730 if self.legends_width > 0:; 731 legend_ax = self.fig.add_subplot(gs[0, 1]); --> 732 self._plot_legend(legend_ax, return_ax_dict, normalize); 733 ; 734 self.ax_dict = return_ax_dict. /opt/conda/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 490 if self.show_size_legend:; 491 size_legend_ax = fig.add_subplot(legend_gs[1]); --> 492 self._plot_size_legend(size_legend_ax); 493 return_ax_dict['size_legend_ax'] = size_legend_ax; 494 . /opt/conda/lib/python3.8/site-packages/scanpy/plotting/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/issues/1701:6321,Testability,log,logical,6321,"t 10 02 44](https://user-images.githubusercontent.com/3297906/109481911-47d78100-7a75-11eb-96c0-b24c1487d0a7.png). I have tried this in a MacOS and two Linux machines with the same error. I have downgraded to `scanpy==1.6` and the error seems to persist. . Any help would be appreciated. . <details>. -----; anndata 0.7.4; scanpy 1.7.1; sinfo 0.3.1; -----; OpenSSL 20.0.1; PIL 8.1.0; anndata 0.7.4; annoy NA; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bbknn NA; brotli NA; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cryptography 3.3.1; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.0; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.49.1; numexpr 2.7.2; numpy 1.18.2; packaging 20.8; pandas 1.0.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.14; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.7.4; pyparsing 2.4.7; pyrsistent NA; pytz 2020.5; requests 2.23.0; ruamel NA; scanpy 1.7.1; scipy 1.4.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.14.0; sklearn 0.22.2.post1; sniffio 1.2.0; socks 1.7.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.3.10; urllib3 1.25.8; wcwidth 0.2.5; yaml 5.3.1; zmq 21.0.1; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 3.0.5; notebook 6.2.0; -----; Python 3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 05:05:16) [GCC 9.3.0]; Linux-4.15.0-112-generic-x86_64-with-glibc2.10; 60 logical CPU cores, x86_64; -----; Session information updated at 2021-03-01 09:45. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1701
https://github.com/scverse/scanpy/pull/1702:177,Availability,down,downgrades,177,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:161,Deployability,install,install,161,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:196,Deployability,install,install,196,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1702:208,Deployability,install,installed,208,"Hahaha and of course after weeks of this bug, everything gets resolved the day I press the merge button. takluyver/flit#395 should fix the issues where. 1. `pip install scvelo` downgrades a `flit install -s` installed scanpy (now the `dist-info` dir name contains the correct version); 2. The wheel built by flit now corresponds to the freshly-changed spec’s [mangling rules](https://packaging.python.org/specifications/binary-distribution-format/#escaping-and-unicode). So we can remove the workarounds. No problem, `git blame` won’t be affected much, this almost exclusively deletes lines.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1702
https://github.com/scverse/scanpy/pull/1703:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1703:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1703
https://github.com/scverse/scanpy/pull/1704:0,Testability,Test,Testing,0,Testing codecov comment to make seeing coverage easier.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1704
https://github.com/scverse/scanpy/issues/1705:131,Integrability,depend,dependent,131,"@fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>; <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1705:56,Modifiability,extend,extend,56,"@fidelram . As noted in #1632, dotplot labels can often extend outside of the plotted area. Whether the full labels can be seen is dependent on how the plots are being output. It would be great if this always worked. <details>; <summary> Example from the docs: </summary>. ![](https://user-images.githubusercontent.com/8238804/107312688-122e2080-6ae5-11eb-8a7e-f61c51a8392c.png). </details>. Could possibly be solved by using `matplotlib`'s `constrained_layout` or `tight_layout`. I think these would require modifying how the grid spec and axes are created.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1705
https://github.com/scverse/scanpy/issues/1706:2726,Testability,log,logging,2726,"ties' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; after removing the cwd from sys.path. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-28-2906b54049c5> in <module>; 3 sc.pp.neighbors(adata, n_neighbors=1); 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A); ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 194 neigh_params.get('metric', 'euclidean'),; 195 neigh_params.get('metric_kwds', {}),; --> 196 verbose=settings.verbosity > 3,; 197 ); 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose); 1022 n_epochs = 200; 1023 ; -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0; 1025 graph.eliminate_zeros(); 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where); 37 def _amax(a, axis=None, out=None, keepdims=False,; 38 initial=_NoValue, where=True):; ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where); 40 ; 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions; For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue.; <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/issues/1706:2897,Usability,learn,learn,2897,"ties' is deprecated. It has been moved to .obsp[connectivities], and will not be accesible here in a future version of anndata.; after removing the cwd from sys.path. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-28-2906b54049c5> in <module>; 3 sc.pp.neighbors(adata, n_neighbors=1); 4 print('Connectivities:\n', adata.uns['neighbors']['connectivities'].A); ----> 5 sc.tl.umap(adata). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 194 neigh_params.get('metric', 'euclidean'),; 195 neigh_params.get('metric_kwds', {}),; --> 196 verbose=settings.verbosity > 3,; 197 ); 198 elif method == 'rapids':. /opt/conda/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose); 1022 n_epochs = 200; 1023 ; -> 1024 graph.data[graph.data < (graph.data.max() / float(n_epochs))] = 0.0; 1025 graph.eliminate_zeros(); 1026 . /opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py in _amax(a, axis, out, keepdims, initial, where); 37 def _amax(a, axis=None, out=None, keepdims=False,; 38 initial=_NoValue, where=True):; ---> 39 return umr_maximum(a, axis, None, out, keepdims, initial, where); 40 ; 41 def _amin(a, axis=None, out=None, keepdims=False,. ValueError: zero-size array to reduction operation maximum which has no identity. ```. #### Versions; For me, scanpy.logging.print_versions() crashes due to the importlib_metadata issue.; <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.20.0 scipy==1.6.0 pandas==1.2.1 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1706
https://github.com/scverse/scanpy/pull/1707:89,Integrability,inject,injection,89,"This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:321,Integrability,depend,dependency,321,"This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/pull/1707:89,Security,inject,injection,89,"This PR addresses https://github.com/theislab/scanpy/issues/1645, which was caused by my injection of normalised matrices from Scanpy workflows, thereby bypassing a sparseness check Scrublet does with the raw matrix. The fix contained here is apply the Scrublet sparseness check, before calling Scrublet functions with a dependency on sparseness.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1707
https://github.com/scverse/scanpy/issues/1708:301,Energy Efficiency,adapt,adapt,301,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-6-455e630e3278> in <module>; 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 286 X.eliminate_zeros(); 287 ; --> 288 obs_metrics = describe_obs(; 289 adata,; 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 49 return self._get_sliceXslice(row, col); 50 elif col.ndim == 1:; ---> 51 return self._get_sliceXarray(row, col); 52 raise IndexError('index results in >2 dimensions'); 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:301,Modifiability,adapt,adapt,301,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. To do some trajectory analysis, I wanted to first try some tutorials to adapt to the workflow of scanpy, after calling sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True) i got the valueerror below. I also tried different Drosophila Datasets and it always happens, and its due to a gene called ""nan"" in the features.tsv or genes.tsv, if this gene is renamed, scanpy works as intended. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-6-455e630e3278> in <module>; 1 adata.var['mt'] = adata.var_names.str.startswith('mt:') # annotate the group of mitochondrial genes as 'mt'; ----> 2 sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 286 X.eliminate_zeros(); 287 ; --> 288 obs_metrics = describe_obs(; 289 adata,; 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 49 return self._get_sliceXslice(row, col); 50 elif col.ndim == 1:; ---> 51 return self._get_sliceXarray(row, col); 52 raise IndexError('index results in >2 dimensions'); 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1708:2887,Usability,learn,learn,2887,"_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 286 X.eliminate_zeros(); 287 ; --> 288 obs_metrics = describe_obs(; 289 adata,; 290 expr_type=expr_type,. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel); 119 for qc_var in qc_vars:; 120 obs_metrics[f""total_{expr_type}_{qc_var}""] = (; --> 121 X[:, adata.var[qc_var].values].sum(axis=1); 122 ); 123 if log1p:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\_index.py in __getitem__(self, key); 49 return self._get_sliceXslice(row, col); 50 elif col.ndim == 1:; ---> 51 return self._get_sliceXarray(row, col); 52 raise IndexError('index results in >2 dimensions'); 53 elif row.ndim == 1:. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\csr.py in _get_sliceXarray(self, row, col); 321 ; 322 def _get_sliceXarray(self, row, col):; --> 323 return self._major_slice(row)._minor_index_fancy(col); 324 ; 325 def _get_arrayXint(self, row, col):. C:\ProgramData\Anaconda3\lib\site-packages\scipy\sparse\compressed.py in _minor_index_fancy(self, idx); 737 """"""; 738 idx_dtype = self.indices.dtype; --> 739 idx = np.asarray(idx, dtype=idx_dtype).ravel(); 740 ; 741 M, N = self._swap(self.shape). C:\ProgramData\Anaconda3\lib\site-packages\numpy\core\_asarray.py in asarray(a, dtype, order, like); 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like); 101 ; --> 102 return array(a, dtype, copy=False, order=order); 103 ; 104 . ValueError: cannot convert float NaN to integer; ```. #### Versions. <details>. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.20.1 scipy==1.6.1 pandas==1.1.3 scikit-learn==0.23.2 statsmodels==0.12.0 python-igraph==0.9.0 leidenalg==0.8.3. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1708
https://github.com/scverse/scanpy/issues/1709:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; It would be great to see alternative statistics to ""mean"" in [matrixplot](https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.matrixplot.html), e.g., median, variance come to mind.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1709
https://github.com/scverse/scanpy/pull/1711:58,Integrability,depend,dependent,58,Backport PR #1707: Add sparsificiation step before sparse-dependent Scrublet calls,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1711
https://github.com/scverse/scanpy/pull/1713:80,Safety,detect,detected,80,"By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/pull/1713:173,Testability,test,tests,173,"By default, Travis does `git clone --depth=50` which means the version can’t be detected from the git tag. In case we ever start relying on the version being correct in the tests, this fixes it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1713
https://github.com/scverse/scanpy/issues/1714:745,Availability,error,error,745,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```when I run ; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb; [Paste the error output produced by the above code here]; ```; Traceback (most recent call last):; File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2157,Availability,error,error,2157,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2252,Availability,error,error,2252,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2579,Availability,error,error,2579,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2601,Availability,Error,Error,2601,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:1897,Safety,timeout,timeout,1897,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2836,Testability,log,logging,2836,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:384,Usability,guid,guide,384,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hi, I tried to use the tutorial of Analysis and visualization of spatial transcriptomics data but is seems have some problems. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```when I run ; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""). ```pytb; [Paste the error output produced by the above code here]; ```; Traceback (most recent call last):; File ""/tmp/pycharm_project_346/spatial.py"", line 11, in <module>; adata = sc.datasets.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/issues/1714:2773,Usability,learn,learn,2773,"ts.visium_sge(sample_id=""V1_Human_Lymph_Node""); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 367, in visium_sge; _download_visium_dataset(sample_id); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/datasets/_datasets.py"", line 325, in _download_visium_dataset; _utils.check_presence_download(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/_utils.py"", line 604, in check_presence_download; _download(backup_url, filename); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/site-packages/scanpy/readwrite.py"", line 905, in _download; urlretrieve(url, str(path), reporthook=update_to); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 247, in urlretrieve; with contextlib.closing(urlopen(url, data)) as fp:; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 222, in urlopen; return opener.open(url, data, timeout); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 531, in open; response = meth(req, response); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 640, in http_response; response = self.parent.error(; File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 502, in _call_chain; result = func(*args); File ""/data/lu/anaconda3/envs/spatial_t/lib/python3.8/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 403: Forbidden. Process finished with exit code 1. #### Versions. <details>; scanpy==1.5.0 anndata==0.7.1 umap==0.4.2 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.1 statsmodels==0.11.0. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1714
https://github.com/scverse/scanpy/pull/1715:74,Deployability,integrat,integrates,74,"Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:; - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc).; - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA; - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed!. Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:928,Energy Efficiency,efficient,efficient,928,"Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:; - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc).; - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA; - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed!. Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:74,Integrability,integrat,integrates,74,"Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:; - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc).; - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA; - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed!. Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/pull/1715:540,Modifiability,layers,layers,540,"Hi everyone,. a while back, @giovp asked me to create a pull request that integrates analytical Pearson residuals in scanpy. We already discussed a bit with @LuckyMD and @ivirshup over at berenslab/umi-normalization#1 how to structure it, and now I made a version that should be ready for review. As discussed earlier, this pull request implements two core methods:; - `sc.pp.normalize_pearson_residuals()`, which applies the method to `adata.X`. Overall, the function is very similar in structure to `sc.pp.normalize_total()` (support for layers, inplace operation etc).; - `sc.pp.highly_variable_genes(flavor='pearson_residuals')`, which selects genes based on Pearson residual variance. The ""inner"" function `_highly_variable_pearson_residuals()` is structured similarly to `_highly_variable_seurat_v3()` (support for multiple batches, median ranks for tie breaking). It includes the `chunksize` argument to allow for memory-efficient computation of the residual variance. We discussed quite a lot how to implement a third function that would bundle gene selection, normalization by analytical residuals and PCA. This PR includes the two options that emerged at the end of that discussion, so now we have to choose ;). - `sc.pp.recipe_pearson_residuals()` which does HVG selection and normalization both via Pearson residuals prior to PCA; - `sc.pp.normalize_pearson_residuals_pca()` which applies any HVG selection if the user previously added one to the `adata` object, and then normalizes via Pearson residuals and does PCA. Both functions retain the raw input counts as `adata.X` and add fields for PCA/Normalization/HVG selection results (or return them) as applicable, most importantly the `X_pca` in `adata.obsm['pearson_residuals_X_pca']`. I hope this addresses some of the issues we discussed over at the other repo in a scanpy-y way. Let me know what you think and where you think improvements are needed!. Cheers, Jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1715
https://github.com/scverse/scanpy/issues/1716:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [x] Other?. We started a [gitter](https://gitter.im/scvi-tools/development) at scvi-tools and surprisingly it has gotten more traction than our Discourse forum. Just putting it out there to gauge interest here. You could have a development room and a usage room. The pros are that it's more informal and less of a barrier of entry compared to github issues, cons include that it's not as searchable (though I'm a novice with it). I feel that you might be able to get better community answers if gitter became actively used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1716
https://github.com/scverse/scanpy/issues/1719:386,Deployability,integrat,integrating,386,"Hi Scanpy team!. After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general?. Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:259,Integrability,depend,dependent,259,"Hi Scanpy team!. After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general?. Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:386,Integrability,integrat,integrating,386,"Hi Scanpy team!. After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general?. Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1719:552,Integrability,interface,interface,552,"Hi Scanpy team!. After facing the issue with duplicated gene symbols again for the n-th time, I realised that one of the best solutions for renaming duplicates would likely be to do the following `'DuplicatedName-ENSEMBL_ID'` rather than just adding an order-dependent number `'DuplicatedName-1'` that can differ between dataset from different papers - preventing correct matching when integrating datasets which in turn essentially requires deleting duplicated genes. . What do you think in general?. Would it be possible to add support for this with interface like `var_names_make_unique(unique_column='ENSEMBL')`?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1719
https://github.com/scverse/scanpy/issues/1720:202,Deployability,continuous,continuously,202,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?. <!-- Please describe your wishes below: -->; Hi there, I have continuously tried to save my dotplots and umaps from scanpy in PDF or SVG; format with the hope to be able and import it on Illustrator for further processing for publication; purposes. Everything works fine with the images, but the text of the labels is not any more recognized ; as text and thus I cannot change the family font/size or correct the text if need be. Any chance you guys have a plan to allow for this type of functionality shortly?. Best,; Anastasia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1720
https://github.com/scverse/scanpy/pull/1722:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/pull/1722:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1722
https://github.com/scverse/scanpy/issues/1723:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. Allow using seaborn color map strings: https://twitter.com/michaelwaskom/status/1367553033454968834. ![image](https://user-images.githubusercontent.com/8238804/110413994-1ef16480-80e3-11eb-9d46-c7ba3ffe3f1f.png). I think this should be as easy as swapping out `mpl.cm.get_cmap` for `sns.color_palette`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1723
https://github.com/scverse/scanpy/issues/1724:758,Deployability,integrat,integration,758,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1068,Deployability,integrat,integration,1068,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1817,Deployability,integrat,integrate,1817,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:758,Integrability,integrat,integration,758,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1068,Integrability,integrat,integration,1068,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1817,Integrability,integrat,integrate,1817,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1724:1548,Modifiability,layers,layers,1548,"Hi everyone,. Seeing how many new single cell and spatial tools are being developed in Python, and how we are increasingly using it in general and scanpy in particular, at saezlab we decided to re-implement our tools to estimate pathways and Transcription factor (TF) activity ([Dorothea](https://saezlab.github.io/dorothea/) and [Progeny](https://saezlab.github.io/progeny/)) in it. Here's a first draft in Python of our tools:; https://github.com/saezlab/dorothea-py; https://github.com/saezlab/progeny-py. Our tools take gene expression as input and generate matrices of TF and pathway activities. They can be understood as: ; 1) Prior-knowledge dimensionality reduction methods (`obsm`). Examples of usage:; 	* Used as input for NN; 	* Used as input for integration methods; 2) New data assays (`X`). Examples of usage:; 	* Plot feature activities in projections such as PCA or UMAP; 	* Plot feature activities in heat-maps, clustermaps, violin plots, etc; 	* Differences between groups can be modeled to find significant differences. Because of this duality, the integration of our tools into scanpy is not straightforward. If we store the activities in `obsm` they can be used as a dimensonality reduction embedding but then we lose acces to all the fantastic plotting functions based on `X`. Then if we add add our activities to `X`, they have a very different distribution than gene expression plus there would be an overlap of names between genes and TFs. A solution to this would be to have a separate `.layer` to store this matrices but layers must contain the same dimensions as `X`. Another workaround would be to store it in `.raw` but then we force the user to use remove its previous contents, plus it is used in some methods as default which could cause problems. . What would be a smart solution to integrate our tools in your universe?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1724
https://github.com/scverse/scanpy/issues/1725:4744,Deployability,update,updated,4744,"re version. Use .loc with labels or .iloc with positions instead.; df.loc[: int(n_top_genes), 'highly_variable'] = True; /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead.; df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1.dev2+g8c469411; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; certifi 2020.12.05; cffi 1.14.4; chardet 4.0.0; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; highs_wrapper NA; idna 2.10; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.1; jupyterlab_server 2.1.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbclassic NA; nbformat 5.0.8; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.0; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.10; ptyprocess 0.7.0; pvectorc NA; pygments 2.7.3; pyparsing 2.4.7; pyrsistent NA; pytz 2020.5; requests 2.25.1; scanpy 1.7.1.dev2+g8c469411; scipy 1.6.0; send2trash NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.0; sniffio 1.2.0; storemagic NA; tables 3.6.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.2; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 3.0.3; notebook 6.1.6; -----; Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]; Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-03-09 19:18. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1725:4690,Testability,log,logical,4690,"re version. Use .loc with labels or .iloc with positions instead.; df.loc[: int(n_top_genes), 'highly_variable'] = True; /gpfs01/berens/user/jlause/libs/scanpy/scanpy/preprocessing/_highly_variable_genes.py:146: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version. Use .loc with labels or .iloc with positions instead.; df.loc[: int(n_top_genes), 'highly_variable'] = True. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1.dev2+g8c469411; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; certifi 2020.12.05; cffi 1.14.4; chardet 4.0.0; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; google NA; h5py 2.10.0; highs_wrapper NA; idna 2.10; ipykernel 5.4.2; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.1; jupyterlab_server 2.1.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbclassic NA; nbformat 5.0.8; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.0; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.10; ptyprocess 0.7.0; pvectorc NA; pygments 2.7.3; pyparsing 2.4.7; pyrsistent NA; pytz 2020.5; requests 2.25.1; scanpy 1.7.1.dev2+g8c469411; scipy 1.6.0; send2trash NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.0; sniffio 1.2.0; storemagic NA; tables 3.6.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.2; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.0; jupyterlab 3.0.3; notebook 6.1.6; -----; Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]; Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-03-09 19:18. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1725
https://github.com/scverse/scanpy/issues/1731:970,Performance,cache,cache,970,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1130,Performance,cache,cache,1130,"analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1500,Performance,cache,cache,1500,"r non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1632,Performance,cache,cache,1632,", but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1638,Performance,cache,cache,1638,", but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:1800,Performance,cache,cache,1800,"-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files there:; ```; ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/; barcodes.tsv features.tsv matr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2142,Performance,cache,cache,2142,"92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files there:; ```; ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/; barcodes.tsv features.tsv matrix.mtx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2350,Performance,cache,cache,2350,"92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files there:; ```; ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/; barcodes.tsv features.tsv matrix.mtx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:2304,Testability,log,logg,2304,"92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs); 713 ; 714 if not is_present:; --> 715 raise FileNotFoundError(f'Did not find file {filename}.'); 716 logg.debug(f'reading {filename}'); 717 if not cache and not suppress_cache_warning:. FileNotFoundError: Did not find file /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/matrix.mtx.gz. ```; But I have 10x files there:; ```; ls /storage/groups/ml01/projects/2020_pancreas_karin.hrovatin/data/pancreas/scRNA/islets_aged_fltp_iCre/rev6/cellranger/MUC13974/count_matrices/filtered_feature_bc_matrix/; barcodes.tsv features.tsv matrix.mtx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1731:168,Usability,simpl,simple,168,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; In function read_10x_mtx there could be an option to search for non-gzipped files when reading v3 10x. Currently, I have files barcodes.tsv features.tsv matrix.mtx, but the function will not read them as they are not gzipped.; ...; ```; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); <ipython-input-8-72e92bd46023> in <module>; ----> 1 adata=sc.read_10x_mtx(path,; 2 var_names='gene_symbols',; 3 make_unique=True,; 4 cache=False,; 5 cache_compression=None,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 468 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 469 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 470 adata = read(; 471 str(path),; 472 var_names=var_names,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 530 """"""; 531 path = Path(path); --> 532 adata = read(; 533 path / f'{prefix}matrix.mtx.gz',; 534 cache=cache,. ~/miniconda3/envs/rpy2_3/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs); 110 filename = Path(filename) # allow passing strings; 111 if is_valid_filename(filename):; --> 112 return _read(; 113 filename,; 114 backed=backed,. ~/miniconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1731
https://github.com/scverse/scanpy/issues/1733:3722,Deployability,update,updated,3722,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python; import numpy as np; import scanpy as sc; import anndata . import sys; sys.path.append(""scanpy/preprocessing""); from _utils import _get_mean_var. np.random.seed(42); adata = anndata.AnnData(np.random.randint(0,5,(100,100))); adata.obs['batch'] = np.random.randint(0,5,(100)); adata.obs['batch'] = adata.obs['batch'].astype('category'); n_top_genes = 50. adata = adata.copy(); sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]; ```. ```pytb; highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches; 87 True 8.0 1.76 2.446869 1.232373 5; 9 False 28.0 1.96 2.281212 1.159891 5; 78 True 24.0 1.95 2.209596 1.124666 5; 30 True 19.0 2.00 2.202020 1.134560 4; 14 False 25.0 2.14 2.162020 1.088266 4; ```; </details>. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1.dev2+g8c469411; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; highs_wrapper NA; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.0; pkg_resources NA; pyparsing 2.4.7; pytz 2020.5; scanpy 1.7.1.dev2+g8c469411; scipy 1.6.0; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.0; skmisc 0.1.3; tables 3.6.1; typing_extensions NA; yaml 5.3.1; -----; Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]; Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-03-10 17:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:849,Modifiability,variab,variable,849,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey, I've noticed another potential problem within the `seurat_v3` flavor of `sc.pp.highly_variable_genes()`. The documentation of the `batch_key` argument says on how the genes are ranked. >For all flavors, genes are first sorted by how many batches they are a HVG. For dispersion-based flavors ties are broken by normalized dispersion. If `flavor = 'seurat_v3'`, ties are broken by the median (across batches) rank based on within-batch normalized variance. However, when genes are sorted after computing everything, the `seurat_v3` method sorts first by the median ranks and then by how many batches a gene is highly variable (contrary to what the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L139-L144. For comparison, the other flavors sort the other way around (as the docstring says):. https://github.com/theislab/scanpy/blob/da66e15eee137b51868a6fb85603cfca9de557a7/scanpy/preprocessing/_highly_variable_genes.py#L505-L510. Not sure which sorting would be correct here to make `seurat_v3` match the original behavior in Seurat, but I found these comments by @adamgayoso in #1204 that mention that when using `batch_key` in the current implementation, results don't match Seurat.. maybe the sorting order is the problem here?. https://github.com/theislab/scanpy/pull/1204#issuecomment-645700601; https://github.com/theislab/scanpy/pull/1204#issuecomment-663879113. Here is a piece of code that shows the top5 genes after `seurat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python; import numpy as np; import scanpy as sc; import anndata . import sys; sys.path.append(""scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:2820,Testability,log,logging,2820,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python; import numpy as np; import scanpy as sc; import anndata . import sys; sys.path.append(""scanpy/preprocessing""); from _utils import _get_mean_var. np.random.seed(42); adata = anndata.AnnData(np.random.randint(0,5,(100,100))); adata.obs['batch'] = np.random.randint(0,5,(100)); adata.obs['batch'] = adata.obs['batch'].astype('category'); n_top_genes = 50. adata = adata.copy(); sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]; ```. ```pytb; highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches; 87 True 8.0 1.76 2.446869 1.232373 5; 9 False 28.0 1.96 2.281212 1.159891 5; 78 True 24.0 1.95 2.209596 1.124666 5; 30 True 19.0 2.00 2.202020 1.134560 4; 14 False 25.0 2.14 2.162020 1.088266 4; ```; </details>. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1.dev2+g8c469411; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; highs_wrapper NA; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.0; pkg_resources NA; pyparsing 2.4.7; pytz 2020.5; scanpy 1.7.1.dev2+g8c469411; scipy 1.6.0; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.0; skmisc 0.1.3; tables 3.6.1; typing_extensions NA; yaml 5.3.1; -----; Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]; Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-03-10 17:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1733:3668,Testability,log,logical,3668,"urat_v3` gene selection and sorting by `highly_variable_nbatches` (which should then all be HVG, but they are not). <details>. ```python; import numpy as np; import scanpy as sc; import anndata . import sys; sys.path.append(""scanpy/preprocessing""); from _utils import _get_mean_var. np.random.seed(42); adata = anndata.AnnData(np.random.randint(0,5,(100,100))); adata.obs['batch'] = np.random.randint(0,5,(100)); adata.obs['batch'] = adata.obs['batch'].astype('category'); n_top_genes = 50. adata = adata.copy(); sc.pp.highly_variable_genes(adata,n_top_genes=n_top_genes,flavor='seurat_v3',inplace=True,batch_key='batch'). adata.var.sort_values(['highly_variable_nbatches'], ascending=[False]).iloc[:5,:]; ```. ```pytb; highly_variable highly_variable_rank means variances variances_norm highly_variable_nbatches; 87 True 8.0 1.76 2.446869 1.232373 5; 9 False 28.0 1.96 2.281212 1.159891 5; 78 True 24.0 1.95 2.209596 1.124666 5; 30 True 19.0 2.00 2.202020 1.134560 4; 14 False 25.0 2.14 2.162020 1.088266 4; ```; </details>. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1.dev2+g8c469411; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; constants NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; highs_wrapper NA; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.19.5; packaging 20.8; pandas 1.2.0; pkg_resources NA; pyparsing 2.4.7; pytz 2020.5; scanpy 1.7.1.dev2+g8c469411; scipy 1.6.0; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.0; skmisc 0.1.3; tables 3.6.1; typing_extensions NA; yaml 5.3.1; -----; Python 3.8.0 (default, Oct 28 2019, 16:14:01) [GCC 8.3.0]; Linux-3.10.0-957.el7.x86_64-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-03-10 17:37. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1733
https://github.com/scverse/scanpy/issues/1736:149,Availability,failure,failure,149,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2447,Availability,error,error,2447,"ite-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2331,Integrability,Message,Message,2331,"okexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2871,Modifiability,config,config,2871,"); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3014,Modifiability,config,config,3014,"ine 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3082,Modifiability,config,config,3082,"fo(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_ses",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:3933,Modifiability,config,config,3933,"n(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4092,Modifiability,config,config,4092,"n(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4225,Modifiability,config,config,4225,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:10,Testability,test,tests,10,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:144,Testability,test,test,144,"Sometimes tests give a lot of useless output when they fail. Generally looks like this (note, this is a small part (<10%) of the output for one test failure):. <details>; <summary> </summary>. ```; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/runner.py"", line 162, in pytest_runtest_call; item.runtest(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/loggi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1696,Testability,test,testfunction,1696,"; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1711,Testability,test,testargs,1711,"; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1755,Testability,test,tests,1755,"; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 1641, in runtest; self.ihook.pytest_pyfunc_call(pyfuncitem=self); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1951,Testability,log,logg,1951,"ython3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:1996,Testability,log,logging,1996,"ine 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2136,Testability,log,logging,2136,"/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2179,Testability,log,log,2179,"); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2263,Testability,log,logging,2263,"); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2288,Testability,log,log,2288,"site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2301,Testability,log,log,2301,"okexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2439,Testability,Log,Logging,2439,"ite-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hoste",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:2552,Testability,log,logging,2552,"); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/python.py"", line 183, in pytest_pyfunc_call; result = testfunction(**testargs); File ""/home/vsts/work/1/s/scanpy/tests/notebooks/test_paga_paul15_subsampled.py"", line 39, in test_paga_paul15_subsampled; sc.tl.draw_graph(adata); File ""/home/vsts/work/1/s/scanpy/tools/_draw_graph.py"", line 181, in draw_graph; logg.info(; File ""/home/vsts/work/1/s/scanpy/logging.py"", line 244, in info; return settings._root_logger.info(msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 56, in info; return self.log(INFO, msg, time=time, deep=deep, extra=extra); File ""/home/vsts/work/1/s/scanpy/logging.py"", line 43, in log; super().log(level, msg, extra=extra); Message: "" finished: added\n 'X_draw_graph_fr', graph_drawing coordinates (adata.obsm)""; Arguments: (); --- Logging error ---; Traceback (most recent call last):; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/logging/__init__.py"", line 1084, in emit; stream.write(msg + self.terminator); ValueError: I/O operation on closed file.; Call stack:; File ""/opt/hostedtoolcache/Python/3.8.8/x64/bin/pytest"", line 8, in <module>; sys.exit(console_main()); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 185, in console_main; code = main(); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/config/__init__.py"", line 162, in main; ret: Union[ExitCode, int] = config.hook.pytest_cmdline_main(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4458,Testability,log,logging,4458,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4540,Testability,log,logging,4540,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4806,Testability,log,loggers,4806,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4825,Testability,log,logging,4825,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4834,Testability,log,loggers,4834,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4845,Testability,log,logging,4845,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4873,Testability,log,logging,4873,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4881,Testability,Log,Logger,4881,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4896,Testability,log,loggerDict,4896,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4922,Testability,log,logger,4922,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4932,Testability,log,loggers,4932,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:4961,Testability,log,logger,4961,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/issues/1736:5012,Testability,log,logger,5012,"olcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; return self._hookexec(self, self.get_hookimpls(), kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 93, in _hookexec; return self._inner_hookexec(hook, methods, kwargs); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/manager.py"", line 84, in <lambda>; self._inner_hookexec = lambda hook, methods, kwargs: hook.multicall(; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/callers.py"", line 187, in _multicall; res = hook_impl.function(*args); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 316, in pytest_cmdline_main; return wrap_session(config, _main); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 269, in wrap_session; session.exitstatus = doit(config, session) or 0; File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/_pytest/main.py"", line 323, in _main; config.hook.pytest_runtestloop(session=session); File ""/opt/hostedtoolcache/Python/3.8.8/x64/lib/python3.8/site-packages/pluggy/hooks.py"", line 286, in __call__; ```. </details>. This seems to be a known problem caused by setting up logging at import: https://github.com/pytest-dev/pytest/issues/5502. Why touching logging at import at all is considered a bug in the setup, I am not sure. Adding this as a required teardown may fix the problem (https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873):. ```python; def clear_loggers():; """"""Remove handlers from all loggers""""""; import logging; loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values()); for logger in loggers:; handlers = getattr(logger, 'handlers', []); for handler in handlers:; logger.removeHandler(handler); ```. Next time we come across a reproducible case of this happening, we should try this out.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1736
https://github.com/scverse/scanpy/pull/1737:19,Testability,test,tested,19,"Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/pull/1737:117,Testability,log,logging,117,"Maybe fixes #1736, tested with #1735 and it seemed to do the trick. @flying-sheep, you're the most familiar with the logging setup. Any thoughts?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1737
https://github.com/scverse/scanpy/issues/1739:389,Availability,down,downstream,389,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:31,Modifiability,layers,layers,31,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:636,Modifiability,extend,extend,636,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1526,Modifiability,layers,layers,1526," emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; sc.tl.cluster.{leiden,louvain}; sc.tl.score.{genes,cell_cycle}; sc.pl.rank_genes.{dotplot,matrixplot,...}; sc.pl.groups.{dot,matrix,violin,...}; sc.pl.embed.{umap,tsne,pca,...}; ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:360,Performance,perform,perform,360,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:433,Testability,test,tests,433,"Hi all,. Right now we have two layers in the scanpy API. The top layer consists of the major modules like `pp,pl,tl` as well as the smaller ones like `queries,get,datasets`. In addition, we have some useful functions directly under the scanpy package like `read/read_text/read_mtx` etc. It is obvious that the field is advancing and alternative/better ways to perform fundamental tasks in downstream analysis (e.g. normalization, DE tests, gene selection) are emerging and will continue to emerge. Consequently, this necessitates an expansion of the scanpy API. However, I argue that having flat top-level modules makes it difficult to extend scanpy, while maintaining a reasonable API. . Right now there are two ways to introduce new functionality (assuming that it's not something completely unrelated). 1) add a new flavor/method to an existing function (e.g. `sc.pp.highly_variable_genes`, `sc.tl.rank_genes_groups`) or . 2) add a new function with a shared prefix e.g. `sc.pp.neighbors_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/issues/1739:1976,Testability,log,logreg,1976,"s_tsne` (see https://github.com/theislab/scanpy/pull/1561) or `sc.pp.normalize_pearson_residuals` (see https://github.com/berenslab/umi-normalization/issues/1) or `sc.pp.normalize_pearson_residuals_pca()` (see #1715 ). . Since option 1 is more complicated in terms of managing the arguments (esp. method-specific ones), I believe we tend to switch to option 2 now. But given that we already have many functions with common prefixes and that shifting towards option 2 will likely introduce more functions with long underscored names, top layers will get even flatter and wider. Therefore, I think it's time to consider a third option which is to add another layer which makes the API a tiny bit more hierarchical. Some examples I can think of are:. ```java; sc.read.{adata,csv,text,mtx,excel,loom,h5_10x,mtx_10x,...}; sc.pp.neighbors.{umap,gauss,rapids,tsne}; sc.pp.hvg.{seurat,seurat_v3,dispersion}; sc.pp.norm.{tpm,pearson}; sc.pp.filter.{genes,cells,rank_genes,...}; sc.tl.rank_genes.{logreg,wilcoxon,ttest}; sc.tl.cluster.{leiden,louvain}; sc.tl.score.{genes,cell_cycle}; sc.pl.rank_genes.{dotplot,matrixplot,...}; sc.pl.groups.{dot,matrix,violin,...}; sc.pl.embed.{umap,tsne,pca,...}; ```. There are a few issues I can think of. 1. I can imagine some resistance from some developers due to losing a few milliseconds by typing more characters 😄 but if you imagine the long term effects of option 2, I think this might save you some time 😛 . 1. What happens to the functions that do not fit in this scheme like `sc.pp.combat`, `sc.tl.ingest/dpt/paga/etc`, `sc.pl.*` (maybe plotting functions with groupby argument can be under sc.pl.groups.*) ? I am not entirely sure, one option is to keep them as is, and another is to make ""singular"" modules for them so that everything is placed in a third layer. 1. It will be harder to specify the ""default"" (i.e. somewhat recommended) method with this scheme. What I mean by that is that when we add a new flavor/method to an existing function, we can still ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1739
https://github.com/scverse/scanpy/pull/1740:657,Testability,test,tests,657,"close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304; Explicit design choices compared to first proposal in squidpy:; - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ); - only working on genes. technically it could work on continuos covariates as well, should I add that option?; - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/pull/1740:615,Usability,feedback,feedback,615,"close #1698 . this is the implementation as proposed here: https://github.com/theislab/squidpy/pull/304; Explicit design choices compared to first proposal in squidpy:; - no joblib present, with low n permutation is fine and saw that you don't even do it in gearys C (which btw, makes a lot of sense in this setting, should consider to skip permutation entirely as well ); - only working on genes. technically it could work on continuos covariates as well, should I add that option?; - I think it could be worth it to add a row wise normalization of the weights (standard in pysal). @ivirshup would be good to have feedback on those points, I will then add tests. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1740
https://github.com/scverse/scanpy/issues/1742:860,Availability,error,error,860,"- . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). ```pytb; [Paste the error output produced by the above code here]; ```; C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3725,Deployability,update,updated,3725,"Warning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; bottleneck 1.3.2; cairo 1.20.0; cffi 1.14.3; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; joblib 0.17.0; kiwisolver 1.3.0; legacy_api_wrap 0.0.0; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.5.0; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.17763-SP0; 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel; -----; Session information updated at 2021-03-14 11:37; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2297,Performance,bottleneck,bottleneck,2297,"C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; bottleneck 1.3.2; cairo 1.20.0; cffi 1.14.3; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; joblib 0.17.0; kiwisolver 1.3.0; legacy_api_wrap 0.0.0; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_exten",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:2136,Testability,log,logging,2136,"te-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; bottleneck 1.3.2; cairo 1.20.0; cffi 1.14.3; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; joblib 0.17.0; kiwisolver 1.3.0; legacy_api_wrap 0.0.0; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:3626,Testability,log,logical,3626,"Warning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; bottleneck 1.3.2; cairo 1.20.0; cffi 1.14.3; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; joblib 0.17.0; kiwisolver 1.3.0; legacy_api_wrap 0.0.0; llvmlite 0.34.0; louvain 0.7.0; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; pandas 1.1.3; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.1; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.6.0; scipy 1.5.2; seaborn 0.11.0; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.5.0; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.17763-SP0; 12 logical CPU cores, Intel64 Family 6 Model 165 Stepping 2, GenuineIntel; -----; Session information updated at 2021-03-14 11:37; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/issues/1742:262,Usability,guid,guide,262,"- . - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'],; jitter=0.4, multi_panel=True). ```pytb; [Paste the error output produced by the above code here]; ```; C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified.; warnings.warn(single_var_warning.format(""Vertical"", ""x"")); C:\Users\laurenh\anaconda3\lib\site-packages\seaborn\_core.py:1303: UserWarning: Vertical orientation ignored with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1742
https://github.com/scverse/scanpy/pull/1743:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/pull/1743:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1743
https://github.com/scverse/scanpy/issues/1744:461,Availability,down,downstream,461,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:162,Modifiability,variab,variables,162,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:232,Modifiability,variab,variables,232,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:528,Modifiability,variab,variables,528,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:186,Testability,test,testing,186,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:300,Testability,test,test,300,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:333,Testability,test,test,333,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1744:563,Testability,test,testing,563,"Hi authors,. First off, love scanpy. Big fan. . I was just wondering if you have considered including an option in `scanpy.tl.rank_genes_groups` to specify which variables to select for testing, allowing users to select a subset of variables which would or would not be considered in the statistical test. For context, I'm trying to test between groups of cells while ignoring ribosomal / mitochondrial genes, but retain them in the `.var` and `.X` objects for downstream analysis/visualisation. Making a temp object with these variables removed solely for stats testing partially works, but it's confounded by having to further apply the boolean slice to the `.raw` object as well. Thanks, K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1744
https://github.com/scverse/scanpy/issues/1745:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. The current `external.pp.scanorarma_integrate()` function has a `basis` argument which isn't actually used in the code (as far as I can tell). This is probably confusing to users (definitely was to me) so I would suggest removing it or at least mentioning in the docs that it isn't used. I can probably submit a PR if maintainers let me know what the preferred option is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1745
https://github.com/scverse/scanpy/issues/1748:2766,Integrability,wrap,wrapt,2766,"72 | 2.049016 | 0.0 | 0.0; NaN | 66.620399 | 1.637823 | 0.0 | 0.0; NaN | 66.236443 | 1.807056 | 0.0 | 0.0; NaN | 64.112152 | 2.446921 | 0.0 | 0.0; NaN | 64.083160 | 2.495992 | 0.0 | 0.0; HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0; NaN | 63.009491 | 2.059168 | 0.0 | 0.0; NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; sca NA; scanpy 1.7.0; scipy 1.6.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; traitlets 4.3.3; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:766,Testability,log,logfoldchanges,766,"- [x ] I have checked that this issue has not already been reported.; - [x ] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, I am using scanpy rank gene function and always get NAN as gene names in the data frame results. . (I might have seen this bug before in this repo but I cant find it in today.). ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(ad,groupby='tissue.id',use_raw=False,method='wilcoxon'); sc.tl.filter_rank_genes_groups(ad, min_fold_change=1,min_in_group_fraction=0.25,max_out_group_fraction=0.25,use_raw=False,key='rank_genes_groups'); sc.get.rank_genes_groups_df(ad,group=['Liver_Met'],key='rank_genes_groups_filtered')[:20]; ```. ```pytb. names | scores | logfoldchanges | pvals | pvals_adj; -- | -- | -- | -- | --; HBB | 94.312996 | 4.962673 | 0.0 | 0.0; HBA2 | 86.154396 | 4.713093 | 0.0 | 0.0; NaN | 83.383812 | 3.280355 | 0.0 | 0.0; NaN | 77.977989 | 3.548592 | 0.0 | 0.0; S100A2 | 73.550644 | 3.764067 | 0.0 | 0.0; NaN | 66.913872 | 2.049016 | 0.0 | 0.0; NaN | 66.620399 | 1.637823 | 0.0 | 0.0; NaN | 66.236443 | 1.807056 | 0.0 | 0.0; NaN | 64.112152 | 2.446921 | 0.0 | 0.0; NaN | 64.083160 | 2.495992 | 0.0 | 0.0; HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0; NaN | 63.009491 | 2.059168 | 0.0 | 0.0; NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1748:3006,Testability,log,logical,3006,"72 | 2.049016 | 0.0 | 0.0; NaN | 66.620399 | 1.637823 | 0.0 | 0.0; NaN | 66.236443 | 1.807056 | 0.0 | 0.0; NaN | 64.112152 | 2.446921 | 0.0 | 0.0; NaN | 64.083160 | 2.495992 | 0.0 | 0.0; HBA1 | 63.376114 | 4.161097 | 0.0 | 0.0; NaN | 63.009491 | 2.059168 | 0.0 | 0.0; NaN | 58.142750 | 2.201216 | 0.0 | 0. ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; colorama 0.4.3; colorlog NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; sca NA; scanpy 1.7.0; scipy 1.6.1; scprep 1.0.5.post2; seaborn 0.10.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; texttable 1.6.2; threadpoolctl 2.1.0; tornado 6.0.4; traitlets 4.3.3; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1748
https://github.com/scverse/scanpy/issues/1749:3516,Deployability,update,updated,3516,".6218119e-04]]; ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; constants NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; google NA; h5py 3.1.0; highs_wrapper NA; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.26.3; wcwidth 0.2.5; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.10; notebook 6.2.0; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-44-generic-x86_64-with-glibc2.10; 28 logical CPU cores; -----; Session information updated at 2021-03-18 12:37. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:1843,Performance,bottleneck,bottleneck,1843,"qual(adata1.obsm['X_pca'], adata2.obsm['X_pca'])); print(adata1.obsm['X_pca'] - adata2.obsm['X_pca']); ```. ```pytb; env: PYTHONHASHSEED=0; False; [[-4.7683716e-07 -3.5762787e-07 -1.1920929e-07 ... -2.7803779e-03; -5.5277348e-04 8.6665154e-05]; [ 9.5367432e-07 4.7683716e-07 6.5565109e-07 ... 3.1501055e-03; -3.6475658e-03 -1.0871887e-04]; [ 1.6689301e-06 0.0000000e+00 -1.1920929e-07 ... 1.7441511e-03; 6.9665909e-04 4.2915344e-04]; ...; [-5.9604645e-07 4.7683716e-07 -3.5762787e-07 ... 1.5980005e-04; -1.0134950e-03 -1.2260675e-04]; [-2.0861626e-07 1.4305115e-06 -8.3446503e-07 ... -7.1705580e-03; -2.4490356e-03 2.4688244e-04]; [ 5.3644180e-07 -5.9604645e-07 -6.8545341e-07 ... -1.5603602e-03; 7.9727173e-04 8.6218119e-04]]; ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; constants NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; google NA; h5py 3.1.0; highs_wrapper NA; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/issues/1749:3470,Testability,log,logical,3470,".6218119e-04]]; ```. #### Versions. I am running scanpy in this singularity container: https://singularity-hub.org/collections/5095. <details>. ```. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; anyio NA; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; constants NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.0; dateutil 2.8.1; decorator 4.4.2; future_fstrings NA; get_version 2.1; google NA; h5py 3.1.0; highs_wrapper NA; idna 2.10; igraph 0.8.3; ipykernel 5.5.0; ipython_genutils 0.2.0; jedi 0.18.0; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.3.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.3; parso 0.8.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; urllib3 1.26.3; wcwidth 0.2.5; yaml 5.4.1; zmq 22.0.3; zope NA; -----; IPython 7.21.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.10; notebook 6.2.0; -----; Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]; Linux-5.8.0-44-generic-x86_64-with-glibc2.10; 28 logical CPU cores; -----; Session information updated at 2021-03-18 12:37. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1749
https://github.com/scverse/scanpy/pull/1750:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1750:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1750
https://github.com/scverse/scanpy/pull/1752:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1752:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1752
https://github.com/scverse/scanpy/pull/1753:442,Availability,error,error-case-sensitive-drives-supported,442,"This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions hav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:749,Deployability,update,update,749,"This PR contains a reorganization of the API reference docs, mostly to ease modification and generation. Fixes #1682. ## Case sensitivity. First big issue addressed, `scanpy.plotting.dotplot.rst` and `scanpy.plotting.DotPlot.rst` are the same path on a case insensitive file system. This is what most people on macOS will have. If you have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions hav",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1327,Usability,learn,learn,1327," have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1349,Usability,learn,learn,1349," have a case sensitive file system, important apps like [Adobe's](https://helpx.adobe.com/creative-suite/kb/error-case-sensitive-drives-supported.html) and [steam](https://support.steampowered.com/kb_article.php?ref=8601-RYPX-5789) won't work. So now the plotting classes are put in `generated/classes`. For me, this means:. * docs now generate without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:1680,Usability,simpl,simplifies,1680,"te without warnings; * DotPlot and MatrixPlot docs are only rebuilt if I update them. ## Separate tracked and generated content. I find it difficult to navigate the rst api docs when there is a large amount of auto generated files mixed in with manually curated ones. This becomes more of a problem since the autogenerated files are not removed by `make clean` and will still generate `html` files and generally be a nuisance while they are still around. Now all autogenerated API files are put in a `generated` directory. This is also what [xarray](https://github.com/pydata/xarray/blob/e6168ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite out of date. <details>; <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2665,Usability,guid,guide,2665,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite out of date. <details>; <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**; - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2818,Usability,guid,guide,2818,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite out of date. <details>; <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**; - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/pull/1753:2999,Usability,guid,guide,2999,"68ed6b771b7377e89acb47cc7e5aa9f21a574/doc/api.rst), [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.extmath.randomized_range_finder.html#sklearn.utils.extmath.randomized_range_finder), and [seaborn](https://github.com/mwaskom/seaborn/blob/ba4bd0fa0a90b2bd00cb62c2b4a5e38013a73ac6/doc/api.rst) do. Now `make clean` also deletes all auto generated `rst` files. This also dramatically simplifies our `.gitignore`. ## Consolidation. I've also consolidated the managed api docs to a smaller number of files. Namely, instead of `api/*.rst` there's now just `api.rst`. Instead of `external/*.rst` there's just `external.rst`. ## Plotting functions API docs. In the current api docs, some plotting functions have a plot displayed inline instead of a one line description. This is nice because it provides a visual reference for what the plotting function does. It's less nice because:. * It takes up a huge amount of space; * It takes up a different amount of space for each function; * These plots are manually generated, and are often quite out of date. <details>; <summary> example </summary>. <img width=""899"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/111894736-5657fd80-8a61-11eb-8077-97bcb5c54765.png"">. </details>. I think the reference docs should be handled in the same way for each of the modules. Example plots make more sense in the user guide/ tutorials and within each functions documentation (#1664). I'd like to go further with this by moving the plotting tutorial's content to the user guide, so we can have more in depth linking to different sections. Additional benefits here include plots being generated with each doc build and having links from functions in the guide to their api docs. ## TODO. - [x] [Redirects](https://docs.readthedocs.io/en/stable/user-defined-redirects.html) (redirects need to be added on readthedocs so old links won't fail) **added**; - [x] Decide where module docs live, as doc-string, or as rst. **rst**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1753
https://github.com/scverse/scanpy/issues/1757:345,Modifiability,variab,variable,345,"This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as ; ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data!. A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------; ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------; ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:; 1. delete the above line 185 (and the other places it shows up...); 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1757:1478,Testability,log,log-scaling,1478,"This issue references the following line of code:. https://github.com/theislab/scanpy/blob/560bd5d348a502d5152eaf20f5f8bef794562a97/scanpy/plotting/_dotplot.py#L185. The documentation accurately describes the `standard_scale='var'` normalization strategy as ; ""Whether or not to standardize the given dimension between 0 and 1, meaning for each variable or group, subtract the minimum and divide each by its maximum."". Something about this normalization has bothered me for a long time, and I finally realized: it's the subtraction of the minimum value. This subtraction means that the minimum valued dot will have color = 0. Imagine a case with only two `groupby` groupings: healthy and disease. In that case, one of the dots will always have color 0, and the other will have color 1. Totally binary, no matter how close the actual values are. I feel that this kind of normalization is very misleading for scRNA-seq data!. A random example follows:. This image makes it look like these genes are very specific to one tissue or another ---------------; ![image](https://user-images.githubusercontent.com/10214815/112070104-6d6f1c00-8b43-11eb-9944-b113da55a567.png). But in reality, if we had scaled by just dividing by the max (and not first subtracting the min), then we'd see -------; ![image](https://user-images.githubusercontent.com/10214815/112070028-4add0300-8b43-11eb-8317-412b74b274aa.png). which is much more realistic, and much closer to what you'd see if you used a log-scaling instead, and made several different plots for genes expressed at different levels overall. I leave it up for discussion, but I would suggest two types of fixes:; 1. delete the above line 185 (and the other places it shows up...); 2. allow the user to specify a custom normalization function (but change the default to `x / max(x)` instead of `(x - min(x)) / max(x)`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1757
https://github.com/scverse/scanpy/issues/1758:264,Testability,log,logfoldchanges,264,"Hello Team,; ```; sc.__version__; '1.7.0rc2.dev6+g5fc12f4a'; ```; I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot ; `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-43-4ca50e495f54> in <module>; ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 656 """"""; 657 ; --> 658 return _rank_genes_groups_plot(; 659 adata,; 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 435 from .._dotplot import dotplot; 436 ; --> 437 _pl = dotplot(; 438 adata,; 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:637,Testability,log,logfoldchanges,637,"Hello Team,; ```; sc.__version__; '1.7.0rc2.dev6+g5fc12f4a'; ```; I just pulled the latest master to see if the issue was just in my earlier version. I'm trying to plot rank_gene_groups dot plot ; `sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False)`. However it doesn't work with the following tranceback:; ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-43-4ca50e495f54> in <module>; ----> 1 sc.pl.rank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 656 """"""; 657 ; --> 658 return _rank_genes_groups_plot(; 659 adata,; 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 435 from .._dotplot import dotplot; 436 ; --> 437 _pl = dotplot(; 438 adata,; 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1392,Testability,log,log,1392,"ank_genes_groups_dotplot(adata, n_genes=4, values_to_plot='logfoldchanges', cmap='bwr', gene_symbols='Uniq_Name', use_raw=False) # swap_axes=True). ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 656 """"""; 657 ; --> 658 return _rank_genes_groups_plot(; 659 adata,; 660 plot_type='dotplot',. ~/projects/scanpy/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 435 from .._dotplot import dotplot; 436 ; --> 437 _pl = dotplot(; 438 adata,; 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 130 **kwds,; 131 ):; --> 132 BasePlot.__init__(; 133 self,; 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds); 109 self._update_var_groups(); 110 ; --> 111 self.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:1916,Testability,log,log,1916,"otting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, min_logfoldchange, key, show, save, return_fig, **kwds); 435 from .._dotplot import dotplot; 436 ; --> 437 _pl = dotplot(; 438 adata,; 439 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 130 **kwds,; 131 ):; --> 132 BasePlot.__init__(; 133 self,; 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds); 109 self._update_var_groups(); 110 ; --> 111 self.categories, self.obs_tidy = _prepare_dataframe(; 112 adata,; 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1864 groupby.remove(groupby_index); 1865 keys = list(groupby) + list(np.unique(var_names)); -> 1866 obs_tidy = get.obs_df(; 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1868 ). ~/projects/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2353,Testability,log,log,2353,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 130 **kwds,; 131 ):; --> 132 BasePlot.__init__(; 133 self,; 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds); 109 self._update_var_groups(); 110 ; --> 111 self.categories, self.obs_tidy = _prepare_dataframe(; 112 adata,; 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1864 groupby.remove(groupby_index); 1865 keys = list(groupby) + list(np.unique(var_names)); -> 1866 obs_tidy = get.obs_df(; 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`.""; ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1758:2764,Testability,log,log,2764,"s, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/projects/scanpy/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 130 **kwds,; 131 ):; --> 132 BasePlot.__init__(; 133 self,; 134 adata,. ~/projects/scanpy/scanpy/plotting/_baseplot_class.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, ax, vmin, vmax, vcenter, norm, **kwds); 109 self._update_var_groups(); 110 ; --> 111 self.categories, self.obs_tidy = _prepare_dataframe(; 112 adata,; 113 self.var_names,. ~/projects/scanpy/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1864 groupby.remove(groupby_index); 1865 keys = list(groupby) + list(np.unique(var_names)); -> 1866 obs_tidy = get.obs_df(; 1867 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1868 ). ~/projects/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). KeyError: ""Could not find keys '['KY.Chr1.1190', ..., 'KY.Chr9.987']' in columns of `adata.obs` or in gene_symbols column `adata.var[Uniq_Name].values`.""; ```. I cant see how to use gene_symbols in the `tl.rank_gene_groups` either. Am I missing something?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1758
https://github.com/scverse/scanpy/issues/1759:956,Performance,load,load,956,"from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below; ```; #!/usr/bin/env python3; # -*- coding: utf-8 -*-; """""". from sklearn import datasets; import scanpy as sc; import numpy as np; import random; import matplotlib.pyplot as plt; from sklearn.manifold import TSNE; np.random.seed(1); random.seed(1). iris = datasets.load_iris(); X = iris.data; label=iris.target. adata=sc.AnnData(X); adata.obs[""celltype""]=label.astype(int).astype(str); sc.tl.tsne(adata,random_state=0,use_fast_tsne=False); axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False); sc_tsne=adata.obsm[""X_tsne""]; #print(ax). print(np.min(sc_tsne[:,0])); print(np.max(sc_tsne[:,0])); print(np.min(sc_tsne[:,1])); print(np.max(sc_tsne[:,1])); print(""====================""). # import pickle; # #with open(); # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'); # tsne2=pickle.load(file). target=label; tsne = TSNE(learning_rate=1000,init='random', random_state=0); X_transformed = tsne.fit_transform(X); fig=plt.figure(); for label in np.unique(target):; plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label); plt.legend(loc=""upper left""); plt.show(); #print(X_transformed); print(np.min(X_transformed[:,0])); print(np.max(X_transformed[:,0])); print(np.min(X_transformed[:,1])); print(np.max(X_transformed[:,1])). print(""==================""); params_sklearn = dict(; perplexity=30,; random_state=0,; verbose=False,; early_exaggeration=12,; learning_rate=1000,; ); from sklearn.manifold import TSNE; # unfortunately, sklearn does not allow to set a minimum number; # of iterations for barnes-hut tSNE; tsne3 = TSNE(**params_sklearn); X_transformed=tsne3.fit_transform(X); print(np.min(X_transformed[:,0])); print(np.max(X_transformed[:,0])); print(np.min(X_transformed[:,1])); print(np.max(X_transformed[:,1])); ```; I get the result; ![image](https://user-images.githubusercontent.com/5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1759:135,Testability,test,test,135,"from the doc of sc.tl.tsne, I knew it was implemented by scikit, but I can't get the same result between sc.tl.tsne and scikit.TSNE，my test code is below; ```; #!/usr/bin/env python3; # -*- coding: utf-8 -*-; """""". from sklearn import datasets; import scanpy as sc; import numpy as np; import random; import matplotlib.pyplot as plt; from sklearn.manifold import TSNE; np.random.seed(1); random.seed(1). iris = datasets.load_iris(); X = iris.data; label=iris.target. adata=sc.AnnData(X); adata.obs[""celltype""]=label.astype(int).astype(str); sc.tl.tsne(adata,random_state=0,use_fast_tsne=False); axis=sc.pl.tsne(adata,color=[""celltype""],size=100,show=False); sc_tsne=adata.obsm[""X_tsne""]; #print(ax). print(np.min(sc_tsne[:,0])); print(np.max(sc_tsne[:,0])); print(np.min(sc_tsne[:,1])); print(np.max(sc_tsne[:,1])); print(""====================""). # import pickle; # #with open(); # file = open('/Users/xiaokang/Desktop/data/tsne.pkl', 'rb'); # tsne2=pickle.load(file). target=label; tsne = TSNE(learning_rate=1000,init='random', random_state=0); X_transformed = tsne.fit_transform(X); fig=plt.figure(); for label in np.unique(target):; plt.scatter(X_transformed[label==target,0], X_transformed[label==target,1],label=label); plt.legend(loc=""upper left""); plt.show(); #print(X_transformed); print(np.min(X_transformed[:,0])); print(np.max(X_transformed[:,0])); print(np.min(X_transformed[:,1])); print(np.max(X_transformed[:,1])). print(""==================""); params_sklearn = dict(; perplexity=30,; random_state=0,; verbose=False,; early_exaggeration=12,; learning_rate=1000,; ); from sklearn.manifold import TSNE; # unfortunately, sklearn does not allow to set a minimum number; # of iterations for barnes-hut tSNE; tsne3 = TSNE(**params_sklearn); X_transformed=tsne3.fit_transform(X); print(np.min(X_transformed[:,0])); print(np.max(X_transformed[:,0])); print(np.min(X_transformed[:,1])); print(np.max(X_transformed[:,1])); ```; I get the result; ![image](https://user-images.githubusercontent.com/5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1759
https://github.com/scverse/scanpy/issues/1760:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; How to use sc.pl.correlation_matrix to compute correlation between two different anndata? I want to compare urine""data1"" with biopsy cells""data2"". ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1760
https://github.com/scverse/scanpy/issues/1761:96,Availability,down,downloads,96,"Hi,; I was reading some mtx file from here: ; https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`; `AnnData object with n_obs × n_vars = 25052 × 606606; ` ; `sc.__version__`; `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. ; That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>; ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1761:276,Performance,load,loading,276,"Hi,; I was reading some mtx file from here: ; https://www.ebi.ac.uk/gxa/sc/experiments/E-HCAD-4/downloads. `adata = sc.read_mtx(""./data/mtx/E-HCAD-4.aggregated_filtered_counts.mtx"")`; `AnnData object with n_obs × n_vars = 25052 × 606606; ` ; `sc.__version__`; `'1.7.1'`. when loading the mtx file the obs and vars are mixed up. ; That happened with another mtx file before. I was wondering if already a fix exists to specify the obs and vars (or switch them if necessary). . Thanks . </details>; ![image](https://user-images.githubusercontent.com/7283790/112545551-a19f4280-8db8-11eb-8e0d-7d56ee0443b5.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1761
https://github.com/scverse/scanpy/issues/1764:69,Performance,perform,performance,69,"Hi,; Scanpy are designed to handle big datasets, while how about the performance on small datasets ? (such as as few as 50 cells from early embryo)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1764
https://github.com/scverse/scanpy/pull/1765:483,Modifiability,variab,variable,483,"An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:; - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house; - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:190,Testability,test,testing,190,"An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:; - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house; - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/pull/1765:525,Testability,test,tests,525,"An implementation of highly deviant gene identification from the 2019 GLMPCA paper. I'm rather fond of the method, as it's a straightforward statistical measure, and comes with significance testing as a form of data-driven cutoff. I put it in a new `highly_deviant_genes()` function, as:; - it comes with a number of unique parameters, and there's only so many different algorithms `highly_variable_genes()` can house; - the paper argues that highly deviant is different from highly variable. I acknowledge that there are no tests, I'm hoping to get some assistance with that if possible.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1765
https://github.com/scverse/scanpy/issues/1766:410,Availability,error,error,410,"Hi; Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:; ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png); Can I modify the y axis limits? I'm sorry I haven't find the parameters yet.; And when I try to use `use_raw=False`, I got error:; `ValueError: Data must be 1-dimensional`; `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`; And my code:; `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`; and my version:; `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer!; Best,; Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/issues/1766:818,Usability,learn,learn,818,"Hi; Thanks for the brilliant tool! And my poblem is when I use sc.pl.rank_genes_groups_violin() function, the y axis limits of the output seems impalpable.Here's my output:; ![image](https://user-images.githubusercontent.com/65101587/112634253-3a50b500-8def-11eb-84dd-28591804266b.png); Can I modify the y axis limits? I'm sorry I haven't find the parameters yet.; And when I try to use `use_raw=False`, I got error:; `ValueError: Data must be 1-dimensional`; `ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series`; And my code:; `sc.tl.rank_genes_groups(merge_data, 'sampleID', groups=['WT_BM'], reference='KO_BM', method='wilcoxon',corr_method='bonferroni')`; and my version:; `scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.1 scipy==1.5.4 pandas==1.2.0 scikit-learn==0.24.0 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3`. Thank you. Hope for you answer!; Best,; Ariel.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1766
https://github.com/scverse/scanpy/pull/1767:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1767:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Added links to dorothea/progeny in the ecosystem documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1767
https://github.com/scverse/scanpy/pull/1768:213,Availability,down,down,213,"The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1768:329,Availability,error,error,329,"The correlation plot example looks different with the new version of Matplotlib. As far as I can tell, the large difference in edge widths is an artifact of pixelation, as if dpi is increased the edge widths slim down. I've also fixed how the `linewidths` key word argument is passed (previous kwarg being checked would cause an error if passed). Old version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775546-f4af1900-9088-11eb-9d5e-4cbe8820b92b.png). New version:. ![correlation](https://user-images.githubusercontent.com/8238804/112775529-e52fd000-9088-11eb-9833-d33a05362a14.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1768
https://github.com/scverse/scanpy/pull/1769:48,Deployability,Update,Update,48,* Minor kwarg fixes in pl.correlation_matrix; * Update test correlation image; * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:55,Testability,test,test,55,* Minor kwarg fixes in pl.correlation_matrix; * Update test correlation image; * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1769:114,Testability,test,test,114,* Minor kwarg fixes in pl.correlation_matrix; * Update test correlation image; * Skip correlation matrix plotting test on python 3.6. Minor conflict due to centered color map changes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1769
https://github.com/scverse/scanpy/pull/1772:1348,Deployability,Update,Update,1348,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:48,Testability,test,tests,48,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:67,Testability,test,test,67,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:251,Testability,test,tests,251,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:267,Testability,Test,Tests,267,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:350,Testability,test,tests,350,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:612,Testability,test,test,612,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:924,Testability,test,tests,924,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:954,Testability,test,tests,954,"We frequently use reference images for plotting tests, that is, we test against a saved copy of a plot from an older version to check that the results haven't changed much. Currently we store the reference image in git inside a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1356,Testability,Test,Tested,1356,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1740,Testability,test,test,1740,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1959,Testability,test,tests,1959,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2028,Testability,test,test,2028,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:2204,Testability,test,test,2204,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1772:1936,Usability,simpl,simple,1936,"de a directory like `scanpy/tests/_images`. Tests generate a new file with the same name as the reference image inside `scanpy/tests/figures`. These files are compared. If they're not similar enough, a file with a similar name, appended with `failed-diff` is written to the figures folder. There are a few annoyances with this setup. ### Opening the relevant files to investigate a failed test. Its not hard to open up the generated file, reference, and diff to see what changed, but it's harder than it should be. You'd have to write a function to make this at all easy. ### It's not obvious from the paths which file is the reference and which file was generated. E.g. given the paths:. ```; scanpy/tests/_images/pca.png; scanpy/tests/figures/pca.png; ```. which one is the reference?. ### Shared file names cause ambiguity. <img width=""771"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113106711-cda24400-924e-11eb-8e00-743f178e40b8.png"">. ~~This is more of a hunch.~~ There should be three images here, but only two show up. I suspect this has to do with the missing image having a duplicated name. Update: Tested this in #1773, all images show up now (@gokceneraslan):. <img width=""364"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/113120191-0f39eb80-925d-11eb-9c99-b2630e829ecf.png"">. ## This PR. This PR addresses the three points from above. Now each reference image gets its own directory. The reference image is named `expected.png`, and is stored in git. When a test runs the generated image is stored as `actual.png`, and compared with `expected.png`. A failing diff is also written to this directory if the comparison fails. * Opening all images is now as simple as `open scanpy/tests/_images/{fig_name}/*`; * Naming conventions are obvious; * Per test, each file has a unique name. ## TODO. - [x] Dev docs; - [ ] Decide on fixture api; - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1772
https://github.com/scverse/scanpy/pull/1773:95,Testability,test,tests,95,Branch of #1772 to check that CI reporting is made better. Makes some reference based plotting tests fail.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1773
https://github.com/scverse/scanpy/pull/1775:280,Integrability,wrap,wrapper,280,"Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper.; I also added a test in `tests/external/test_scnym.py` that passes.; Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see.; Thanks for building a great ecosystem!. Best,; Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:305,Testability,test,test,305,"Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper.; I also added a test in `tests/external/test_scnym.py` that passes.; Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see.; Thanks for building a great ecosystem!. Best,; Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:314,Testability,test,tests,314,"Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper.; I also added a test in `tests/external/test_scnym.py` that passes.; Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see.; Thanks for building a great ecosystem!. Best,; Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/pull/1775:271,Usability,simpl,simply,271,"Hi scanpy folks,. This PR adds our cell identity classification model [`scnym`](https://github.com/calico/scnym) as a tool in `sc.external.tl.scnym`. The `scnym` API was inspired by `scanpy` and intended to be compatible, so the implementation in `external/_scnym.py` is simply a wrapper.; I also added a test in `tests/external/test_scnym.py` that passes.; Everything was linted with `black,flake8,autopep8` through `pre-commit`. Please let me know if there are any issues or changes you'd like to see.; Thanks for building a great ecosystem!. Best,; Jacob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1775
https://github.com/scverse/scanpy/issues/1776:0,Deployability,Update,Update,0,"Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/issues/1776:162,Usability,simpl,simplify,162,"Update `pyproject.toml` to use [PEP-621](https://www.python.org/dev/peps/pep-0621/) and [PEP-631](https://www.python.org/dev/peps/pep-0631/) metadata. Basically, simplify by removing most of the `tool.flit` stuff. @flying-sheep, would you like to do this/ do you foresee any blockers?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1776
https://github.com/scverse/scanpy/pull/1780:457,Availability,down,downstream,457,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:0,Deployability,Integrat,Integrated,0,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:554,Deployability,install,installed,554,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:605,Deployability,integrat,integrate,605,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:0,Integrability,Integrat,Integrated,0,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/pull/1780:605,Integrability,integrat,integrate,605,"Integrated [Shannon Component Analysis](https://www.biorxiv.org/content/10.1101/2021.01.19.427303v2.full) into the external API, with full documentation and references. SCA operates like PCA, storing a lower-dimensional representation of `adata.X` (or the chosen `layer`) in `adata.obsm[key_added]`. . Like PCA and ICA, SCA is linear; however, we have found SCA representations better than PCA or ICA at separating true cell types, yielding better clusters downstream. The source repository can be found [here](https://github.com/bendemeo/shannonca) and installed using `pip`. If you decide you'd like to integrate this into the main API (i.e. as `sc.tl.sca`), I would be happy to assist.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1780
https://github.com/scverse/scanpy/issues/1781:1300,Deployability,install,install,1300,".com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-wit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2359,Deployability,update,updated,2359,"produce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17; 56 logical CPU cores, x86_64; -----; Session information updated at 2021-04-06 12:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:460,Security,access,access,460,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setupt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:1391,Testability,log,logging,1391," reproduce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17; 56 logical CPU cores, x86_64; -----; Session information updated at 2021-04-06 12:14. </detai",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:2305,Testability,log,logical,2305,"produce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.9.4 (default, Apr 5 2021, 15:43:56) [GCC 7.3.1 20180303 (Red Hat 7.3.1-5)]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.17; 56 logical CPU cores, x86_64; -----; Session information updated at 2021-04-06 12:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1781:259,Usability,guid,guide,259,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; scvi does not have models class anymore to access VAE and LDVAE, please change it to use scvi.module. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); ```. ```pytb; File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 116, in scvi; from scvi.models import VAE, LDVAE; ModuleNotFoundError: No module named 'scvi.models'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/data/lab/MCF7/for_PAGA/MCF7_batch_attempt1.py"", line 140, in <module>; sc.external.pp.scvi(adata, train_size=0.8, batch_key='batch'); File ""/usr/local/apps/python/3.9.4/lib/python3.9/site-packages/scanpy/external/pp/_scvi.py"", line 120, in scvi; raise ImportError(; ImportError: Please install scvi package from https://github.com/YosefLab/scVI. ```. #### Versions; >>> scanpy.logging.print_versions() ; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 3.2.1; igraph 0.9.1; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.3; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.1; scipy 1.6.2; setupt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1781
https://github.com/scverse/scanpy/issues/1782:266,Availability,error,error,266,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 41",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:1389,Availability,error,error,1389," ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2231,Modifiability,layers,layers,2231,", :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects ""; 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data.; ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; PyObjCTools NA; anndata 0.7.5; anndata2ri 1.0.5; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; jsonschema 3.2.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:334,Performance,load,loaded,334,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---. Hello, I am trying to run `sc.pp.highly_variable_genes` with `flavor='seurat_v3'` on some data, but it is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file; it should be raw count data. . ### Minimal code sample. ```python; zf_48 = anndata.read_h5ad(""data.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.var_names_make_unique(); sc.pp.filter_cells(zf_48, min_genes=550); sc.pp.filter_genes(zf_48, min_cells=10); zf_48; #AnnData object with n_obs × n_vars = 887 × 13180; # obs: 'n_genes'; # var: 'gene_name', 'gene_ids', 'n_cells'. zf_48.var['mt'] = zf_48.var_names.str.startswith('mt-') ; sc.pp.calculate_qc_metrics(zf_48, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1); ```; Here is the error:; ```pytb; ValueError Traceback (most recent call last); <ipython-input-170-37cd37b7326e> in <module>; 16 zf_48 = zf_48[zf_48.obs.n_genes_by_counts < 2500, :]; 17 zf_48 = zf_48[zf_48.obs.pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 41",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2544,Performance,load,loading,2544,"pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects ""; 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data.; ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; PyObjCTools NA; anndata 0.7.5; anndata2ri 1.0.5; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; jsonschema 3.2.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.8; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.8; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.3; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2607,Performance,load,loaded,2607,"pct_counts_mt < 10, :]; ---> 18 sc.pp.highly_variable_genes(zf_48, flavor='seurat_v3', span=1). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects ""; 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data.; ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; PyObjCTools NA; anndata 0.7.5; anndata2ri 1.0.5; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; jsonschema 3.2.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.8; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.8; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.3; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/issues/1782:2830,Performance,bottleneck,bottleneck,2830,"disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key); 413 ; 414 if flavor == 'seurat_v3':; --> 415 return _highly_variable_genes_seurat_v3(; 416 adata,; 417 layer=layer,. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace); 59 X = adata.layers[layer] if layer is not None else adata.X; 60 if check_nonnegative_integers(X) is False:; ---> 61 raise ValueError(; 62 ""`pp.highly_variable_genes` with `flavor='seurat_v3'` expects ""; 63 ""raw count data."". ValueError: `pp.highly_variable_genes` with `flavor='seurat_v3'` expects raw count data.; ```. Am I loading the data in wrong? This processing has worked for data loaded in using 'sc.read_10x_mtx()'. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; PyObjCTools NA; anndata 0.7.5; anndata2ri 1.0.5; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2020.12.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.4.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.0; jsonschema 3.2.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.8; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.8; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.8; psutil 5.7.3; ptyprocess 0.6.0; pvectorc NA; pygments 2.7.3; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; rpy2 3.3.6; scanpy 1.6.0; scipy 1.5.4; seaborn 0.11.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; skmisc 0.1.3; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1782
https://github.com/scverse/scanpy/pull/1785:11,Deployability,release,release,11,Will tag a release on merge,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1785
https://github.com/scverse/scanpy/pull/1786:10,Deployability,release,release,10,Add 1.7.3 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1786
https://github.com/scverse/scanpy/pull/1787:0,Deployability,Update,Update,0,Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1787:13,Deployability,release,release,13,Update 1.7.2 release notes on master,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1787
https://github.com/scverse/scanpy/pull/1790:40,Modifiability,config,config,40,Backport PR #1789: Fix malformed flake8 config file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1790
https://github.com/scverse/scanpy/issues/1791:257,Usability,guid,guide,257,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). 1) create a new env; ```bash; conda create -n test_scanpy python=3.7 ipykernel scanpy -y; ```. 2) tutorial notebook; [test_scanpy.html.zip](https://github.com/theislab/scanpy/files/6272105/test_scanpy.html.zip),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1791
https://github.com/scverse/scanpy/issues/1793:632,Testability,test,tests,632,"A lot of computing will be GPU accelerated in the near and distant future. ScanPy is no exception as was recently demonstrated by NVIDIA. We got a nice PR (https://github.com/theislab/scanpy/pull/1533) to get started, but we are hesitant to merge it since we cannot yet cover GPU accelerated algorithms with our CI. - [ ] Get machines with GPUs; - [ ] Set them up with CUDA etc; - [ ] Explore whether GA or Azure suits us better for a custom runner; - [ ] Hook up the custom runner with the ScanPy repository; - [ ] Investigate whether we should use custom triggers for GPU related PRs or just always run them; - [ ] Write GPU only tests",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1793
https://github.com/scverse/scanpy/issues/1794:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Currently for most plots (where it makes sense) you can specify the column of .var which contains gene symbols. This doesn't seem to work for sc.pl.violin because. https://github.com/theislab/scanpy/blob/c488909a54e9ab1462186cca35b537426e4630db/scanpy/plotting/_anndata.py#L727. is not getting passed a `gene_symbols` argument when called from violin (that method does accept that argument). This should be an easy fix and make violin plot behave a bit more closely to the other plots. Happy to submit a PR.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1794
https://github.com/scverse/scanpy/issues/1795:589,Availability,error,error,589,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## save command; adata.write(folder + ""before_regression.h5ad""); ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:695,Testability,log,logging,695,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## save command; adata.write(folder + ""before_regression.h5ad""); ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1795:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## save command; adata.write(folder + ""before_regression.h5ad""); ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1795
https://github.com/scverse/scanpy/issues/1796:5793,Availability,error,error,5793,"0 0.001387 0.043064; ENSMUSG00000033845 ENSMUSG00000033845 Mrpl15 False ... -0.469772 0.349803 0.824321; ENSMUSG00000025903 ENSMUSG00000025903 Lypla1 False ... -0.396586 0.136585 0.531308; ENSMUSG00000104217 ENSMUSG00000104217 Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6936,Deployability,update,updated,6936," Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----; Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]; Linux-4.19.121-linuxkit-x86_64-with-debian-10.8; 2 logical CPU cores; -----; Session information updated at 2021-04-12 15:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:1107,Modifiability,config,configs,1107,"en reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import pandas as pd; import numpy as np; import urllib.request; ; url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad""; # 75 MB anndata; urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(; adata,; save='.png',; show=False,; gene_symbols='Symbol',; n_genes=10,; log=False,; use_raw=False,; ); ```. ```pytb; Traceback (most recent call last):; File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>; sc.pl.rank_genes_groups_dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot; return _rank_genes_groups_plot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot; _pl = dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot; dp = DotPlot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__; BasePlot.__init__(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__; self.categories, self.obs_tidy = _prepare_dataframe(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe; obs_tidy = get.obs_df(; File ""/usr/local/lib/python3.8/site-packages/scanpy/get/ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:922,Testability,log,log,922,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import pandas as pd; import numpy as np; import urllib.request; ; url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad""; # 75 MB anndata; urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(; adata,; save='.png',; show=False,; gene_symbols='Symbol',; n_genes=10,; log=False,; use_raw=False,; ); ```. ```pytb; Traceback (most recent call last):; File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>; sc.pl.rank_genes_groups_dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot; return _rank_genes_groups_plot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot; _pl = dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot; dp = DotPlot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__; BasePlot.__init__(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__; self.categories, self.obs_tidy = _prepare_dataframe(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe; obs_tidy = get.obs_df(; Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:5992,Testability,log,logging,5992," Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----; Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]; Linux-4.19.121-linuxkit-x86_64-with-debian-10.8; 2 logical CPU cores; -----; Session information updated at 2021-04-12 15:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:6890,Testability,log,logical,6890," Gm37988 False ... -1.059987 0.036154 0.246548; ENSMUSG00000033813 ENSMUSG00000033813 Tcea1 False ... -0.342200 0.578174 1.001880; ... ... ... ... ... ... ... ...; ENSMUSG00000094915 ENSMUSG00000094915 AC168977.2 False ... -3.593359 0.000265 0.015330; ENSMUSG00000079808 ENSMUSG00000079808 AC168977.1 False ... -0.756427 0.023002 0.199670; ENSMUSG00000095041 ENSMUSG00000095041 AC149090.1 False ... 0.816554 0.149080 0.578574; ENSMUSG00000063897 ENSMUSG00000063897 CAAA01118383.1 False ... 0.403835 0.041207 0.304460; ENSMUSG00000095742 ENSMUSG00000095742 CAAA01147332.1 False ... -0.307310 0.001870 0.058347; ```. So when `pl.rank_genes_groups` is being called, some adequate mapping is being done from the index of `adata.var` to Symbol, whereas when the other methods are called, this mapping is skipped, hence the error. I would expect the different `pl.rank_genes_groups_*` methods to behave as `pl.rank_genes_groups` when it comes to symbols not being used as indexes. Thanks!. #### Versions. <details>. >>> sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.2; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; h5py 2.10.0; igraph 0.8.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; packaging 20.9; pandas 1.1.5; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; texttable 1.6.3; typing_extensions NA; zipp NA; -----; Python 3.6.13 | packaged by conda-forge | (default, Feb 19 2021, 05:36:01) [GCC 9.3.0]; Linux-4.19.121-linuxkit-x86_64-with-debian-10.8; 2 logical CPU cores; -----; Session information updated at 2021-04-12 15:14. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1796:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import pandas as pd; import numpy as np; import urllib.request; ; url = ""https://humancellatlas.usegalaxy.eu/datasets/11ac94870d0bb33a8d1d2e6bc37a120e/display?to_ext=h5ad""; # 75 MB anndata; urllib.request.urlretrieve(url, '11ac94.h5ad'). adata = sc.read('11ac94.h5ad'). sc.settings.figdir = '.'. sc.pl.rank_genes_groups_dotplot(; adata,; save='.png',; show=False,; gene_symbols='Symbol',; n_genes=10,; log=False,; use_raw=False,; ); ```. ```pytb; Traceback (most recent call last):; File ""/private/var/folders/23/wwh84vd95rncnf5mx753cpgh0000gp/T/tmpenni0vju/job_working_directory/000/11/configs/tmp4tnm4xxb"", line 15, in <module>; sc.pl.rank_genes_groups_dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 647, in rank_genes_groups_dotplot; return _rank_genes_groups_plot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py"", line 426, in _rank_genes_groups_plot; _pl = dotplot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 913, in dotplot; dp = DotPlot(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py"", line 127, in __init__; BasePlot.__init__(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_baseplot_class.py"", line 105, in __init__; self.categories, self.obs_tidy = _prepare_dataframe(; File ""/usr/local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 1845, in _prepare_dataframe; obs_tidy = get.obs_df(; Fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1796
https://github.com/scverse/scanpy/issues/1797:1991,Availability,error,errors,1991,"n; 4 from ._highly_variable_genes import highly_variable_genes; 5 from ._simple import log1p, sqrt, scale, subsample. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in; 4 from anndata import AnnData; 5; ----> 6 from . import _simple as pp; 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2925,Availability,error,errors,2925,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3561,Availability,error,errors,3561,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2126,Modifiability,config,config,2126,"mple. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in; 4 from anndata import AnnData; 5; ----> 6 from . import _simple as pp; 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2134,Modifiability,extend,extending,2134,"mple. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_recipes.py in; 4 from anndata import AnnData; 5; ----> 6 from . import _simple as pp; 7 from ._deprecated.highly_variable_genes import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2343,Modifiability,config,config,2343," import filter_genes_dispersion, filter_genes_cv_deprecated; 8 from ._normalization import normalize_total. ~/.conda/envs/scanpy/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py in; 8 from typing import Union, Optional, Tuple, Collection, Sequence, Iterable; 9; ---> 10 import numba; 11 import numpy as np; 12 import scipy as sp. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/init.py in; 32; 33 # Re-export decorators; ---> 34 from numba.core.decorators import (cfunc, generated_jit, jit, njit, stencil,; 35 jit_module); 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:2952,Modifiability,config,config,2952,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1797:3569,Modifiability,config,config,3569,"; 36. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/decorators.py in; 10; 11 from numba.core.errors import DeprecationError, NumbaDeprecationWarning; ---> 12 from numba.stencils.stencil import stencil; 13 from numba.core import config, extending, sigutils, registry; 14. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/stencils/stencil.py in; 9 from llvmlite import ir as lir; 10; ---> 11 from numba.core import types, typing, utils, ir, config, ir_utils, registry; 12 from numba.core.typing.templates import (CallableTemplate, signature,; 13 infer_global, AbstractTemplate). ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/registry.py in; 2; 3 from numba.core.descriptors import TargetDescriptor; ----> 4 from numba.core import utils, typing, dispatcher, cpu; 5; 6 # -----------------------------------------------------------------------------. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/dispatcher.py in; 13; 14 from numba import _dispatcher; ---> 15 from numba.core import utils, types, errors, typing, serialize, config, compiler, sigutils; 16 from numba.core.compiler_lock import global_compiler_lock; 17 from numba.core.typeconv.rules import default_type_manager. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler.py in; 11 from numba.core.environment import lookup_environment; 12; ---> 13 from numba.core.compiler_machinery import PassManager; 14; 15 from numba.core.untyped_passes import (ExtractByteCode, TranslateByteCode,. ~/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/compiler_machinery.py in; 5 from numba.core.compiler_lock import global_compiler_lock; 6 from numba.core import errors, config, transforms; ----> 7 from numba.core.utils import add_metaclass; 8 from numba.core.tracing import event; 9 from numba.core.postproc import PostProcessor. ImportError: cannot import name 'add_metaclass' from 'numba.core.utils' (/home/qsw5175/.conda/envs/scanpy/lib/python3.8/site-packages/numba/core/utils.py)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1797
https://github.com/scverse/scanpy/issues/1798:277,Modifiability,layers,layers,277,"It is common to store raw counts (=unnormalized) of all measured genes under `adata.raw`, while having normalized and unnormalized expression of a subset of genes (might be only protein coding genes, or all genes except ribosomal and mitochondrial etc) at `adata.X` and `adata.layers['counts']` respectively. This however gives rise to a lot of trouble in plotting since visualizing raw counts is not a great idea due to the dynamic range. It is super annoying to pass `use_raw=False` to a lot of functions. Furthermore, weird `rank_genes_groups` outputs as a result of raw counts might go unnoticed because of this. (happened to me many times). I think there was a discussion somewhere about switching to `use_raw=False` by default in all functions, but this may potentially break things since it's a significant behavior change. This might be reasonable for Scanpy 2.0, but not in 1.x I assume. My suggestion is to have a `use_raw` option under `sc.settings` (i.e. the global `ScanpyConfig` instance) which is `None` by default, and can be set to `False` (e.g. `sc.settings.use_raw=False`) which would then affect all the functions with `use_raw` argument. This way we don't break the behavior but still have a reasonable way to turn this thing off :) . Let me know what you think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1798
https://github.com/scverse/scanpy/issues/1799:188,Availability,error,error,188,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:511,Availability,error,errors,511,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3851,Availability,error,errors,3851,"mport UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4377,Availability,error,errors,4377,"ce.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5806,Availability,avail,available,5806,"a/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9625,Availability,error,errors,9625,"e:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback); 129 value = type(); 130 try:; --> 131 self.gen.throw(type, value, traceback); 132 except StopIteration as exc:; 133 # Suppress StopIteration *unless* it's the same exception that; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 ; ; LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32; ; File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^; ; During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2603,Deployability,install,installed,2603,"kages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:4919,Deployability,pipeline,pipeline,4919,"/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5031,Deployability,pipeline,pipeline,5031,"/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5816,Deployability,pipeline,pipelines,5816,"a/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7738,Deployability,pipeline,pipeline,7738,"pile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs); 36 return _acquire_compile_lock; 37 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state); 287 mutated |= check(pss.run_initialization, internal_state); 288 with SimpleTimer() as pass_time:; --> 289 mutated |= check(pss.run_pass, internal_state); 290 with SimpleTimer() as finalize_time:; 291 mutated |= check(pss.run_finalizer, internal_state); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 260 ; 261 def check(func, compiler_state):; --> 262 mangled = func(compiler_state); 263 if mangled not in (True, False):; 264 msg = (""CompilerPass implementations should return True/False. ""; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 461 ; 462 # TODO: Pull this out into the pipeline; --> 463 NativeLowering().run_pass(state); 464 lowered = state['cr']; 465 signature = typing.signature(state.return_type, *state.args); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 382 lower = lowering.Lower(targetctx, library, fndesc, interp,; 383 metadata=metadata); --> 384 lower.lower(); 385 if not flags.no_cpython_wrapper:; 386 lower.create_cpython_wrapper(flags.release_gil); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower(self); 134 if self.generator_info is None:; 135 self.genlower = None; --> 136 self.lower_normal_function(self.fndesc); 137 else:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9918,Deployability,pipeline,pipeline,9918,"e:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback); 129 value = type(); 130 try:; --> 131 self.gen.throw(type, value, traceback); 132 except StopIteration as exc:; 133 # Suppress StopIteration *unless* it's the same exception that; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 ; ; LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32; ; File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^; ; During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3334,Energy Efficiency,Reduce,Reduced,3334,"ces,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:2578,Integrability,message,message,2578,"kages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we didn't; 807 # use dense distances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:3451,Integrability,wrap,wrapper,3451,"obs, n_neighbors, set_op_mix_ratio, local_connectivity); 385 # umap 0.5.0; 386 warnings.filterwarnings(""ignore"", message=r""Tensorflow not installed""); --> 387 from umap.umap_ import fuzzy_simplicial_set; 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/__init__.py in <module>; ----> 1 from .umap_ import UMAP; 2 ; 3 # Workaround: https://github.com/numba/numba/issues/3341; 4 import numba; 5 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/umap_.py in <module>; 52 from umap.spectral import spectral_layout; 53 from umap.utils import deheap_sort, submatrix; ---> 54 from umap.layouts import (; 55 optimize_layout_euclidean,; 56 optimize_layout_generic,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py in <module>; 37 },; 38 ); ---> 39 def rdist(x, y):; 40 """"""Reduced Euclidean distance.; 41 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/decorators.py in wrapper(func); 219 with typeinfer.register_dispatcher(disp):; 220 for sig in sigs:; --> 221 disp.compile(sig); 222 disp.disable_compile(); 223 return disp; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, sig); 907 with ev.trigger_event(""numba:compile"", data=ev_details):; 908 try:; --> 909 cres = self._compiler.compile(args, return_type); 910 except errors.ForceLiteralArg as e:; 911 def folded(args, kws):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in compile(self, args, return_type); 77 ; 78 def compile(self, args, return_type):; ---> 79 status, retval = self._compile_cached(args, return_type); 80 if status:; 81 return retval; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_cached(self, args, return_type); 91 ; 92 try:; ---> 93 retval = self._compile_core(args, return_type); 94 except errors.TypingError as e:; 95 self._failed_cache[key] = e; ; ~/miniforge3/envs/scVelo/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:9790,Modifiability,config,config,9790,"e:; 138 self.genlower = self.GeneratorLower(self); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_normal_function(self, fndesc); 188 # Init argument values; 189 self.extract_function_arguments(); --> 190 entry_block_tail = self.lower_function_body(); 191 ; 192 # Close tail of entry block; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_function_body(self); 214 bb = self.blkmap[offset]; 215 self.builder.position_at_end(bb); --> 216 self.lower_block(block); 217 self.post_lower(); 218 return entry_block_tail; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 228 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,; 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); 232 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/contextlib.py in __exit__(self, type, value, traceback); 129 value = type(); 130 try:; --> 131 self.gen.throw(type, value, traceback); 132 except StopIteration as exc:; 133 # Suppress StopIteration *unless* it's the same exception that; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 749 newerr = errcls(e).add_context(_format_msg(fmt_, args, kwargs)); 750 tb = sys.exc_info()[2] if numba.core.config.FULL_TRACEBACKS else None; --> 751 raise newerr.with_traceback(tb); 752 ; 753 ; ; LoweringError: Failed in nopython mode pipeline (step: nopython mode backend); Storing i64 to ptr of i32 ('dim'). FE type int32; ; File ""../../../../miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py"", line 52:; def rdist(x, y):; <source elided>; result = 0.0; dim = x.shape[0]; ^; ; During: lowering ""dim = static_getitem(value=$8load_attr.2, index=0, index_var=$const10.3, fn=<built-in function getitem>)"" at /Users/depretis.stefano/miniforge3/envs/scVelo/lib/python3.8/site-packages/umap/layouts.py (52); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:397,Testability,Assert,AssertionError,397,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1166,Testability,Assert,AssertionError,1166,"` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:1196,Testability,Assert,AssertionError,1196,"` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds); 806 # we need self._distances also for method == 'gauss' if we di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:5475,Testability,assert,assert,5475,"lo/lib/python3.8/site-packages/numba/core/dispatcher.py in _compile_core(self, args, return_type); 104 ; 105 impl = self._get_implementation(args, {}); --> 106 cres = compiler.compile_extra(self.targetdescr.typing_context,; 107 self.targetdescr.target_context,; 108 impl,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class); 604 pipeline = pipeline_class(typingctx, targetctx, library,; 605 args, return_type, flags, locals); --> 606 return pipeline.compile_extra(func); 607 ; 608 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in compile_extra(self, func); 351 self.state.lifted = (); 352 self.state.lifted_from = None; --> 353 return self._compile_bytecode(); 354 ; 355 def compile_ir(self, func_ir, lifted=(), lifted_from=None):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_bytecode(self); 413 """"""; 414 assert self.state.func_ir is None; --> 415 return self._compile_core(); 416 ; 417 def _compile_ir(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 393 self.state.status.fail_reason = e; 394 if is_final_pipeline:; --> 395 raise e; 396 else:; 397 raise CompilerError(""All available pipelines exhausted""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler.py in _compile_core(self); 384 res = None; 385 try:; --> 386 pm.run(self.state); 387 if self.state.cr is not None:; 388 break; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(ps",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:238,Usability,learn,learn,238,"Hi all, we (@ste-depo) are trying to run scanpy on M1 architecture. We have created a conda environment using Miniforge for osx64-arm. However, when running `sc.pp.neighbors` we have this error. I understand that this is related to `umap-learn` and not directly to `scanpy`, but I think it's worth to mention here. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/errors.py in new_error_context(fmt_, *args, **kwargs); 743 try:; --> 744 yield; 745 except NumbaError as e:; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_block(self, block); 229 loc=self.loc, errcls_=defaulterrcls):; --> 230 self.lower_inst(inst); 231 self.post_block(block); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in lower_inst(self, inst); 327 val = self.lower_assign(ty, inst); --> 328 self.storevar(val, inst.target.name); 329 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/lowering.py in storevar(self, value, name); 1277 name=name); -> 1278 raise AssertionError(msg); 1279 ; ; AssertionError: Storing i64 to ptr of i32 ('dim'). FE type int32; ; During handling of the above exception, another exception occurred:; ; LoweringError Traceback (most recent call last); <ipython-input-19-ef300851c737> in <module>; 1 n_neighbors = int(np.sqrt(adata.shape[0])/2); ----> 2 sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=15); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7093,Usability,Simpl,SimpleTimer,7093,"ba/core/compiler_machinery.py in run(self, state); 337 (self.pipeline_name, pass_desc); 338 patched_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs); 36 return _acquire_compile_lock; 37 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state); 287 mutated |= check(pss.run_initialization, internal_state); 288 with SimpleTimer() as pass_time:; --> 289 mutated |= check(pss.run_pass, internal_state); 290 with SimpleTimer() as finalize_time:; 291 mutated |= check(pss.run_finalizer, internal_state); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 260 ; 261 def check(func, compiler_state):; --> 262 mangled = func(compiler_state); 263 if mangled not in (True, False):; 264 msg = (""CompilerPass implementations should return True/False. ""; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 461 ; 462 # TODO: Pull this out into the pipeline; --> 463 NativeLowering().run_pass(state); 464 lowered = state['cr']; 465 signature = typing.signature(state.return_type, *state.args); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 382 lower = lowering.Lower(targetctx, library, fndesc, interp,; 383 metadata=metadata); --> 384 lower.lower(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1799:7187,Usability,Simpl,SimpleTimer,7187,"_exception = self._patch_error(msg, e); --> 339 raise patched_exception; 340 ; 341 def dependency_analysis(self):; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in run(self, state); 328 pass_inst = _pass_registry.get(pss).pass_inst; 329 if isinstance(pass_inst, CompilerPass):; --> 330 self._runPass(idx, pass_inst, state); 331 else:; 332 raise BaseException(""Legacy pass in use""); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 33 def _acquire_compile_lock(*args, **kwargs):; 34 with self:; ---> 35 return func(*args, **kwargs); 36 return _acquire_compile_lock; 37 ; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in _runPass(self, index, pss, internal_state); 287 mutated |= check(pss.run_initialization, internal_state); 288 with SimpleTimer() as pass_time:; --> 289 mutated |= check(pss.run_pass, internal_state); 290 with SimpleTimer() as finalize_time:; 291 mutated |= check(pss.run_finalizer, internal_state); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/compiler_machinery.py in check(func, compiler_state); 260 ; 261 def check(func, compiler_state):; --> 262 mangled = func(compiler_state); 263 if mangled not in (True, False):; 264 msg = (""CompilerPass implementations should return True/False. ""; ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 461 ; 462 # TODO: Pull this out into the pipeline; --> 463 NativeLowering().run_pass(state); 464 lowered = state['cr']; 465 signature = typing.signature(state.return_type, *state.args); ; ~/miniforge3/envs/scVelo/lib/python3.8/site-packages/numba/core/typed_passes.py in run_pass(self, state); 382 lower = lowering.Lower(targetctx, library, fndesc, interp,; 383 metadata=metadata); --> 384 lower.lower(); 385 if not flags.no_cpython_wrapper:; 386 lower.create_cpython_wrapper(flags.release_gil); ; ~/m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1799
https://github.com/scverse/scanpy/issues/1800:122,Testability,log,logFC,122,"Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ?. I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1800:161,Testability,log,logFC,161,"Hello,. I'm using the Wilcoxon method from the scanpy.tl.rank_genes_groups() function for my dataset. I am not seeing any logFC values in the output (the lowest logFC is zero). Should I be expecting to see some negative values (like we see in bulk RNAseq DE results) ?. I apologize in advance if this is a naive question. Thanks for your help.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1800
https://github.com/scverse/scanpy/issues/1804:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; I would like to see how to use scanpy to compare the cell types distribution per cohort per different condition. Imagine you have different disease state who have different drug exposure, so you need to compare different cell types in each cohort per each condition or drug exposure. so it id three dimension: cell types[Bcells and Tcells], disease status[CKD vs DKD] and drug exposure[absent vs non absent]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1804
https://github.com/scverse/scanpy/pull/1805:241,Testability,Test,Tested,241,I allowed the 'resolution' parameter to be used in Louvain clustering when flavor='rapids'. The resolution parameter works with cuGraph Louvain clustering: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.community.louvain. Tested that the function works and docs are built correctly.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1805
https://github.com/scverse/scanpy/issues/1806:79,Availability,down,down,79,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:234,Availability,error,errors,234,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:528,Availability,error,error,528,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:929,Deployability,install,install,929,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:483,Integrability,Depend,Depending,483,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/issues/1806:263,Modifiability,variab,variable,263,"Ref https://github.com/theislab/scanpy/issues/1698#issuecomment-824634639, cut down in https://github.com/theislab/scanpy/issues/1698#issuecomment-826712541. Basically, `gearys_c`, `morans_i` can run into silent numba parallelization errors when all values for a variable are the same. We should specifically address these cases. As suggested by @Hrovatin, `nan` and a warning is probably sufficient for this case. That said, it may take some work to consistently throw a warning. * Depending on the threading backend, this may error (solving the problem of incorrect values); * We may be able to control this, but how the parallel backend interacts with the `error_model` seems unclear; * I don't think we can throw a warning from numba code, let alone parallel numba code; * It would be nice if we could guarantee a `tbb` or `omp` threading backend, since they seem more consistent, but I personally have not been able to `pip install` these for a bit over a year now. This may be macOS specific.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1806
https://github.com/scverse/scanpy/pull/1807:258,Testability,log,logging,258,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1807:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Add pynndescent to `sc.logging.print_header()`. Close #1613,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1807
https://github.com/scverse/scanpy/pull/1808:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1808:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Inline documentation for the matrixplot. Addressing issue #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1808
https://github.com/scverse/scanpy/pull/1809:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. part of #1664; add inline examples for; - sc.pl.draw_graph; - sc.pl.heatmap; - sc.pl.dendrogram; - sc.pl.tsne; - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1809:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. part of #1664; add inline examples for; - sc.pl.draw_graph; - sc.pl.heatmap; - sc.pl.dendrogram; - sc.pl.tsne; - sc.pl.diffmap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1809
https://github.com/scverse/scanpy/pull/1810:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1810:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. Adress one point in #1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1810
https://github.com/scverse/scanpy/pull/1814:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1814:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; Add violin plot examples according to https://github.com/theislab/scanpy/issues/1664,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1814
https://github.com/scverse/scanpy/pull/1815:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/pull/1815:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; ref #1664 sc.pl.pca_loadings,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1815
https://github.com/scverse/scanpy/issues/1816:2114,Deployability,update,updated,2114,"onal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python; import scanpy as sc; import numpy as np; import pandas as pd; adata = sc.datasets.pbmc68k_reduced(); sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb; ValueError: Axis limits cannot be NaN or Inf; ```; **Note**: recalculating pca solves the problem . #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.8.0.dev78+gc488909a; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appnope 0.1.0; attr 19.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.20.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0+1.g022ab0f; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.2.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.7; numba 0.50.1; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; scanpy 1.8.0.dev78+gc488909a; scipy 1.5.0; seaborn 0.10.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.3; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 2.1.5; notebook 6.0.3; -----; Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-04-27 11:22. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:698,Performance,bottleneck,bottleneck,698,"- [x] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python; import scanpy as sc; import numpy as np; import pandas as pd; adata = sc.datasets.pbmc68k_reduced(); sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb; ValueError: Axis limits cannot be NaN or Inf; ```; **Note**: recalculating pca solves the problem . #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.8.0.dev78+gc488909a; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appnope 0.1.0; attr 19.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.20.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0+1.g022ab0f; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.2.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.7; numba 0.50.1; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; scanpy 1.8.0.dev78+gc488909a; scipy 1.5.0; seaborn 0.10.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.3; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 2.1.5; notebook 6.0.3; -----; Python 3.8.3 (default, Jul 2 2020, 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1816:2062,Testability,log,logical,2062,"onal) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . ```python; import scanpy as sc; import numpy as np; import pandas as pd; adata = sc.datasets.pbmc68k_reduced(); sc.pl.pca_loadings(adata, components = '1,2,3'). ```. ```pytb; ValueError: Axis limits cannot be NaN or Inf; ```; **Note**: recalculating pca solves the problem . #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.8.0.dev78+gc488909a; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appnope 0.1.0; attr 19.3.0; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.0; cloudpickle 1.5.0; colorama 0.4.3; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.1; dask 2.20.0; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.1; jinja2 2.11.2; joblib 0.16.0; jsonschema 3.2.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.33.0+1.g022ab0f; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.2.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; nbformat 5.0.7; numba 0.50.1; numexpr 2.7.1; numpy 1.18.5; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.7.0; ptyprocess 0.6.0; pvectorc NA; pygments 2.6.1; pyparsing 2.4.7; pyrsistent NA; pytz 2020.1; scanpy 1.8.0.dev78+gc488909a; scipy 1.5.0; seaborn 0.10.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; sphinxcontrib NA; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tblib 1.6.0; texttable 1.6.3; tlz 0.10.1; toolz 0.10.0; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 2.1.5; notebook 6.0.3; -----; Python 3.8.3 (default, Jul 2 2020, 11:26:31) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-04-27 11:22. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1816
https://github.com/scverse/scanpy/issues/1817:141,Availability,recover,recover,141,"Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips?. ```; ad.X = ad.obsm['raw_data'].copy(); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1817:141,Safety,recover,recover,141,"Hi scanpy team,. The HVG method seurat_v3 requires raw count as input. So I stored my data into adata.obsm['raw_data']. When i was trying to recover the raw count with the following code. it is very slow. Do you have any tips?. ```; ad.X = ad.obsm['raw_data'].copy(); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1817
https://github.com/scverse/scanpy/issues/1818:660,Deployability,integrat,integrate,660,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:660,Integrability,integrat,integrate,660,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:496,Safety,detect,detection,496,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/issues/1818:646,Usability,simpl,simple,646,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Adding multiplex community detection from Leiden: https://leidenalg.readthedocs.io/en/stable/multiplex.html#layer-multiplex. It seems very straightforward and would be the most simple way to integrate two modalities on the graph. We would make great use of it in Squidpy (rna counts+image), but I think it should live in Scanpy becasue it could be useful for other multi-modal data. This is a duplicate of #1107 and it has been extensively discussed in #1117 . In the latter however, lots of thought went into normalization/processing which is superfluous for this case as it is only specific for CITE-seq data. Here we'd just want to allow users to get partitions out of multiple graphs. This could be done in two ways:; - adding arguments to existing `tl.leiden`, so that it accepts multiple graphs and multiple resolutions params per graph.; - creating a separate function `sc.tl.leiden_multiplex`.; Any thoughts on this @ivirshup @Koncopd ?. I think @WeilerP also had some thoughts along these lines. Have you ever tried this out? is there any other analysis tool you explored with a simlar purpose? Would be interested to hear your thoughts!; worth mentioning that another approach, the WNN from seurat, was also mentioned here: https://github.com/theislab/scanpy/pull/1117#issuecomment-777020580; although am not sure how much work that requries.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1818
https://github.com/scverse/scanpy/pull/1821:293,Deployability,continuous,continuous,293,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:72,Usability,guid,guidelines,72,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1821:103,Usability,guid,guide,103,<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. closes #1502 . ensure that `legend_loc=None` also removes continuous colorbars for scatterplots like umap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1821
https://github.com/scverse/scanpy/pull/1822:72,Usability,guid,guidelines,72,"<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/pull/1822:103,Usability,guid,guide,103,"<!-- ; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; closses #1174 . hue key is now added to keys if hue is in kwds. before obs_tidy did not include this keyword, so this resulted in an ValueError. an alternative would be to add hue as a function parameter to `sc.pl.violin`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1822
https://github.com/scverse/scanpy/issues/1823:460,Deployability,install,installation,460,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Apologies if this is issue is already know but I couldn't find it and the doc advertises python 3.6 so I figured I would report it. ---; ### Minimal code sample (that we can copy&paste without having any data). After following Anaconda installation instructions in a brand new conda env created with python 3.9.4:. ```python; import scanpy as sc; ```; returns:; ```pytb; Illegal instruction (core dumped); ```. Another brand new env with 3.7 imports scanpy successfully. . #### Versions; scanpy 1.7.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1823
https://github.com/scverse/scanpy/issues/1824:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; I am wondering if scanpy has an option to plot three dimension of information in one plot such as stacked barplot. I need to show cell types distribution in absent/present of medication per each cohort.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1824
https://github.com/scverse/scanpy/issues/1825:2247,Deployability,update,updated,2247," See below. ```python; import scanpy as sc; x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'); x.var_names_make_unique(); print(x); sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); ```. ```pytb; AnnData object with n_obs × n_vars = 600 × 32838; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'; var: 'features'; Traceback (most recent call last):; File ""./main.py"", line 8, in <module>; sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3; model.fit(); File ""_loess.pyx"", line 899, in _loess.loess.fit; ValueError: b'reciprocal condition number 3.9554e-16\n'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.18.1; packaging 20.8; pandas 1.0.1; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-03 11:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1825:2195,Testability,log,logical,2195," See below. ```python; import scanpy as sc; x=sc.read('merges2.h5ad', backup_url='https://ndownloader.figshare.com/files/27854286?private_link=8cd07dabcde5a773defd'); x.var_names_make_unique(); print(x); sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); ```. ```pytb; AnnData object with n_obs × n_vars = 600 × 32838; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'sampleid'; var: 'features'; Traceback (most recent call last):; File ""./main.py"", line 8, in <module>; sc.pp.highly_variable_genes(x, flavor='seurat_v3', n_top_genes=50, batch_key='sampleid', subset=True); File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes; return _highly_variable_genes_seurat_v3(; File ""/usr/local/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 85, in _highly_variable_genes_seurat_v3; model.fit(); File ""_loess.pyx"", line 899, in _loess.loess.fit; ValueError: b'reciprocal condition number 3.9554e-16\n'; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.1.0; anndata 0.7.5; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; get_version 2.1; google NA; h5py 2.10.0; igraph 0.8.3; joblib 1.0.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.2; numpy 1.18.1; packaging 20.8; pandas 1.0.1; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.4.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.3; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; -----; Python 3.8.8 (default, Feb 26 2021, 23:59:43) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-03 11:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1825
https://github.com/scverse/scanpy/issues/1826:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Is there a function in scanpy to compute and plot the correlation between the cell types frequency and the cells clinical information n stored in obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1826
https://github.com/scverse/scanpy/issues/1827:3141,Deployability,update,updated,3141,"canpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; attr 20.1.0; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.3; colorlog NA; cupy 7.8.0; cupyx NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.1; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fastrlock 0.5; fsspec 0.8.7; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; iniconfig NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.1; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; py 1.9.0; pyarrow 0.16.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytest 6.1.2; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; sca NA; scanpy 1.7.0; scipy 1.6.1; scprep 1.0.5.post2; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; skmisc 0.1.3; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; tblib 1.7.0; texttable 1.6.2; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; typing_extensions NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-03 16:30; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:2835,Integrability,wrap,wrapt,2835,"canpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; attr 20.1.0; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.3; colorlog NA; cupy 7.8.0; cupyx NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.1; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fastrlock 0.5; fsspec 0.8.7; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; iniconfig NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.1; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; py 1.9.0; pyarrow 0.16.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytest 6.1.2; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; sca NA; scanpy 1.7.0; scipy 1.6.1; scprep 1.0.5.post2; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; skmisc 0.1.3; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; tblib 1.7.0; texttable 1.6.2; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; typing_extensions NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-03 16:30; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1827:3087,Testability,log,logical,3087,"canpy 1.7.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.5; appdirs 1.4.4; attr 20.1.0; autoreload NA; backcall 0.2.0; bioservices 1.7.8; bs4 4.9.1; cairo 1.19.1; certifi 2020.12.05; cffi 1.14.4; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.3; colorlog NA; cupy 7.8.0; cupyx NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.03.1; dateutil 2.8.1; decorator 4.4.2; deprecated 1.2.10; easydev 0.9.38; fa2 NA; fastrlock 0.5; fsspec 0.8.7; future 0.18.2; future_fstrings NA; get_version 2.1; graphtools 1.5.2; gseapy 0.10.1; h5py 2.10.0; idna 2.10; igraph 0.8.2; iniconfig NA; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.1; llvmlite 0.34.0; louvain 0.7.0; lxml 4.5.2; magic 2.0.3; matplotlib 3.3.1; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; numba 0.51.2; numexpr 2.7.1; numpy 1.19.1; packaging 20.8; pandas 1.2.1; parso 0.7.1; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; pluggy 0.13.1; prompt_toolkit 3.0.6; psutil 5.7.2; ptyprocess 0.6.0; py 1.9.0; pyarrow 0.16.0; pycparser 2.20; pygments 2.6.1; pygsp 0.5.1; pylab NA; pyparsing 2.4.7; pytest 6.1.2; pytz 2020.1; requests 2.24.0; requests_cache 0.5.2; sca NA; scanpy 1.7.0; scipy 1.6.1; scprep 1.0.5.post2; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; skmisc 0.1.3; soupsieve 2.0.1; statsmodels 0.11.1; storemagic NA; tables 3.6.1; tasklogger 1.0.0; tblib 1.7.0; texttable 1.6.2; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; tqdm 4.48.2; traitlets 4.3.3; typing_extensions NA; umap 0.4.6; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zmq 19.0.2; zope NA; -----; IPython 7.17.0; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.1.3; -----; Python 3.8.2 (default, May 7 2020, 20:00:49) [GCC 7.3.0]; Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-03 16:30; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1827
https://github.com/scverse/scanpy/issues/1829:896,Availability,robust,robust,896,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:539,Modifiability,variab,variables,539,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:907,Safety,avoid,avoid,907,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1829:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Especially when we visualize large datasets with multiple categorical variables (e.g. patient, disease, cell type) using `sc.pl.dotplot`, and we use a sequence in the `groupby` argument (`e.g. sc.pl.dotplot(ad, 'genex', groupby=['individual', 'disease_status', 'cell type'])`), sometimes we end up with too few cells in some rows, in which summary statistics like fraction of nonzero expressors or mean expression are not very robust. To avoid that, I think it'd be cool to have a minimum observation cutoff in the function, where e.g. `min_cells=5` would show `groupby` combinations with at least 5 cells. Without this option, this sort of filtering becomes an annoying pandas exercise (which some might enjoy but possibly not everyone).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1829
https://github.com/scverse/scanpy/issues/1831:520,Testability,test,test,520,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hi, ; If this is frequency table per cohort; which test to use to identify significant cell type per group? ; ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1831:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hi, ; If this is frequency table per cohort; which test to use to identify significant cell type per group? ; ![image](https://user-images.githubusercontent.com/23288387/117582425-efa1a880-b0cf-11eb-8095-2f7ecacaf7b0.png). ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1831
https://github.com/scverse/scanpy/issues/1832:608,Availability,mainten,maintenance,608,"I was wondering if plotting could be facilitated and made more consistent across ; the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem; * provides helper functions for handling colors, saving figures, etc. ; * encourages a consistent plotting API (e.g. by defining abstract base classes); * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:; * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:; - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. ; - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db); - scvelo has its own `scatter`; * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). ; * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1832:596,Energy Efficiency,reduce,reduces,596,"I was wondering if plotting could be facilitated and made more consistent across ; the Scanpy ecosystem. I envisage a library (""scanpyplot"" or whatever) that . * provides building blocks for single-cell-related plots which can be re-used across the ecosystem; * provides helper functions for handling colors, saving figures, etc. ; * encourages a consistent plotting API (e.g. by defining abstract base classes); * See also: https://github.com/theislab/scanpy/issues/956. ## Motivation:; * Even within scanpy, there is quite some duplicated code in the plotting section. Reducing duplicated code reduces the maintenance burden in the long run. Across the ecosystem there's even more duplicated plotting code:; - While implementing the [`scirpy.pl.clonotype_network`](https://icbi-lab.github.io/scirpy/generated/scirpy.pl.clonotype_network.html#scirpy.pl.clonotype_network) function, I found myself copying over a lot of code from the `scanpy.pl.paga` and `scanpy.pl.dotplot` functions. ; - [scvelo also copied most of the paga code](https://github.com/theislab/scvelo/commit/082be06940267917118988ca0b9d18ba86c026db); - scvelo has its own `scatter`; * All the scanpy helper functions for plotting (e.g. `savefig_or_show`, `_set_color_for_categorical_obs` etc.) are private scanpy functions. Implementing plotting functions with consistent bahaviour requires either to duplicate a lot of code, or to rely on a potentially unstable API. In fact, e.g. `scvelo` has duplicates of most of these scanpy helper functions. Squidpy has [similar functions, too](https://github.com/theislab/squidpy/blob/04ba5e887f4b6cd80fd45989e599d926a0f6efb9/squidpy/pl/_utils.py#L51-L93). ; * I know at least three ecosystem libraries that implement some variant of a stacked barplot based on `AnnData.obs` ([`dandelion.pl.stackedbarplot`](https://sc-dandelion.readthedocs.io/en/latest/modules/dandelion.plotting.stackedbarplot.html#dandelion.plotting.stackedbarplot) by @zktuong, [`sc_toolbox.api.plot.cluster_composition_st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1832
https://github.com/scverse/scanpy/issues/1837:227,Availability,error,error,227,"Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.umap(adata, init_pos='paga', method='rapids'); ```. ```pytb; WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:1650,Deployability,update,update,1650,"formation for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.umap(adata, init_pos='paga', method='rapids'); ```. ```pytb; WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; 2f7ece400a652629565c523b34ee61b04afa385c NA; PIL 8.1.2; absl NA; anndata 0.7.6; anyio NA; astunparse 1.6.3; attr 20.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; cachetools 4.2.2; cellrank 1.3.1; certifi 2020.12.05; cffi 1.14.4; chardet 4.0.0; click 7.1.2; cloudpickle 1.6.0; colorama 0.4.4; cudf 0.20.0a+294.gfbb9a988fa; cugraph 0.20.0a+65.g924f6782.dirty; cuml 0.20.0a+110.gab47f2e11; cupy 9.0.0; cupy_backends NA; cupyx NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dask_cuda 0+unknown; dask_cudf 0.20.0a+294.gfbb9a988fa; dateutil 2.8.1; decorator 4.4.2; distributed 2021.04.0; docrep 0.3.2; fastrlock 0.5; flatbuffers NA;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4719,Deployability,update,updated,4719,"eapdict NA; idna 2.10; igraph 0.9.1; ipykernel 5.4.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; netifaces 0.10.9; networkx 2.5.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; nvtx NA; opt_einsum v3.3.0; packaging 20.8; pandas 1.2.4; parso 0.8.1; petsc4py 3.14.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.10; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 1.0.1; pycparser 2.20; pygam 0.8.0; pygments 2.7.4; pygpcca 1.0.2; pynndescent 0.5.2; pynvml 8.0.4; pyparsing 2.4.7; pyrsistent NA; python_utils NA; pytz 2021.1; requests 2.25.1; rmm 0.20.0a+28.g7768d4d; scanpy 1.7.2; scanpy_gpu_funcs NA; scipy 1.6.3; scvelo 0.2.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.2; slepc4py 3.14.0; sniffio 1.2.0; socks 1.7.1; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; tensorboard 2.6.0a20210510; tensorflow 2.6.0-dev20210510; termcolor 1.1.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; treelite 1.1.0; treelite_runtime 1.1.0; typing_extensions NA; ucp 0.20.0a+30.g2aa87da; umap 0.5.1; urllib3 1.26.4; virtualenvwrapper NA; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zict 2.0.0; zipp NA; zmq 21.0.1; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.5; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.8.0-50-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2021-05-12 13:23. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4363,Integrability,wrap,wrapt,4363,"eapdict NA; idna 2.10; igraph 0.9.1; ipykernel 5.4.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; netifaces 0.10.9; networkx 2.5.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; nvtx NA; opt_einsum v3.3.0; packaging 20.8; pandas 1.2.4; parso 0.8.1; petsc4py 3.14.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.10; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 1.0.1; pycparser 2.20; pygam 0.8.0; pygments 2.7.4; pygpcca 1.0.2; pynndescent 0.5.2; pynvml 8.0.4; pyparsing 2.4.7; pyrsistent NA; python_utils NA; pytz 2021.1; requests 2.25.1; rmm 0.20.0a+28.g7768d4d; scanpy 1.7.2; scanpy_gpu_funcs NA; scipy 1.6.3; scvelo 0.2.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.2; slepc4py 3.14.0; sniffio 1.2.0; socks 1.7.1; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; tensorboard 2.6.0a20210510; tensorflow 2.6.0-dev20210510; termcolor 1.1.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; treelite 1.1.0; treelite_runtime 1.1.0; typing_extensions NA; ucp 0.20.0a+30.g2aa87da; umap 0.5.1; urllib3 1.26.4; virtualenvwrapper NA; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zict 2.0.0; zipp NA; zmq 21.0.1; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.5; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.8.0-50-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2021-05-12 13:23. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:2182,Performance,cache,cachetools,2182,", n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; 2f7ece400a652629565c523b34ee61b04afa385c NA; PIL 8.1.2; absl NA; anndata 0.7.6; anyio NA; astunparse 1.6.3; attr 20.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; cachetools 4.2.2; cellrank 1.3.1; certifi 2020.12.05; cffi 1.14.4; chardet 4.0.0; click 7.1.2; cloudpickle 1.6.0; colorama 0.4.4; cudf 0.20.0a+294.gfbb9a988fa; cugraph 0.20.0a+65.g924f6782.dirty; cuml 0.20.0a+110.gab47f2e11; cupy 9.0.0; cupy_backends NA; cupyx NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dask_cuda 0+unknown; dask_cudf 0.20.0a+294.gfbb9a988fa; dateutil 2.8.1; decorator 4.4.2; distributed 2021.04.0; docrep 0.3.2; fastrlock 0.5; flatbuffers NA; fsspec 2021.04.0; future_fstrings NA; gast NA; get_version 2.1; google NA; h5py 3.1.0; heapdict NA; idna 2.10; igraph 0.9.1; ipykernel 5.4.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; nbclassic NA; nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:4665,Testability,log,logical,4665,"eapdict NA; idna 2.10; igraph 0.9.1; ipykernel 5.4.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; netifaces 0.10.9; networkx 2.5.1; numba 0.53.1; numexpr 2.7.3; numpy 1.19.5; nvtx NA; opt_einsum v3.3.0; packaging 20.8; pandas 1.2.4; parso 0.8.1; petsc4py 3.14.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; progressbar 3.53.1; prometheus_client NA; prompt_toolkit 3.0.10; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pyarrow 1.0.1; pycparser 2.20; pygam 0.8.0; pygments 2.7.4; pygpcca 1.0.2; pynndescent 0.5.2; pynvml 8.0.4; pyparsing 2.4.7; pyrsistent NA; python_utils NA; pytz 2021.1; requests 2.25.1; rmm 0.20.0a+28.g7768d4d; scanpy 1.7.2; scanpy_gpu_funcs NA; scipy 1.6.3; scvelo 0.2.3; seaborn 0.11.1; send2trash NA; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.24.2; slepc4py 3.14.0; sniffio 1.2.0; socks 1.7.1; sortedcontainers 2.3.0; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; tensorboard 2.6.0a20210510; tensorflow 2.6.0-dev20210510; termcolor 1.1.0; texttable 1.6.3; threadpoolctl 2.1.0; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; treelite 1.1.0; treelite_runtime 1.1.0; typing_extensions NA; ucp 0.20.0a+30.g2aa87da; umap 0.5.1; urllib3 1.26.4; virtualenvwrapper NA; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.4.1; zict 2.0.0; zipp NA; zmq 21.0.1; -----; IPython 7.19.0; jupyter_client 6.1.11; jupyter_core 4.7.1; jupyterlab 3.0.5; notebook 6.2.0; -----; Python 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 16:22:27) [GCC 9.3.0]; Linux-5.8.0-50-generic-x86_64-with-glibc2.10; 32 logical CPU cores, x86_64; -----; Session information updated at 2021-05-12 13:23. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1837:551,Usability,guid,guide,551,"Hello,. I found an issue with init_pos and rapids. Since cuMLs UMAP doesn't allow initial positions, it would be nice if `sc.tl.umap` would check if an `init_pos` other than spectral and random is used if method is rapids. The error `paga` produces in cuMLs UMAP is not really user friendly. . - [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.umap(adata, init_pos='paga', method='rapids'); ```. ```pytb; WARNING: .obsp[""connectivities""] have not been computed using umap. ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <timed eval> in <module>. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 221 ) # 0 is not a valid value for rapids, unlike original umap; 222 X_contiguous = np.ascontiguousarray(X, dtype=np.float32); --> 223 umap = UMAP(; 224 n_neighbors=n_neighbors,; 225 n_components=n_components,. ~/miniconda3/envs/rapids-0.20/lib/python3.8/site-packages/cuml/internals/api_decorators.py in inner_f(*args, **kwargs); 792 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); 793 ; --> 794 return func(**kwargs); 795 ; 796 # Set this flag to prevent auto adding this decorator twice. cuml/manifold/umap.pyx in cuml.manifold.umap.UMAP.__init__(). TypeError: %d format: a number is required, not str; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1837
https://github.com/scverse/scanpy/issues/1838:570,Availability,error,errors,570,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though; # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue; # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks; ```. ```pytb; [---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-2f4062a9e25b> in <module>; ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype); 46 Numpy data type.; 47 """"""; ---> 48 return read_text(filename, delimiter, first_column_names, dtype); 49 ; 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype); 323 else:; 324 with filename.open() as f:; --> 325 return _read_text(f, delimiter, first_column_names, dtype); 326 ; 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype); 386 first_column_names = True; 387 row_names.append(line_list[0]); --> 388 data.append(np.array(line_list[1:], dtype=dtype)); 389 else:; 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1838:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; I used the following command to read the meta file but it gives me the errors below. Not sure if I need to read with extra parameters though; # meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). I got around the problem with the command below but I thought I should let you know about the issue; # meta = pd.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). Thanks; ```. ```pytb; [---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-16-2f4062a9e25b> in <module>; ----> 1 meta = sc.read_csv(""CensusImmune-CordBlood-10x_cell_type_2020-03-12.csv""). ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_csv(filename, delimiter, first_column_names, dtype); 46 Numpy data type.; 47 """"""; ---> 48 return read_text(filename, delimiter, first_column_names, dtype); 49 ; 50 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in read_text(filename, delimiter, first_column_names, dtype); 323 else:; 324 with filename.open() as f:; --> 325 return _read_text(f, delimiter, first_column_names, dtype); 326 ; 327 . ~/.local/lib/python3.7/site-packages/anndata/_io/read.py in _read_text(f, delimiter, first_column_names, dtype); 386 first_column_names = True; 387 row_names.append(line_list[0]); --> 388 data.append(np.array(line_list[1:], dtype=dtype)); 389 else:; 390 data.append(np.array(line_list, dtype=dtype)). ValueError: could not convert string to float: '6_CB6_cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1838
https://github.com/scverse/scanpy/issues/1839:194,Modifiability,variab,variable,194,"I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:; I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677; It seems that the code performs the fitting for all specified variables at once, but I am not sure:; https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701; If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:427,Modifiability,variab,variables,427,"I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:; I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677; It seems that the code performs the fitting for all specified variables at once, but I am not sure:; https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701; If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1839:388,Performance,perform,performs,388,"I was wondering if someone who is familiar with sc.pp.regress_out could confirm the following:; I would like to regress out nonlinear effect, e.g. ~1 + a + a^2 + a^3, where a is non-categorical variable. I have looked at the code of regress_out: https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L677; It seems that the code performs the fitting for all specified variables at once, but I am not sure:; https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/preprocessing/_simple.py#L701; If the design passed to GLM is combined of all keys passed to the function then I could just create the necessary columns a, a^2, a^3 and pass this as keys. Can someone confirm if I understand this correctly and passing the polynomial columns will do the fitting of a polynom?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1839
https://github.com/scverse/scanpy/issues/1840:244,Availability,error,errors,244,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:28,Deployability,install,installing,28,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:74,Deployability,install,installing,74,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1840:209,Deployability,install,installation,209,"I am having lots of trouble installing scanpy on my M1 Macbook Pro. After installing the arm64 version of Miniforge 3 and creating a virtual environment on Python 3.9.4, I followed the documentation for conda installation. However, I got build errors when running the pip commands. Has anyone discovered a workaround to this?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1840
https://github.com/scverse/scanpy/issues/1842:288,Safety,detect,detects,288,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python; import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):; ipython_format = [ipython_format]; matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format); ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/issues/1842:1045,Usability,undo,undocumented,1045,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Found while investigating #1477. `scanpy.set_figure_parms` detects whether we're in an IPython session (or at least tries to #1841), and sets the default output format. The way it sets the format [is deprecated](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.set_matplotlib_formats), as it looks like the `matplotlib_inline` backend has moved to a separate package. . The new way to call this is: . ```python; import matplotlib_inline.backend_inline. if isinstance(ipython_format, str):; ipython_format = [ipython_format]; matplotlib_inline.backend_inline.set_matplotlib_formats(*ipython_format); ```. It may take some investigation to figure out how to do this in a backwards compatible way. I would also note the current backend format that we are using (`""png2x""`) is undocumented. It is equivalent to the documented format `""retina""`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1842
https://github.com/scverse/scanpy/pull/1844:230,Deployability,Release,Release,230,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:33,Testability,test,test,33,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:97,Testability,test,test,97,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:171,Testability,test,test,171,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/pull/1844:252,Testability,Test,Test,252,"Fixes #1841. It would be nice to test this, but I'm not sure we're set up for that. E.g., we can test that it doesn't work in a python session, but I'm not sure if we can test that it does work in an ipython session. TODO:. - [x] Release note; - [ ] ~~Test?~~ Not so sure how to do this, and it's useful now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1844
https://github.com/scverse/scanpy/issues/1845:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... How to do correlation between celltypes and age in scanpy?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1845
https://github.com/scverse/scanpy/issues/1846:3881,Deployability,update,updated,3881,"; sc.pl.umap(adata2, color = 'sample'); ```; ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; Bio 1.78; PIL 8.2.0; adjustText NA; anndata 0.7.5; annoy NA; backcall 0.2.0; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.5; changeo 1.0.2; chardet 4.0.0; cloudpickle 1.6.0; cycler 0.10.0; cython_runtime NA; dandelion 0.1.2; dask 2021.03.0; dateutil 2.8.1; decorator 5.0.6; descartes NA; distance NA; get_version 2.1; google NA; h5py 2.10.0; harmonypy NA; hdmedians NA; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mizani 0.7.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.20.2; packaging 20.9; palettable 3.3.0; pandas 1.2.4; parso 0.8.2; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.7.1; polyleven NA; presto 0.6.2; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytoml NA; pytz 2021.1; pywt 1.1.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.3; scrublet NA; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; skbio 0.5.6; skimage 0.18.1; sklearn 0.23.2; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.59.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-19 16:44. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:2248,Performance,cache,cachecontrol,2248,"busercontent.com/26215587/118845227-7ec67180-b8c3-11eb-9bce-a877ef26b47a.png). If i don't use harmony and just ran with `n_pcs = 50`, the result is similar.; ```python; adatax = adata.copy(); sc.pp.neighbors(adatax, n_pcs = 50); sc.tl.umap(adatax, min_dist = .3); sc.pl.umap(adatax, color = 'sample'); ```; ![image](https://user-images.githubusercontent.com/26215587/118845811-01e7c780-b8c4-11eb-8ca9-3ea639d97684.png). What i don't get is, why does the following work then?; ```python; # my current workaround; adata2 = adata.copy(); sc.external.pp.harmony_integrate(adata2, key = 'sample', adjusted_basis='X_pca'); sc.pp.neighbors(adata2, n_pcs = 20); sc.tl.umap(adata2); sc.pl.umap(adata2, color = 'sample'); ```; ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; Bio 1.78; PIL 8.2.0; adjustText NA; anndata 0.7.5; annoy NA; backcall 0.2.0; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.5; changeo 1.0.2; chardet 4.0.0; cloudpickle 1.6.0; cycler 0.10.0; cython_runtime NA; dandelion 0.1.2; dask 2021.03.0; dateutil 2.8.1; decorator 5.0.6; descartes NA; distance NA; get_version 2.1; google NA; h5py 2.10.0; harmonypy NA; hdmedians NA; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mizani 0.7.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.20.2; packaging 20.9; palettable 3.3.0; pandas 1.2.4; parso 0.8.2; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.7.1; polyleven NA; presto 0.6.2; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytoml NA; pytz 2021.1; pywt 1.1.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.3; scrublet ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1846:3827,Testability,log,logical,3827,"; sc.pl.umap(adata2, color = 'sample'); ```; ![image](https://user-images.githubusercontent.com/26215587/118843486-04492200-b8c2-11eb-8e2b-6aaf59564721.png). #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.1; sinfo 0.3.1; -----; Bio 1.78; PIL 8.2.0; adjustText NA; anndata 0.7.5; annoy NA; backcall 0.2.0; brotli NA; cachecontrol 0.12.6; cairo 1.19.1; certifi 2020.06.20; cffi 1.14.5; changeo 1.0.2; chardet 4.0.0; cloudpickle 1.6.0; cycler 0.10.0; cython_runtime NA; dandelion 0.1.2; dask 2021.03.0; dateutil 2.8.1; decorator 5.0.6; descartes NA; distance NA; get_version 2.1; google NA; h5py 2.10.0; harmonypy NA; hdmedians NA; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mizani 0.7.2; mpl_toolkits NA; msgpack 1.0.2; natsort 7.1.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.20.2; packaging 20.9; palettable 3.3.0; pandas 1.2.4; parso 0.8.2; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotnine 0.7.1; polyleven NA; presto 0.6.2; prompt_toolkit 3.0.17; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytoml NA; pytz 2021.1; pywt 1.1.1; requests 2.25.1; scanpy 1.7.1; scipy 1.6.3; scrublet NA; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; skbio 0.5.6; skimage 0.18.1; sklearn 0.23.2; socks 1.7.1; sparse 0.11.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.59.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]; Linux-4.15.0-142-generic-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-05-19 16:44. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1846
https://github.com/scverse/scanpy/issues/1847:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [X] Other?. <!-- Please describe your wishes below: -->. Would it be possible to project a query dataset onto an existing reference umap, such that the reference dataset is not altered? The readout would be the existing reference umap with perhaps the density of query cells overlaid on top. Perhaps also quantification of the percentage of query cells falling into specific clusters on the reference data set? Apologies if this already exists, I would be very interested to know how to do this using the anndata framework. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1847
https://github.com/scverse/scanpy/pull/1848:225,Safety,detect,detect-private-key,225,"Hey,. finally solves #1563 . I added: . ```; - id: trailing-whitespace; - id: end-of-file-fixer; - id: check-added-large-files; - id: check-case-conflict; - id: check-toml; - id: check-yaml; - id: check-merge-conflict; - id: detect-private-key; ```. They are super super fast, so speed is not a concern. Signed-off-by: zethson <lukas.heumos@posteo.net>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1848
https://github.com/scverse/scanpy/issues/1850:329,Availability,error,error,329,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey!. I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors.; Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`; ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-39-d43e888a7389> in <module>; ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:442,Availability,error,error,442,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hey!. I've run into a weird issue where I can't plot categorical data in scanpy, it always gives an error (`NotImplementedError: isna is not defined for MultiIndex`) while assigning colors (see below for the full error). Plotting numerical data works just fine and also plotting categorical data with scvelo works fine. Manually specifying a color palette works, but results in a weird choice of colors.; Example output of `sc.pl.umap(pbmc, color = 'phase', palette = 'tab10')`; ![image](https://user-images.githubusercontent.com/36991381/119331910-2eb32a80-bc88-11eb-9fca-eb4b8f494410.png). Any ideas of what could be the issue here?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. <details>; <summary> Traceback </summary>. ```pytb; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-39-d43e888a7389> in <module>; ----> 1 sc.pl.umap(adata, color = 'phase'). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutlin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7080,Deployability,update,updated,7080,"e: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; backcall 0.2.0; bbknn NA; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.2; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; palantir 1.0.0; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.5.2; scvelo 0.2.3; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; yaml 5.3.1; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-24 12:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4436,Performance,Cache,CachedProperty,4436,"nd; 272 # ordered=None.; --> 273 dtype = CategoricalDtype(categories, ordered); 274 ; 275 return dtype. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered); 158 ; 159 def __init__(self, categories=None, ordered: Ordered = False):; --> 160 self._finalize(categories, ordered, fastpath=False); 161 ; 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath); 312 ; 313 if categories is not None:; --> 314 categories = self.validate_categories(categories, fastpath=fastpath); 315 ; 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath); 505 if not fastpath:; 506 ; --> 507 if categories.hasnans:; 508 raise ValueError(""Categorical categories cannot be null""); 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self); 2193 """"""; 2194 if self._can_hold_na:; -> 2195 return bool(self._isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for Mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:4727,Performance,Cache,CachedProperty,4727,"= False):; --> 160 self._finalize(categories, ordered, fastpath=False); 161 ; 162 @classmethod. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath); 312 ; 313 if categories is not None:; --> 314 categories = self.validate_categories(categories, fastpath=fastpath); 315 ; 316 self._categories = categories. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath); 505 if not fastpath:; 506 ; --> 507 if categories.hasnans:; 508 raise ValueError(""Categorical categories cannot be null""); 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self); 2193 """"""; 2194 if self._can_hold_na:; -> 2195 return bool(self._isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; backcall 0.2.0; bb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:5743,Performance,bottleneck,bottleneck,5743,"_get__(). ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; backcall 0.2.0; bbknn NA; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.2; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; palantir 1.0.0; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.5.2; scvelo 0.2.3; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1850:7026,Testability,log,logical,7026,"e: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/anaconda3/envs/scanpy1_7/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex. ```. </details>. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; backcall 0.2.0; bbknn NA; bottleneck 1.3.2; cairo 1.19.1; cffi 1.14.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; fcsparser 0.2.1; future_fstrings NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.2.0; legacy_api_wrap 0.0.0; leidenalg 0.8.2; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.3.2; mkl 2.3.0; mpl_toolkits NA; natsort 7.0.1; networkx 2.5; numba 0.51.2; numexpr 2.7.1; numpy 1.19.2; packaging 20.4; palantir 1.0.0; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; phenograph 1.5.7; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.7.2; scipy 1.5.2; scvelo 0.2.3; seaborn 0.11.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; yaml 5.3.1; zipp NA; zmq 19.0.2; -----; IPython 7.18.1; jupyter_client 6.1.7; jupyter_core 4.6.3; notebook 6.1.4; -----; Python 3.8.0 | packaged by conda-forge | (default, Nov 22 2019, 19:11:38) [GCC 7.3.0]; Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.10; 4 logical CPU cores, x86_64; -----; Session information updated at 2021-05-24 12:06. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1850
https://github.com/scverse/scanpy/issues/1852:275,Integrability,depend,dependencies,275,"[`sinfo` has been replaced](https://pypi.org/project/sinfo/) with [`session_info`](https://gitlab.com/joelostblom/session_info), which is definitely a better name. We should switch over to using this. I think we'll be calling it like: `import session_info; session_info.show(dependencies=True, html=False, **extra_kwargs)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1852
https://github.com/scverse/scanpy/pull/1854:8,Deployability,install,install,8,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:308,Integrability,depend,dependency,308,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:375,Testability,test,test,375,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:603,Testability,Test,Test,603,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/pull/1854:622,Testability,Test,Test,622,"I can't install MulticoreTSNE, and it may not even work on python >3.6. Since we want to drop 3.6 support (#1697), it would be good to stop recommending it, and pass the n_jobs parameter to sklearn's tsne. This PR attempts to do that, along with a bunch of deprecation warnings. I've also bumped the sklearn dependency to make sure TSNE is multithreaded. Metric was added to test if n_jobs was working. Either way, it seems to be using all the cpu on my laptop. Not sure what's up with that. ## TODO:. - ~~[ ] Figure out how to get n_jobs to actually limit cpu usage~~ Leaving this up to sklearn; - [x] Test metric; - [x] Test deprecations",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1854
https://github.com/scverse/scanpy/issues/1855:542,Deployability,continuous,continuous,542,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:553,Modifiability,variab,variables,553,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1855:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; is there a scanpy method to do a correlation between cell types and continuous variables stored in .obs?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1855
https://github.com/scverse/scanpy/issues/1857:2713,Deployability,update,updated,2713,"IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2019.3; requests 2.24.0; scipy 1.4.1; seaborn 0.10.0; send2trash NA; six 1.14.0; sklearn 0.23.1; sniffio 1.2.0; statsmodels 0.12.2; storemagic NA; swig_runtime_data4 NA; tables 3.6.1; tensorboard 2.2.2; tensorflow 2.2.0; termcolor 1.1.0; texttable 1.6.3; tornado 6.1; traitlets 4.3.3; typing_extensions NA; umap 0.5.1; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 3.0.5; notebook 6.0.3; -----; Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]; Darwin-20.2.0-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-26 22:36. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2387,Integrability,wrap,wrapt,2387,"IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2019.3; requests 2.24.0; scipy 1.4.1; seaborn 0.10.0; send2trash NA; six 1.14.0; sklearn 0.23.1; sniffio 1.2.0; statsmodels 0.12.2; storemagic NA; swig_runtime_data4 NA; tables 3.6.1; tensorboard 2.2.2; tensorflow 2.2.0; termcolor 1.1.0; texttable 1.6.3; tornado 6.1; traitlets 4.3.3; typing_extensions NA; umap 0.5.1; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 3.0.5; notebook 6.0.3; -----; Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]; Darwin-20.2.0-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-26 22:36. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:2661,Testability,log,logical,2661,"IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2019.3; requests 2.24.0; scipy 1.4.1; seaborn 0.10.0; send2trash NA; six 1.14.0; sklearn 0.23.1; sniffio 1.2.0; statsmodels 0.12.2; storemagic NA; swig_runtime_data4 NA; tables 3.6.1; tensorboard 2.2.2; tensorflow 2.2.0; termcolor 1.1.0; texttable 1.6.3; tornado 6.1; traitlets 4.3.3; typing_extensions NA; umap 0.5.1; urllib3 1.25.10; wcwidth 0.2.5; wrapt 1.12.1; yaml 5.3.1; zipp NA; zmq 19.0.1; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; jupyterlab 3.0.5; notebook 6.0.3; -----; Python 3.7.7 (v3.7.7:d7c567b08f, Mar 10 2020, 02:56:16) [Clang 6.0 (clang-600.0.57)]; Darwin-20.2.0-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-05-26 22:36. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/issues/1857:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.highly_variable_genes(adata); ```. ```pytb; ---------------------------------------------------------------------------; FileNotFoundError Traceback (most recent call last); /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj); ... FileNotFoundError: [Errno 2] No such file or directory: '/Users/name/.matplotlib/fontlist-v310.json.matplotlib-lock'. ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; 0294638c8bf50491b025b096f3dba0a1 NA; absl NA; anyio NA; appnope 0.1.0; astunparse 1.6.3; attr 19.3.0; babel 2.9.0; backcall 0.2.0; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.5; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; gast NA; get_version 2.2; google NA; h5py 2.10.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.3; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 0.16.0; json5 NA; jsonschema 3.2.0; jupyter_server 1.2.2; jupyterlab_server 2.1.2; keras_preprocessing 1.1.2; kiwisolver 1.2.0; legacy_api_wrap 1.2; llvmlite 0.36.0; markupsafe 1.1.1; matplotlib 3.2.1; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.0.7; numba 0.53.1; numexpr 2.7.3; numpy 1.19.0; opt_einsum v3.3.0; packaging 20.4; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.5; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.6.1; pynndescent 0.5.2; py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1857
https://github.com/scverse/scanpy/pull/1858:746,Usability,guid,guidelines,746,"Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. ; I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:; - tools/_diffmap.py _diffmap function (tl.diffmap function); - tools/_dpt.py _diffmap function; - neighbors/__init__.py compute_eigen function. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/pull/1858:777,Usability,guid,guide,777,"Currently tl.diffmap generates slightly different results on consequent runs. This is because the v0 argument is not provided in the scipy.sparse.linalg.eigsh call (inside the compute_eigen function). . To fix this I set the random_state inside the compute_eigen function and generate a random vector to pass into scipy.sparse.linalg.eigsh as v0. ; I tried to follow how random_state is implemented in other scanpy functions, I hope this is consistent. To allow user control of the random_state I added random_state arguments to:; - tools/_diffmap.py _diffmap function (tl.diffmap function); - tools/_dpt.py _diffmap function; - neighbors/__init__.py compute_eigen function. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1858
https://github.com/scverse/scanpy/issues/1859:353,Deployability,pipeline,pipeline,353,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I noticed that my UMAP projection was not quite the same each time I reran my notebook, so I systematically went through my pipeline to find the source(s) of this irreproducibility, one of which turned out to be `sc.pl.paga`. Specifically, the positions (`adata.uns['paga']['pos']`) generated by this function were slightly different each time I ran the notebook, which then leads to the differences in the UMAP as I use `sc.tl.umap(adata, init_pos='paga')`. Code:; ```python; sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Slight differences in each run; ```. I did some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python; import random; random.seed(0). sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run; ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.6; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; nt NA; ntsecuritycon NA; numba 0.51.2; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2750,Testability,log,logical,2750,"id some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python; import random; random.seed(0). sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run; ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.6; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pythoncom NA; pytz 2021.1; pywintypes NA; scanpy 1.7.2; scipy 1.6.2; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1859:2271,Usability,simpl,simplegeneric,2271,"id some digging (=a lot of digging) and found that `scanpy.pl._tools.paga._compute_pos` uses igraph layouts, i.e. `pos_list = g.layout(...)`. Apparently, igraph uses python's built-in RNG, which has not been seeded. I therefore did the following, which fixed my irreproducibility problem:. ```python; import random; random.seed(0). sc.tl.paga(adata); sc.pl.paga(adata, color='degree_solid'). print(adata.uns['paga']['pos']) # Exact same result each run; ```. I think it would be nice if this could be included wherever igraph layouts are used to improve reproducibility. I'm not sure, but perhaps issue #1418 occurs due to this problem. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.5; cairo 1.20.0; cffi 1.14.5; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 5.0.6; get_version 2.1; h5py 2.10.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; networkx 2.5; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pythoncom NA; pytz 2021.1; pywintypes NA; scanpy 1.7.2; scipy 1.6.2; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; win32api NA; win32com NA; win32security NA; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.7.9 (default, Aug 31 2020, 17:10:11) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 8 logical CPU cores, Intel64 Family 6 Model 142 Stepping 12, GenuineIntel; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1859
https://github.com/scverse/scanpy/issues/1860:356,Modifiability,layers,layers,356,"The scanpy.read_10X_mtx works well for reading in the STARsolo output matrices, which are based on the CellRanger Outputs. . However, it would be nice to have a function or modification of the read_10X_mtx function (e.g. a boolean for STARsolo velocyto) to automate inputting the velocyto matrices that STARsolo outputs and placing them in the appropriate layers. A boolean switch for filtered versus raw matrices would be a good addition as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1860
https://github.com/scverse/scanpy/issues/1861:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; It would be great to manually specify the `.obsm` key generated by the `.tl` functions like UMAP, PCA, etc. `sc.tl.umap(adata, key_added=""X_custom_umap"")`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1861
https://github.com/scverse/scanpy/issues/1862:560,Availability,down,downloaded,560,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,; I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; InvalidIndexError Traceback (most recent call last); <ipython-input-54-668f41c58e57> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 231 ctrl_size ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:665,Availability,error,error,665,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,; I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; InvalidIndexError Traceback (most recent call last); <ipython-input-54-668f41c58e57> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 231 ctrl_size ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4141,Availability,toler,tolerance,4141,"e_list); 152 ; --> 153 X_list = _adata[:, gene_list].X; 154 if issparse(X_list):; 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance); 3170 if not self.is_unique:; 3171 raise InvalidIndexError(; -> 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ); 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:4432,Testability,log,logging,4432,"e_list); 152 ; --> 153 X_list = _adata[:, gene_list].X; 154 if issparse(X_list):; 155 X_list = np.array(_sparse_nanmean(X_list, axis=1)).flatten(). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1085 def __getitem__(self, index: Index) -> ""AnnData"":; 1086 """"""Returns a sliced view of the object.""""""; -> 1087 oidx, vidx = self._normalize_indices(index); 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1089 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1066 ; 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1068 return _normalize_indices(index, self.obs_names, self.var_names); 1069 ; 1070 # TODO: this is not quite complete... c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 33 ax0, ax1 = unpack_index(index); 34 ax0 = _normalize_index(ax0, names0); ---> 35 ax1 = _normalize_index(ax1, names1); 36 return ax0, ax1; 37 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 95 return positions # np.ndarray[int]; 96 else: # indexer should be string array; ---> 97 positions = index.get_indexer(indexer); 98 if np.any(positions < 0):; 99 not_found = indexer[positions < 0]. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\indexes\base.py in get_indexer(self, target, method, limit, tolerance); 3170 if not self.is_unique:; 3171 raise InvalidIndexError(; -> 3172 ""Reindexing only valid with uniquely valued Index objects""; 3173 ); 3174 . InvalidIndexError: Reindexing only valid with uniquely valued Index objects; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1862:257,Usability,guid,guide,257,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Hello,; I am trying to work with a dataset published in one paper. This downloaded dataset somehow has rows and columns transposed which I corrected. But I am encountering this error at the cell cycle score calculation step and don't understand the exact reason. kindly help me to solve this issue. . ```python; ## Mouse; folder = ""D:/Pawandeep/Alldatasets/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; InvalidIndexError Traceback (most recent call last); <ipython-input-54-668f41c58e57> in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\tools\_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 231 ctrl_size ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1862
https://github.com/scverse/scanpy/issues/1863:911,Safety,predict,prediction,911,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1863:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; `sc.tl.score_genes_cell_cycle` calculates scores via `sc.tl.score_genes` but also assigns a categorical label of cell cycle phase. Given lists of marker genes of cell types, can a similar approach be used to potentially annotate putative cell types? Maybe it is too naive? My main concern is that cells that do not fit any cell type for which there are markers will be mis-assigned. I am aware that there are tons of automated cell type prediction tools for scRNA-seq, but not found anything directly supported by scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1863
https://github.com/scverse/scanpy/issues/1866:673,Availability,down,downstream,673,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:1412,Availability,error,error,1412,"uce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 147 ; --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:3854,Availability,error,error,3854,"in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-17-f0b30fa7797a> in <module>; ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5596,Availability,error,error,5596,"h, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5726,Availability,error,error,5726,"et_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:5813,Availability,error,error,5813,"13 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fssp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6195,Availability,down,downgrade,6195,"python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6174,Deployability,install,installs,6174,"python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6311,Deployability,install,install,6311,"rite_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8164,Deployability,update,updated,8164,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scipy 1.6.3; send2trash NA; six 1.16.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.9.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.3.0; -----; Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-06-04 10:04. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2669,Integrability,wrap,wrapper,2669,"key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 147 ; --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter); 139 if (data is not None) and (not isinstance(data, Empty)):; --> 140 dset_id.write(h5s.ALL, h5s.ALL, data); 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:2725,Integrability,wrap,wrapper,2725,"c(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,. ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 147 ; --> 148 dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds); 149 dset = dataset.Dataset(dsid). ~/anaconda3/lib/python3.8/site-packages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter); 139 if (data is not None) and (not isinstance(data, Empty)):; --> 140 dset_id.write(h5s.ALL, h5s.ALL, data); 141 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5d.pyx in h5py.h5d.DatasetID.write(). h5py/_proxy.pyx in h5py._proxy.dset_rw(). h5py/_conv.pyx in h5py._conv.str2vlen(). h5py/_conv.pyx in h5py._conv.generic_converter(). h5py/_conv.pyx in h5py._conv.conv_str2vlen(). TypeError: Can't implicitly convert non-string objects to strings. The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:4952,Integrability,wrap,wrapper,4952,"xception:. TypeError Traceback (most recent call last); <ipython-input-17-f0b30fa7797a> in <module>; ----> 1 gex_matrix.write('/Volumes/Bf110/ct5/raw_data/single_cell/external/GSE156793/GSE156793_GEX_ctl210604.raw.h5ad'). ~/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 109 else:; 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); --> 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs). ~/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6256,Integrability,message,message,6256,"e, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:741,Performance,Load,Load,741,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6607,Performance,bottleneck,bottleneck,6607,"le writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scipy 1.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:6155,Safety,avoid,avoid,6155,"python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'Batch' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'obs' of <class 'h5py._hl.files.File'> from /. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:8112,Testability,log,logical,8112,"e to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.2.0; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; bottleneck 1.3.2; brotli NA; cairo 1.20.0; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; fsspec 2021.05.0; get_version 2.2; google NA; h5py 3.2.1; idna 2.10; igraph 0.7.1; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.7.0; llvmlite 0.36.0; loompy 3.0.6; markupsafe 1.1.1; matplotlib 3.3.4; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; scipy 1.6.3; send2trash NA; six 1.16.0; sklearn 0.24.1; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.9.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.3.0; -----; Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]; macOS-10.15.7-x86_64-i386-64bit; 4 logical CPU cores, i386; -----; Session information updated at 2021-06-04 10:04. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1866:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data); Hi, . I'm processing the `loom` object from the Cao et al 2020 (Dataset [GSE156793](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE156793)), so I can save it as an `anndata` for downstream analyses. Below are the steps I'm taking to do this: . - Load modules. ```python; import anndata; import numpy as np; import pandas as pd; import scanpy as sc; from scipy.sparse import csr_matrix, csc_matrix; ```; - Read loom object. Takes ~ 4 hrs. . ```python; gex_matrix = sc.read_loom('GSE156793_S3_gene_count.loom'); gex_matrix; ```; - Read in metadata ; ```python; gex_metadata = pd.read_csv('GSE156793_S1_metadata_cells.txt.gz', sep = ',', index_col = 0); gex_matrix.obs = gex_metadata; gex_matrix.obs; ```; - Transform to `CSR` matrix; ```python; gex_matrix.X = csr_matrix(gex_matrix.X); gex_matrix.X; ```; - Save object; ```python; gex_matrix.write('GSE156793_GEX_ctl210604.raw.h5ad'); ```. However, I get the following error. Any ideas what this may be related to? . ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 269 if series.dtype == object: # Assuming it’s string; --> 270 group.create_dataset(; 271 key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1866
https://github.com/scverse/scanpy/issues/1867:220,Deployability,update,updated,220,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:424,Deployability,update,updated,424,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:863,Deployability,update,updated,863,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1544,Deployability,update,update,1544,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:1049,Integrability,depend,depending,1049,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/issues/1867:20,Testability,test,tests,20,"Hey,; while writing tests for #1715 I noted the following behavior:. `output = sc.pp.highly_variable(adata,inplace=True,subset=False,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated but shape stays the same :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=True,subset=True,n_top_genes=100)`; --> Returns nothing :heavy_check_mark: ; --> `adata.var` fields are updated and shape is subsetted correctly :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=False,n_top_genes=100)`; --> output is a dataframe with the original number of genes as rows :heavy_check_mark: ; --> `adata` is unchanged :heavy_check_mark: . `output = sc.pp.highly_variable(adata,inplace=False,subset=True,n_top_genes=100)`; --> Returns nothing :x: ; --> `adata` shape is changed an `var` fields are updated :x: . I think the last case is unexpected, assuming that `inplace=False` should protect `adata` from changes and results in an output. I think these parts of code are the cause (depending on the flavor):. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L148-L174. https://github.com/theislab/scanpy/blob/4dd8de9e355ce8d59009c15522670a3d0970462c/scanpy/preprocessing/_highly_variable_genes.py#L528-L553. To fix this, one could change `if subset or inplace:` to `if inplace:`. Then one would need to add another `if subet:` in the `else` block, like so (half-pseudocode):. ```; if inplace: ; ; #update adata; ; if batch_key is not None:; #drop batch related keys; if subset:; adata._inplace_subset_var(df['highly_variable'].values); else:; if batch_key is None:; #drop batch related keys; if subset: ; df=df.iloc[df.highly_variable.values,:]; ; return df; ```. I can make a quick PR if this is the intended behavior. :slightly_smiling_face: ; best, jan.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1867
https://github.com/scverse/scanpy/pull/1868:0,Deployability,Update,Updated,0,Updated `sc.external.pp.bbknn()` to match current arguments and docstring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1868
https://github.com/scverse/scanpy/issues/1869:339,Modifiability,variab,variable,339,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:718,Modifiability,variab,variable,718,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:228,Testability,log,logfoldchanges,228,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:361,Testability,log,logfoldchanges,361,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1869:682,Testability,test,test,682,"Hi,; Thank you for your amazing package!. I ran ""sc.tl.rank_genes_groups"" on Jupyter Notebook, and when I did: . `pd.DataFrame(; {group + '_' + key[:1]: result[key][group]; for group in groups for key in ['names', 'pvals_adj', 'logfoldchanges']})`. I was only able to see 0.0 for p-values and adjusted p-values for all of the 2,000 highly variable genes, while logfoldchanges showed 6 decimal places like 1.816276. . The version of Scanpy that I am using is 1.7.2, and I was wondering if there was a way to see more decimal places for p-values and adjusted p-values, like in the form of 3.642456e-222 in your tutorial. If this is not a formatting problem, do you think the Wilcoxon test gave me 0.0 for all the highly variable genes? ; Based on sc.pl.rank_genes_groups, the scores for 25 genes per cluster are pretty high though (most of them are in a range of 100-200). I am pretty new to python and scanpy, so your advice will be greatly helpful.; Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1869
https://github.com/scverse/scanpy/issues/1870:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; I need to filter the cells which expressed 'A' and 'B' genes >1; The below line should work for one gene but how to do it for two genes?; `adata = adata[adata[: , 'A'].X > 1, :] `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1870
https://github.com/scverse/scanpy/issues/1871:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi; I am wondering Why there is not expression_cutoff in stacked violin plot as in the dot plot?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1871
https://github.com/scverse/scanpy/issues/1872:529,Testability,log,logging,529,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import bbknn; sc.logging.print_header(); adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') ; sc.external.pp.bbknn(adata, batch_key='batch') #error2; ```. ```pytb. tuple' object has no attribute 'tocsr'; ```. #### Versions; <bbknn : 1.5.0>; <scanpy:1.7.0>; umap: 0.1.1; umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:887,Testability,log,logging,887,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import bbknn; sc.logging.print_header(); adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') ; sc.external.pp.bbknn(adata, batch_key='batch') #error2; ```. ```pytb. tuple' object has no attribute 'tocsr'; ```. #### Versions; <bbknn : 1.5.0>; <scanpy:1.7.0>; umap: 0.1.1; umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:249,Usability,guid,guide,249,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import bbknn; sc.logging.print_header(); adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') ; sc.external.pp.bbknn(adata, batch_key='batch') #error2; ```. ```pytb. tuple' object has no attribute 'tocsr'; ```. #### Versions; <bbknn : 1.5.0>; <scanpy:1.7.0>; umap: 0.1.1; umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:844,Usability,learn,learn,844,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import bbknn; sc.logging.print_header(); adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') ; sc.external.pp.bbknn(adata, batch_key='batch') #error2; ```. ```pytb. tuple' object has no attribute 'tocsr'; ```. #### Versions; <bbknn : 1.5.0>; <scanpy:1.7.0>; umap: 0.1.1; umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/issues/1872:1048,Usability,learn,learn,1048,"- I have checked that this issue has not already been reported.; - I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import bbknn; sc.logging.print_header(); adata = sc.read('pancreas.h5ad', backup_url='https://www.dropbox.com/s/qj1jlm9w10wmt0u/pancreas.h5ad?dl=1') ; sc.external.pp.bbknn(adata, batch_key='batch') #error2; ```. ```pytb. tuple' object has no attribute 'tocsr'; ```. #### Versions; <bbknn : 1.5.0>; <scanpy:1.7.0>; umap: 0.1.1; umap-learn: 0.5.1. [Paste the output of scanpy. logging.print_versions() leaving a blank line after the details tag]. </scanpy==1.4.6 anndata==0.7.4 umap==0.5.1 numpy==1.20.3 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.2>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1872
https://github.com/scverse/scanpy/pull/1873:259,Usability,guid,guidelines,259,"Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/pull/1873:290,Usability,guid,guide,290,"Latest BBKNN versions (>=1.5.x) [uses annoy_n_trees in place of n_trees](https://github.com/Teichlab/bbknn/commit/288e05990c74467601c263a23538779991fb7635), just applying that fix here. . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1873
https://github.com/scverse/scanpy/issues/1874:34,Availability,error,error,34,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:463,Availability,error,error,463,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:745,Availability,error,error,745,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:263,Modifiability,layers,layers,263,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:60,Testability,test,test,60,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:240,Testability,test,test,240,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1874:637,Usability,learn,learn,637,"Is there anybody meeting the same error with me?; I used de.test.wald() to do differentially expressed genes analysis with totally 47K cells. ### Minimal code sample (that we can copy&paste without having any data). ```python; test_sf = de.test.wald(; data=adata.layers['counts'],; formula_loc=""~ 1 + disease + size_factors"",; factor_loc_totest=""disease"",; as_numeric=['size_factors'],; gene_names=adata.var_names,; sample_description=adata.obs; ); ```. ```pytb; error: 'i' format requires -2147483648 <= number <= 2147483647; ```. #### Versions. <scanpy==1.7.1 anndata==0.7.5 umap==0.4.6 numpy==1.19.2 scipy==1.5.2 pandas==1.1.3 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.8.3 louvain==0.7.0 leidenalg==0.8.3>. #### It seems this error happens when cell amount is over 10K",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1874
https://github.com/scverse/scanpy/issues/1875:537,Availability,down,downstream,537,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one?; Can I have all them in my h5ad object and how to switch between them?; In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1875:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hi,. In my h5ad object in adata.X, which data I should use for downstream analysis? counts, normalized or scaled one?; Can I have all them in my h5ad object and how to switch between them?; In seurat there is option called active assay to assign.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1875
https://github.com/scverse/scanpy/issues/1876:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Hi,; I'm wondering if it is possible to add a new feature to sc.pl.dotplot if it is not too much of work. Say I'm interested in just one gene, and I want to plot the expression across two conditions. I understand that currently this could be achieved by using groupby = ['var1', 'var2'], but it'll be only one column, and conditions will be coerced into var1_var2. Is it possible to add a feature to the plotting function and change this behavior? I want var1 to be the x axis and var2 to be the y axis. Thank you very much!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1876
https://github.com/scverse/scanpy/pull/1877:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/pull/1877:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1877
https://github.com/scverse/scanpy/issues/1878:181,Usability,intuit,intuitive,181,"Hi, I would like to request Cubé be added to the Scanpy Ecosystem page (https://scanpy.readthedocs.io/en/stable/ecosystem.html). Cubé (https://github.com/connerlambden/Cube/) is an intuitive network algorithm that searches for multiplicative combinations of genes that have high/low correlation and are members of a known biological pathway. Given an input gene1, Cubé searches for gene2 and gene3 such that the expression of gene1 ~= gene2 * gene3 only in cells that express all three genes. Let me know if you have any questions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1878
https://github.com/scverse/scanpy/issues/1879:538,Modifiability,variab,variable,538,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; How to generate two umaps for one gene split by a condition[one variable in obs] ?; so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function?; https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1879:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; How to generate two umaps for one gene split by a condition[one variable in obs] ?; so you can compare where gene expressed in cell types and how they differ in the two conditions. could we add option split by to umap scanpy function?; https://github.com/theislab/scanpy/issues/759,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1879
https://github.com/scverse/scanpy/issues/1880:1019,Modifiability,variab,variable,1019,"Hi ,; In my case, the seurat object using the sceasy algorithm to transfer into anndata object for trajectory inference analysis.; The code lying below:; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.pp.recipe_zheng17(adata); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='paul15_clusters', legend_loc='on data'); The picture showing confused result posted below:; ![Uploading image.png…](). The object information:; >>> adata; AnnData object with n_obs × n_vars = 17885 × 999; obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'RNA_snn_res.0.5', 'seurat_clusters', 'pANN_0.25_0.02_752', 'DF.classifications_0.25_0.02_752', 'percent.rp', 'pANN_0.25_0.02_826', 'DF.classifications_0.25_0.02_826', 'group', 'celltype', 'n_counts_all'; var: 'vst.mean', 'vst.variance', 'vst.variance.expected', 'vst.variance.standardized', 'vst.variable', 'n_counts', 'mean', 'std'; uns: 'seurat_clusters_colors', 'log1p', 'pca', 'neighbors', 'draw_graph'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1880
https://github.com/scverse/scanpy/issues/1882:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; How to convert from Seurat visium to AnnData?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1882
https://github.com/scverse/scanpy/pull/1884:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/pull/1884:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->. When `RGB` color represented by 3D arrays, we cannot compare them as `list` vs `list`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1884
https://github.com/scverse/scanpy/issues/1885:446,Availability,error,error,446,"_Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`!; > ; > The following code should reproduce the error:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. -------------------------------. On current release this errors:. <details>; <summary> </summary>. ```python; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-1-4c43dbe94eaf> in <module>; 4 ; 5 pbmc = sc.datasets.pbmc68k_reduced(); ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:667,Availability,error,errors,667,"_Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`!; > ; > The following code should reproduce the error:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. -------------------------------. On current release this errors:. <details>; <summary> </summary>. ```python; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-1-4c43dbe94eaf> in <module>; 4 ; 5 pbmc = sc.datasets.pbmc68k_reduced(); ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5309,Availability,error,error,5309,"isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6645,Availability,error,errors,6645,". ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]; ```. ```; [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),; (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),; (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:654,Deployability,release,release,654,"_Originally posted by @OnlyBelter in https://github.com/theislab/scanpy/issues/1850#issuecomment-863089065_. > But in the original jupyter notebook which I used to process this .h5ad file (also contains many other steps before this step), I cannot use some specific columns to set parameter color in this function (some columns can be used correctly). > I think this problem may cause by `seaborn`!; > ; > The following code should reproduce the error:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase'); ```. -------------------------------. On current release this errors:. <details>; <summary> </summary>. ```python; ---------------------------------------------------------------------------; NotImplementedError Traceback (most recent call last); <ipython-input-1-4c43dbe94eaf> in <module>; 4 ; 5 pbmc = sc.datasets.pbmc68k_reduced(); ----> 6 sc.pl.umap(pbmc, color = 'phase'). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 601 If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; 602 """"""; --> 603 return embedding(adata, 'umap', **kwargs); 604 ; 605 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 244 groups=groups,; 245 ); --> 246 color_vector, categorical = _color_vector(; 247 adata,; 248 value_to_plot,. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4133,Performance,Cache,CachedProperty,4133,"dered=None.; --> 273 dtype = CategoricalDtype(categories, ordered); 274 ; 275 return dtype. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in __init__(self, categories, ordered); 158 ; 159 def __init__(self, categories=None, ordered: Ordered = False):; --> 160 self._finalize(categories, ordered, fastpath=False); 161 ; 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath); 312 ; 313 if categories is not None:; --> 314 categories = self.validate_categories(categories, fastpath=fastpath); 315 ; 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath); 505 if not fastpath:; 506 ; --> 507 if categories.hasnans:; 508 raise ValueError(""Categorical categories cannot be null""); 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self); 2193 """"""; 2194 if self._can_hold_na:; -> 2195 return bool(self._isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:4428,Performance,Cache,CachedProperty,4428,"-> 160 self._finalize(categories, ordered, fastpath=False); 161 ; 162 @classmethod. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in _finalize(self, categories, ordered, fastpath); 312 ; 313 if categories is not None:; --> 314 categories = self.validate_categories(categories, fastpath=fastpath); 315 ; 316 self._categories = categories. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/dtypes.py in validate_categories(categories, fastpath); 505 if not fastpath:; 506 ; --> 507 if categories.hasnans:; 508 raise ValueError(""Categorical categories cannot be null""); 509 . pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in hasnans(self); 2193 """"""; 2194 if self._can_hold_na:; -> 2195 return bool(self._isnan.any()); 2196 else:; 2197 return False. pandas/_libs/properties.pyx in pandas._libs.properties.CachedProperty.__get__(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, whi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5449,Safety,avoid,avoided,5449,"(). ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/indexes/base.py in _isnan(self); 2172 """"""; 2173 if self._can_hold_na:; -> 2174 return isna(self); 2175 else:; 2176 # shouldn't reach to this condition by checking hasnans beforehand. ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on mas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:5766,Safety,avoid,avoided,5766,"ndas/core/dtypes/missing.py in isna(obj); 125 Name: 1, dtype: bool; 126 """"""; --> 127 return _isna(obj); 128 ; 129 . ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]; ```. ```; [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),; (0.86666666666666",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/issues/1885:6083,Safety,avoid,avoided,6083,". ~/miniconda3/envs/scanpy-forge/lib/python3.8/site-packages/pandas/core/dtypes/missing.py in _isna(obj, inf_as_na); 154 # hack (for now) because MI registers as ndarray; 155 elif isinstance(obj, ABCMultiIndex):; --> 156 raise NotImplementedError(""isna is not defined for MultiIndex""); 157 elif isinstance(obj, type):; 158 return False. NotImplementedError: isna is not defined for MultiIndex; ```. </details>. I don't get an error from this on master, but I do get these warnings. ```; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; *c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*. Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.; ```. No differences between pandas, seaborn, or matplotlib versions between these environments. Seems like it's sorta fixed on master. I think this might be a cause:. ```python; import scanpy as sc; import seaborn as sns; sns.set() # <--- here. pbmc = sc.datasets.pbmc68k_reduced(); sc.pl.umap(pbmc, color = 'phase') # This errors. pbmc.uns[""phase_colors""]; ```. ```; [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725),; (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),; (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1885
https://github.com/scverse/scanpy/pull/1886:154,Availability,error,errors,154,"If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:253,Security,validat,validation,253,"If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/pull/1886:272,Security,validat,validate,272,"If you call `sns.set_palette`, seaborn sets the default color palette as rgb tuples. matplotlib sometimes complains about this, and something this causes errors with our other code. We were putting these tuples into `adata.uns[f""{key}_colors""]` without validation. Now we validate this. Fixes #1885.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1886
https://github.com/scverse/scanpy/issues/1888:103,Availability,error,error,103,"When the X matrix is not sparse, the `flatten` function is not applied and the function fails with the error: ; ```; ValueError: Data must be 1-dimensional; ```. https://github.com/theislab/scanpy/blob/04987bd4290db411873236c9f6c662a0b445b76f/scanpy/plotting/_tools/__init__.py#L910",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1888
https://github.com/scverse/scanpy/pull/1890:389,Energy Efficiency,adapt,adapted,389,"As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:389,Modifiability,adapt,adapted,389,"As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1890:401,Testability,test,tests,401,"As discussed in issue #313, score_genes function returns different values on various machines. This is due to using float32 dtype in the `np.nanmean` calls. This PR fixes this behaviour by changing the dtype to float64 in the relevant sections of code ie. functions `gene_score()` and `_sparse_nanmean`. Following the suggestion of @ivirshup the returned value is now also float64. I also adapted the tests `test_add_score` and `test_npnanmean_vs_sparsemean` to use and expect float64.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1890
https://github.com/scverse/scanpy/pull/1891:70,Modifiability,variab,variables,70,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:127,Modifiability,variab,variable,127,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:222,Modifiability,variab,variable,222,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:523,Performance,Perform,Performance,523,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/pull/1891:426,Testability,log,logic,426,"Fixes #1806. New behaviour for Moran's I and Geary's C. If one of the variables passed has constant values, the score for that variable is `nan` and the function warns the user about this. Previously, the presence of this variable would silently fail, corrupting the other outputs as well. Adds a new utility `is_constant` to check if values in an array are constant. * Could have less code repetition, since now there's some logic that is applied to any case which is 2d, but the conditional isn't structured this way.; * Performance hit pretty minor, as computing the metric itself is expensive.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1891
https://github.com/scverse/scanpy/issues/1892:269,Availability,ping,ping,269,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:45,Deployability,update,updated,45,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:4,Testability,test,tests,4,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:92,Testability,test,tests,92,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/issues/1892:261,Testability,test,test,261,"The tests are currently failing as scipy has updated their implementation of Mann-Whitney U tests, which we use as a reference. We should figure out what changed, and how to proceed (e.g. do we change our function, or pass different parameters to theirs in the test?). ping: @Koncopd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1892
https://github.com/scverse/scanpy/pull/1893:88,Availability,error,error,88,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:103,Modifiability,variab,variables,103,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/pull/1893:59,Testability,test,tests,59,"Fixes #1892. Scipy now returns `np.nan` for Mann-Whitney U tests where there it used to error. Namely, variables for which all values are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1893
https://github.com/scverse/scanpy/issues/1894:757,Availability,error,error,757,"`_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>; <summary> possible solution </summary>. ```python; from numba import njit, prange; import numpy as np. @njit(parallel=True); def nanmean_lowlevel(data, indices, indptr, shape):; N, M = shape; sums = np.zeros(N, dtype=np.float64); nans = np.zeros(N, dtype=np.int64); for i in prange(N):; start = indptr[i]; stop = indptr[i+1]; window = data[start:stop]; n_nan = np.int64(0); i_sum = np.float64(0.); for j_val in window:; if np.isnan(j_val):; n_nan += 1; else:; i_sum += j_val; sums[i] = i_sum; nans[i] = n_nan; sums /= (M - nans); return sums; ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/issues/1894:58,Performance,perform,performs,58,"`_sparse_nanmean` makes two copies of the data matrix and performs a set index operation on a sparse array. It could be much faster by not doing this things. Noticed while reviewing #1890. <details>; <summary> possible solution </summary>. ```python; from numba import njit, prange; import numpy as np. @njit(parallel=True); def nanmean_lowlevel(data, indices, indptr, shape):; N, M = shape; sums = np.zeros(N, dtype=np.float64); nans = np.zeros(N, dtype=np.int64); for i in prange(N):; start = indptr[i]; stop = indptr[i+1]; window = data[start:stop]; n_nan = np.int64(0); i_sum = np.float64(0.); for j_val in window:; if np.isnan(j_val):; n_nan += 1; else:; i_sum += j_val; sums[i] = i_sum; nans[i] = n_nan; sums /= (M - nans); return sums; ```. Has more error from dense reference compared to current solution, not sure why. Something about the sums being different. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1894
https://github.com/scverse/scanpy/pull/1895:262,Availability,down,downstream,262,"On current master:. ```python; import scanpy as sc. a = sc.datasets.krumsiek11(); assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]; # True; ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895
https://github.com/scverse/scanpy/pull/1895:82,Testability,assert,assert,82,"On current master:. ```python; import scanpy as sc. a = sc.datasets.krumsiek11(); assert a.raw is None. sc.tl.rank_genes_groups(a, ""cell_type"", method=""wilcoxon""). a.uns[""rank_genes_groups""][""params""][""use_raw""]; # True; ```. This is bad, and causes issues with downstream plotting functions which use `use_raw` to check where they should be getting expression values from. This PR fixes that. Along with other recent bug fixes, fixes #1114.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1895
https://github.com/scverse/scanpy/issues/1896:94,Availability,error,error,94,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:123,Availability,error,error,123,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2,Deployability,install,installed,2,"I installed GProfiler using conda, then went to run `sc.queries.enrich(my_adata)` and got the error below. I get a similar error if I try to run `from gprofiler import GProfiler` myself, and it's resolved if I remove the capitalization (`from gprofiler import gprofiler`), as suggested [here](https://github.com/vals/python-gprofiler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2315,Deployability,install,installed,2315,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 266 except ImportError:; 267 raise ImportError(; --> 268 ""This method requires the `gprofiler-official` module to be installed.""; 269 ); 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed.; ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2478,Deployability,install,installed,2478,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 266 except ImportError:; 267 raise ImportError(; --> 268 ""This method requires the `gprofiler-official` module to be installed.""; 269 ); 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed.; ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1288,Integrability,wrap,wrapper,1288,"ler/issues/9). Do you know why the enrich function uses capitalization, and how I can get my gprofiler compatible with it? Versions listed below. Thanks. ```pytb; ImportError Traceback (most recent call last); /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 264 try:; --> 265 from gprofiler import GProfiler; 266 except ImportError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 266 except ImportError:; 267 raise ImportError(; --> 268 ""This method requires the `gprofiler-official` module to be installed.""; 26",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:1875,Integrability,wrap,wrapper,1875,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 266 except ImportError:; 267 raise ImportError(; --> 268 ""This method requires the `gprofiler-official` module to be installed.""; 269 ); 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed.; ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/issues/1896:2666,Usability,learn,learn,2666,"portError:. ImportError: cannot import name 'GProfiler'. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last); <ipython-input-383-c1b09359d1a1> in <module>; 14 ; 15 #get gene set enrichment; ---> 16 print(sc.queries.enrich(this_adata, org='hsapiens', group='malignant', key='malignantvshealthy', pval_cutoff=0.01, log2fc_min=np.log2(1.5))); 17 ; 18 #plot volcano (makes a sep df along the way, should consolidate with above). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in _enrich_anndata(adata, group, org, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols, gprofiler_kwargs); 305 else:; 306 gene_list = list(de[""names""].dropna()); --> 307 return enrich(gene_list, org=org, gprofiler_kwargs=gprofiler_kwargs). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/functools.py in wrapper(*args, **kw); 805 '1 positional argument'); 806 ; --> 807 return dispatch(args[0].__class__)(*args, **kw); 808 ; 809 funcname = getattr(func, '__name__', 'singledispatch function'). /anaconda3/envs/mm_singlecell_v2/lib/python3.6/site-packages/scanpy/queries/_queries.py in enrich(container, org, gprofiler_kwargs); 266 except ImportError:; 267 raise ImportError(; --> 268 ""This method requires the `gprofiler-official` module to be installed.""; 269 ); 270 gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True). ImportError: This method requires the `gprofiler-official` module to be installed.; ```. #### Versions. gprofiler-official bioconda/noarch::gprofiler-official-1.0.0-py_0. scanpy==1.7.1 anndata==0.7.5 umap==0.5.1 numpy==1.19.5 scipy==1.5.3 pandas==1.1.5 scikit-learn==0.19.1 statsmodels==0.12.2 python-igraph==0.8.3 leidenalg==0.8.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1896
https://github.com/scverse/scanpy/pull/1897:155,Deployability,install,install,155,"Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:167,Integrability,depend,dependencies,167,"Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:221,Performance,cache,cached,221,"Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1897:260,Performance,cache,cache,260,"Fixes #1697. I'll leave any major backwards compatibility changes (i.e. updating to use python 3.7+ features) to the future. CI took a really long time to install the dependencies on the first run. Hopefully that will be cached? Not sure what triggers a saved cache. At the moment it looks like building `louvain` is taking a while, which we should actually just get around to deprecating.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1897
https://github.com/scverse/scanpy/pull/1898:386,Availability,error,errors,386,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:490,Availability,error,error,490,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:3929,Availability,avail,available,3929,"port_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all?. ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921); - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:211,Testability,log,logic,211,"Fixes #1887. Order of node coordinates used in `paga_compare` could be wrong since the group medians were not necessarily in the order of `adata.obs[group].cat.categories`. Now they are. Additionally, moved the logic for computing the group medians to `paga_compare` so the `_tmp_pos` hack can be removed. As a side effect, a number of arguments to `sc.pl.paga_compare` no longer cause errors. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:4091,Testability,Test,Test,4091,"port_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all?. ## TODO:. - [x] Figure out how to handle arguments that work now. Maybe remove? (Opened an issue so this can be merged, #1921); - [x] Test somehow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/pull/1898:2782,Usability,simpl,simplefilter,2782,"le_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1898
https://github.com/scverse/scanpy/issues/1901:52,Availability,down,downregulated,52,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:194,Availability,down,down,194,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:288,Availability,down,downregulated,288,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/issues/1901:394,Availability,down,downregulated,394,"How does `sc.queries.enrich` handle upregulated and downregulated differentially expressed genes? Are they both input into GProfiler, with no distinction made between which are up and which are down? . I ask because it's important for interpretation. For example, if both upregulated and downregulated genes are input to GProfiler without distinction, then if `rank_genes_groups` had found all downregulated genes for phenotype A, then the pathways reported for phenotype A would actually be enriched in phenotype B. My current understanding is that all genes are passed together. If you supply a min log2fc_min > 0, it will include only upregulated genes, but otherwise it will include all. Is this correct?. More generally, is there some place I could view the API code, to get a better sense of how this function works? On GitHub all I can see is `gprofiler = GProfiler(user_agent=""scanpy"", return_dataframe=True)`, and I can't find the details in GProfiler's documentation either. Where is the ""container"" object created?. p.s. I think it might be helpful to clarify the syntax for passing parameters to gprofiler_kwargs. It took some playing around for me to find the right combination of string + boolean for `gprofiler_kwargs={'no_evidences':False}`. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1901
https://github.com/scverse/scanpy/pull/1902:0,Testability,Test,Testing,0,Testing to see if the way versions are being retrieved is the problem,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1902
https://github.com/scverse/scanpy/pull/1904:34,Deployability,release,release,34,"@giovp, could you check the 1.8.0 release notes to make sure I got everyone's names?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1904
https://github.com/scverse/scanpy/issues/1908:330,Availability,down,down-sampled,330,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:231,Testability,test,tests,231,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:456,Testability,test,testing,456,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1908:480,Usability,clear,clear,480,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; https://github.com/theislab/scanpy/tree/master/scanpy/tests/_data/10x_data/3.0.0 - this h5 object is 1107 cells by 507 genes but what is the data? Is it down-sampled pbmc3k or some other dataset? How was it generated?. I'm looking for a tiny h5 object like this for our own unit testing, but want to be clear on the data source, thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1908
https://github.com/scverse/scanpy/issues/1909:975,Deployability,toggle,toggleswitch,975,"## Current build process. Current build process (as used on azure) does not include the `LICENSE`, as well as a number of other files (which may note be necessary). ```; git checkout 1.8.0; python -m build --sdist --wheel .; tar tzf dist/scanpy-1.8.0.tar.gz ; ```. <details>; <summary> contents of source dist </summary>. ```; scanpy-1.8.0/README.rst; scanpy-1.8.0/pyproject.toml; scanpy-1.8.0/scanpy/__init__.py; scanpy-1.8.0/scanpy/__main__.py; scanpy-1.8.0/scanpy/_compat.py; scanpy-1.8.0/scanpy/_metadata.py; scanpy-1.8.0/scanpy/_settings.py; scanpy-1.8.0/scanpy/_utils/__init__.py; scanpy-1.8.0/scanpy/_utils/compute/is_constant.py; scanpy-1.8.0/scanpy/cli.py; scanpy-1.8.0/scanpy/datasets/10x_pbmc68k_reduced.h5ad; scanpy-1.8.0/scanpy/datasets/__init__.py; scanpy-1.8.0/scanpy/datasets/_datasets.py; scanpy-1.8.0/scanpy/datasets/_ebi_expression_atlas.py; scanpy-1.8.0/scanpy/datasets/_utils.py; scanpy-1.8.0/scanpy/datasets/krumsiek11.txt; scanpy-1.8.0/scanpy/datasets/toggleswitch.txt; scanpy-1.8.0/scanpy/external/__init__.py; scanpy-1.8.0/scanpy/external/exporting.py; scanpy-1.8.0/scanpy/external/pl.py; scanpy-1.8.0/scanpy/external/pp/__init__.py; scanpy-1.8.0/scanpy/external/pp/_bbknn.py; scanpy-1.8.0/scanpy/external/pp/_dca.py; scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py; scanpy-1.8.0/scanpy/external/pp/_hashsolo.py; scanpy-1.8.0/scanpy/external/pp/_magic.py; scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py; scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py; scanpy-1.8.0/scanpy/external/pp/_scrublet.py; scanpy-1.8.0/scanpy/external/tl/__init__.py; scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py; scanpy-1.8.0/scanpy/external/tl/_palantir.py; scanpy-1.8.0/scanpy/external/tl/_phate.py; scanpy-1.8.0/scanpy/external/tl/_phenograph.py; scanpy-1.8.0/scanpy/external/tl/_pypairs.py; scanpy-1.8.0/scanpy/external/tl/_sam.py; scanpy-1.8.0/scanpy/external/tl/_trimap.py; scanpy-1.8.0/scanpy/external/tl/_wishbone.py; scanpy-1.8.0/scanpy/get/__init__.py; scanpy-1.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:3873,Deployability,toggle,toggleswitch,3873,ng/_utils.py; scanpy-1.8.0/scanpy/plotting/palettes.py; scanpy-1.8.0/scanpy/preprocessing/__init__.py; scanpy-1.8.0/scanpy/preprocessing/_combat.py; scanpy-1.8.0/scanpy/preprocessing/_deprecated/__init__.py; scanpy-1.8.0/scanpy/preprocessing/_deprecated/highly_variable_genes.py; scanpy-1.8.0/scanpy/preprocessing/_distributed.py; scanpy-1.8.0/scanpy/preprocessing/_docs.py; scanpy-1.8.0/scanpy/preprocessing/_highly_variable_genes.py; scanpy-1.8.0/scanpy/preprocessing/_normalization.py; scanpy-1.8.0/scanpy/preprocessing/_pca.py; scanpy-1.8.0/scanpy/preprocessing/_qc.py; scanpy-1.8.0/scanpy/preprocessing/_recipes.py; scanpy-1.8.0/scanpy/preprocessing/_simple.py; scanpy-1.8.0/scanpy/preprocessing/_utils.py; scanpy-1.8.0/scanpy/queries/__init__.py; scanpy-1.8.0/scanpy/queries/_queries.py; scanpy-1.8.0/scanpy/readwrite.py; scanpy-1.8.0/scanpy/sim_models/__init__.py; scanpy-1.8.0/scanpy/sim_models/krumsiek11.txt; scanpy-1.8.0/scanpy/sim_models/krumsiek11_params.txt; scanpy-1.8.0/scanpy/sim_models/toggleswitch.txt; scanpy-1.8.0/scanpy/sim_models/toggleswitch_params.txt; scanpy-1.8.0/scanpy/tools/__init__.py; scanpy-1.8.0/scanpy/tools/_dendrogram.py; scanpy-1.8.0/scanpy/tools/_diffmap.py; scanpy-1.8.0/scanpy/tools/_dpt.py; scanpy-1.8.0/scanpy/tools/_draw_graph.py; scanpy-1.8.0/scanpy/tools/_embedding_density.py; scanpy-1.8.0/scanpy/tools/_ingest.py; scanpy-1.8.0/scanpy/tools/_leiden.py; scanpy-1.8.0/scanpy/tools/_louvain.py; scanpy-1.8.0/scanpy/tools/_marker_gene_overlap.py; scanpy-1.8.0/scanpy/tools/_paga.py; scanpy-1.8.0/scanpy/tools/_pca.py; scanpy-1.8.0/scanpy/tools/_rank_genes_groups.py; scanpy-1.8.0/scanpy/tools/_score_genes.py; scanpy-1.8.0/scanpy/tools/_sim.py; scanpy-1.8.0/scanpy/tools/_top_genes.py; scanpy-1.8.0/scanpy/tools/_tsne.py; scanpy-1.8.0/scanpy/tools/_umap.py; scanpy-1.8.0/scanpy/tools/_utils.py; scanpy-1.8.0/scanpy/tools/_utils_clustering.py; scanpy-1.8.0/PKG-INFO; ```. </details>. ## Flit build. Using flit to build it includes all the files I would expect,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1909:2042,Testability,log,logging,2042,-1.8.0/scanpy/external/exporting.py; scanpy-1.8.0/scanpy/external/pl.py; scanpy-1.8.0/scanpy/external/pp/__init__.py; scanpy-1.8.0/scanpy/external/pp/_bbknn.py; scanpy-1.8.0/scanpy/external/pp/_dca.py; scanpy-1.8.0/scanpy/external/pp/_harmony_integrate.py; scanpy-1.8.0/scanpy/external/pp/_hashsolo.py; scanpy-1.8.0/scanpy/external/pp/_magic.py; scanpy-1.8.0/scanpy/external/pp/_mnn_correct.py; scanpy-1.8.0/scanpy/external/pp/_scanorama_integrate.py; scanpy-1.8.0/scanpy/external/pp/_scrublet.py; scanpy-1.8.0/scanpy/external/tl/__init__.py; scanpy-1.8.0/scanpy/external/tl/_harmony_timeseries.py; scanpy-1.8.0/scanpy/external/tl/_palantir.py; scanpy-1.8.0/scanpy/external/tl/_phate.py; scanpy-1.8.0/scanpy/external/tl/_phenograph.py; scanpy-1.8.0/scanpy/external/tl/_pypairs.py; scanpy-1.8.0/scanpy/external/tl/_sam.py; scanpy-1.8.0/scanpy/external/tl/_trimap.py; scanpy-1.8.0/scanpy/external/tl/_wishbone.py; scanpy-1.8.0/scanpy/get/__init__.py; scanpy-1.8.0/scanpy/get/get.py; scanpy-1.8.0/scanpy/logging.py; scanpy-1.8.0/scanpy/metrics/__init__.py; scanpy-1.8.0/scanpy/metrics/_gearys_c.py; scanpy-1.8.0/scanpy/metrics/_metrics.py; scanpy-1.8.0/scanpy/metrics/_morans_i.py; scanpy-1.8.0/scanpy/neighbors/__init__.py; scanpy-1.8.0/scanpy/plotting/__init__.py; scanpy-1.8.0/scanpy/plotting/_anndata.py; scanpy-1.8.0/scanpy/plotting/_baseplot_class.py; scanpy-1.8.0/scanpy/plotting/_docs.py; scanpy-1.8.0/scanpy/plotting/_dotplot.py; scanpy-1.8.0/scanpy/plotting/_matrixplot.py; scanpy-1.8.0/scanpy/plotting/_preprocessing.py; scanpy-1.8.0/scanpy/plotting/_qc.py; scanpy-1.8.0/scanpy/plotting/_rcmod.py; scanpy-1.8.0/scanpy/plotting/_stacked_violin.py; scanpy-1.8.0/scanpy/plotting/_tools/__init__.py; scanpy-1.8.0/scanpy/plotting/_tools/paga.py; scanpy-1.8.0/scanpy/plotting/_tools/scatterplots.py; scanpy-1.8.0/scanpy/plotting/_utils.py; scanpy-1.8.0/scanpy/plotting/palettes.py; scanpy-1.8.0/scanpy/preprocessing/__init__.py; scanpy-1.8.0/scanpy/preprocessing/_combat.py; scanpy-1.8.0/scanpy/prep,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1909
https://github.com/scverse/scanpy/issues/1910:300,Availability,error,error,300,"It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/issues/1910:80,Modifiability,variab,variable,80,"It looks like we might not be handling non-expressed genes in all of the highly variable genes implementations. For me this was solved by filtering out genes that were not expressed in any cell!; `sc.pp.filter_genes(adata, min_cells=1)`; If I include a batch_key in the hvg function, I still get the error. I guess in that case you have to ensure that every gene is expressed in every batch? Seems like a bug to fix. _Originally posted by @LisaSikkema in https://github.com/theislab/scanpy/issues/391#issuecomment-870384617_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1910
https://github.com/scverse/scanpy/pull/1911:31,Deployability,release,release,31,Backport PR #1907: Start 1.8.1 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1911
https://github.com/scverse/scanpy/issues/1912:76,Deployability,install,installation,76,We should mention that scanpy is now distributed through conda forge in the installation instructions,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1912
https://github.com/scverse/scanpy/issues/1913:501,Integrability,depend,dependent,501,"I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1913:412,Usability,simpl,simply,412,"I have two suggestions/questions about dot/matrix plots:. 1- If `standard_scale='var'` is given, we can write `Mean expression\nin group\n(min-max scaled)` on the color legend to be more accurate about what is being displayed. 2- People/journals usually expect gene names to be written with italicized characters (don't ask why, see https://en.wikipedia.org/wiki/Gene_nomenclature). So I was wondering if we can simply do that in the plots. One important thing to consider is whether this is organism-dependent. I guess it's not but would be cool to discuss.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1913
https://github.com/scverse/scanpy/issues/1915:343,Availability,error,errors,343,"### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); cats = pbmc.obs[""louvain""].cat.categories; genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]); ```. ```pytb; ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-580bb69f9615> in <module>; ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:440,Availability,ERROR,ERROR,440,"### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(); cats = pbmc.obs[""louvain""].cat.categories; genes = list(pbmc.uns[""rank_genes_groups""][""names""][0]). # this works:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[::-1]). # this errors:; sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]); ```. ```pytb; ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-580bb69f9615> in <module>; ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 );",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2142,Availability,error,error,2142,"ategories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 ); 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'; ```. First, what's up with the printed error?. Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>; <summary> </summary>. ```python; -----; anndata 0.7.7.dev4+g49739eb; scanpy 1.9.0.dev7+g092376d2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4595,Deployability,update,updated,4595," 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.8.0; jupyterlab_server 2.6.0; kiwisolver 1.2.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; nbinom_ufunc NA; numba 0.53.1; numcodecs 0.8.0; numexpr 2.7.2; numpy 1.21.0; packaging 20.9; pandas 1.2.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2020.1; requests 2.25.1; scanpy 1.9.0.dev7+g092376d2; scipy 1.7.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; snappy NA; sniffio 1.2.0; socks 1.7.1; sparse 0.12.0+21.gc96cc1a; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.6.0; terminado 0.8.3; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.61.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 1.1.0; yaml 5.3.1; zappy NA; zarr 2.8.3; zmq 19.0.2; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-07-01 15:01; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:2291,Modifiability,variab,variable,2291,"_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 ); 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'; ```. First, what's up with the printed error?. Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behaviour I can't quite remember while fixing up #1529. Noticed this specific case while looking at #1914. #### Versions. <details>; <summary> </summary>. ```python; -----; anndata 0.7.7.dev4+g49739eb; scanpy 1.9.0.dev7+g092376d2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.8.0; jupyterlab_server 2.6.0; kiwisolver 1.2.0; le",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:1246,Testability,log,log,1246,"order=cats[:3]); ```. ```pytb; ERROR: Please check that the categories given by the `order` parameter match the categories that want to be reordered. Mismatch: {'Dendritic cells', 'Megakaryocytes', 'NK cells', 'FCGR3A+ Monocytes', 'CD8 T cells'}. Given order categories: Index(['CD4 T cells', 'CD14+ Monocytes', 'B cells'], dtype='object'). louvain categories: ['CD4 T cells', 'CD14+ Monocytes', 'B cells', 'CD8 T cells', 'NK cells', 'FCGR3A+ Monocytes', 'Dendritic cells', 'Megakaryocytes']. ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-5-580bb69f9615> in <module>; ----> 1 sc.pl.dotplot(pbmc, genes, groupby=""louvain"", categories_order=cats[:3]). ~/github/scanpy/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 982 return dp; 983 else:; --> 984 dp.make_figure(); 985 savefig_or_show(DotPlot.DEFAULT_SAVE_PREFIX, show=show, save=save); 986 show = settings.autoshow if show is None else show. ~/github/scanpy/scanpy/plotting/_baseplot_class.py in make_figure(self); 606 mainplot_height = len(self.categories) * category_height; 607 mainplot_width = (; --> 608 len(self.var_names) * category_width + self.group_extra_size; 609 ); 610 if self.are_axes_swapped:. AttributeError: 'DotPlot' object has no attribute 'group_extra_size'; ```. First, what's up with the printed error?. Second, I think subsetting the groups and specifying the order can be done at the same time. This is the behaviour of the `groups` kwarg for variable axis of `sc.pl.rank_genes_groups`. This is also the behaviour of `var_names`. I'd noticed some related behavio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1915:4543,Testability,log,logical,4543," 0.3.1; -----; PIL 8.2.0; anndata 0.7.7.dev4+g49739eb; anyio NA; appnope 0.1.0; argon2 20.1.0; asciitree NA; attr 20.3.0; babel 2.8.0; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli 1.0.9; certifi 2020.06.20; cffi 1.14.0; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.05.0; dateutil 2.8.1; decorator 4.4.2; fasteners NA; fsspec 2021.06.0; google NA; h5py 3.2.1; idna 2.10; igraph 0.9.6; ipykernel 5.5.4; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.8.0; jupyterlab_server 2.6.0; kiwisolver 1.2.0; leidenalg 0.8.3; llvmlite 0.36.0; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.4.2; monotonic NA; mpl_toolkits NA; msgpack 1.0.0; natsort 7.1.1; nbclassic NA; nbformat 5.1.2; nbinom_ufunc NA; numba 0.53.1; numcodecs 0.8.0; numexpr 2.7.2; numpy 1.21.0; packaging 20.9; pandas 1.2.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.18; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.0; pyparsing 2.4.7; pyrsistent NA; pytoml NA; pytz 2020.1; requests 2.25.1; scanpy 1.9.0.dev7+g092376d2; scipy 1.7.0; send2trash NA; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; snappy NA; sniffio 1.2.0; socks 1.7.1; sparse 0.12.0+21.gc96cc1a; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.6.0; terminado 0.8.3; texttable 1.6.3; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.61.1; traitlets 5.0.5; typing_extensions NA; urllib3 1.26.4; wcwidth 0.2.5; websocket 1.1.0; yaml 5.3.1; zappy NA; zarr 2.8.3; zmq 19.0.2; -----; IPython 7.23.1; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.16; notebook 6.4.0; -----; Python 3.8.10 (default, May 4 2021, 03:05:50) [Clang 12.0.0 (clang-1200.0.32.29)]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-07-01 15:01; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1915
https://github.com/scverse/scanpy/issues/1916:9,Availability,error,error,9,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:328,Availability,Error,Error,328,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:564,Availability,toler,tolerance,564,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2309,Availability,toler,tolerance,2309,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2450,Availability,toler,tolerance,2450,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1318,Performance,cache,cache,1318,"pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:1675,Performance,cache,cache,1675,"ngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:858,Security,hash,hashtable,858,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:951,Security,hash,hashtable,951,"I get an error when I use sc.read_10x_mtx() to read scRNA-seq files (matrix.mtx.gz, barcodes.tsv.gz, and features.tsv.gz) generated by ""Illumina HiSeq 4000"". The function works fine when I read files generated by other 10x platforms such as ""Illumina NovaSeq 6000"". . Example:; ```python; sc.read_10x_mtx(""GSE145328_RAW""); ```. Error:; ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3079 try:; -> 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2710,Testability,log,logging,2710,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1916:2596,Usability,learn,learn,2596,".get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 2. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); <ipython-input-20-26443e0aed95> in <module>; ----> 1 rnaseq1 = sc.read_10x_mtx(""GSE145328_RAW""). ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only, prefix); 479 genefile_exists = (path / f'{prefix}genes.tsv').is_file(); 480 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 481 adata = read(; 482 str(path),; 483 var_names=var_names,. ~/anaconda3/lib/python3.8/site-packages/scanpy/readwrite.py in _read_v3_10x_mtx(path, var_names, make_unique, cache, cache_compression, prefix); 560 else:; 561 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""); --> 562 adata.var['feature_types'] = genes[2].values; 563 adata.obs_names = pd.read_csv(path / f'{prefix}barcodes.tsv.gz', header=None)[; 564 0. ~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3022 if self.columns.nlevels > 1:; 3023 return self._getitem_multilevel(key); -> 3024 indexer = self.columns.get_loc(key); 3025 if is_integer(indexer):; 3026 indexer = [indexer]. ~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3080 return self._engine.get_loc(casted_key); 3081 except KeyError as err:; -> 3082 raise KeyError(key) from err; 3083 ; 3084 if tolerance is not None:. KeyError: 2; ```. #### Versions; scanpy==1.8.0 anndata==0.7.6 umap==0.5.1 numpy==1.19.2 scipy==1.6.3 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.2. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1916
https://github.com/scverse/scanpy/issues/1917:648,Integrability,wrap,wrap,648,"We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:21,Testability,test,tests,21,"We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1917:576,Usability,undo,undocumented,576,"We have some failing tests due to a couple bugs introduced in pandas 1.3.0:. * https://github.com/pandas-dev/pandas/issues/42380. I think this one is small in scope. Has problems when `df.agg` is called, when all columns are categorical and index is non-unique. Definitely a bug in pandas, and I don't think we do this much. Switching to `df.apply` works around the problem. * https://github.com/pandas-dev/pandas/issues/42376. Assignment of single columns `np.matrix` to dataframe columns no longer works as if the matrix were a 1d array. I think this is a bug since it's an undocumented behaviour change. Fixes are pretty easy, since we can just wrap occurrences with `np.ravel`, however I wouldn't be surprised if there were many places in the codebase that this happened. I would be good if these didn't happen.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1917
https://github.com/scverse/scanpy/issues/1919:61,Deployability,release,releases,61,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:96,Deployability,release,release,96,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:154,Deployability,release,release,154,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:320,Deployability,release,release,320,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:478,Deployability,release,releases,478,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:609,Deployability,release,release,609,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:755,Deployability,release,releases,755,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:284,Integrability,depend,dependencies,284,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:133,Testability,test,tested,133,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1919:584,Testability,test,testing,584,"It would be nice if we had a better way of handling upstream releases. E.g. when pandas makes a release it would be good that we had tested against their release candidates, or if we had a good process for dealing with bugs if they do occur. One think we could do, is defensively pin dependencies to below their current release series. I don't like doing this since I think it's pretty restrictive when most of the time we don't have issues. Maybe we could do this for breaking releases, but that wouldn't have prevented issues like #1917. It would be nice to automate the process of testing against upstream release candidates. Basically, when something comes out, we build against it so we can report issues early and don't have to deal with it in live releases. I'm not sure how to do this with `pip search` not working anymore.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1919
https://github.com/scverse/scanpy/issues/1921:161,Availability,error,error,161,"## Example of potentially bad groups argument (copied from PR):. For example, on current master passing any value for `groups` to `sc.pl.paga_compare` causes an error (since the ""wrong"" number of medians is calculated). Now it works, but it's a bit unclear if it's doing the right thing:. ```python; import scanpy as sc. adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, ""louvain""); sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4]); ```. On master:. <details>; <summary> traceback </summary>. ```python; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-13-e5188d753713> in <module>; 1 adata = sc.datasets.pbmc3k_processed(); 2 sc.tl.paga(adata, ""louvain""); ----> 3 sc.pl.paga_compare(adata, groups=list(adata.obs[""louvain""].cat.categories[:4])). ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga_compare(adata, basis, edges, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, size, title, right_margin, left_margin, show, save, title_graph, groups_graph, **paga_graph_params); 135 if legend_fontoutline is not None:; 136 paga_graph_params['fontoutline'] = legend_fontoutline; --> 137 paga(; 138 adata,; 139 ax=axs[1],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plottin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:3600,Availability,avail,available,3600,"in, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97f1-468d43c9eec0.png). Why is `groups` a handled argument if it doesn't do anything with the paga representation? Should it be an available argument at all? What was the intent of the argument when it was added?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/issues/1921:2453,Usability,simpl,simplefilter,2453,"le_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax); 552 if title[icolor] is not None:; 553 axs[icolor].set_title(title[icolor]); --> 554 sct = _paga_graph(; 555 adata,; 556 axs[icolor],. ~/github/scanpy/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize); 820 with warnings.catch_warnings():; 821 warnings.simplefilter(""ignore""); --> 822 nx.draw_networkx_edges(; 823 nx_g_solid, pos, ax=ax, width=widths, edge_color='black'; 824 ). /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, connectionstyle, min_source_margin, min_target_margin); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. /usr/local/lib/python3.8/site-packages/networkx/drawing/nx_pylab.py in <listcomp>(.0); 654 ; 655 # set edge positions; --> 656 edge_pos = np.asarray([(pos[e[0]], pos[e[1]]) for e in edgelist]); 657 ; 658 # Check if edge_color is an array of floats and map to edge_cmap. KeyError: 5; ```. </details>. In this PR:. ![image](https://user-images.githubusercontent.com/8238804/123222118-f5820a80-d512-11eb-97",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1921
https://github.com/scverse/scanpy/pull/1922:76,Deployability,Update,Update,76,"Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests; - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:115,Deployability,Release,Release,115,"Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests; - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/pull/1922:102,Testability,test,tests,102,"Fixes #1859. `igraph` uses python's random state, not numpy's. TODO:. - [x] Update saved examples for tests; - [x] Release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1922
https://github.com/scverse/scanpy/issues/1925:1736,Availability,error,error,1736," adata.var_names.str.startswith('mt'); sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True); adata.var['rp'] = adata.var_names.str.startswith('Rps', 'Rpl'); sc.pp.calculate_qc_metrics(adata, qc_vars=['rp'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the follow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2025,Availability,toler,tolerance,2025,".violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt', 'pct_counts_rp'], groupby = 'Author', jitter=0.4, multi_panel=True). Benitez = adata[adata.obs['Author'].isin(['Benitez'])]; Rajbhandari = adata[adata.obs['Author'].isin(['Rajbhandari'])]; Sun = adata[adata.obs['Author'].isin(['Sun'])]. sc.pl.scatter(Benitez, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Benitez, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Rajbhandari, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:3180,Availability,toler,tolerance,3180,"n3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-3-69925a75d466> in <module>; 1 #calcular e visualizar metricas de QC por estudo; ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), ; 3 percent_top=None, layer=None, use_raw=False, inplace=True,; 4 log1p=False, parallel=None); 5 adata.var['mt'] = adata.var_names.str.startswith('mt'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel); 304 X.eliminate_zeros(); 305 ; --> 306 obs_metrics = describe_obs(; 307 adata,; 308 expr_type=expr_type,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2515,Security,hash,hashtable,2515,"s_mt'); sc.pl.scatter(Rajbhandari, x='total_counts', y='n_genes_by_counts'). sc.pl.scatter(Sun, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-3-69925a75d466> in <module>; 1 #calcular e visualizar metricas de QC por estudo; ----> 2 sc.pp.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/issues/1925:2611,Security,hash,hashtable,2611,"x='total_counts', y='pct_counts_mt'); sc.pl.scatter(Sun, x='total_counts', y='n_genes_by_counts'). ```. And this is the error. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'total_counts'. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/frame.py in _set_item_mgr(self, key, value); 3745 try:; -> 3746 loc = self._info_axis.get_loc(key); 3747 except KeyError:. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 . KeyError: 'total_counts'. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last); <ipython-input-3-69925a75d466> in <module>; 1 #calcular e visualizar metricas de QC por estudo; ----> 2 sc.pp.calculate_qc_metrics(adata, expr_type='counts', var_type='genes', qc_vars=(), ; 3 percent_top=None",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1925
https://github.com/scverse/scanpy/pull/1926:24,Deployability,release,release,24,Getting ready for 1.8.1 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1926
https://github.com/scverse/scanpy/pull/1927:69,Availability,error,erroring,69,Try pinning pynndescent `<=0.5.2` to see if that gets builds to stop erroring.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1927
https://github.com/scverse/scanpy/issues/1929:380,Availability,error,error,380,"- [√] I have checked that this issue has not already been reported.; - [√] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; small bug report:; https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py; line 538 wrong error raised when `use_raw=True`; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is not None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; Second `not` should be removed ,Corrected codes should be; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions; this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:1118,Testability,log,logging,1118,"- [√] I have checked that this issue has not already been reported.; - [√] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; small bug report:; https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py; line 538 wrong error raised when `use_raw=True`; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is not None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; Second `not` should be removed ,Corrected codes should be; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions; this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1929:879,Usability,guid,guide,879,"- [√] I have checked that this issue has not already been reported.; - [√] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; small bug report:; https://github.com/theislab/scanpy/blob/fb9e12f36b5c600913fa6243819d1575906c384e/scanpy/tools/_rank_genes_groups.py; line 538 wrong error raised when `use_raw=True`; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is not None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; Second `not` should be removed ,Corrected codes should be; ```python; if use_raw is None:; use_raw = adata.raw is not None; elif use_raw is True and adata.raw is None:; raise ValueError(""Received `use_raw=True`, but `adata.raw` is empty.""); ```; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. #### Versions; this bug appeard in v1.8.0. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1929
https://github.com/scverse/scanpy/issues/1931:57,Availability,avail,available,57,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:174,Availability,avail,available,174,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:317,Availability,avail,available,317,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:477,Availability,avail,available,477,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:516,Availability,error,errors,516,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:406,Deployability,install,install,406,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:988,Deployability,install,installed,988,"a can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1022,Deployability,install,install,1022,"a can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2529,Deployability,install,installed,2529,"sed https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:861,Integrability,depend,dependency,861,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1113,Integrability,depend,dependencies,1113,"ynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:1241,Integrability,depend,dependency,1241,"ently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to req",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:22,Safety,detect,detect,22,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:498,Safety,detect,detects,498,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:890,Safety,avoid,avoided,890,"Numba can’t correctly detect when a threading backend is available. This was fine in the past, since `pynndescent`/ `umap` were forcing a `workqueue` backend which is always available. `pynndescent` 0.5.3 recently came out, and started favoring the `tbb` backend. This is a problem since numba thinks this backend is available on our CI (and on my HPC), but it’s actually not. I also can’t get tbb to even install in a way numba sees in on these systems. If tbb isn’t actually available, but numba detects it we get errors with horrible tracebacks anytime parallelized numba code is used https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, y",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1931:2177,Usability,simpl,simpler,2177,"sed https://github.com/lmcinnes/pynndescent/issues/129. These tracebacks are so horrible they break our CI further https://github.com/pytest-dev/pytest-nunit/issues/47. So what do we do?. ## Possible solutions:. * Pin pynndescent below 0.5.3. This makes pynndescent a required dependency. We’ve previously avoided this since it would change results for people using `umap<0.4` (e.g. anyone with `scvelo` installed) who did not explicitly install pynndescent. However, given the lack of complaints around umap results changing as dependencies have increased, this may not be so bad. It would be great if we could constrain the version without having it be a dependency. This would be similar to what's possible with `pip` and [constraints files](https://pip.pypa.io/en/stable/user_guide/#constraints-files), I don't see how one would be able to specify this for a package. I don't think it's possible, but maybe I'm missing something about the version string syntax. * Make sure the numba threading layer is `“workqueue”` after pynndescent is imported. This is tricky. pynndescent<0.5.3 takes a long time to import, so we don’t want to do this at the top level. So we would need to add a check after everytiem pynndescent could possibly be imported to check that it didn’t set the threading backend to anything else. My understanding of the numba threading system is that once you’ve called for parallel compilation, you’re locked into the threading backend for that session. * Make sure the threading layer is workqueue after pynndescent is imported, but make pynndescent import fast. A kinda simpler solution would be to require pynndescent 0.5.3, import it at the top level (boosts total import time by about ~0.2 seconds out of 3.3 total), and set the threading layer right there. This also has the advantage of letting users specify the threading layer after import scanpy and not having us interfere. This also requires that pynndescent is installed, which hits the reproducibility issues again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1931
https://github.com/scverse/scanpy/issues/1932:479,Availability,error,error,479,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, I have a list of genes in an excel sheet. I selected few genes of interest and made a text document (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1); ```. ```pytb; TypeError Traceback (most recent call last); <ipython-input-17-15b8850a67a5> in <module>; 1 #New dot plot (12 weeks feature genes); ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 151 # 1. compute fraction of cells having value > expression_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1163,Testability,log,log,1163,"ment (only the name of the genes). I have successfully uploaded them in scanpy to generate a dot plot from this text document, but I am facing this error Please help me with this issue. Thank you in advance. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1); ```. ```pytb; TypeError Traceback (most recent call last); <ipython-input-17-15b8850a67a5> in <module>; 1 #New dot plot (12 weeks feature genes); ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 151 # 1. compute fraction of cells having value > expression_cutoff; 152 # transform obs_tidy into boolean matrix using the expression_cutoff; --> 153 obs_bool = self.obs_tidy > expression_cutoff; 154 ; 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:1708,Testability,log,log,1708," <ipython-input-17-15b8850a67a5> in <module>; 1 #New dot plot (12 weeks feature genes); ----> 2 sc.pl.dotplot(adata, genes, groupby = ""louvain"", figsize = (20, 6), dendrogram = True, use_raw= False, dot_max = 1). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, **kwds); 930 dot_color_df=dot_color_df,; 931 ax=ax,; --> 932 **kwds,; 933 ); 934 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\scanpy\plotting\_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, **kwds); 151 # 1. compute fraction of cells having value > expression_cutoff; 152 # transform obs_tidy into boolean matrix using the expression_cutoff; --> 153 obs_bool = self.obs_tidy > expression_cutoff; 154 ; 155 # compute the sum per group which in the boolean matrix this is the number. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other); 63 other = item_from_zerodim(other); 64 ; ---> 65 return method(self, other); 66 ; 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arraylike.py in __gt__(self, other); 43 @unpack_zerodim_and_defer(""__gt__""); 44 def __gt__(self, other):; ---> 45 return self._cmp_method(other, operator.gt); 46 ; 47 @unpack_zerodim_and_defer(""__ge__""). c:\users\pawandeep\appdata\local\programs\python\p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/issues/1932:4970,Testability,log,logging,4970,"ta); 5970 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\frame.py in _dispatch_frame_op(self, right, func, axis); 6003 if not is_list_like(right):; 6004 # i.e. scalar, faster than checking np.ndim(right) == 0; -> 6005 bm = self._mgr.apply(array_op, right=right); 6006 return type(self)(bm); 6007 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\managers.py in apply(self, f, align_keys, ignore_failures, **kwargs); 423 try:; 424 if callable(f):; --> 425 applied = b.apply(f, **kwargs); 426 else:; 427 applied = getattr(b, f)(**kwargs). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\internals\blocks.py in apply(self, func, **kwargs); 376 """"""; 377 with np.errstate(all=""ignore""):; --> 378 result = func(self.values, **kwargs); 379 ; 380 return self._split_op_result(result). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\array_ops.py in comparison_op(left, right, op); 227 if should_extension_dispatch(lvalues, rvalues):; 228 # Call the method on lvalues; --> 229 res_values = op(lvalues, rvalues); 230 ; 231 elif is_scalar(rvalues) and isna(rvalues):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\ops\common.py in new_method(self, other); 63 other = item_from_zerodim(other); 64 ; ---> 65 return method(self, other); 66 ; 67 return new_method. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\pandas\core\arrays\categorical.py in func(self, other); 75 if opname in [""__lt__"", ""__gt__"", ""__le__"", ""__ge__""]:; 76 raise TypeError(; ---> 77 ""Unordered Categoricals can only compare equality or not""; 78 ); 79 if isinstance(other, Categorical):. TypeError: Unordered Categoricals can only compare equality or not; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1932
https://github.com/scverse/scanpy/pull/1933:34,Modifiability,variab,variable,34,Also move the `MPLBACKEND=agg` to variable definitions. Threading layer docs: https://numba.pydata.org/numba-doc/latest/user/threading-layer.html,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1933
https://github.com/scverse/scanpy/pull/1935:31,Availability,error,error,31,Backport PR #1934: Fix use_raw error with sc.tl.rank_genes_groups,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1935
https://github.com/scverse/scanpy/pull/1937:26,Deployability,release,release,26,Prepping for 1.8.1 bugfix release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1937
https://github.com/scverse/scanpy/issues/1940:367,Energy Efficiency,efficient,efficient,367,"Hi thanks for your excellent work!. I noticed for a subset adata object, say; batch1 = adata[adata.obs[""batch""] == ""batch1"", :]; it will be a view of the original adata; ; For further analysis, if I just wanted to calculate the mean of selected rows (it will give me the mean of all the rows of original data as it is a view),; I was wondering if there is any memory-efficient way to do it instead of using copy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1940
https://github.com/scverse/scanpy/issues/1941:737,Availability,Error,Error,737,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello; This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:; ```; #use this; sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'); ```. Error:. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-16-30381f660d76> in <module>; 1 #use this; ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 659 tl.dendrogram; 660 """"""; --> 661 return _rank_genes_groups_plot(; 662 adata,; 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:292,Testability,test,tested,292,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello; This block seemed to be running fine a few weeks ago. I tested on the same AnnData file. I couldn't find other issue related to this and not sure how to work around it. Code:; ```; #use this; sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'); ```. Error:. ```; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-16-30381f660d76> in <module>; 1 #use this; ----> 2 sc.pl.rank_genes_groups_heatmap(adata, n_genes=200, standard_scale='var', key='rank_genes_groups_filtered', swap_axes=True); 3 sc.pl.correlation_matrix(adata, 'leiden_0.8', figsize=(14,6)); 4 sc.pl.rank_genes_groups_stacked_violin(adata, groupby = 'leiden_0.8', n_genes=2, key='rank_genes_groups_filtered'). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 659 tl.dendrogram; 660 """"""; --> 661 return _rank_genes_groups_plot(; 662 adata,; 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2187,Testability,log,log,2187,"b/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds); 659 tl.dendrogram; 660 """"""; --> 661 return _rank_genes_groups_plot(; 662 adata,; 663 plot_type='heatmap',. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds); 1022 ); 1023 ; -> 1024 categories, obs_tidy = _prepare_dataframe(; 1025 adata,; 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1917 groupby.remove(groupby_index); 1918 keys = list(groupby) + list(np.unique(var_names)); -> 1919 obs_tidy = get.obs_df(; 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 270 alias_index = None; 271 ; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1941:2683,Testability,log,log,2683,"ogoamb/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 578 from .._anndata import heatmap; 579 ; --> 580 return heatmap(; 581 adata,; 582 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds); 1022 ); 1023 ; -> 1024 categories, obs_tidy = _prepare_dataframe(; 1025 adata,; 1026 var_names,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols); 1917 groupby.remove(groupby_index); 1918 keys = list(groupby) + list(np.unique(var_names)); -> 1919 obs_tidy = get.obs_df(; 1920 adata, keys=keys, layer=layer, use_raw=use_raw, gene_symbols=gene_symbols; 1921 ). /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw); 270 alias_index = None; 271 ; --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(; 273 adata.obs,; 274 var.index,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw); 165 not_found.append(key); 166 if len(not_found) > 0:; --> 167 raise KeyError(; 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in""; 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['nan']' in columns of ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1941
https://github.com/scverse/scanpy/issues/1944:1404,Usability,guid,guided,1404,"the sc.pl.dendrogram function doesn't include height, which I wanted to include in the dendrogram I am producing that will inform subsequent modifications. I wanted to use the output from adata.uns[""dendrogram_bulk_labels""][""dendrogram_info""] for subsequent analysis (e.g. keys `""linkage""` and `""ivl""`), but the labels in the `""ivl""` key do not agree with the order of the leaves on the dendrogram. . ```; import numpy as np; import pandas as pd; import scanpy as sc. from scipy.cluster import hierarchy; from scipy.cluster.hierarchy import dendrogram, linkage; import matplotlib.pyplot as plt. # import adata; adata = sc.datasets.pbmc68k_reduced(); sc.pp.normalize_total(adata, target_sum = 1e4); sc.pp.log1p(adata); groupCat = ""bulk_labels""; sc.tl.dendrogram(adata, groupby = groupCat). zLab = ""dendrogram_"" + groupCat; Z = adata.uns[zLab][""linkage""]. ### scanpy dendrogram; sc.pl.dendrogram(adata, groupby = groupCat,; orientation = ""right"",; dendrogram_key = zLab). scanpyIVL =adata.uns[zLab][""dendrogram_info""][""ivl""]. print(scanpyIVL) # output: ['CD14+ Monocyte', 'Dendritic', 'CD19+ B', 'CD34+', 'CD4+/CD45RA+/CD25- Naive T', 'CD8+/CD45RA+ Naive Cytotoxic', 'CD4+/CD25 T Reg', 'CD4+/CD45RO+ Memory', 'CD8+ Cytotoxic T', 'CD56+ NK']. ```. in this case, it's the reverse order of the leaves. for different adata objects I've tried, I get completely shuffled lists.; I tried checking if the order is guided based on the index of 'leaves' and I did not find it to be for the objects ive tried.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1944
https://github.com/scverse/scanpy/issues/1946:53,Availability,error,error,53,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:244,Availability,fault,fault,244,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2813,Availability,Error,Error,2813,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2884,Availability,error,error,2884,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3105,Availability,Error,Error,3105,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3178,Availability,fault,fault,3178,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:3598,Availability,error,error,3598,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:0,Deployability,Update,Update,0,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2567,Deployability,release,release-notes,2567,"oading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2592,Deployability,release,release-notes,2592,"ntory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2617,Deployability,release,release-notes,2617,"cipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2642,Deployability,release,release-notes,2642,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2667,Deployability,release,release-notes,2667,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2692,Deployability,release,release-notes,2692,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2717,Deployability,release,release-notes,2717,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2742,Deployability,release,release-notes,2742,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:2756,Deployability,release,release-latest,2756,"doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.ScanpyConfig.N_PCS'):. Extension error (sphinx.ext.autosummary):; Handler <function process_generate_options at 0x139c4a940> for event 'builder-inited' threw an exception (exception: type object 'ScanpyConfig' has no attribute 'N_PCS'); make: *** [html] Error 2; ```. </details>. However, I'm entirely sure if this is Sphinx's fault, or our own. Currently the [N_PCS parameter isn't in the rendered documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig). I think it should be, and am not sure why it's not showing up here. To summarize:. * Previous versions of our doc builds didn't seem to be including attribute docstrings for `ScanpyConfig`.; * Sphinx 4.1.0 raises an error when it hits this attribute",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:421,Performance,load,loading,421,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:513,Performance,load,loading,513,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:603,Performance,load,loading,603,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:684,Performance,load,loading,684,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:766,Performance,load,loading,766,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:858,Performance,load,loading,858,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:952,Performance,load,loading,952,Update:. Docs don't build with sphinx 4.1.0 due to a error triggered by `scanpydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1051,Performance,load,loading,1051,pydoc`. Sphinx will be pinned until this is solved (which is when this issue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1125,Performance,load,loading,1125,sue should be closed). It's not obvious to me at the moment whether sphinx or scanpydoc is at fault. ---------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1231,Performance,load,loading,1231,------------. Trying to build the docs with Sphinx 4.1.0 fails with the following output:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1315,Performance,load,loading,1315,put:. <details>; <summary> </summary>. ```sh; $ make html; Running Sphinx v4.1.0; loading intersphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1411,Performance,load,loading,1411,"sphinx inventory from https://anndata.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1496,Performance,load,loading,1496,"g intersphinx inventory from https://bbknn.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1573,Performance,load,loading,1573,"nv...; loading intersphinx inventory from https://matplotlib.org/cycler/objects.inv...; loading intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, rele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1667,Performance,load,loading,1667," intersphinx inventory from http://docs.h5py.org/en/stable/objects.inv...; loading intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1745,Performance,load,loading,1745,"g intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1828,Performance,load,loading,1828," loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.rst, tutorials.rst, usage-principles.rst; Error in github_url('scanpy._settings.Scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/issues/1946:1795,Usability,learn,learn,1795,"g intersphinx inventory from https://ipython.readthedocs.io/en/stable/objects.inv...; loading intersphinx inventory from https://leidenalg.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://louvain-igraph.readthedocs.io/en/latest/objects.inv...; loading intersphinx inventory from https://matplotlib.org/objects.inv...; loading intersphinx inventory from https://networkx.github.io/documentation/networkx-1.10/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/numpy/objects.inv...; loading intersphinx inventory from https://pandas.pydata.org/pandas-docs/stable/objects.inv...; loading intersphinx inventory from https://docs.pytest.org/en/latest/objects.inv...; loading intersphinx inventory from https://docs.python.org/3/objects.inv...; loading intersphinx inventory from https://docs.scipy.org/doc/scipy/reference/objects.inv...; loading intersphinx inventory from https://seaborn.pydata.org/objects.inv...; loading intersphinx inventory from https://scikit-learn.org/stable/objects.inv...; loading intersphinx inventory from https://scanpy-tutorials.readthedocs.io/en/latest/objects.inv...; intersphinx inventory has moved: https://networkx.github.io/documentation/networkx-1.10/objects.inv -> https://networkx.org/documentation/networkx-1.10/objects.inv; intersphinx inventory has moved: https://docs.scipy.org/doc/numpy/objects.inv -> https://numpy.org/doc/stable/objects.inv; intersphinx inventory has moved: http://docs.h5py.org/en/stable/objects.inv -> https://docs.h5py.org/en/stable/objects.inv; [autosummary] generating autosummary for: _key_contributors.rst, api.rst, basic_usage.rst, community.rst, contributors.rst, dev/ci.rst, dev/code.rst, dev/documentation.rst, dev/external-tools.rst, dev/getting-set-up.rst, ..., release-notes/1.7.1.rst, release-notes/1.7.2.rst, release-notes/1.8.0.rst, release-notes/1.8.1.rst, release-notes/1.8.2.rst, release-notes/1.9.0.rst, release-notes/index.rst, release-notes/release-latest.r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1946
https://github.com/scverse/scanpy/pull/1947:31,Deployability,release,release,31,Backport PR #1945: Start 1.8.2 release notes file,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1947
https://github.com/scverse/scanpy/issues/1949:724,Testability,log,logging,724,"This might be a bit of a rant, and I'm aware there are some good arguments for the way things are... but I just wasted 4 hours of my life because I wasn't aware of the default `gex_only=True` in `sc.read_10x_h5()`. Just wanted to flag that if scanpy support for multimodality becomes a thing, then this default may need to change to prevent frustration. I think moving read/write functionality to AnnData was already discussed at some point. For multimodal support, this might become more important again. If this is moved, then `read_10x_h5` should probably not default to `gex_only=True` anymore. Would it already be worth either making `gex_only` a required input? For backward compatability it could also just trigger a logging warning for now. I do think that this is quite an important thing to let people know with more and more 10X Multiome data being generated now (and CITE-seq for that matter).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1949
https://github.com/scverse/scanpy/pull/1950:71,Usability,guid,guidelines,71,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/pull/1950:102,Usability,guid,guide,102,<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1950
https://github.com/scverse/scanpy/issues/1951:47,Availability,error,error,47,"Now if I intend to run ingest, I will get this error:; running ingest; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 486 # If key already exists, we will overwrite the file; --> 487 data_name = overloads[key]; 488 except KeyError:. KeyError: ((array(int32, 1d, C), array(int32, 1d, C), array(float32, 1d, C), array(float32, 2d, C), type(CPUDispatcher(<function squared_euclidean at 0x7fdefdb13830>)), array(int64, 1d, C), float64), ('x86_64-unknown-linux-gnu', 'broadwell', '+64bit,+adx,+aes,+avx,+avx2,-avx512bf16,-avx512bitalg,-avx512bw,-avx512cd,-avx512dq,-avx512er,-avx512f,-avx512ifma,-avx512pf,-avx512vbmi,-avx512vbmi2,-avx512vl,-avx512vnni,-avx512vpopcntdq,+bmi,+bmi2,-cldemote,-clflushopt,-clwb,-clzero,+cmov,+cx16,+cx8,-enqcmd,+f16c,+fma,-fma4,+fsgsbase,+fxsr,-gfni,+invpcid,-lwp,+lzcnt,+mmx,+movbe,-movdir64b,-movdiri,-mwaitx,+pclmul,-pconfig,-pku,+popcnt,-prefetchwt1,+prfchw,-ptwrite,-rdpid,+rdrnd,+rdseed,+rtm,+sahf,-sgx,-sha,-shstk,+sse,+sse2,+sse3,+sse4.1,+sse4.2,-sse4a,+ssse3,-tbm,-vaes,-vpclmulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); 13 frames; <ipython-input-22-9176945aef7f> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 131 ; 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:3164,Availability,error,errors,3164,"dx.query(test, k, epsilon); 472 ; 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1061 self._distance_func,; 1062 self.rng_state,; -> 1063 self.diversify_prob,; 1064 ); 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4170,Energy Efficiency,reduce,reduce,4170,"types.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4772,Integrability,protocol,protocol,4772,"types.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:4934,Integrability,protocol,protocol,4934,"types.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with self._guard_against_spurious_io_errors():; --> 671 self._save_overload(sig, data); 672 ; 673 def _save_overload(self, sig, data):. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_overload(self, sig, data); 679 key = self._index_key(sig, _get_codegen(data)); 680 data = self._impl.reduce(data); --> 681 self._cache_file.save(key, data); 682 ; 683 @contextlib.contextmanager. /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save(self, key, data); 494 break; 495 overloads[key] = data_name; --> 496 self._save_index(overloads); 497 self._save_data(data_name, data); 498 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _save_index(self, overloads); 540 def _save_index(self, overloads):; 541 data = self._source_stamp, overloads; --> 542 data = self._dump(data); 543 with self._open_for_write(self._index_path) as f:; 544 pickle.dump(self._version, f, protocol=-1). /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in _dump(self, obj); 568 ; 569 def _dump(self, obj):; --> 570 return pickle.dumps(obj, protocol=-1); 571 ; 572 @contextlib.contextmanager. TypeError: can't pickle weakref objects. How to solve this problem? Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2849,Modifiability,config,config,2849,"obs):; 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state); 469 self._nnd_idx.search_rng_state = rng_state; 470 ; --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 472 ; 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1061 self._distance_func,; 1062 self.rng_state,; -> 1063 self.diversify_prob,; 1064 ); 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.ForceLiteralArg as e:; 369 # Received request for compiler re-entry with the list of arguments. /usr/local/lib/python3.7/dist-packages/numba/core/compiler_lock.py in _acquire_compile_lock(*args, **kwargs); 30 def _acquire_compile_lock(*args, **kwargs):; 31 with self:; ---> 32 return func(*args, **kwargs); 33 return _acquire_compile_lock; 34 . /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in compile(self, sig); 823 raise e.bind_fold_arguments(folded); 824 self.add_overload(cres); --> 825 self._cache.save_overload(sig, cres); 826 return cres.entry_point; 827 . /usr/local/lib/python3.7/dist-packages/numba/core/caching.py in save_overload(self, sig, data); 669 """"""; 670 with se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1951:2158,Testability,test,test,2158,"ulqdq,-waitpkg,-wbnoinvd,-xop,+xsave,-xsavec,+xsaveopt,-xsaves'), ('308c49885ad3c35a475c360e21af1359caa88c78eb495fa0f5e8c6676ae5019e', 'e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855')). During handling of the above exception, another exception occurred:. TypeError Traceback (most recent call last); 13 frames; <ipython-input-22-9176945aef7f> in <module>(); ----> 1 sc.tl.ingest(adata, adata_ref, obs='louvain') #ingest. /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 131 ; 132 if obs is not None:; --> 133 ing.neighbors(**kwargs); 134 for i, col in enumerate(obs):; 135 ing.map_labels(col, labeling_method[i]). /usr/local/lib/python3.7/dist-packages/scanpy/tools/_ingest.py in neighbors(self, k, queue_size, epsilon, random_state); 469 self._nnd_idx.search_rng_state = rng_state; 470 ; --> 471 self._indices, self._distances = self._nnd_idx.query(test, k, epsilon); 472 ; 473 else:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in query(self, query_data, k, epsilon); 1564 """"""; 1565 if not hasattr(self, ""_search_graph""):; -> 1566 self._init_search_graph(); 1567 ; 1568 if not self._is_sparse:. /usr/local/lib/python3.7/dist-packages/pynndescent/pynndescent_.py in _init_search_graph(self); 1061 self._distance_func,; 1062 self.rng_state,; -> 1063 self.diversify_prob,; 1064 ); 1065 reverse_graph.eliminate_zeros(). /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 432 e.patch_message('\n'.join((str(e).rstrip(), help_msg))); 433 # ignore the FULL_TRACEBACKS config, this needs reporting!; --> 434 raise e; 435 ; 436 def inspect_llvm(self, signature=None):. /usr/local/lib/python3.7/dist-packages/numba/core/dispatcher.py in _compile_for_args(self, *args, **kws); 365 argtypes.append(self.typeof_pyval(a)); 366 try:; --> 367 return self.compile(tuple(argtypes)); 368 except errors.Fo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1951
https://github.com/scverse/scanpy/issues/1955:538,Deployability,integrat,integrate,538,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:674,Deployability,integrat,integrated,674,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:538,Integrability,integrat,integrate,538,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:674,Integrability,integrat,integrated,674,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:409,Security,access,accessible,409,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1955:109,Usability,simpl,simple,109,"- [x] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [x] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. I'd really like a smarter d/e method to be accessible easily from Scanpy, one that allows proper treatment of covariates etc. MAST is obviously very popular, but fiddly to integrate from R. I see diffxpy mentioned about the place here, and see it's an in-house tool of yours. Is there a reason it's not been integrated already? If nobody's working on it, shall I take a crack at it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1955
https://github.com/scverse/scanpy/issues/1956:471,Safety,avoid,avoid,471,"I was wondering whether it is possible to plot this split dotplot (in this case, half of a dot represents mRNA levels while the other half about protein)?; ![image](https://user-images.githubusercontent.com/4110443/126654762-9de9bb40-ade5-4131-b6d3-410e36b5f986.png); This is useful in two places: 1. when we are visualizing mRNA and protein levels of a same group of genes 2. when we are comparing two conditions (control PBMC vs stimulated PBMC etc.). Because it would avoid duplicating the gene/cell type names and save half the space compared to this one:; ![image](https://user-images.githubusercontent.com/4110443/126655187-3aaf5c3d-3122-47a3-9864-48eb5ea47142.png). Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1956
https://github.com/scverse/scanpy/issues/1957:359,Integrability,wrap,wrapper,359,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python; import scanpy; adata = scanpy.datasets.pbmc3k(); scanpy.external.pp.scrublet(adata); ```; and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:; ```python; adata_obs.layers['raw'] = adata_obs.X; print(adata_obs.layers['raw']); pp.normalize_total(adata_obs) <--- currently normalizes all layers and X; print(adata_obs.layers['raw']); ```; ---; ### Impact; The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:830,Modifiability,layers,layers,830,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python; import scanpy; adata = scanpy.datasets.pbmc3k(); scanpy.external.pp.scrublet(adata); ```; and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:; ```python; adata_obs.layers['raw'] = adata_obs.X; print(adata_obs.layers['raw']); pp.normalize_total(adata_obs) <--- currently normalizes all layers and X; print(adata_obs.layers['raw']); ```; ---; ### Impact; The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:875,Modifiability,layers,layers,875,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python; import scanpy; adata = scanpy.datasets.pbmc3k(); scanpy.external.pp.scrublet(adata); ```; and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:; ```python; adata_obs.layers['raw'] = adata_obs.X; print(adata_obs.layers['raw']); pp.normalize_total(adata_obs) <--- currently normalizes all layers and X; print(adata_obs.layers['raw']); ```; ---; ### Impact; The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:951,Modifiability,layers,layers,951,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python; import scanpy; adata = scanpy.datasets.pbmc3k(); scanpy.external.pp.scrublet(adata); ```; and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:; ```python; adata_obs.layers['raw'] = adata_obs.X; print(adata_obs.layers['raw']); pp.normalize_total(adata_obs) <--- currently normalizes all layers and X; print(adata_obs.layers['raw']); ```; ---; ### Impact; The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1957:981,Modifiability,layers,layers,981,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, according to the documentation, the simulation of doublets with scrublet works best with un-normalized counts. The current wrapper implementation however uses a layer to hold the raw data, which then gets normalized anyway. . Please have in mind, that this is the first issue I have ever opened. If I made any grievous mistakes please inform me of such. . ---. ### Minimal code sample:. ```python; import scanpy; adata = scanpy.datasets.pbmc3k(); scanpy.external.pp.scrublet(adata); ```; and around line 177 in scanpy.external.pp.scrublet we need to 'observe' the values:; ```python; adata_obs.layers['raw'] = adata_obs.X; print(adata_obs.layers['raw']); pp.normalize_total(adata_obs) <--- currently normalizes all layers and X; print(adata_obs.layers['raw']); ```; ---; ### Impact; The 'raw' layer is later used in line 194 of scanpy.external.pp.scrublet to simulate doublets, however, it doesn't contain raw data anymore. ```python; adata_sim = scrublet_simulate_doublets(; adata_obs,; layer='raw',; sim_doublet_ratio=sim_doublet_ratio,; synthetic_doublet_umi_subsampling=synthetic_doublet_umi_subsampling,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1957
https://github.com/scverse/scanpy/issues/1959:53,Deployability,update,update,53,"Discovered in #1950. It looks like a recent networkx update generates slightly different plots, which breaks CI. The changes don't look particularly important to me. Here's the differences for a umap showing edges:. ![image](https://user-images.githubusercontent.com/8238804/127100302-a988dae5-385f-4e62-9edb-c97b6360247c.png); ![image](https://user-images.githubusercontent.com/8238804/127100323-1aa151aa-53c7-464f-908b-079c01e569bf.png). Diff:. ![image](https://user-images.githubusercontent.com/8238804/127100348-c662d8d0-4338-42b4-91f1-3e0550802b1c.png). Similar thing for PAGA:. ![image](https://user-images.githubusercontent.com/8238804/127100426-5fdcaf2b-132d-4b3f-9ed7-d69256c5135a.png). It looks like the coordinates are shifted. It would be nice to know if this meant you couldn't ""overlay"" images when using this, or if it's just shifting the window and the Axis' reference coordinates stay intact. If that isn't an issue, just updating the reference images would be fine. Possibly related to these changes in networkx: https://github.com/networkx/networkx/issues/4806",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1959
https://github.com/scverse/scanpy/pull/1960:13,Deployability,Update,Updates,13,Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:111,Testability,test,tests,111,Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1960:167,Testability,test,tests,167,Fixes #1959. Updates plots to work with how edge plotting is handled in networkx>2.6. Also moves paga plotting tests to (i) their own module (ii) their own individual tests (so we don't just see the first one that fails).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1960
https://github.com/scverse/scanpy/pull/1961:32,Testability,test,tests,32,Backport PR #1960: Fix plotting tests for networkx >= 2.6.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1961
https://github.com/scverse/scanpy/issues/1963:931,Deployability,continuous,continuous,931,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',; 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']; adata = sc.AnnData(embedding); adata.obs[""category""] = label.astype(np.int); adata.obs[""domain""] = batch.astype(np.int); sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10); adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]); adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]); sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],; show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1963:212,Energy Efficiency,green,green,212,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; colors_use = ['red', 'blue', 'green', 'purple', 'yellow', 'brown', 'black', 'peru', 'orange', 'olive',; 'darksage', 'cyan', 'lime', 'pink', 'teal', 'violet', 'darkblue', 'magenta', 'coral', 'gray']; adata = sc.AnnData(embedding); adata.obs[""category""] = label.astype(np.int); adata.obs[""domain""] = batch.astype(np.int); sc.tl.tsne(adata, use_rep = 'X', n_jobs = 10); adata.uns[""category_colors""] = list(colors_use[:len(np.unique(label))]); adata.uns[""domain_colors""] = list(colors_use[:len(np.unique(batch))]); sc.pl.tsne(adata, color = [""category"", ""domain""], title = [""class"", ""domain""],; show = False, size = 50000 / len(label), save = ""/{}.pdf"".format(file)). My scanpy version is 1.4.6, but when I run the above codes, I find that the color is continuous, why cannot set my specific color?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1963
https://github.com/scverse/scanpy/issues/1967:610,Availability,error,error,610,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1967:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. The *Edit on GitHub* button on the docs page for `scanpy.read_csv` [here](https://scanpy.readthedocs.io/en/stable/generated/scanpy.read_csv.html) forwards to a non-existing web page causing a 404 error. The same problem exists for `scanpy.read_h5ad`, `scanpy.read_excel` and `scanpy.read_hdf`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1967
https://github.com/scverse/scanpy/issues/1968:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ## Description. ATM, the argument `delimiter` in `scvelo.readwrite.py::read` is not passed to `read_csv`. For more flexibility when reading from CSV files, it would be good to do so.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1968
https://github.com/scverse/scanpy/issues/1971:289,Availability,error,error,289,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1130,Availability,error,error,1130,"ve confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1573,Availability,error,error,1573,"ew weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'); pairs_set = list(set(pairs)); s = sorted(pairs_set); half = int((len(s)/2)); list1 = s[:half]; list2 = s[half:]; lz_cluster_method = list(zip(list1, list2)). cat = pd.DataFrame(); for i in lz_cluster_method:; sc.tl.rank_genes_groups(adata, 'pairs_'+cluster_method, groups=[str([i[1]])], reference=str(i[0]), use_raw=True, n_genes=n_genes, method=method); result = adata.u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:6021,Deployability,update,updated,6021,"ast NA; genericpath NA; google NA; gprofiler 1.0.0; h5py 3.3.0; idna 3.1; igraph 0.9.6; imagecodecs 2021.6.8; imageio 2.9.0; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; networkx 2.5; ntpath NA; numba 0.53.1; numexpr 2.7.3; numpy 1.21.1; opcode NA; openpyxl 3.0.7; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pooch v1.4.0; posixpath NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydoc_data NA; pyexpat NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; requests 2.26.0; scanpy 1.8.1; scipy 1.7.0; seaborn 0.11.1; sinfo 0.3.1; sip NA; six 1.16.0; skimage 0.18.2; sklearn 0.24.2; socks 1.7.1; soupsieve 2.0.1; sphinxcontrib NA; spyder 5.0.5; spyder_kernels 2.0.5; spydercustomize NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tensorboard 2.5.0; tensorflow 2.5.0; termcolor 1.1.0; texttable 1.6.4; tifffile 2021.7.2; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.61.2; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.6; wcwidth 0.2.5; wrapt 1.12.1; wurlitzer 2.1.0; xlsxwriter 1.4.4; yaml 5.4.1; zmq 22.1.0; -----; IPython 7.25.0; jupyter_client 6.1.12; jupyter_core 4.7.1; -----; Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]; Linux-5.4.0-72-generic-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-07-29 21:02; </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5685,Integrability,wrap,wrapt,5685,"ast NA; genericpath NA; google NA; gprofiler 1.0.0; h5py 3.3.0; idna 3.1; igraph 0.9.6; imagecodecs 2021.6.8; imageio 2.9.0; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; networkx 2.5; ntpath NA; numba 0.53.1; numexpr 2.7.3; numpy 1.21.1; opcode NA; openpyxl 3.0.7; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pooch v1.4.0; posixpath NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydoc_data NA; pyexpat NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; requests 2.26.0; scanpy 1.8.1; scipy 1.7.0; seaborn 0.11.1; sinfo 0.3.1; sip NA; six 1.16.0; skimage 0.18.2; sklearn 0.24.2; socks 1.7.1; soupsieve 2.0.1; sphinxcontrib NA; spyder 5.0.5; spyder_kernels 2.0.5; spydercustomize NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tensorboard 2.5.0; tensorflow 2.5.0; termcolor 1.1.0; texttable 1.6.4; tifffile 2021.7.2; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.61.2; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.6; wcwidth 0.2.5; wrapt 1.12.1; wurlitzer 2.1.0; xlsxwriter 1.4.4; yaml 5.4.1; zmq 22.1.0; -----; IPython 7.25.0; jupyter_client 6.1.12; jupyter_core 4.7.1; -----; Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]; Linux-5.4.0-72-generic-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-07-29 21:02; </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1263,Modifiability,variab,variable,1263,"rror with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+cluster_method]=adata.obs['pairs_'+cluster_method].astype('category'); pairs_set = list(set(pairs)); s = sorted(pairs_set); half = int((len(s)/2)); list1 = s[:half]; list2 = s[half:]; lz_cluster_method = list(zip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:4160,Performance,concurren,concurrent,4160,"nes, method=method). File ""/home/smith/anaconda3/envs/scanpy18/lib/python3.9/site-packages/scanpy/tools/_rank_genes_groups.py"", line 574, in rank_genes_groups; raise ValueError(. ValueError: reference = (0, 0) needs to be one of groupby = [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 14), (0, 15), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15)].; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; 2f7ece400a652629565c523b34ee61b04afa385c NA; ACWS_filterCells NA; PIL 8.3.1; PyQt5 NA; absl NA; anndata 0.7.6; appdirs 1.4.4; astunparse 1.6.3; autoreload NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; charset_normalizer 2.0.0; cloudpickle 1.6.0; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.0; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; encodings NA; et_xmlfile 1.0.1; flatbuffers NA; fsspec 2021.07.0; gast NA; genericpath NA; google NA; gprofiler 1.0.0; h5py 3.3.0; idna 3.1; igraph 0.9.6; imagecodecs 2021.6.8; imageio 2.9.0; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; networkx 2.5; ntpath NA; numba 0.53.1; numexpr 2.7.3; numpy 1.21.1; opcode NA; openpyxl 3.0.7; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pooch v1.4.0; posixpath NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydoc_data NA; pyexpat NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; requests 2.26.0; scanpy 1.8.1; scipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:5967,Testability,log,logical,5967,"ast NA; genericpath NA; google NA; gprofiler 1.0.0; h5py 3.3.0; idna 3.1; igraph 0.9.6; imagecodecs 2021.6.8; imageio 2.9.0; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.17.2; joblib 1.0.1; keras_preprocessing 1.1.2; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; networkx 2.5; ntpath NA; numba 0.53.1; numexpr 2.7.3; numpy 1.21.1; opcode NA; openpyxl 3.0.7; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.0; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; pooch v1.4.0; posixpath NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydoc_data NA; pyexpat NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; requests 2.26.0; scanpy 1.8.1; scipy 1.7.0; seaborn 0.11.1; sinfo 0.3.1; sip NA; six 1.16.0; skimage 0.18.2; sklearn 0.24.2; socks 1.7.1; soupsieve 2.0.1; sphinxcontrib NA; spyder 5.0.5; spyder_kernels 2.0.5; spydercustomize NA; sre_compile NA; sre_constants NA; sre_parse NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tensorboard 2.5.0; tensorflow 2.5.0; termcolor 1.1.0; texttable 1.6.4; tifffile 2021.7.2; tlz 0.11.0; toolz 0.11.1; tornado 6.1; tqdm 4.61.2; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; urllib3 1.26.6; wcwidth 0.2.5; wrapt 1.12.1; wurlitzer 2.1.0; xlsxwriter 1.4.4; yaml 5.4.1; zmq 22.1.0; -----; IPython 7.25.0; jupyter_client 6.1.12; jupyter_core 4.7.1; -----; Python 3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:39:48) [GCC 9.3.0]; Linux-5.4.0-72-generic-x86_64-with-glibc2.27; 40 logical CPU cores, x86_64; -----; Session information updated at 2021-07-29 21:02; </details>. PS - As a side note, another issue that pandas 1.3 introduced is that adata.write() no longer works unless I manually convert every column in adata.obs back to its original data type (e.g. adata.obs['leiden']=adata.obs['leiden'].astype('int')), because I get a TypeError from h5py until I do that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:774,Usability,simpl,simple,774,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1971:1003,Usability,simpl,simple,1003,"ve confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Since updating to scanpy 1.8 and pandas 1.3 I am getting an error with sc.tl.rank_genes_groups that my reference needs to be one of groupby=[cats], but as you can see in the traceback below, it appears identical. It has something to do with the data types, I've been dealing with this for a few weeks now and on some data sets I am eventually able to figure it out and get it to run, on some I am not. I think this is more of a pandas issue than scanpy, so I am wondering what version of pandas you recommend for anndata 0.7.6? Or if you know a simple workaround to make sure that the datatypes match? This has been a massive headache. I use this list(zip()) syntax in my code frequently, have never had an issue with datatypes inside of a zipped object... so this may be a simple pythonic question, but if there is a different method of accomplishing the same thing thing that doesn't introduce this error I would be happy to hear that as well. In the example below, in my adata.obs I have a column 'condition' that is a categorical variable of biological condition for differential expression, and so all cells belong to either group 0 or 1. I have tried seemingly every combination of having these, and the leiden clusters column be integers, strings, objects, before converting to the categorical dtype in line 7 below, always get the same error, and the reference = item always appears identical to the first item in the groupby = list. ### Minimal code sample (that we can copy&paste without having any data). ```python; cluster_method='leiden'; n_genes=1000; g1n='Control'; adata.obs['condition']=adata.obs['condition'].astype('category'); adata.obs[cluster_method]=adata.obs[cluster_method].astype('category'); pairs = list(zip(adata.obs['condition'], adata.obs[cluster_method])); adata.obs['pairs_'+cluster_method]=pairs; adata.obs['pairs_'+c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1971
https://github.com/scverse/scanpy/issues/1975:2404,Usability,learn,learn,2404,"c.obs['cell_types'] = pbmc.obs['phase']; pbmc.obs['cell_types'].cat.categories = new_cluster_names; sc.pl.umap(pbmc, color=['cell_types']). pbmc.rename_categories('phase', new_cluster_names); sc.pl.umap(pbmc, color=['phase']). ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-82-890b788bf078> in <module>; ----> 1 sc.pl.umap(pbmc, color=['phase']). ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 255 color_source_vector,; 256 palette=palette,; --> 257 na_color=na_color,; 258 ); 259 . ~/miniconda3/envs/single_cell_181/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in _color_vector(adata, values_key, values, palette, na_color); 1275 # Set color to 'missing color' for all missing values; 1276 if color_vector.isna().any():; -> 1277 color_vector = color_vector.add_categories([to_hex(na_color)]); 1278 color_vector = color_vector.fillna(to_hex(na_color)); 1279 return color_vector, True. AttributeError: 'Float64Index' object has no attribute 'add_categories'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.3.1 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.6 pynndescent==0.5.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1975
https://github.com/scverse/scanpy/issues/1976:348,Availability,error,error,348,"I wonder for datasets whose umap results looking like this:; ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1976:207,Safety,predict,predict,207,"I wonder for datasets whose umap results looking like this:; ![image](https://user-images.githubusercontent.com/43333475/128300875-6cb34999-500b-4b5b-8ecb-4a6a0e018247.png). Can the tool, Ingest, be used to predict the cell type label for datasets with batch effect? Since in this dataset, it seems that I will face ""ValueError: 0 is not in index"" error. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1976
https://github.com/scverse/scanpy/issues/1977:137,Availability,error,errors,137,"I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory.; Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1977:62,Performance,perform,perform,62,"I have a dataset with around 400K observations -- I wanted to perform batch correction using sc.pp.combat, but I'm getting out of memory errors after running for a couple hours with > 2 TB of memory. My understanding was that combat used a dense matrix, which requires a lot of memory.; Why is this? Are there suggestions for workarounds here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1977
https://github.com/scverse/scanpy/issues/1978:48,Availability,error,error,48,"Hey!. I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```; import pandas as pd; #pd.set_option(""display.max_columns"", None); import numpy as np; import anndata; import scanpy as sc. %store -r df. adata = anndata.AnnData(df); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata); sc.pl.paga(adata, plot=False); sc.tl.umap(adata, init_pos='paga'); ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```; AttributeError Traceback (most recent call last); <ipython-input-7-7cfb2fb3103e> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'); 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 141 import umap; 142 ; --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):; 144 ; 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'; ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:528,Availability,error,error,528,"Hey!. I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```; import pandas as pd; #pd.set_option(""display.max_columns"", None); import numpy as np; import anndata; import scanpy as sc. %store -r df. adata = anndata.AnnData(df); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata); sc.pl.paga(adata, plot=False); sc.tl.umap(adata, init_pos='paga'); ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```; AttributeError Traceback (most recent call last); <ipython-input-7-7cfb2fb3103e> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'); 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 141 import umap; 142 ; --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):; 144 ; 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'; ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1978:1234,Integrability,depend,dependency,1234,"Hey!. I hope you are doing well. I run into the error AttributeError: module 'umap' has no attribute '__version__' when running this code:. ```; import pandas as pd; #pd.set_option(""display.max_columns"", None); import numpy as np; import anndata; import scanpy as sc. %store -r df. adata = anndata.AnnData(df); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); sc.tl.paga(adata); sc.pl.paga(adata, plot=False); sc.tl.umap(adata, init_pos='paga'); ```. I am using Python 3.8 on Jupyter Notebooks on Mac M1. Please find below the error in a more detailed fashion:. ```; AttributeError Traceback (most recent call last); <ipython-input-7-7cfb2fb3103e> in <module>; ----> 1 sc.tl.umap(adata, init_pos='paga'); 2 sc.pl.umap(adata). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 141 import umap; 142 ; --> 143 if version.parse(umap.__version__) >= version.parse(""0.5.0""):; 144 ; 145 def simplicial_set_embedding(*args, **kwargs):. AttributeError: module 'umap' has no attribute '__version__'; ```. Would you have any idea on how to solve this? I think it is a package dependency problem. Thank you in advance for your help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1978
https://github.com/scverse/scanpy/issues/1980:1372,Testability,log,logging,1372,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import os; import sys. data = sc.read(""data_bbknn_umap.h5ad""); sc.tl.louvain(data,resolution=res); ```. ```pytb; Traceback (most recent call last):; File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>; sc.tl.louvain(dat_merge,resolution=res); File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain; g = _utils.get_igraph_from_adjacency(adjacency, directed=directed); File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency; g.es['weight'] = weights; SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1980:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import os; import sys. data = sc.read(""data_bbknn_umap.h5ad""); sc.tl.louvain(data,resolution=res); ```. ```pytb; Traceback (most recent call last):; File ""/home/scanpy/12.bbknn0814-4/bbknn2.py"", line 27, in <module>; sc.tl.louvain(dat_merge,resolution=res); File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/tools/_louvain.py"", line 132, in louvain; g = _utils.get_igraph_from_adjacency(adjacency, directed=directed); File ""/home/scanpy/miniconda3/envs/SC2/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 219, in get_igraph_from_adjacency; g.es['weight'] = weights; SystemError: /home/conda/feedstock_root/build_artifacts/python-split_1625973859697/work/Objects/listobject.c:138: bad argument to internal function. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1980
https://github.com/scverse/scanpy/issues/1981:982,Availability,error,error,982,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up?. **(1) when I do:** ; sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,; save = '_test2.png'; ). I get an AttributeError: 'str' object has no attribute 'mkdir'; ; **(2) when I do:**; sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,; save = '_test2.png'; ); then nothing happens there is no error and the directory doesn't actually change. ```python; sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,; save = '_test2.png'; ). ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-fd106b753fe2> in <module>; ----> 1 sc.pl.umap(Tgd,; 2 save = '_test2.png'; 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3497,Availability,down,downgrade,3497,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3476,Deployability,install,installs,3476,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3613,Deployability,install,install,3613," ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5721,Deployability,update,updated,5721,"joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.18.5; packaging 21.0; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.9.0; pylab NA; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; requests_cache 0.6.4; scipy 1.6.2; seaborn 0.11.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; soupsieve 2.2.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; url_normalize 1.4.3; urllib3 1.26.6; wcwidth 0.2.5; webencodings 0.5.1; wrapt 1.12.1; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.4.0; -----; Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-08-16 12:24",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3558,Integrability,message,message,3558,"savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5417,Integrability,wrap,wrapt,5417,"joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.18.5; packaging 21.0; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.9.0; pylab NA; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; requests_cache 0.6.4; scipy 1.6.2; seaborn 0.11.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; soupsieve 2.2.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; url_normalize 1.4.3; urllib3 1.26.6; wcwidth 0.2.5; webencodings 0.5.1; wrapt 1.12.1; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.4.0; -----; Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-08-16 12:24",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3944,Performance,bottleneck,bottleneck,3944,"canpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.18.5; packaging 21.0; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.9.0; pylab NA; pynndescent",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3457,Safety,avoid,avoid,3457,"; 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3154,Testability,log,logging,3154,", save, ax, return_fig, **kwargs); 447 return fig; 448 axs = axs if grid else ax; --> 449 _utils.savefig_or_show(basis, show=show, save=save); 450 if show is False:; 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save); 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:5669,Testability,log,logical,5669,"joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; colorlog NA; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.07.2; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; docutils 0.17.1; easydev 0.11.1; fsspec 2021.07.0; gseapy 0.10.5; h5py 2.10.0; html5lib 1.1; idna 2.10; igraph 0.9.4; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.6.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; louvain 0.7.0; lxml 4.6.3; markupsafe 2.0.1; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.53.1; numexpr 2.7.3; numpy 1.18.5; packaging 21.0; pandas 1.1.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.9.0; pylab NA; pynndescent 0.5.2; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; requests_cache 0.6.4; scipy 1.6.2; seaborn 0.11.1; send2trash NA; six 1.16.0; sklearn 0.24.2; sniffio 1.2.0; socks 1.7.1; soupsieve 2.2.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.3; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; url_normalize 1.4.3; urllib3 1.26.6; wcwidth 0.2.5; webencodings 0.5.1; wrapt 1.12.1; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.4.0; -----; Python 3.8.11 (default, Aug 3 2021, 05:10:14) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-08-16 12:24",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:259,Usability,guid,guide,259,"- [ x] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). This code worked fine a couple of days ago but now it's not working at all not sure what happened. Figure is still produced just save path is all messed up?. **(1) when I do:** ; sc._settings.ScanpyConfig.figdir = 'path/folder/' . sc.pl.umap(anndata,; save = '_test2.png'; ). I get an AttributeError: 'str' object has no attribute 'mkdir'; ; **(2) when I do:**; sc._settings.ScanpyConfig(figdir = 'path/folder/'). sc.pl.umap(anndata,; save = '_test2.png'; ); then nothing happens there is no error and the directory doesn't actually change. ```python; sc._settings.ScanpyConfig.figdir = 'Volumes/G_DRIVE_mobile/Lynch_Lab_Data_Drive/BroadCRC_AUG2020/Tcell_my_clustering_aug14_2021/'. sc.pl.umap(Tgd,; save = '_test2.png'; ). ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-11-fd106b753fe2> in <module>; ----> 1 sc.pl.umap(Tgd,; 2 save = '_test2.png'; 3 ). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1981:3036,Usability,learn,learn,3036,"gend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 447 return fig; 448 axs = axs if grid else ax; --> 449 _utils.savefig_or_show(basis, show=show, save=save); 450 if show is False:; 451 return axs. ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig_or_show(writekey, show, dpi, ext, save); 310 show = settings.autoshow if show is None else show; 311 if save:; --> 312 savefig(writekey, dpi=dpi, ext=ext); 313 if show:; 314 pl.show(). ~/opt/anaconda3/lib/python3.8/site-packages/scanpy/plotting/_utils.py in savefig(writekey, dpi, ext); 280 else:; 281 dpi = rcParams['savefig.dpi']; --> 282 settings.figdir.mkdir(parents=True, exist_ok=True); 283 if ext is None:; 284 ext = settings.file_format_figs. AttributeError: 'str' object has no attribute 'mkdir'; ```. #### Versions. scanpy==1.8.1 anndata==0.7.6 umap==0.5.1 numpy==1.18.5 scipy==1.6.2 pandas==1.1.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.4 louvain==0.7.0 pynndescent==0.5.2. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; anyio NA; appdirs 1.4.4; appnope 0.1.2; attr 21.2.0; babel 2.9.1; backcall 0.2.0; bioservices 1.7.12; bottleneck 1.3.2; brotli NA; bs4 4.9.3; certifi 2021.05.30; cffi 1.14.6; chardet 4.0.0; clou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1981
https://github.com/scverse/scanpy/issues/1982:248,Availability,error,error,248,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:352,Availability,error,error,352,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:470,Availability,error,error,470,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:1098,Availability,error,error,1098," scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3042,Availability,error,error,3042,"_objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs); --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs); 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:3962,Availability,error,error,3962,"r: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:4053,Availability,error,error,4053,"name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_dataframe(f, key, df, dataset_kwargs); 262 for col_name, (_, series) in zip(col_names, df.items()):; --> 263 write_series(group, col_name, series, dataset_kwargs=dataset_kwargs); 264 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); <ipython-input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5875,Availability,error,error,5875,"ute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5997,Availability,error,error,5997,"s); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6088,Availability,error,error,6088,"tribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6179,Availability,error,error,6179,"n3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8183,Deployability,update,updated,8183,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; rpy2 3.4.5; samalg 0.8.6; scipy 1.6.2; seaborn 0.11.1; send2trash NA; six 1.15.0; sklearn 0.24.1; skmisc 0.1.4; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.9.4; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; tzlocal NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.3.0; -----; Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-08-16 12:25; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2031,Integrability,wrap,wrapper,2031,"te_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs); --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs); 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:2087,Integrability,wrap,wrapper,2087,"s the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/_objects.pyx in h5py._objects.with_phil.wrapper(). h5py/h5o.pyx in h5py.h5o.link(). RuntimeError: Unable to create link (name already exists). The above exception was the direct cause of the following exception:. RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_series(group, key, series, dataset_kwargs); 283 write_array(group, category_key, categories, dataset_kwargs=dataset_kwargs); --> 284 write_array(group, key, codes, dataset_kwargs=dataset_kwargs); 285 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <cla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:5223,Integrability,wrap,wrapper,5223,"input-21-ded14f7730cd> in <module>; 8 zf_48.var.index = zf_48.var[""gene_name""]; 9 ; ---> 10 zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense); 1903 filename = self.filename; 1904 ; -> 1905 _write_h5ad(; 1906 Path(filename),; 1907 self,. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs); 110 write_attribute(f, ""raw"", adata.raw, dataset_kwargs=dataset_kwargs); 111 write_attribute(f, ""obs"", adata.obs, dataset_kwargs=dataset_kwargs); --> 112 write_attribute(f, ""var"", adata.var, dataset_kwargs=dataset_kwargs); 113 write_attribute(f, ""obsm"", adata.obsm, dataset_kwargs=dataset_kwargs); 114 write_attribute(f, ""varm"", adata.varm, dataset_kwargs=dataset_kwargs). ~/opt/anaconda3/lib/python3.8/functools.py in wrapper(*args, **kw); 873 '1 positional argument'); 874 ; --> 875 return dispatch(args[0].__class__)(*args, **kw); 876 ; 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:316,Performance,load,loaded,316,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:409,Performance,load,loading,409,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; ---; Hello, I am trying to save my .h5ad files to my desktop from scanpy, but adata.write is giving me an error. The data has been run through Kallisto Bustools and is being loaded in as an .h5ad file, but the error appears even if I try to save it immediately after loading it in, without any modifications. Unfortunately, the error does not happen when I try it on other data, such as the pbmc3k data. ### Minimal code sample . ```python; zf_48 = anndata.read_h5ad(""/Users/julius/Desktop/48hpf_adata.h5ad""); zf_48.var[""gene_ids""] = zf_48.var.index.values. t2g = pd.read_csv(""/Users/julius/Desktop/zf_transcripts_to_genes_no_rm.txt"", header=None, names=[""tid"", ""gene_id"", ""gene_name""], sep=""\t""); t2g.index = t2g.gene_id; t2g = t2g.loc[~t2g.index.duplicated(keep='first')]; zf_48.var[""gene_name""] = zf_48.var.gene_ids.map(t2g[""gene_name""]); zf_48.var.index = zf_48.var[""gene_name""] . zf_48.write_h5ad(""/Users/julius/Desktop/zf_48.h5ad""); ```; Here is the error:; ```pytb; RuntimeError Traceback (most recent call last); ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 208 try:; --> 209 return func(elem, key, val, *args, **kwargs); 210 except Exception as e:. ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/h5ad.py in write_array(f, key, value, dataset_kwargs); 184 value = _to_hdf5_vlen_strings(value); --> 185 f.create_dataset(key, data=value, **dataset_kwargs); 186 . ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in create_dataset(self, name, shape, dtype, data, **kwds); 138 if name is not None:; --> 139 self[name] = dset; 140 return dset. ~/opt/anaconda3/lib/python3.8/site-packages/h5py/_hl/group.py in __setitem__(self, name, obj); 372 if isinstance(obj, HLObject):; --> 373 h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl); 374 . h5py/_objects.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:6533,Performance,bottleneck,bottleneck,6533,"); 128 if key in f:; 129 del f[key]; --> 130 _write_method(type(value))(f, key, value, *args, **kwargs); 131 ; 132 . ~/opt/anaconda3/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs); 210 except Exception as e:; 211 parent = _get_parent(elem); --> 212 raise type(e)(; 213 f""{e}\n\n""; 214 f""Above error raised while writing key {key!r} of {type(elem)}"". RuntimeError: Unable to create link (name already exists). Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'gene_name' of <class 'h5py._hl.group.Group'> from /. Above error raised while writing key 'var' of <class 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; rpy2 3.4.5; samalg 0.8.6;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1982:8131,Testability,log,logical,8131,"ass 'h5py._hl.files.File'> from /. ```. Am I doing something wrong with this data? Or should I be using a different command?. #### Versions. <details>. anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.2.0; anndata2ri 1.0.6; anyio NA; appnope 0.1.2; attr 20.3.0; babel 2.9.0; backcall 0.2.0; backports NA; bottleneck 1.3.2; brotli NA; certifi 2020.12.05; cffi 1.14.5; chardet 4.0.0; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; decorator 5.0.6; dunamai 1.6.0; fsspec 0.9.0; get_version 3.5; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.17.2; jinja2 2.11.3; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.4.1; jupyterlab_server 2.4.0; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.35.0; markupsafe 1.1.1; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; numba 0.52.0; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.17; psutil 5.8.0; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.25.1; rpy2 3.4.5; samalg 0.8.6; scipy 1.6.2; seaborn 0.11.1; send2trash NA; six 1.15.0; sklearn 0.24.1; skmisc 0.1.4; sniffio 1.2.0; socks 1.7.1; sphinxcontrib NA; statsmodels 0.12.2; storemagic NA; tables 3.6.1; tblib 1.7.0; terminado 0.9.4; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.1; traitlets 5.0.5; typing_extensions NA; tzlocal NA; umap 0.5.1; urllib3 1.26.4; wcwidth 0.2.5; yaml 5.4.1; zmq 20.0.0; zope NA; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; jupyterlab 3.0.14; notebook 6.3.0; -----; Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]; macOS-10.16-x86_64-i386-64bit; 16 logical CPU cores, i386; -----; Session information updated at 2021-08-16 12:25; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1982
https://github.com/scverse/scanpy/issues/1983:345,Availability,error,errors,345,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:601,Availability,error,error,601,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3631,Availability,error,error,3631,"stances; --> 808 self._distances, self._connectivities = _compute_connectivities_umap(; 809 knn_indices,; 810 knn_distances,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in _compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity); 388 ; 389 X = coo_matrix(([], ([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; jobli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4007,Availability,down,downgrade,4007,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3986,Deployability,install,installs,3986,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4123,Deployability,install,install,4123,"a3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pygments 2.9.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; scvelo 0.2.3; six 1.16.0; sklearn 0.24.2; storemagic NA; tables 3.6.1; texttabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5482,Deployability,update,updated,5482,"n_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pygments 2.9.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; scvelo 0.2.3; six 1.16.0; sklearn 0.24.2; storemagic NA; tables 3.6.1; texttable 1.6.4; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; zipp NA; zmq 22.1.0; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.4.0; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10; 96 logical CPU cores, x86_64; -----; Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00); ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4068,Integrability,message,message,4068,"1 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pygments 2.9.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; scvelo 0.2.3; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1331,Modifiability,variab,variable,1331," I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:4384,Performance,bottleneck,bottleneck,4384,"at32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pygments 2.9.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; scvelo 0.2.3; six 1.16.0; sklearn 0.24.2; storemagic NA; tables 3.6.1; texttable 1.6.4; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; zipp NA; zmq 22.1.0; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.4.0; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-4.18.0-240.22.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1232,Safety,detect,detected,1232,"---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:3967,Safety,avoid,avoid,3967,"([], [])), shape=(n_obs, 1)); --> 390 connectivities = fuzzy_simplicial_set(; 391 X,; 392 n_neighbors,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/umap/umap_.py in fuzzy_simplicial_set(X, n_neighbors, random_state, metric, metric_kwds, knn_indices, knn_dists, angular, set_op_mix_ratio, local_connectivity, apply_set_operations, verbose); 600 knn_dists = knn_dists.astype(np.float32); 601 ; --> 602 sigmas, rhos = smooth_knn_dist(; 603 knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),; 604 ). SystemError: CPUDispatcher(<function smooth_knn_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:683,Testability,test,test,683,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Apologies for all the edits, but I'm stuck on this so have been playing around with it. Basically I'm getting weird errors when running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:1348,Testability,Log,Logarithmized,1348,"n running scanpy on scvelo objects. I first had this issue when running `sc.pp.pca(adata_panc, n_comps=50)`, but managed to solve it by previously setting `adata_panc.X = np.array(adata_panc.X.todense())`. However, I'm now getting the exact same error when running `sc.pp.neighbors(adata_panc)` and I'm not sure which matrix to test. Any advice would be very much appreciated!. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_panc = scv.datasets.pancreas(); scv.pp.filter_and_normalize(adata_panc, n_top_genes=3000, min_shared_counts=20); del adata_panc.obsm['X_pca']; del adata_panc.obsm['X_umap']; del adata_panc.obsp['distances']; del adata_panc.obsp['connectivities']; adata_panc.X = np.array(adata_panc.X.todense()); sc.pp.pca(adata_panc, n_comps=50); sc.pp.neighbors(adata_panc); ```. ```pytb; Filtered out 20801 genes that are detected 20 counts (shared).; Normalized count data: X, spliced, unspliced.; Extracted 3000 highly variable genes.; Logarithmized X.; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float32]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /hps/scratch/lsf_tmpdir/hl-codon-10-04/ipykernel_2322052/531027197.py in <module>; 7 adata_panc.X = np.array(adata_panc.X.todense()); 8 sc.pp.pca(adata_panc, n_comps=50); ----> 9 sc.pp.neighbors(adata_panc). /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy); 137 adata._init_as_actual(adata.copy()); 138 neighbors = Neighbors(adata); --> 139 neighbors.compute_neighbors(; 140 n_neighbors=n_neighbors,; 141 knn=knn,. /hps/software/users/marioni/Leah/miniconda3/envs/scvelo/lib/python3.8/site-packages/scanpy/neig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/issues/1983:5428,Testability,log,logical,5428,"n_dist at 0x14a113bac160>) returned a result with an error set. time: 4.73 s (started: 2021-08-18 11:47:40 +01:00); ```. #### Versions. <details>. ```pytb; WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.1; autotime 0.3.1; backcall 0.2.0; bottleneck 1.3.2; cffi 1.14.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; decorator 5.0.9; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipykernel 6.0.3; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.7; llvmlite 0.33.0; loompy 3.0.6; louvain 0.7.0; matplotlib 3.4.2; matplotlib_inline NA; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; numba 0.50.1; numexpr 2.7.3; numpy 1.20.3; numpy_groupies 0.9.13; packaging 21.0; pandas 1.3.0; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; ptyprocess 0.7.0; pycparser 2.20; pygments 2.9.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; scvelo 0.2.3; six 1.16.0; sklearn 0.24.2; storemagic NA; tables 3.6.1; texttable 1.6.4; tornado 6.1; traitlets 5.0.5; wcwidth 0.2.5; zipp NA; zmq 22.1.0; -----; IPython 7.26.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.4.0; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-4.18.0-240.22.1.el8_3.x86_64-x86_64-with-glibc2.10; 96 logical CPU cores, x86_64; -----; Session information updated at 2021-08-17 16:58. time: 402 ms (started: 2021-08-17 16:58:46 +01:00); ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1983
https://github.com/scverse/scanpy/pull/1985:84,Availability,error,error,84,"Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/pull/1985:488,Testability,test,tests,488,"Calling `sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes)` results in an error if `n_top_genes` is larger than the size of the `dispersion_norm` vector, which is the vector that we want to subset. Before this fix, scanpy just checked if `n_top_genes` was greater than `adata.n_vars`, which is unreliable since `dispersion_norm` can be smaller than that due to the subsetting in line 261: `dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]`. This PR fixes this. All tests in `test_highly_variable_genes.py` pass, but others like `test_plotting.py::test_violin` fail. I'm not sure why -- anyone have an idea?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1985
https://github.com/scverse/scanpy/issues/1986:2653,Deployability,update,updated,2653,".8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-52-9844c466c985>"", line 1, in <module>; sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter; and (color is None or color in adata.obs.keys() or color in adata.var.index); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; IPython 7.25.0; PIL 8.3.1; anndata 0.7.6; backcall 0.2.0; backend_interagg NA; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; console_thrift NA; cycler 0.10.0; cython_runtime NA; datalore NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.18.1; packaging 20.9; pandas 1.3.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.1; scipy 1.7.0; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; texttable 1.6.4; tqdm 4.61.2; traitlets 5.0.5; umap 0.5.1; wcwidth 0.2.5; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2021-08-26 10:01. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:1287,Security,hash,hash,1287," sc. adata = sc.datasets.paul15(); adata.obs['batch'] = np.random.randint(3, size=adata.n_obs); adata.obs['X'] = adata.X[:,1]; adata.obs['Y'] = adata.X[:,2]. sc.pl.scatter(adata, x='X', y='Y', color='batch') # works; sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']) # fails; ```. ```pytb; Traceback (most recent call last):; File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-52-9844c466c985>"", line 1, in <module>; sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter; and (color is None or color in adata.obs.keys() or color in adata.var.index); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; IPython 7.25.0; PIL 8.3.1; anndata 0.7.6; backcall 0.2.0; backend_interagg NA; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; console_thrift NA; cycler 0.10.0; cython_runtime NA; datalore NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.18.1; packaging 20.9; pandas 1.3.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.1; scipy 1.7.0; sinfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1986:2607,Testability,log,logical,2607,".8/site-packages/IPython/core/interactiveshell.py"", line 3441, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-52-9844c466c985>"", line 1, in <module>; sc.pl.scatter(adata, x='X', y='Y', color=['paul15_clusters', 'batch']); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/scanpy/plotting/_anndata.py"", line 131, in scatter; and (color is None or color in adata.obs.keys() or color in adata.var.index); File ""/home/mumichae/miniconda3/envs/opsca/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4572, in __contains__; hash(key); TypeError: unhashable type: 'list'; ```. #### Versions. <details>. ```; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; IPython 7.25.0; PIL 8.3.1; anndata 0.7.6; backcall 0.2.0; backend_interagg NA; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; console_thrift NA; cycler 0.10.0; cython_runtime NA; datalore NA; dateutil 2.8.1; decorator 4.4.2; defusedxml 0.7.1; h5py 2.10.0; igraph 0.9.6; ipython_genutils 0.2.0; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; llvmlite 0.36.0; louvain 0.7.0; matplotlib 3.4.2; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.18.1; packaging 20.9; pandas 1.3.1; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.19; psutil 5.8.0; ptyprocess 0.7.0; pycparser 2.20; pydev_console NA; pydev_ipython NA; pydevconsole NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.9.0; pynndescent 0.5.4; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.1; scipy 1.7.0; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; texttable 1.6.4; tqdm 4.61.2; traitlets 5.0.5; umap 0.5.1; wcwidth 0.2.5; -----; Python 3.8.10 | packaged by conda-forge | (default, May 11 2021, 07:01:05) [GCC 9.3.0]; Linux-5.13.10-200.fc34.x86_64-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2021-08-26 10:01. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1986
https://github.com/scverse/scanpy/issues/1987:340,Availability,error,error,340,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1740,Deployability,install,install,1740,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1795,Deployability,install,install,1795,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1833,Deployability,update,update,1833,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:212,Integrability,rout,routine,212,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1753,Usability,learn,learn,1753,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1987:1784,Usability,simpl,simply,1784,"My version of scanpy:; scanpy 1.8.1 pyhd8ed1ab_0 conda-forge; I'm working on a linux system based server, and uses miniconda3 for environment management.; After some changes in my environment, I tried to run the routine process of my analysis.; But when running sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40), I encountered the following error: . > Traceback (most recent call last):; File ""/data1/exhaustT/process.py"", line 118, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; File ""/data1/exhaustT/umap.py"", line 48, in <module>; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40); File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 808, in compute_neighbors; self._distances, self._connectivities = _compute_connectivities_umap(; File ""/data1/exhaustT/miniconda3/lib/python3.9/site-packages/scanpy/neighbors/ __init__.py"", line 387, in _compute_connectivities_umap; from umap.umap_ import fuzzy_simplicial_set; ModuleNotFoundError: No module named 'umap.umap_'; 'umap' is not a package. I've tried to re-install umap-learn from conda-forge, and/or simply pip install umap, neither worked for me. #update, the problem found to be that I named my own script umap.py, even though it's in a different direction, it still caused trouble.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1987
https://github.com/scverse/scanpy/issues/1988:2306,Deployability,update,updated,2306,"ealised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python; scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'); ```. ```pytb; ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png); ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; attr 20.3.0; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; jsonschema 3.2.0; kaleido 0.2.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.1.3; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 4.14.3; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; retrying NA; scanpy 1.7.2; scipy 1.5.3; scvi 0.6.8; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; solo 0.1; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; torch 1.8.1+cu102; tornado 6.1; tqdm 4.54.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-08-30 15:50. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:2260,Testability,log,logical,2260,"ealised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python; scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'); ```. ```pytb; ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png); ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; attr 20.3.0; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; jsonschema 3.2.0; kaleido 0.2.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.1.3; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 4.14.3; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; retrying NA; scanpy 1.7.2; scipy 1.5.3; scvi 0.6.8; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; solo 0.1; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; torch 1.8.1+cu102; tornado 6.1; tqdm 4.54.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-08-30 15:50. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1988:1769,Usability,simpl,simplegeneric,1769,"ealised that when I used the groups separation the legend has 2 elements: the selected sample and NA. In the older version it was only the name selected in groups. I also tried to get rid afterwards, but it modifies the whole legend... ### Code:. ```python; scanpy.pl.umap(adata,color='Sample_ID',groups='1M_curiox'); ```. ```pytb; ![out](https://user-images.githubusercontent.com/59560120/131350267-f6c2f0b2-209a-4c3c-8f88-6df0ab001333.png); ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; MulticoreTSNE NA; PIL 8.0.1; anndata 0.7.5; annoy NA; attr 20.3.0; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; idna 2.10; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; jsonschema 3.2.0; kaleido 0.2.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; nbformat 5.1.3; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; patsy 0.5.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; plotly 4.14.3; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; retrying NA; scanpy 1.7.2; scipy 1.5.3; scvi 0.6.8; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; solo 0.1; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; torch 1.8.1+cu102; tornado 6.1; tqdm 4.54.0; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-08-30 15:50. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1988
https://github.com/scverse/scanpy/issues/1989:243,Availability,error,error,243,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,; I got an error when running tl.umap after bbknn normalisation... new in version 1.7.2. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3); ; ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-73-a5a2e6833485> in <module>(); 1 adata_bbknn = bbknn.bbknn(adata, batch_key = metacol, n_pcs = number_of_pcs_for_reduction,copy=True); ----> 2 scanpy.tl.umap(adata_bbknn, min_dist=0.2, spread=2, n_components=3). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key); 205 neigh_params.get('metric', 'euclidean'),; 206 neigh_params.get('metric_kwds', {}),; --> 207 verbose=settings.verbosity > 3,; 208 ); 209 elif method == 'rapids':. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/umap_.py in simplicial_set_embedding(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, output_metric, output_metric_kwds, euclidean_output, parallel, verbose); 1037 random_state,; 1038 metric=metric,; -> 1039 metric_kwds=metric_kwds,; 1040 ); 1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2844,Deployability,update,update,2844,"6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; 305 metric=metric,; --> 306 metric_kwds=metric_kwds,; 307 ); 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds); 191 random_state,; 192 metric=metric,; --> 193 metric_kwds=metric_kwds,; 194 ); 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds); 120 else:; 121 distance_matrix = pairwise_distances(; --> 122 component_centroids, metric=metric, **metric_kwds; 123 ); 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs); 70 FutureWarning); 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 72 return f(**kwargs); 73 return inner_f; 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5053,Deployability,update,updated,5053,", n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; annoy NA; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-09-01 08:49; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:2772,Security,validat,validation,2772,"1041 expansion = 10.0 / np.abs(initialisation).max(). /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in spectral_layout(data, graph, dim, random_state, metric, metric_kwds); 304 random_state,; 305 metric=metric,; --> 306 metric_kwds=metric_kwds,; 307 ); 308 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in multi_component_layout(data, graph, n_components, component_labels, dim, random_state, metric, metric_kwds); 191 random_state,; 192 metric=metric,; --> 193 metric_kwds=metric_kwds,; 194 ); 195 else:. /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/umap/spectral.py in component_layout(data, n_components, component_labels, dim, random_state, metric, metric_kwds); 120 else:; 121 distance_matrix = pairwise_distances(; --> 122 component_centroids, metric=metric, **metric_kwds; 123 ); 124 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs); 70 FutureWarning); 71 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 72 return f(**kwargs); 73 return inner_f; 74 . /home/sguenth/.conda/envs/scRNAseq_analysis_1.6/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:5007,Testability,log,logical,5007,", n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; annoy NA; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-09-01 08:49; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1989:4558,Usability,simpl,simplegeneric,4558,", n_jobs, force_all_finite, **kwds); 1738 raise ValueError(""Unknown metric %s. ""; 1739 ""Valid metrics are %s, or 'precomputed', or a ""; -> 1740 ""callable"" % (metric, _VALID_METRICS)); 1741 ; 1742 if metric == ""precomputed"":. ValueError: Unknown metric angular. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'nan_euclidean', 'haversine'], or 'precomputed', or a callable; ```. #### Versions. <details>. -----; anndata 0.7.5; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; annoy NA; bbknn NA; cached_property 1.5.1; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.34.0; louvain 0.6.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.51.2; numexpr 2.7.1; numpy 1.19.4; packaging 20.4; pandas 1.1.4; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.8.0; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.7.2; scipy 1.5.3; seaborn 0.11.0; setuptools_scm NA; simplegeneric NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; statsmodels 0.12.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; zipp NA; zmq 20.0.0; -----; IPython 5.8.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.7.8 | packaged by conda-forge | (default, Nov 27 2020, 19:24:58) [GCC 9.3.0]; Linux-4.9.0-16-amd64-x86_64-with-debian-9.13; 8 logical CPU cores; -----; Session information updated at 2021-09-01 08:49; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1989
https://github.com/scverse/scanpy/issues/1990:99,Availability,error,error,99,"I was running this:; `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`; Which gave me this error:; ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_30806/3135920018.py in <module>; ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the; 587 # structure of the gene_names dataFrame; --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values; 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values; 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1161 ; 1162 # fall thru to straight lookup; -> 1163 self._validate_key(key, axis); 1164 return self._get_label(key, axis=axis); 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis); 970 # boolean not in slice and with boolean index; 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):; --> 972 raise KeyError(; 973 f""{key}: boolean label can not be used without a boolean index""; 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```; Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1990:590,Testability,log,log,590,"I was running this:; `sc.tl.filter_rank_genes_groups(adata, groupby='leiden')`; Which gave me this error:; ```; Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.5. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /tmp/ipykernel_30806/3135920018.py in <module>; ----> 1 sc.tl.filter_rank_genes_groups(adata, groupby='leiden'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction); 586 # that is assigned *as column* to fraction_in_cluster_matrix to follow the; 587 # structure of the gene_names dataFrame; --> 588 fraction_in_cluster_matrix.loc[:, cluster] = fraction_obs.loc[True].values; 589 fraction_out_cluster_matrix.loc[:, cluster] = fraction_obs.loc[False].values; 590 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 929 ; 930 maybe_callable = com.apply_if_callable(key, self.obj); --> 931 return self._getitem_axis(maybe_callable, axis=axis); 932 ; 933 def _is_scalar_access(self, key: tuple):. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1161 ; 1162 # fall thru to straight lookup; -> 1163 self._validate_key(key, axis); 1164 return self._get_label(key, axis=axis); 1165 . ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_key(self, key, axis); 970 # boolean not in slice and with boolean index; 971 if isinstance(key, bool) and not is_bool_dtype(self.obj.index):; --> 972 raise KeyError(; 973 f""{key}: boolean label can not be used without a boolean index""; 974 ). KeyError: 'True: boolean label can not be used without a boolean index'. ```; Any ideas? I'm using Scanpy 1.5.0 and pandas 1.3.1. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1990
https://github.com/scverse/scanpy/issues/1992:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ... I want to save h5ad object without cells in the red circle, how to do that in scanpy?. Thank you; ![image](https://user-images.githubusercontent.com/23288387/132060260-4700d085-595e-473f-ab09-6ff70ffde357.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1992
https://github.com/scverse/scanpy/pull/1994:0,Deployability,update,updates,0,updates:; - https://github.com/python/black → https://github.com/psf/black; - [github.com/psf/black: 20.8b1 → 21.8b0](https://github.com/psf/black/compare/20.8b1...21.8b0); - https://gitlab.com/pycqa/flake8 → https://github.com/PyCQA/flake8; - [github.com/PyCQA/flake8: 3.8.4 → 3.9.2](https://github.com/PyCQA/flake8/compare/3.8.4...3.9.2); - [github.com/pre-commit/mirrors-autopep8: v1.5.5 → v1.5.7](https://github.com/pre-commit/mirrors-autopep8/compare/v1.5.5...v1.5.7),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1994
https://github.com/scverse/scanpy/issues/1995:2362,Availability,error,error,2362," n_bins, flavor, subset, inplace, batch_key, check_values); 425 span=span,; 426 subset=subset,; --> 427 inplace=inplace,; 428 ); 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 ); 66 ; ---> 67 df['means'], df['variances'] = _get_mean_var(X); 68 ; 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis); 6 def _get_mean_var(X, *, axis=0):; 7 if sparse.issparse(X):; ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis); 9 else:; 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3986,Deployability,update,updated,3986,"). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0; seaborn 0.9.0; setuptools 41.4.0; setuptools_scm NA; simplejson 3.17.2; six 1.12.0; sklearn 0.24.2; skmisc 0.1.4; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; tblib 1.4.0; tensorboard 2.6.0; threadpoolctl 2.2.0; toolz 0.10.0; torch 1.9.0; torchmetrics 0.5.1; tornado 6.0.3; tqdm 4.56.0; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.1.2; zipp NA; zmq 18.1.0; -----; IPython 7.8.0; jupyter_client 5.3.3; jupyter_core 4.5.0; jupyterlab 1.1.4; notebook 6.0.1; -----; Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]; Darwin-20.5.0-x86_64-i386-64bit; 8 logical CPU cores, i386; -----; Session information updated at 2021-09-08 10:28. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:2540,Performance,bottleneck,bottleneck,2540,"nes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 ); 66 ; ---> 67 df['means'], df['variances'] = _get_mean_var(X); 68 ; 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis); 6 def _get_mean_var(X, *, axis=0):; 7 if sparse.issparse(X):; ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis); 9 else:; 10 mean = np.mean(X, axis=axis, dtype=np.float64). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0; seaborn 0.9.0; setuptools 41.4.0; setuptools_scm NA; simplejson 3.17.2; six 1.12.0; sklearn 0.24.2; skmisc 0.1.4; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; tblib 1.4.0; tensorboard 2.6.0; th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3934,Testability,log,logical,3934,"). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0; seaborn 0.9.0; setuptools 41.4.0; setuptools_scm NA; simplejson 3.17.2; six 1.12.0; sklearn 0.24.2; skmisc 0.1.4; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; tblib 1.4.0; tensorboard 2.6.0; threadpoolctl 2.2.0; toolz 0.10.0; torch 1.9.0; torchmetrics 0.5.1; tornado 6.0.3; tqdm 4.56.0; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.1.2; zipp NA; zmq 18.1.0; -----; IPython 7.8.0; jupyter_client 5.3.3; jupyter_core 4.5.0; jupyterlab 1.1.4; notebook 6.0.1; -----; Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]; Darwin-20.5.0-x86_64-i386-64bit; 8 logical CPU cores, i386; -----; Session information updated at 2021-09-08 10:28. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.pp.highly_variable_genes(; adata,; n_top_genes=4000,; # subset=True, # to automatically subset to the 4000 genes; layer=""counts"",; flavor=""seurat_v3""; ); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); TypeError: expected dtype object, got 'numpy.dtype[float64]'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); <ipython-input-15-144c5f8e718e> in <module>; 4 # subset=True, # to automatically subset to the 4000 genes; 5 layer=""counts"",; ----> 6 flavor=""seurat_v3""; 7 ). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 425 span=span,; 426 subset=subset,; --> 427 inplace=inplace,; 428 ); 429 . ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 65 ); 66 ; ---> 67 df['means'], df['variances'] = _get_mean_var(X); 68 ; 69 if batch_key is None:. ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in _get_mean_var(X, axis); 6 def _get_mean_var(X, *, axis=0):; 7 if sparse.issparse(X):; ----> 8 mean, var = sparse_mean_variance_axis(X, axis=axis); 9 else:; 10 mean = np.mean(X, axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1995:3368,Usability,simpl,simplejson,3368,"). ~/anaconda3/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py in sparse_mean_variance_axis(mtx, axis); 40 ); 41 else:; ---> 42 return sparse_mean_var_minor_axis(mtx.data, mtx.indices, *shape, np.float64); 43 ; 44 . SystemError: CPUDispatcher(<function sparse_mean_var_minor_axis at 0x7fcea12550e0>) returned a result with an error set; ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 6.2.0; absl NA; attr 19.2.0; backcall 0.1.0; beta_ufunc NA; binom_ufunc NA; bottleneck 1.2.1; cffi 1.12.3; cloudpickle 1.2.2; colorama 0.4.1; cycler 0.10.0; cython_runtime NA; cytoolz 0.10.0; dask 2.5.2; dateutil 2.8.0; decorator 4.4.0; deprecate 0.3.0; fsspec 2021.08.1; google NA; h5py 2.10.0; ipykernel 5.1.2; ipython_genutils 0.2.0; ipywidgets 7.5.1; jedi 0.15.1; joblib 0.13.2; kiwisolver 1.1.0; llvmlite 0.29.0; matplotlib 3.4.3; more_itertools NA; mpl_toolkits NA; natsort 7.0.1; nbinom_ufunc NA; numba 0.45.1; numexpr 2.7.0; numpy 1.21.2; opt_einsum v3.3.0; packaging 21.0; pandas 1.3.2; parso 0.5.1; pexpect 4.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.6.3; ptyprocess 0.6.0; pycparser 2.19; pygments 2.10.0; pyparsing 2.4.2; pyro 1.7.0; pytorch_lightning 1.3.8; pytz 2019.3; rich NA; scipy 1.7.1; scvi 0.13.0; seaborn 0.9.0; setuptools 41.4.0; setuptools_scm NA; simplejson 3.17.2; six 1.12.0; sklearn 0.24.2; skmisc 0.1.4; sphinxcontrib NA; statsmodels 0.10.1; storemagic NA; tables 3.5.2; tblib 1.4.0; tensorboard 2.6.0; threadpoolctl 2.2.0; toolz 0.10.0; torch 1.9.0; torchmetrics 0.5.1; tornado 6.0.3; tqdm 4.56.0; traitlets 4.3.3; typing_extensions NA; wcwidth NA; yaml 5.1.2; zipp NA; zmq 18.1.0; -----; IPython 7.8.0; jupyter_client 5.3.3; jupyter_core 4.5.0; jupyterlab 1.1.4; notebook 6.0.1; -----; Python 3.7.4 (default, Aug 13 2019, 15:17:50) [Clang 4.0.1 (tags/RELEASE_401/final)]; Darwin-20.5.0-x86_64-i386-64bit; 8 logical CPU cores, i386; -----; Session information updated at 2021-09-08 10:28. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1995
https://github.com/scverse/scanpy/issues/1996:305,Availability,down,downgrade,305,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:284,Deployability,install,installs,284,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:421,Deployability,install,install,421,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:366,Integrability,message,message,366,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1996:265,Safety,avoid,avoid,265,"https://github.com/theislab/scanpy/blob/63b42e4bff46a9e1386abfede4adeef3a8100c7b/pyproject.toml#L65. > The sinfo package has changed name and is now called session_info to become more discoverable and self-explanatory. The sinfo PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install session_info instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1996
https://github.com/scverse/scanpy/issues/1997:2764,Availability,down,downgrading,2764,"ygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3175,Availability,down,downgrade,3175,"2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3247,Availability,down,downgrading,3247,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:91,Deployability,install,installation,91,"Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date).; Minimal working example:; ```python; import scanpy as sc; paul15 = sc.datasets.paul15(); sc.pp.recipe_zheng17(paul15); sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20); sc.tl.paga(paul15, groups='paul15_clusters'); sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph; nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```; #### Versions; scanpy 1.8.1; networkx 2.6.2; matplotlib 3.4.3. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; PIL 8.0.1; PyQt5 NA; anndata 0.7.6; autoreload NA; backcall 0.2.0; bottleneck 1.3.2; bs4 4.9.3; cairo 1.20.1; cffi 1.14.3; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; h5py 2.10.0; html5lib 1.1; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.1; joblib 1.0.1; kiwisolver 1.3.0; leidenalg 0.8.7; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; networkx 2.6.2; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2590,Deployability,update,updated,2590,"numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3525,Deployability,install,installation,3525,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:1082,Performance,bottleneck,bottleneck,1082,"own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date).; Minimal working example:; ```python; import scanpy as sc; paul15 = sc.datasets.paul15(); sc.pp.recipe_zheng17(paul15); sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20); sc.tl.paga(paul15, groups='paul15_clusters'); sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph; nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```; #### Versions; scanpy 1.8.1; networkx 2.6.2; matplotlib 3.4.3. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; PIL 8.0.1; PyQt5 NA; anndata 0.7.6; autoreload NA; backcall 0.2.0; bottleneck 1.3.2; bs4 4.9.3; cairo 1.20.1; cffi 1.14.3; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; h5py 2.10.0; html5lib 1.1; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.1; joblib 1.0.1; kiwisolver 1.3.0; leidenalg 0.8.7; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; networkx 2.6.2; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:868,Testability,log,logging,868,"Hi, I'm having trouble exporting a PAGA graph as gexf format. I did a manual fix in my own installation of scanpy but it seems like a version issue with networkx2.6.2 (which is the latest of this date).; Minimal working example:; ```python; import scanpy as sc; paul15 = sc.datasets.paul15(); sc.pp.recipe_zheng17(paul15); sc.pp.neighbors(paul15, n_neighbors=4, n_pcs=20); sc.tl.paga(paul15, groups='paul15_clusters'); sc.pl.paga(paul15, labels=None, color='paul15_clusters'). gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True). ```. ```pytb. File ""anaconda3\lib\site-packages\scanpy\plotting\_tools\paga.py"", line 860, in _paga_graph; nx_g_solid.node[count]['label'] = str(node_labels[count]). AttributeError: 'Graph' object has no attribute 'node'```. ```; #### Versions; scanpy 1.8.1; networkx 2.6.2; matplotlib 3.4.3. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.1; -----; PIL 8.0.1; PyQt5 NA; anndata 0.7.6; autoreload NA; backcall 0.2.0; bottleneck 1.3.2; bs4 4.9.3; cairo 1.20.1; cffi 1.14.3; chardet 3.0.4; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2.30.0; dateutil 2.8.1; decorator 4.4.2; h5py 2.10.0; html5lib 1.1; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.1; joblib 1.0.1; kiwisolver 1.3.0; leidenalg 0.8.7; llvmlite 0.34.0; lxml 4.6.1; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; networkx 2.6.2; nt NA; ntsecuritycon NA; numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:2492,Testability,log,logical,2492,"numba 0.51.2; numexpr 2.7.1; numpy 1.20.3; packaging 20.4; pandas 1.3.2; parso 0.7.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; psutil 5.7.2; pyarrow 0.16.0; pycparser 2.20; pygments 2.7.2; pynndescent 0.5.2; pyparsing 2.4.7; pythoncom NA; pytz 2020.1; pywintypes NA; scanpy 1.8.1; scipy 1.5.2; sinfo 0.3.1; sip NA; six 1.15.0; sklearn 0.23.2; soupsieve 2.0.1; sphinxcontrib NA; spyder 4.1.5; spyder_kernels 1.9.4; spydercustomize NA; statsmodels 0.12.0; storemagic NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; tornado 6.0.4; traitlets 5.0.5; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; webencodings 0.5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1997:3542,Usability,simpl,simply,3542,".5.1; win32api NA; win32com NA; win32security NA; yaml 5.3.1; zmq 19.0.2; zope NA; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.6.3; jupyterlab 2.2.6; notebook 6.1.4; -----; Python 3.8.5 (default, Sep 3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]; Windows-10-10.0.19041-SP0; 4 logical CPU cores, Intel64 Family 6 Model 78 Stepping 3, GenuineIntel; -----; Session information updated at 2021-09-09 14:23. </details>\. Reading this stackoverflow (https://stackoverflow.com/questions/58518554/attributeerror-graph-object-has-no-attribute-node) I tried downgrading to networkx version 2.3 instead of 2.6.2 and it fixed this issue, but raised a separate incompatibility between networkx and matplotlib. ```pytb; AttributeError: module 'matplotlib.cbook' has no attribute 'iterable'; ```; ; which traces back to an issue in networkx rather than scanpy.; The following stackoverflow suggests that the older networkx2.3 requires matplotlib2.2.3 which is quite a large downgrade from my current matplatlib3.4.3 (current as of this date), so downgrading both networkx and matplotlib is not a great solution: https://stackoverflow.com/questions/63198347/attributeerror-module-matplotlib-cbook-has-no-attribute-iterable,. How i fixed it: ; After all that I went to line 860-862 of plotting/_tools/paga.py in my own scanpy installation and simply changed all the 'node' to 'nodes':; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.node[count]['label'] = str(node_labels[count]); nx_g_solid.node[count]['color'] = str(colors[count]); nx_g_solid.node[count]['viz'] = dict(; ```; to; ```python; for count, n in enumerate(nx_g_solid.nodes()):; nx_g_solid.nodes[count]['label'] = str(node_labels[count]); nx_g_solid.nodes[count]['color'] = str(colors[count]); nx_g_solid.nodes[count]['viz'] = dict(; ```. which apparently solved the issue; ```pytb; gexf=sc.pl.paga(paul15, labels=None, color='paul15_clusters', export_to_gexf=True); WARNING: exporting to write\paga_graph.gexf; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1997
https://github.com/scverse/scanpy/issues/1998:247,Usability,clear,clear,247,"I think the docs for this can be improved, particularly in the ""visualising marker genes"" vignette and in the sc.pl.xxx api documentation. I noticed the following:. (1) The ""use_raw"" parameter documentation for e.g. sc.pl.dotplot does not make it clear that .raw is used by default if present. It seems this issue is addressed upstream but not picked up for the html docs yet. Please compare: https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html with https://github.com/theislab/scanpy/blob/9360422823fade22a625f3c7840bef132364027e/scanpy/plotting/_anndata.py#L109. (2) It would be very helpful to provide and link in the docs to the script used to pre-process/create the example datasets such as sc.datasets.pbmc68k_reduced(). . (3) The visualisation vignette (https://scanpy-tutorials.readthedocs.io/en/multiomics/visualizing-marker-genes.html) does not state that normalised log1p data is being used for the example visualisations (and is presumably recommended). By itself the warning against use of scaled data leaves the situation ambiguous. . Because of these issues, and apologies if I missed the explanation, it is currently not straightforward to be sure what data is being plotted in the dot plots shown in this vignette. From inspecting the anndata object, reading the _anndata.py code and reading the 3k vignette I assume that it is the log1p normalised data! . Many thanks, S.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1998
https://github.com/scverse/scanpy/pull/1999:572,Availability,error,error,572,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:578,Integrability,message,message,578,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:71,Usability,guid,guidelines,71,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/pull/1999:102,Usability,guid,guide,102,"<!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->; This PR fixes the case when `use_raw=None` in `scanpy.tl.score_genes`. It causes to first fetch `var_names` from `adata.var_names`, but later a subset on `adata.raw` can happen, which can have different gene names.; Also fixes the type of `use_raw` and adds a `ValueError` if `gene_pool` is empty (otherwise, crashes with non-informative error message). related issue: https://github.com/theislab/cellrank/issues/746",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1999
https://github.com/scverse/scanpy/issues/2000:181,Deployability,install,installation,181,"Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:568,Deployability,install,install,568,"Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1037,Deployability,install,installed,1037,"i! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1113,Deployability,install,installed,1113,"As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; pkg_resource",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2455,Deployability,update,updated,2455,"e sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; tqdm 4.62.1; typing_extensions NA; yaml 5.4.1; zipp NA; -----; Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]; Darwin-20.4.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-09-15 10:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:71,Integrability,depend,dependencies,71,"Hi! I am wondering why `loompy` and `pybiomart` are not in the list of dependencies. As of now ; the package (at least in bioconda) is not fully functional and requieres some extra installation; steps if one wants to use certain functionalities provided. - [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Minimal code sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:1708,Performance,bottleneck,bottleneck,1708,"e sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; tqdm 4.62.1; typing_extensions NA; yaml 5.4.1; zipp NA; -----; Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]; Darwin-20.4.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-09-15 10:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2000:2403,Testability,log,logical,2403,"e sample (that we can copy&paste without having any data); ```bash; conda install -c bioconda scanpy; ````. ```python; import scanpy as sc; annot = sc.queries.biomart_annotations(""mmusculus"", [""ensembl_gene_id"", ""external_gene_name""]); ```; ```pytb; line 108, in biomart_annotations; return simple_query(org=org, attrs=attrs, host=host, use_cache=use_cache); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/scanpy/queries/_queries.py"", line 64, in simple_query; ""This method requires the `pybiomart` module to be installed.""; ImportError: This method requires the `pybiomart` module to be installed.; ```. ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); adata.write_loom('dummy.loom'); ```; ```pytb; write_loom(filename, self, write_obsm_varm=write_obsm_varm); File ""/Users/jfnavarro/opt/anaconda3/envs/nf-core/lib/python3.7/site-packages/anndata/_io/write.py"", line 112, in write_loom; from loompy import create; ModuleNotFoundError: No module named 'loompy'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.1; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; bottleneck 1.3.2; cffi 1.14.6; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; get_version 3.5; h5py 2.10.0; joblib 1.0.1; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; llvmlite 0.36.0; matplotlib 3.4.2; mkl 2.4.0; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; numba 0.53.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.2; pkg_resources NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; tables 3.6.1; tqdm 4.62.1; typing_extensions NA; yaml 5.4.1; zipp NA; -----; Python 3.7.11 (default, Jul 27 2021, 07:03:16) [Clang 10.0.0 ]; Darwin-20.4.0-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2021-09-15 10:41. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2000
https://github.com/scverse/scanpy/issues/2001:740,Availability,Error,Error,740,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:746,Integrability,message,message,746,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1402,Modifiability,Variab,Variables,1402,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1456,Modifiability,variab,variables,1456,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1503,Modifiability,Variab,Variables,1503,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1549,Modifiability,variab,variables,1549,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1623,Testability,log,logging,1623,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2001:1752,Usability,learn,learn,1752,"- [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [X ] (optional) I have confirmed this bug exists on the master branch of scanpy. I'm working on comit `63b42e4b` (latest master).; I'm not sure if intended or not but it seems like it would be usefull if one were able to ingest data that don't share 100% of all features. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.pp.pca(adata_ref); sc.pp.neighbors(adata_ref); sc.tl.leiden(adata_ref); adata = adata_ref[:, :1000].copy() # assume adata_ref has more than 1000 genes.; sc.tl.ingest(adata, adata_ref, obs='leiden'); ```. Error message; ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-37-b3cd11e67810> in <module>; ----> 1 sc.tl.ingest(adata, adata_ref, obs='leiden'). ~/projects/scanpy/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 125 ; 126 ing = Ingest(adata_ref, neighbors_key); --> 127 ing.fit(adata); 128 ; 129 for method in embedding_method:. ~/projects/scanpy/scanpy/tools/_ingest.py in fit(self, adata_new); 437 ; 438 if not ref_var_names.equals(new_var_names):; --> 439 raise ValueError(; 440 'Variables in the new adata are different '; 441 'from variables in the reference adata'. ValueError: Variables in the new adata are different from variables in the reference adata; ```. --- . #### Versions. <details>. sc.logging.print_header(); scanpy==1.8.0.dev78+gc488909a anndata==0.7.6 umap==0.5.0 numpy==1.19.4 scipy==1.5.4 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 leidenalg==0.8.3 pynndescent==0.5.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2001
https://github.com/scverse/scanpy/issues/2002:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [X] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi,; ""Scanorama outputs both corrected expression matrices and embeddings."" However, `scanpy.external.pp` only implemented `.scanorama_integrate` #1332 . Is there any plan to implement the `.scanorama_correct` method as well? Or let `.scanorama_integrate` output the correct matrices as an option. ; Thanks!; Hurley",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2002
https://github.com/scverse/scanpy/issues/2003:355,Availability,error,error,355,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]; pd.set_option(""display.max_colwidth"", 800); first_enrichment_results.iloc[:50,:]; plot_enrich(first_enrichment_results); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-28-72ef52261ce6> in <module>; ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save); 75 fig = plt.gcf(); 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]); ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes); 78 cbar.ax.set_yticklabels(ticks_labs); 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw); 2341 'panchor']; 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2344 ; 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3599,Deployability,patch,patch,3599,"hon37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value); 1218 if not self.scaled():; 1219 raise ValueError(""Not invertible until scaled""); -> 1220 self._check_vmin_vmax(); 1221 vmin, vmax = self.vmin, self.vmax; 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self); 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1180 elif self.vmin <= 0:; -> 1181 raise ValueError(""minvalue must be positive""); 1182 ; 1183 def __call__(self, value, clip=None):; ValueError: minvalue must be positive",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3868,Energy Efficiency,Power,PowerNorm,3868,"precation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value); 1218 if not self.scaled():; 1219 raise ValueError(""Not invertible until scaled""); -> 1220 self._check_vmin_vmax(); 1221 vmin, vmax = self.vmin, self.vmax; 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self); 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1180 elif self.vmin <= 0:; -> 1181 raise ValueError(""minvalue must be positive""); 1182 ; 1183 def __call__(self, value, clip=None):; ValueError: minvalue must be positive; ```. #### Versions. <details>. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2609,Integrability,wrap,wrapper,2609,"v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2344 ; 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:; -> 1734 cb = Colorbar(cax, mappable, **kwargs); 1735 ; 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs); 1226 if isinstance(mappable, martist.Artist):; 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1228 ColorbarBase.__init__(self, ax, **kwargs); 1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\progr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:2806,Integrability,wrap,wrapper,2806,"elf.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:; -> 1734 cb = Colorbar(cax, mappable, **kwargs); 1735 ; 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs); 1226 if isinstance(mappable, martist.Artist):; 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1228 ColorbarBase.__init__(self, ax, **kwargs); 1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3002,Modifiability,extend,extend,3002,"34 cb = Colorbar(cax, mappable, **kwargs); 1735 ; 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs); 1226 if isinstance(mappable, martist.Artist):; 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1228 ColorbarBase.__init__(self, ax, **kwargs); 1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3053,Modifiability,extend,extendfrac,3053,"34 cb = Colorbar(cax, mappable, **kwargs); 1735 ; 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs); 1226 if isinstance(mappable, martist.Artist):; 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1228 ColorbarBase.__init__(self, ax, **kwargs); 1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3065,Modifiability,extend,extendrect,3065,"34 cb = Colorbar(cax, mappable, **kwargs); 1735 ; 1736 cid = mappable.callbacksSM.connect('changed', cb.update_normal). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, mappable, **kwargs); 1226 if isinstance(mappable, martist.Artist):; 1227 _add_disjoint_kwargs(kwargs, alpha=mappable.get_alpha()); -> 1228 ColorbarBase.__init__(self, ax, **kwargs); 1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3430,Modifiability,extend,extend,3430,"1229 ; 1230 @cbook.deprecated(""3.3"", alternative=""update_normal""). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value); 1218 if not self.scaled():; 1219 raise ValueError(""Not invertible until scaled""); -> 1220 self._check_vmin_vmax(); 1221 vmin, vmax = self.vmin, self.vmax; 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self); 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1180 elif self.vmin <= 0:; -> 1181 raise ValueError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3592,Modifiability,extend,extend,3592,"hon37\lib\site-packages\matplotlib\cbook\deprecation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value); 1218 if not self.scaled():; 1219 raise ValueError(""Not invertible until scaled""); -> 1220 self._check_vmin_vmax(); 1221 vmin, vmax = self.vmin, self.vmax; 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self); 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1180 elif self.vmin <= 0:; -> 1181 raise ValueError(""minvalue must be positive""); 1182 ; 1183 def __call__(self, value, clip=None):; ValueError: minvalue must be positive",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:3886,Testability,Log,LogNorm,3886,"precation.py in wrapper(*args, **kwargs); 449 ""parameter will become keyword-only %(removal)s."",; 450 name=name, obj_type=f""parameter of {func.__name__}()""); --> 451 return func(*args, **kwargs); 452 ; 453 return wrapper. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in __init__(self, ax, cmap, norm, alpha, values, boundaries, orientation, ticklocation, extend, spacing, ticks, format, drawedges, filled, extendfrac, extendrect, label); 489 else:; 490 self.formatter = format # Assume it is a Formatter or None; --> 491 self.draw_all(); 492 ; 493 def _extend_lower(self):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in draw_all(self); 506 # sets self._boundaries and self._values in real data units.; 507 # takes into account extend values:; --> 508 self._process_values(); 509 # sets self.vmin and vmax in data units, but just for the part of the; 510 # colorbar that is not part of the extend patch:. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in _process_values(self, b); 961 expander=0.1); 962 ; --> 963 b = self.norm.inverse(self._uniform_y(self.cmap.N + 1)); 964 ; 965 if isinstance(self.norm, (colors.PowerNorm, colors.LogNorm)):. c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in inverse(self, value); 1218 if not self.scaled():; 1219 raise ValueError(""Not invertible until scaled""); -> 1220 self._check_vmin_vmax(); 1221 vmin, vmax = self.vmin, self.vmax; 1222 . c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colors.py in _check_vmin_vmax(self); 1179 raise ValueError(""minvalue must be less than or equal to maxvalue""); 1180 elif self.vmin <= 0:; -> 1181 raise ValueError(""minvalue must be positive""); 1182 ; 1183 def __call__(self, value, clip=None):; ValueError: minvalue must be positive; ```. #### Versions. <details>. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2003:486,Usability,guid,guide,486,"- [ ] I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I am trying to run the gene ontology enrichment analysis from the latest script of the scanpy notebook and encountered this error below. I have pasted the last 3 code lines I used from the scanpy notebook. Please help me. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; first_enrichment_results = first_enrichment.set_index('native').sort_values('p_value').iloc[:,[2,5,7,10,1]; pd.set_option(""display.max_colwidth"", 800); first_enrichment_results.iloc[:50,:]; plot_enrich(first_enrichment_results); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-28-72ef52261ce6> in <module>; ----> 1 plot_enrich(first_enrichment_results). <ipython-input-12-f7e84411a548> in plot_enrich(data, n_terms, save); 75 fig = plt.gcf(); 76 cbaxes = fig.add_axes([0.8, 0.15, 0.03, 0.4]); ---> 77 cbar = ax.figure.colorbar(sm, ticks=ticks_vals, shrink=0.5, anchor=(0,0.1), cax=cbaxes); 78 cbar.ax.set_yticklabels(ticks_labs); 79 cbar.set_label(""Adjusted p-value"", fontsize=14, fontweight='bold'). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\figure.py in colorbar(self, mappable, cax, ax, use_gridspec, **kw); 2341 'panchor']; 2342 cb_kw = {k: v for k, v in kw.items() if k not in NON_COLORBAR_KEYS}; -> 2343 cb = cbar.colorbar_factory(cax, mappable, **cb_kw); 2344 ; 2345 self.sca(current_ax). c:\users\pawandeep\appdata\local\programs\python\python37\lib\site-packages\matplotlib\colorbar.py in colorbar_factory(cax, mappable, **kwargs); 1732 cb = ColorbarPatch(cax, mappable, **kwargs); 1733 else:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2003
https://github.com/scverse/scanpy/issues/2004:24,Deployability,integrat,integrate,24,"Dear author,. Can bbknn integrate multiple variables？such as Platform and Individual. Looking forward your reply; Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn; return bbknn(; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn; if batch_key not in adata.obs:; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__; return key in self._info_axis; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__; hash(key); TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:24,Integrability,integrat,integrate,24,"Dear author,. Can bbknn integrate multiple variables？such as Platform and Individual. Looking forward your reply; Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn; return bbknn(; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn; if batch_key not in adata.obs:; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__; return key in self._info_axis; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__; hash(key); TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:43,Modifiability,variab,variables,43,"Dear author,. Can bbknn integrate multiple variables？such as Platform and Individual. Looking forward your reply; Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn; return bbknn(; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn; if batch_key not in adata.obs:; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__; return key in self._info_axis; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__; hash(key); TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2004:850,Security,hash,hash,850,"Dear author,. Can bbknn integrate multiple variables？such as Platform and Individual. Looking forward your reply; Siyu. >>> sc.external.pp.bbknn(mydata, batch_key=[""Platform"",""Individual_2""],n_pcs=50,set_op_mix_ratio=ratio). computing batch balanced neighbors; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/scanpy/external/pp/_bbknn.py"", line 134, in bbknn; return bbknn(; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/bbknn/__init__.py"", line 110, in bbknn; if batch_key not in adata.obs:; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py"", line 1721, in __contains__; return key in self._info_axis; File ""/home/scCell2/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py"", line 4071, in __contains__; hash(key); TypeError: unhashable type: 'list",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2004
https://github.com/scverse/scanpy/issues/2007:1713,Availability,error,error,1713,"er, after running a new embedding and clustering on `adata_sub`, I have noticed that I can plot genes that shouldn't be in `adata_sub` (but were in `adata`), and that when I run `sc.tl.rank_genes_groups` my results aren't restricted to my 990 genes of interest. I am guessing that I subsetted my data incorrectly (though, why would I have the correct shape?). ### Minimal code sample (that we can copy&paste without having any data). ```python; # subset adata to genes of interest; adata_sub = adata[:, [g in genes_list for g in adata.var_names]].copy(). # filter out cells that don't express any genes of interest; sc.pp.filter_cells(adata_sub, min_genes=1). # run new embedding and clustering; sc.pp.pca(adata_sub, n_comps=50, use_highly_variable=False, svd_solver='arpack'); sc.pp.neighbors(adata_sub); sc.tl.umap(adata_sub); sc.tl.leiden(adata_sub, key_added='leiden_sub'); ```. When I use `sc.pl.umap(adata_sub)` to plot expression of a gene that is _not_ one of my genes of interest, it is still plotted (I would expect an error telling me that the gene is not found in my `adata_sub` object). Similarly, the results of `sc.tl.rank_genes_groups(adata_sub, groupby='leiden_sub', key_added='rank_genes_sub', method='wilcoxon')` returns top ranked genes that are not (or should not be) in my `adata_sub` object. Thank you for any help/clarification as to what's going on!. #### Versions. <details>; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2019.11.28; cffi 1.14.6; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.4.3; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.4.0; idna 2.8; igraph 0.9.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.4; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007
https://github.com/scverse/scanpy/issues/2007:3919,Deployability,update,updated,3919,"should not be) in my `adata_sub` object. Thank you for any help/clarification as to what's going on!. #### Versions. <details>; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2019.11.28; cffi 1.14.6; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.4.3; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.4.0; idna 2.8; igraph 0.9.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.4; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; networkx 2.6.3; numba 0.54.0; numexpr 2.7.3; numpy 1.20.0; packaging 21.0; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.22.0; scipy 1.7.1; seaborn 0.11.2; send2trash NA; sitecustomize NA; six 1.14.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.0rc0; storemagic NA; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; tornado 6.1; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; urllib3 1.25.8; wcwidth 0.2.5; websocket 1.2.1; zmq 22.3.0; -----; IPython 7.27.0; jupyter_client 7.0.2; jupyter_core 4.7.1; jupyterlab 3.1.11; notebook 6.4.3; -----; Python 3.8.10 (default, Jun 2 2021, 10:49:15) [GCC 9.4.0]; Linux-5.10.25-linuxkit-x86_64-with-glibc2.29; 6 logical CPU cores, x86_64; -----; Session information updated at 2021-09-30 18:02. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007
https://github.com/scverse/scanpy/issues/2007:3865,Testability,log,logical,3865,"should not be) in my `adata_sub` object. Thank you for any help/clarification as to what's going on!. #### Versions. <details>; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; anyio NA; attr 21.2.0; babel 2.9.1; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; certifi 2019.11.28; cffi 1.14.6; chardet 3.0.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.4.3; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; gi 3.36.0; gio NA; glib NA; gobject NA; gtk NA; h5py 3.4.0; idna 2.8; igraph 0.9.6; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.4; jedi 0.18.0; jinja2 3.0.1; joblib 1.0.1; json5 NA; jsonschema 3.2.0; jupyter_server 1.11.0; jupyterlab_server 2.8.1; kiwisolver 1.3.2; leidenalg 0.8.7; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; natsort 7.1.1; nbclassic NA; nbformat 5.1.3; nbinom_ufunc NA; networkx 2.6.3; numba 0.54.0; numexpr 2.7.3; numpy 1.20.0; packaging 21.0; pandas 1.3.2; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.20; ptyprocess 0.7.0; pvectorc NA; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.4; pyparsing 2.4.7; pyrsistent NA; pytz 2021.1; requests 2.22.0; scipy 1.7.1; seaborn 0.11.2; send2trash NA; sitecustomize NA; six 1.14.0; sklearn 0.24.2; sniffio 1.2.0; statsmodels 0.13.0rc0; storemagic NA; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; tornado 6.1; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; urllib3 1.25.8; wcwidth 0.2.5; websocket 1.2.1; zmq 22.3.0; -----; IPython 7.27.0; jupyter_client 7.0.2; jupyter_core 4.7.1; jupyterlab 3.1.11; notebook 6.4.3; -----; Python 3.8.10 (default, Jun 2 2021, 10:49:15) [GCC 9.4.0]; Linux-5.10.25-linuxkit-x86_64-with-glibc2.29; 6 logical CPU cores, x86_64; -----; Session information updated at 2021-09-30 18:02. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2007
https://github.com/scverse/scanpy/issues/2008:281,Availability,error,error,281,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I also tried 'log1p = False' and produced the other error. Thank you. . ```python; sc.pp.calculate_qc_metrics(adata); ```. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 294, in calculate_qc_metrics; obs_metrics = describe_obs(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/preprocessing/_qc.py"", line 111, in describe_obs; obs_metrics[f""log1p_total_{expr_type}""] = np.log1p(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3612, in __setitem__; self._set_item(key, value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 3784, in _set_item; value = self._sanitize_column(value); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 4509, in _sanitize_column; com.require_length_match(value, self.index); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/common.py"", line 531, in require_length_match; raise ValueError(; ValueError: Length of values (1) does not match length of index (35255); >; ```. `sc.pp.calculate_qc_metrics(adata, log1p = False)`. ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 995, in __repr__; self.to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/core/frame.py"", line 1131, in to_string; return fmt.DataFrameRenderer(formatter).to_string(; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1053, in to_string; string = string_formatter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008
https://github.com/scverse/scanpy/issues/2008:5263,Deployability,update,updated,5263,"lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1518, in _format_strings; return list(self.get_result_as_array()); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1482, in get_result_as_array; formatted_values = format_values_with(float_format); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1456, in format_values_with; values = format_with_na_rep(values, formatter, na_rep); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1427, in format_with_na_rep; [; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1428, in <listcomp>; formatter(val) if not m else na_rep; ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.2; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; encodings NA; genericpath NA; get_version 3.5; h5py 3.4.0; joblib 1.0.1; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.37.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.0; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.3; pkg_resources NA; posixpath NA; pycparser 2.20; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tables 3.6.1; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-glibc2.31; 24 logical CPU cores, x86_64; -----; Session information updated at 2021-10-01 14:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008
https://github.com/scverse/scanpy/issues/2008:4425,Performance,concurren,concurrent,4425,"lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1518, in _format_strings; return list(self.get_result_as_array()); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1482, in get_result_as_array; formatted_values = format_values_with(float_format); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1456, in format_values_with; values = format_with_na_rep(values, formatter, na_rep); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1427, in format_with_na_rep; [; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1428, in <listcomp>; formatter(val) if not m else na_rep; ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.2; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; encodings NA; genericpath NA; get_version 3.5; h5py 3.4.0; joblib 1.0.1; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.37.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.0; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.3; pkg_resources NA; posixpath NA; pycparser 2.20; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tables 3.6.1; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-glibc2.31; 24 logical CPU cores, x86_64; -----; Session information updated at 2021-10-01 14:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008
https://github.com/scverse/scanpy/issues/2008:5209,Testability,log,logical,5209,"lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1518, in _format_strings; return list(self.get_result_as_array()); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1482, in get_result_as_array; formatted_values = format_values_with(float_format); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1456, in format_values_with; values = format_with_na_rep(values, formatter, na_rep); File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1427, in format_with_na_rep; [; File ""/root/miniconda3/envs/scanpy/lib/python3.9/site-packages/pandas/io/formats/format.py"", line 1428, in <listcomp>; formatter(val) if not m else na_rep; ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.1; -----; PIL 8.3.2; anndata 0.7.6; beta_ufunc NA; binom_ufunc NA; cffi 1.14.6; colorama 0.4.4; concurrent NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; dunamai 1.6.0; encodings NA; genericpath NA; get_version 3.5; h5py 3.4.0; joblib 1.0.1; kiwisolver 1.3.2; legacy_api_wrap 0.0.0; llvmlite 0.37.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; nbinom_ufunc NA; ntpath NA; numba 0.54.0; numexpr 2.7.3; numpy 1.20.3; opcode NA; packaging 21.0; pandas 1.3.3; pkg_resources NA; posixpath NA; pycparser 2.20; pyexpat NA; pyparsing 2.4.7; pytz 2021.1; scanpy 1.7.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 1.0; sphinxcontrib NA; sre_compile NA; sre_constants NA; sre_parse NA; tables 3.6.1; -----; Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]; Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-glibc2.31; 24 logical CPU cores, x86_64; -----; Session information updated at 2021-10-01 14:56. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2008
https://github.com/scverse/scanpy/issues/2013:789,Deployability,patch,patches,789,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?; ...; It would be nice to have something like https://github.com/powellgenomicslab/Nebulosa to plot sparse genes.; On one hand, ordering with highest value on top (top plot) does not always work as what is below top layer is hidden and decreasing point size to combat this is not always good if different regions of UMAP are differently dense, thus creating white patches. On the other hand, random ordering (middle plot) can be hard to look at for sparse genes.; The gene on the plot is highly correlated with pattern from the bottom plot, but this is not so clear when plotting the gene alone. Sort order=True; <img width=""221"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395395-ec372b26-6552-4136-ae91-875713f700cb.png"">; Random cell ordering; <img width=""217"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395363-9e9fad24-e451-4d47-ac64-ff9b6b7b5774.png"">; Strongly correlated with; <img width=""194"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395551-1d6731aa-0749-425b-be68-f57344df0376.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2013
https://github.com/scverse/scanpy/issues/2013:168,Usability,simpl,simple,168,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?; ...; It would be nice to have something like https://github.com/powellgenomicslab/Nebulosa to plot sparse genes.; On one hand, ordering with highest value on top (top plot) does not always work as what is below top layer is hidden and decreasing point size to combat this is not always good if different regions of UMAP are differently dense, thus creating white patches. On the other hand, random ordering (middle plot) can be hard to look at for sparse genes.; The gene on the plot is highly correlated with pattern from the bottom plot, but this is not so clear when plotting the gene alone. Sort order=True; <img width=""221"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395395-ec372b26-6552-4136-ae91-875713f700cb.png"">; Random cell ordering; <img width=""217"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395363-9e9fad24-e451-4d47-ac64-ff9b6b7b5774.png"">; Strongly correlated with; <img width=""194"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395551-1d6731aa-0749-425b-be68-f57344df0376.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2013
https://github.com/scverse/scanpy/issues/2013:985,Usability,clear,clear,985,"<!-- What kind of feature would you like to request? -->; - [ x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?; ...; It would be nice to have something like https://github.com/powellgenomicslab/Nebulosa to plot sparse genes.; On one hand, ordering with highest value on top (top plot) does not always work as what is below top layer is hidden and decreasing point size to combat this is not always good if different regions of UMAP are differently dense, thus creating white patches. On the other hand, random ordering (middle plot) can be hard to look at for sparse genes.; The gene on the plot is highly correlated with pattern from the bottom plot, but this is not so clear when plotting the gene alone. Sort order=True; <img width=""221"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395395-ec372b26-6552-4136-ae91-875713f700cb.png"">; Random cell ordering; <img width=""217"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395363-9e9fad24-e451-4d47-ac64-ff9b6b7b5774.png"">; Strongly correlated with; <img width=""194"" alt=""image"" src=""https://user-images.githubusercontent.com/47607471/136395551-1d6731aa-0749-425b-be68-f57344df0376.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2013
https://github.com/scverse/scanpy/issues/2014:1222,Availability,avail,available,1222,"ster branch of scanpy. ---. I noticed that running the same single-cell analyses on different nodes of our HPC produces different results. ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014
https://github.com/scverse/scanpy/issues/2014:1360,Availability,avail,available,1360,". ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014
https://github.com/scverse/scanpy/issues/2014:1210,Deployability,pipeline,pipeline,1210,"ster branch of scanpy. ---. I noticed that running the same single-cell analyses on different nodes of our HPC produces different results. ; Starting from the same anndata object with a precomputed `X_scVI` latent representation, the UMAP and leiden-clustering looks different. . On ; * Intel(R) Xeon(R) CPU E5-2699A v4 @ 2.40GHz; * AMD EPYC 7352 24-Core Processor; * Intel(R) Xeon(R) CPU E7-4850 v4 @ 2.10GHz. ![image](https://user-images.githubusercontent.com/7051479/137452257-b88f24fc-bb08-4620-9c1a-98d865ae5956.png); ```python; adata.obs[""leiden""].value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014
https://github.com/scverse/scanpy/issues/2014:2711,Deployability,update,updated,2711,"value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; umap 0.4.6; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.8.6 | packaged by conda-forge | (default, Nov 27 2020, 19:31:52) [GCC 9.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-10-15 09:58; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014
https://github.com/scverse/scanpy/issues/2014:2657,Testability,log,logical,2657,"value_counts(); ```; ```console; 0 4268; 1 2132; 2 1691; 3 1662; 4 1659; 5 1563; ...; ```. On ; * Intel(R) Xeon(R) CPU E7- 4870 @ 2.40GHz. ![image](https://user-images.githubusercontent.com/7051479/137452439-7a094705-6473-4d22-8916-da3139273c6c.png); ```console; 0 3856; 1 2168; 2 2029; 3 1659; 4 1636; 5 1536; ...; ```. ### Minimal code sample (that we can copy&paste without having any data). A git repository with example data, notebook and a nextflow pipeline is available here:; https://github.com/grst/scanpy_reproducibility. A report of the analysis executed on four different CPU architectures is available here:; https://grst.github.io/scanpy_reproducibility/. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 8.0.1; anndata 0.7.5; backcall 0.2.0; cairo 1.20.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 3.1.0; igraph 0.8.3; ipykernel 5.3.4; ipython_genutils 0.2.0; jedi 0.17.2; joblib 0.17.0; kiwisolver 1.3.1; legacy_api_wrap 0.0.0; leidenalg 0.8.3; llvmlite 0.35.0; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.0; numba 0.52.0; numexpr 2.7.1; numpy 1.19.4; packaging 20.7; pandas 1.1.4; parso 0.7.1; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.8; ptyprocess 0.6.0; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pytz 2020.4; scanpy 1.6.0; scipy 1.5.3; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.2; sphinxcontrib NA; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.1; traitlets 5.0.5; umap 0.4.6; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; -----; Python 3.8.6 | packaged by conda-forge | (default, Nov 27 2020, 19:31:52) [GCC 9.3.0]; Linux-3.10.0-1160.11.1.el7.x86_64-x86_64-with-glibc2.10; 64 logical CPU cores, x86_64; -----; Session information updated at 2021-10-15 09:58; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2014
https://github.com/scverse/scanpy/issues/2015:2607,Availability,error,error,2607,"provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G', 'H',; 'I', 'J',; 'K', 'L']; adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].cat.rename_categories(new_cluster_names); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, threshold=0.03); sc.tl.draw_graph(adata, init_pos='paga'); sc.pl.draw_graph(adata, color=['seurat_clusters'], legend_loc='right margin'); adata.uns['iroot'] = np.flatnonzero(adata.obs['seurat_clusters'] == 'C')[0]; sc.tl.dpt(adata); adata.obs['dpt_pseudotime']; adata; sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']); ```pytb; [Paste the error output produced by the above code here]; ```; ![1634300003(1)](https://user-images.githubusercontent.com/92583306/137486504-8a01bfc7-cbdf-409f-a730-dfec94f8c4f7.png). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015
https://github.com/scverse/scanpy/issues/2015:1243,Testability,log,logging,1243,"t is the scanpy to be blamed. But two of my data both face this problem. When I run trajectory analysis upon. sc.tl.dpt(adata); sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']). branches of image for dpt_pseudotime were all deep blue, which indicated close to zero. And. adata.obs['dpt_pseudotime']. also print number(0.07, 0.06, etc) that close to zero.; Therefore, I do not know if there is something wrong with my previous code, or there is something wrong with scanpy. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G', 'H',; 'I', 'J',; 'K', 'L']; adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].cat.rename_categories(new_cluster_names); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, threshold=0.03); sc.tl.draw_graph(adata, init_pos='p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015
https://github.com/scverse/scanpy/issues/2015:2834,Testability,log,logging,2834,"provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G', 'H',; 'I', 'J',; 'K', 'L']; adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].cat.rename_categories(new_cluster_names); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, threshold=0.03); sc.tl.draw_graph(adata, init_pos='paga'); sc.pl.draw_graph(adata, color=['seurat_clusters'], legend_loc='right margin'); adata.uns['iroot'] = np.flatnonzero(adata.obs['seurat_clusters'] == 'C')[0]; sc.tl.dpt(adata); adata.obs['dpt_pseudotime']; adata; sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']); ```pytb; [Paste the error output produced by the above code here]; ```; ![1634300003(1)](https://user-images.githubusercontent.com/92583306/137486504-8a01bfc7-cbdf-409f-a730-dfec94f8c4f7.png). #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015
https://github.com/scverse/scanpy/issues/2015:821,Usability,guid,guide,821,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I do not know if it is the scanpy to be blamed. But two of my data both face this problem. When I run trajectory analysis upon. sc.tl.dpt(adata); sc.pl.draw_graph(adata, color=['seurat_clusters', 'dpt_pseudotime'], legend_loc='right margin',title = ['','pseudotime']). branches of image for dpt_pseudotime were all deep blue, which indicated close to zero. And. adata.obs['dpt_pseudotime']. also print number(0.07, 0.06, etc) that close to zero.; Therefore, I do not know if there is something wrong with my previous code, or there is something wrong with scanpy. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; import numpy as np; import pandas as pd; import matplotlib.pyplot as pl; from matplotlib import rcParams; import scanpy as sc; sc.settings.verbosity = 3; sc.logging.print_versions(); adata = sc.read_h5ad(""/home/dell/at scanpy/pbmc3k.h5ad""); adata; adata.X=adata.X.astype('float64'); sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20); sc.tl.draw_graph(adata); adata.obs['seurat_clusters']= adata.obs['seurat_clusters'].astype('category'); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='right margin',title = """"); sc.tl.diffmap(adata); sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap'); sc.tl.draw_graph(adata); sc.pl.draw_graph(adata, color='seurat_clusters', legend_loc='on data',title = """"); sc.tl.paga(adata, groups='seurat_clusters'); sc.pl.paga(adata, color=['seurat_clusters'],title = """"); new_cluster_names = [; 'A', 'B',; 'C', 'D',; 'E', 'F',; G',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2015
https://github.com/scverse/scanpy/issues/2018:627,Availability,toler,tolerance,627,"Hello, . Whenever I try to plot gene expression I get the following KeyError, regardless of the gene/plotting function. I have confirmed that all genes I have tried do exist in adata.var_names. Id like to highlight that my adata object was created from h5ad converted from seurat. How can I check the keys? . Thank you!. Lucy. ---. ```python; sc.pl.draw_graph(myeloid, color=['SPP1']); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2645 try:; -> 2646 return self._engine.get_loc(key); 2647 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-94-440b32bde3cc> in <module>(); ----> 1 sc.pl.draw_graph(myeloid, color=['SPP1']). /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:2313,Availability,error,error,2313,"a3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 233 palette=palette,; 234 use_raw=use_raw,; --> 235 gene_symbols=gene_symbols,; 236 ); 237 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in _get_color_values(adata, value_to_plot, groups, palette, use_raw, gene_symbols, layer); 1035 ] # TODO: Throw helpful error if this doesn't work; 1036 if use_raw and value_to_plot not in adata.obs.columns:; -> 1037 values = adata.raw.obs_vector(value_to_plot); 1038 else:; 1039 values = adata.obs_vector(value_to_plot, layer=layer). /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:3556,Availability,toler,tolerance,3556,"thon3.6/site-packages/anndata/_core/raw.py in obs_vector(self, k); 168 def obs_vector(self, k: str) -> np.ndarray:; 169 # TODO decorator to copy AnnData.obs_vector docstring; --> 170 idx = self._normalize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:3752,Availability,toler,tolerance,3752,"lize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:3762,Availability,toler,tolerance,3762,"lize_indices((slice(None), k)); 171 a = self.X[idx]; 172 if issparse(a):. /software/anaconda3/lib/python3.6/site-packages/anndata/_core/raw.py in _normalize_indices(self, packed_index); 159 obs, var = unpack_index(packed_index); 160 obs = _normalize_index(obs, self._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:4281,Performance,bottleneck,bottleneck,4281,"74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; networkx 2.5.1; numba 0.51.2; numexpr 2.6.5; numpy 1.19.5; packaging 21.0; pandas 1.1.5; parso 0.2.0; pexpect 4.5.0; pickleshare 0.7.4; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.4.5; ptyprocess 0.5.2; pycparser 2.18; pygments 2.2.0; pynndescent 0.5.0; pyparsing 2.2.0; pytz 2018.4; ruamel NA; scipy 1.4.1; scvelo 0.2.4; setuptools_scm NA; simplegeneric NA; six 1.11.0; sklearn 0.24.2; sphinxcontrib NA; storemagic NA; tables 3.4.3; texttable 1.6.2; toolz 0.9.0; tornado 5.0.2; tqdm 4.32.1; traitlets 4.3.2; typing_extensions",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:907,Security,hash,hashtable,907,"Hello, . Whenever I try to plot gene expression I get the following KeyError, regardless of the gene/plotting function. I have confirmed that all genes I have tried do exist in adata.var_names. Id like to highlight that my adata object was created from h5ad converted from seurat. How can I check the keys? . Thank you!. Lucy. ---. ```python; sc.pl.draw_graph(myeloid, color=['SPP1']); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2645 try:; -> 2646 return self._engine.get_loc(key); 2647 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-94-440b32bde3cc> in <module>(); ----> 1 sc.pl.draw_graph(myeloid, color=['SPP1']). /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:1003,Security,hash,hashtable,1003," Whenever I try to plot gene expression I get the following KeyError, regardless of the gene/plotting function. I have confirmed that all genes I have tried do exist in adata.var_names. Id like to highlight that my adata object was created from h5ad converted from seurat. How can I check the keys? . Thank you!. Lucy. ---. ```python; sc.pl.draw_graph(myeloid, color=['SPP1']); ```. ```pytb; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2645 try:; -> 2646 return self._engine.get_loc(key); 2647 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last); <ipython-input-94-440b32bde3cc> in <module>(); ----> 1 sc.pl.draw_graph(myeloid, color=['SPP1']). /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in draw_graph(adata, layout, **kwargs); 701 ); 702 ; --> 703 return embedding(adata, basis, **kwargs); 704 ; 705 . /software/anaconda3/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, img_key, crop_coord, alpha_img, bw, library_id, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:4013,Security,hash,hashtable,4013,"f._adata.obs_names); --> 161 var = _normalize_index(var, self.var_names); 162 return obs, var; 163 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; networkx 2.5.1; numba 0.51.2; numexpr 2.6.5; numpy 1.19.5; packaging 21.0; pandas 1.1.5; parso 0.2.0; pexpect 4.5.0; pickleshare 0.7.4; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.4.5; ptyprocess 0.5.2; pycparser 2.18; pygments 2.2.0; pynndescent 0.5.0; pypa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:4109,Security,hash,hashtable,4109,"63 . /software/anaconda3/lib/python3.6/site-packages/anndata/_core/index.py in _normalize_index(indexer, index); 72 return indexer; 73 elif isinstance(indexer, str):; ---> 74 return index.get_loc(indexer) # int; 75 elif isinstance(indexer, (Sequence, np.ndarray, pd.Index, spmatrix, np.matrix)):; 76 if hasattr(indexer, ""shape"") and (. /software/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 2646 return self._engine.get_loc(key); 2647 except KeyError:; -> 2648 return self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; networkx 2.5.1; numba 0.51.2; numexpr 2.6.5; numpy 1.19.5; packaging 21.0; pandas 1.1.5; parso 0.2.0; pexpect 4.5.0; pickleshare 0.7.4; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.4.5; ptyprocess 0.5.2; pycparser 2.18; pygments 2.2.0; pynndescent 0.5.0; pyparsing 2.2.0; pytz 2018.4; ruamel NA; scipy 1.4.1; scvelo 0.2.4; setuptools_scm NA; simplegeneric",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:5601,Testability,log,logical,5601,"self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; networkx 2.5.1; numba 0.51.2; numexpr 2.6.5; numpy 1.19.5; packaging 21.0; pandas 1.1.5; parso 0.2.0; pexpect 4.5.0; pickleshare 0.7.4; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.4.5; ptyprocess 0.5.2; pycparser 2.18; pygments 2.2.0; pynndescent 0.5.0; pyparsing 2.2.0; pytz 2018.4; ruamel NA; scipy 1.4.1; scvelo 0.2.4; setuptools_scm NA; simplegeneric NA; six 1.11.0; sklearn 0.24.2; sphinxcontrib NA; storemagic NA; tables 3.4.3; texttable 1.6.2; toolz 0.9.0; tornado 5.0.2; tqdm 4.32.1; traitlets 4.3.2; typing_extensions NA; umap 0.4.6; wcwidth NA; yaml 5.1.2; zipp NA; zmq 17.0.0; -----; IPython 6.4.0; jupyter_client 5.2.3; jupyter_core 4.4.0; jupyterlab 0.32.1; notebook 5.5.0; -----; Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0]; Linux-3.10.0-957.21.3.el7.x86_64-x86_64-with-centos-7.6.1810-Core; 120 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/issues/2018:5101,Usability,simpl,simplegeneric,5101,"self._engine.get_loc(self._maybe_cast_indexer(key)); 2649 indexer = self.get_indexer([key], method=method, tolerance=tolerance); 2650 if indexer.ndim > 1 or indexer.size > 1:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'SPP1'. ```. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.7.2; sinfo 0.3.4; -----; PIL 8.4.0; backcall 0.1.0; bottleneck 1.2.1; cffi 1.11.5; cloudpickle 0.5.3; colorama 0.3.9; cycler 0.10.0; cython_runtime NA; cytoolz 0.9.0.1; dask 0.17.5; dateutil 2.7.3; decorator 4.3.0; fa2 NA; flaskext NA; get_version 2.1; google NA; h5py 2.10.0; igraph 0.9.7; ipykernel 4.8.2; ipython_genutils 0.2.0; ipywidgets 7.2.1; jedi 0.12.0; joblib 0.13.2; kiwisolver 1.0.1; legacy_api_wrap 1.2; leidenalg 0.8.8; llvmlite 0.34.0; louvain 0.6.1; lxml NA; matplotlib 3.3.4; mpl_toolkits NA; natsort 6.0.0; networkx 2.5.1; numba 0.51.2; numexpr 2.6.5; numpy 1.19.5; packaging 21.0; pandas 1.1.5; parso 0.2.0; pexpect 4.5.0; pickleshare 0.7.4; pkg_resources NA; prompt_toolkit 1.0.15; psutil 5.4.5; ptyprocess 0.5.2; pycparser 2.18; pygments 2.2.0; pynndescent 0.5.0; pyparsing 2.2.0; pytz 2018.4; ruamel NA; scipy 1.4.1; scvelo 0.2.4; setuptools_scm NA; simplegeneric NA; six 1.11.0; sklearn 0.24.2; sphinxcontrib NA; storemagic NA; tables 3.4.3; texttable 1.6.2; toolz 0.9.0; tornado 5.0.2; tqdm 4.32.1; traitlets 4.3.2; typing_extensions NA; umap 0.4.6; wcwidth NA; yaml 5.1.2; zipp NA; zmq 17.0.0; -----; IPython 6.4.0; jupyter_client 5.2.3; jupyter_core 4.4.0; jupyterlab 0.32.1; notebook 5.5.0; -----; Python 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) [GCC 7.2.0]; Linux-3.10.0-957.21.3.el7.x86_64-x86_64-with-centos-7.6.1810-Core; 120 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2018
https://github.com/scverse/scanpy/pull/2020:79,Deployability,update,update,79,"Conflict in the sphinx versions, manual backport of #2019. * pin sphinx<4.2; * update violin plots",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2020
https://github.com/scverse/scanpy/pull/2023:97,Safety,predict,predictions,97,"This is a bugfix to allow for the fact that Scrublet doesn't always find a threshold and produce predictions by:. - Detecting when threshold not present, and setting prediction column to False'; - Not assuming presence of threshold in plot functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023
https://github.com/scverse/scanpy/pull/2023:116,Safety,Detect,Detecting,116,"This is a bugfix to allow for the fact that Scrublet doesn't always find a threshold and produce predictions by:. - Detecting when threshold not present, and setting prediction column to False'; - Not assuming presence of threshold in plot functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023
https://github.com/scverse/scanpy/pull/2023:166,Safety,predict,prediction,166,"This is a bugfix to allow for the fact that Scrublet doesn't always find a threshold and produce predictions by:. - Detecting when threshold not present, and setting prediction column to False'; - Not assuming presence of threshold in plot functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2023
https://github.com/scverse/scanpy/issues/2024:167,Usability,simpl,simple,167,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ![](https://els-jbs-prod-cdn.jbs.elsevierhealth.com/cms/attachment/e9e581b0-24ce-4e5b-a848-11de803dba32/gr3_lrg.jpg). Hi! It would be great if Scanpy could create sublevels of annotation like the the attached figure 3D of the seurat v4 paper. This would make legends clearer in cases where you have different subtypes of T cells for example. For instance the `color` argument could take as an input a dictionary with the label categories.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2024
https://github.com/scverse/scanpy/issues/2024:736,Usability,clear,clearer,736,<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. ![](https://els-jbs-prod-cdn.jbs.elsevierhealth.com/cms/attachment/e9e581b0-24ce-4e5b-a848-11de803dba32/gr3_lrg.jpg). Hi! It would be great if Scanpy could create sublevels of annotation like the the attached figure 3D of the seurat v4 paper. This would make legends clearer in cases where you have different subtypes of T cells for example. For instance the `color` argument could take as an input a dictionary with the label categories.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2024
https://github.com/scverse/scanpy/issues/2026:324,Usability,learn,learn,324,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . The UMAP embeddings appear incorrect using the 0.5.2 version of umap-learn Scanpy [pbmc3k tutorial example](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). These results can be reproduced using the Google Colab links. . * colab notebook [scanpy_pbmc3k_umap-learn_0.5.1.ipynb](https://colab.research.google.com/drive/1kAPRClaUWoZdao458Q_6fwnxQaQ4xwsP?usp=sharing). ![Screen Shot 2021-10-29 at 4 25 46 PM](https://user-images.githubusercontent.com/8352840/139497658-454d28e8-1988-4e1e-8014-2d234348d271.png). * colab notebook [scanpy_pbmc3k_umap-learn_0.5.2.ipynb](https://colab.research.google.com/drive/1_J5Kzx-Qja_rIvCW3ziAamgdagq2x0op?usp=sharing); ![Screen Shot 2021-10-29 at 4 25 52 PM](https://user-images.githubusercontent.com/8352840/139497674-93d80465-5c2c-4865-a0d3-04dde2a76b17.png). ```python; # we copied the code from the pbmc3k example: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```. #### Versions. Scanpy 1.8.1. The issue seems to be the new version of umap-learn 0.5.2. We also raised this issue on the umap-learn repo here https://github.com/lmcinnes/umap/issues/798,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026
https://github.com/scverse/scanpy/issues/2026:1265,Usability,learn,learn,1265,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . The UMAP embeddings appear incorrect using the 0.5.2 version of umap-learn Scanpy [pbmc3k tutorial example](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). These results can be reproduced using the Google Colab links. . * colab notebook [scanpy_pbmc3k_umap-learn_0.5.1.ipynb](https://colab.research.google.com/drive/1kAPRClaUWoZdao458Q_6fwnxQaQ4xwsP?usp=sharing). ![Screen Shot 2021-10-29 at 4 25 46 PM](https://user-images.githubusercontent.com/8352840/139497658-454d28e8-1988-4e1e-8014-2d234348d271.png). * colab notebook [scanpy_pbmc3k_umap-learn_0.5.2.ipynb](https://colab.research.google.com/drive/1_J5Kzx-Qja_rIvCW3ziAamgdagq2x0op?usp=sharing); ![Screen Shot 2021-10-29 at 4 25 52 PM](https://user-images.githubusercontent.com/8352840/139497674-93d80465-5c2c-4865-a0d3-04dde2a76b17.png). ```python; # we copied the code from the pbmc3k example: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```. #### Versions. Scanpy 1.8.1. The issue seems to be the new version of umap-learn 0.5.2. We also raised this issue on the umap-learn repo here https://github.com/lmcinnes/umap/issues/798,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026
https://github.com/scverse/scanpy/issues/2026:1316,Usability,learn,learn,1316,- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample . The UMAP embeddings appear incorrect using the 0.5.2 version of umap-learn Scanpy [pbmc3k tutorial example](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). These results can be reproduced using the Google Colab links. . * colab notebook [scanpy_pbmc3k_umap-learn_0.5.1.ipynb](https://colab.research.google.com/drive/1kAPRClaUWoZdao458Q_6fwnxQaQ4xwsP?usp=sharing). ![Screen Shot 2021-10-29 at 4 25 46 PM](https://user-images.githubusercontent.com/8352840/139497658-454d28e8-1988-4e1e-8014-2d234348d271.png). * colab notebook [scanpy_pbmc3k_umap-learn_0.5.2.ipynb](https://colab.research.google.com/drive/1_J5Kzx-Qja_rIvCW3ziAamgdagq2x0op?usp=sharing); ![Screen Shot 2021-10-29 at 4 25 52 PM](https://user-images.githubusercontent.com/8352840/139497674-93d80465-5c2c-4865-a0d3-04dde2a76b17.png). ```python; # we copied the code from the pbmc3k example: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html; ```. #### Versions. Scanpy 1.8.1. The issue seems to be the new version of umap-learn 0.5.2. We also raised this issue on the umap-learn repo here https://github.com/lmcinnes/umap/issues/798,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2026
https://github.com/scverse/scanpy/pull/2027:278,Availability,error,errors,278,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2027:21,Integrability,wrap,wrapper,21,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2027:77,Modifiability,variab,variable,77,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2027:311,Modifiability,variab,variables,311,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2027:479,Usability,guid,guidelines,479,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2027:510,Usability,guid,guide,510,"sc.pl.scatter() is a wrapper for _scatter_obs(). It checks to make sure; the variable names the caller is requesting to plot exist in var and/or; obs, but does not take into account whether it should look in raw based; on the use_raw flag, as _scatter_obs() does. This leads to errors when a; user asks to plot variables that are in the raw but not the filtered; matrix of adata. This commit fixes that bug. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2027
https://github.com/scverse/scanpy/pull/2028:11,Usability,learn,learn,11,As of umap-learn 0.5.2 an ``n_epochs`` value of 0 is now a valid value and None is used instead to indicate a value should be generated. To maintain forward compatability and backward compatibility with older umap-learn versions we instead make use of the epch setting criterion internal to umap-learn here directly. This should resolve issue #2026 and lmcinnes/umap#798. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2028
https://github.com/scverse/scanpy/pull/2028:214,Usability,learn,learn,214,As of umap-learn 0.5.2 an ``n_epochs`` value of 0 is now a valid value and None is used instead to indicate a value should be generated. To maintain forward compatability and backward compatibility with older umap-learn versions we instead make use of the epch setting criterion internal to umap-learn here directly. This should resolve issue #2026 and lmcinnes/umap#798. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2028
https://github.com/scverse/scanpy/pull/2028:296,Usability,learn,learn,296,As of umap-learn 0.5.2 an ``n_epochs`` value of 0 is now a valid value and None is used instead to indicate a value should be generated. To maintain forward compatability and backward compatibility with older umap-learn versions we instead make use of the epch setting criterion internal to umap-learn here directly. This should resolve issue #2026 and lmcinnes/umap#798. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2028
https://github.com/scverse/scanpy/pull/2028:443,Usability,guid,guidelines,443,As of umap-learn 0.5.2 an ``n_epochs`` value of 0 is now a valid value and None is used instead to indicate a value should be generated. To maintain forward compatability and backward compatibility with older umap-learn versions we instead make use of the epch setting criterion internal to umap-learn here directly. This should resolve issue #2026 and lmcinnes/umap#798. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2028
https://github.com/scverse/scanpy/pull/2028:474,Usability,guid,guide,474,As of umap-learn 0.5.2 an ``n_epochs`` value of 0 is now a valid value and None is used instead to indicate a value should be generated. To maintain forward compatability and backward compatibility with older umap-learn versions we instead make use of the epch setting criterion internal to umap-learn here directly. This should resolve issue #2026 and lmcinnes/umap#798. <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2028
https://github.com/scverse/scanpy/issues/2029:263,Testability,test,test,263,"Hello all,; In the “Finding marker genes” part of PBMC3K tutorial, the authors mentioned that “For this, by default, the .raw attribute of AnnData is used in case it has been initialized before” and the fuction `sc.tl.rank_genes_groups(adata, ‘leiden’, method=‘t-test’)` setting `use_raw=True` as default.; I tried `use_raw=False` in this `sc.tl.rank_genes_groups()` function and found that the results of marker genes are quite different. So, which data is recommended for finding the marker genes, adata after scaling, which is `use_raw=False`, or `adata.raw`?; Thanks!; Best; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2029
https://github.com/scverse/scanpy/issues/2030:391,Availability,error,errors,391,"Hello all,; For these 2 functions,; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; the authors make `inplace=True` as default. Because I want to tranfer the output into an variable, I change these functions to; ```python; a=sc.pp.filter_cells(adata, min_genes=200, inplace=False); sc.pp.filter_genes(a, min_cells=3, inplace=False); ```; but it creates errors and the output of a is NoType:; ```python; aceback (most recent call last):; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py”, line 3343, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File “”, line 2, in; sc.pp.filter_genes(a, min_cells=3, inplace=False) # exclude genes only expressed in <3 cells; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\scanpy\preprocessing_simple.py”, line 259, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ```. Does anybody know why inplace=False doesn’t work?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030
https://github.com/scverse/scanpy/issues/2030:211,Modifiability,variab,variable,211,"Hello all,; For these 2 functions,; `sc.pp.filter_cells(adata, min_genes=200)`; `sc.pp.filter_genes(adata, min_cells=3)`; the authors make `inplace=True` as default. Because I want to tranfer the output into an variable, I change these functions to; ```python; a=sc.pp.filter_cells(adata, min_genes=200, inplace=False); sc.pp.filter_genes(a, min_cells=3, inplace=False); ```; but it creates errors and the output of a is NoType:; ```python; aceback (most recent call last):; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\IPython\core\interactiveshell.py”, line 3343, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File “”, line 2, in; sc.pp.filter_genes(a, min_cells=3, inplace=False) # exclude genes only expressed in <3 cells; File “C:\Users\Yuanjian\AppData\Local\Programs\Python\Python36\lib\site-packages\scanpy\preprocessing_simple.py”, line 259, in filter_genes; X if min_cells is None and max_cells is None else X > 0, axis=0; ```. Does anybody know why inplace=False doesn’t work?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2030
https://github.com/scverse/scanpy/pull/2031:0,Deployability,update,updates,0,updates:; - [github.com/psf/black: 21.9b0 → 21.10b0](https://github.com/psf/black/compare/21.9b0...21.10b0),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2031
https://github.com/scverse/scanpy/pull/2033:19,Deployability,Update,Update,19,Backport PR #2028: Update for cope with issue introduced in umap-learn 0.5.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2033
https://github.com/scverse/scanpy/pull/2033:65,Usability,learn,learn,65,Backport PR #2028: Update for cope with issue introduced in umap-learn 0.5.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2033
https://github.com/scverse/scanpy/issues/2034:311,Availability,error,error,311,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034
https://github.com/scverse/scanpy/issues/2034:251,Modifiability,variab,variable,251,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034
https://github.com/scverse/scanpy/issues/2034:371,Modifiability,layers,layers,371,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034
https://github.com/scverse/scanpy/issues/2034:449,Safety,safe,safe,449,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Selection of highly variable genes works fine in default settings, but I get an error when I try to use seurat_v3 flavor. ```python; adata2.layers[""counts""] = adata2.X.copy(); adata2.raw = adata2 # keep full dimension safe; sc.pp.normalize_total(adata2, target_sum=1e4); sc.pp.log1p(adata2); sc.pp.highly_variable_genes(; adata2,; flavor=""seurat_v3"",; n_top_genes=3000,; layer=""counts"",; batch_key=""Sample"",; subset=True; ); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-18-64d280f5029c> in <module>; 3 sc.pp.normalize_total(adata2, target_sum=1e4); 4 sc.pp.log1p(adata2); ----> 5 sc.pp.highly_variable_genes(; 6 adata2,; 7 flavor=""seurat_v3"",. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values); 417 ; 418 if flavor == 'seurat_v3':; --> 419 return _highly_variable_genes_seurat_v3(; 420 adata,; 421 layer=layer,. /data04/projects04/MarianaBoroni/lbbc_members/lib/conda_envs/diogoamb/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace); 83 x = np.log10(mean[not_const]); 84 model = loess(x, y, span=span, degree=2); ---> 85 model.fit(); 86 estimat_var[not_const] = model.outputs.fitted_values; 87 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'svddc failed in l2fit.'; ```. #### Versions; 0.10.00",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2034
https://github.com/scverse/scanpy/pull/2037:19,Deployability,release,release,19,Prepping the 1.8.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2037
https://github.com/scverse/scanpy/pull/2038:30,Deployability,release,release,30,Backport PR #2037: Prep 1.8.2 release,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2038
https://github.com/scverse/scanpy/pull/2039:4,Deployability,release,release,4,Add release notes template for 1.8.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2039
https://github.com/scverse/scanpy/issues/2040:488,Availability,Down,Download,488,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:954,Availability,Down,Downloads,954,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:1679,Availability,error,errors,1679,"ore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.11.1 python-igraph==0.9.6 pynndescent==0.5.4. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:2213,Availability,Down,Downloads,2213,"ore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.11.1 python-igraph==0.9.6 pynndescent==0.5.4. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:1506,Security,validat,validate,1506,"ested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:1515,Security,validat,validate,1515,"ested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:515,Testability,test,tested,515,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). Download HCA loom dataset (tested with data from: https://data.humancellatlas.org/explore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/issues/2040:2489,Usability,learn,learn,2489,"ore/projects/0c3b7785-f74d-4091-8616-a68757e4c2a8/m/project-matrices). ```python; import scanpy; loomdata = scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""). #I also tried:; loomdata=scanpy.read_loom(""path/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom"", obs_names='CellID', var_names='ensembl_ids'. ```. ```pytb; scanpy.read_loom(""/Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f; return f(*args, **kwargs); File ""/usr/local/anaconda3/lib/python3.8/site-packages/anndata/_io/read.py"", line 261, in read_loom; with connect(filename, ""r"", **kwargs) as lc:; File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 1140, in connect; return LoomConnection(filename, mode, validate=validate, spec_version=spec_version); File ""/usr/local/anaconda3/lib/python3.8/site-packages/loompy/loompy.py"", line 84, in __init__; raise ValueError(""\n"".join(lv.errors) + f""\n{filename} does not appead to be a valid Loom file according to Loom spec version '{spec_version}'""); ValueError: Row attribute 'Gene' dtype object is not allowed; Row attribute 'ensembl_ids' dtype object is not allowed; Row attribute 'gene_names' dtype object is not allowed; Column attribute 'CellID' dtype object is not allowed; Column attribute 'cell_names' dtype object is not allowed; Column attribute 'input_id' dtype object is not allowed; For help, see http://linnarssonlab.org/loompy/format/; /Users/acastanza/Downloads/bone-marrow-myeloma-human-hematopoeitic-10XV2.loom does not appead to be a valid Loom file according to Loom spec version '2.0.1'; ```. #### Versions. <details>. scanpy==1.8.1 anndata==0.7.6.dev49+g19ba44d umap==0.5.1 numpy==1.19.2 scipy==1.7.1 pandas==1.2.4 scikit-learn==0.24.2 statsmodels==0.11.1 python-igraph==0.9.6 pynndescent==0.5.4. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2040
https://github.com/scverse/scanpy/pull/2042:0,Testability,Test,Testing,0,"Testing if I did the pyproject.toml right for pep-621. Still need to decide if it's also worth updating it for the 1.8.x branch, or if this should wait until we're near `1.9`. Fixes #1776 if merged.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2042
https://github.com/scverse/scanpy/issues/2043:165,Availability,error,error,165,"Haven't done much investigation into why, but the [Fly Cell Atlas](https://flycellatlas.org) head dataset (10x, Stringent, H5AD) causes `sc.tl.embedding_density` to error when `groupby=""annotation_broad_extrapolated""`. ```python; import scanpy as sc; # Warning: 2.5gb; !wget -O s_fca_biohub_head_10x.h5ad https://cloud.flycellatlas.org/index.php/s/LAEybPc2HZnpzKs/download. adata = sc.read_h5ad(""s_fca_biohub_head_10x.h5ad""); sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""); ```. <details>; <summary> traceback </summary>. ```pytb; /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py:563: RuntimeWarning: Degrees of freedom <= 0 for slice; self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,; /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide; c *= np.true_divide(1, fact); /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply; c *= np.true_divide(1, fact); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_4569/1429565136.py in <module>; ----> 1 sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""). ~/github/scanpy/scanpy/tools/_embedding_density.py in embedding_density(adata, basis, groupby, key_added, components); 164 embed_y = adata.obsm[f'X_{basis}'][cat_mask, components[1]]; 165 ; --> 166 dens_embed = _calc_density(embed_x, embed_y); 167 density_values[cat_mask] = dens_embed; 168 . ~/github/scanpy/scanpy/tools/_embedding_density.py in _calc_density(x, y); 19 # Calculate the point density; 20 xy = np.vstack([x, y]); ---> 21 z = gaussian_kde(xy)(xy); 22 ; 23 min_z = np.min(z). /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:364,Availability,down,download,364,"Haven't done much investigation into why, but the [Fly Cell Atlas](https://flycellatlas.org) head dataset (10x, Stringent, H5AD) causes `sc.tl.embedding_density` to error when `groupby=""annotation_broad_extrapolated""`. ```python; import scanpy as sc; # Warning: 2.5gb; !wget -O s_fca_biohub_head_10x.h5ad https://cloud.flycellatlas.org/index.php/s/LAEybPc2HZnpzKs/download. adata = sc.read_h5ad(""s_fca_biohub_head_10x.h5ad""); sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""); ```. <details>; <summary> traceback </summary>. ```pytb; /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py:563: RuntimeWarning: Degrees of freedom <= 0 for slice; self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,; /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide; c *= np.true_divide(1, fact); /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py:2493: RuntimeWarning: invalid value encountered in multiply; c *= np.true_divide(1, fact); ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /var/folders/bd/43q20k0n6z15tdfzxvd22r7c0000gn/T/ipykernel_4569/1429565136.py in <module>; ----> 1 sc.tl.embedding_density(adata, groupby=""annotation_broad_extrapolated""). ~/github/scanpy/scanpy/tools/_embedding_density.py in embedding_density(adata, basis, groupby, key_added, components); 164 embed_y = adata.obsm[f'X_{basis}'][cat_mask, components[1]]; 165 ; --> 166 dens_embed = _calc_density(embed_x, embed_y); 167 density_values[cat_mask] = dens_embed; 168 . ~/github/scanpy/scanpy/tools/_embedding_density.py in _calc_density(x, y); 19 # Calculate the point density; 20 xy = np.vstack([x, y]); ---> 21 z = gaussian_kde(xy)(xy); 22 ; 23 min_z = np.min(z). /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:2987,Availability,mask,masked,2987,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:3645,Availability,error,error,3645,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:3758,Availability,mask,mask,3758,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:3804,Availability,mask,mask,3804,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2043:3855,Availability,mask,mask,3855,"ts/kde.py in __init__(self, dataset, bw_method, weights); 204 self._neff = 1/sum(self._weights**2); 205 ; --> 206 self.set_bandwidth(bw_method=bw_method); 207 ; 208 def evaluate(self, points):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in set_bandwidth(self, bw_method); 552 raise ValueError(msg); 553 ; --> 554 self._compute_covariance(); 555 ; 556 def _compute_covariance(self):. /usr/local/lib/python3.8/site-packages/scipy/stats/kde.py in _compute_covariance(self); 564 bias=False,; 565 aweights=self.weights)); --> 566 self._data_inv_cov = linalg.inv(self._data_covariance); 567 ; 568 self.covariance = self._data_covariance * self.factor**2. /usr/local/lib/python3.8/site-packages/scipy/linalg/basic.py in inv(a, overwrite_a, check_finite); 937 ; 938 """"""; --> 939 a1 = _asarray_validated(a, check_finite=; ); 940 if len(a1.shape) != 2 or a1.shape[0] != a1.shape[1]:; 941 raise ValueError('expected square matrix'). /usr/local/lib/python3.8/site-packages/scipy/_lib/_util.py in _asarray_validated(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact); 291 raise ValueError('masked arrays are not supported'); 292 toarray = np.asarray_chkfinite if check_finite else np.asarray; --> 293 a = toarray(a); 294 if not objects_ok:; 295 if a.dtype is np.dtype('O'):. /usr/local/lib/python3.8/site-packages/numpy/lib/function_base.py in asarray_chkfinite(a, dtype, order); 486 a = asarray(a, dtype=dtype, order=order); 487 if a.dtype.char in typecodes['AllFloat'] and not np.isfinite(a).all():; --> 488 raise ValueError(; 489 ""array must not contain infs or NaNs""); 490 return a. ValueError: array must not contain infs or NaNs; ```. </details>. I think it's that one of the categories only has one observation. Probably just needs a better error. ------------. Yup, one obs reproduces:. ```python; adata = sc.datasets.pbmc3k_processed().raw.to_adata(); mask = adata.obs[""louvain""] != ""CD4 T cells""; mask.iloc[0] = True; sc.tl.embedding_density(adata[mask], groupby=""louvain""); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2043
https://github.com/scverse/scanpy/issues/2044:628,Performance,bottleneck,bottleneck,628,"### Minimal code sample (that we can copy&paste without having any data). when I follow your tutorial on https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html; to the ; ```python; cdata = sc.external.pp.mnn_correct(alldata['covid_1'],alldata['covid_15'],alldata['covid_17'],; alldata['ctrl_5'],alldata['ctrl_13'],alldata['ctrl_14'], ; svd_dim = 50, batch_key = 'sample', save_raw = True, var_subset = var_genes); ```; line, then it said; `[1] 1764091 illegal hardware instruction (core dumped`. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.2.0; bottleneck 1.3.2; cffi 1.14.5; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; fsspec 0.9.0; h5py 2.10.0; igraph 0.9.8; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.36.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 8.0.0; numba 0.53.1; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 5.4.1; zope NA; -----; Python 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]; Linux-5.11.0-38-generic-x86_64-with-glibc2.10; 64 logical CPU cores; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2044
https://github.com/scverse/scanpy/issues/2044:1382,Testability,log,logical,1382,"### Minimal code sample (that we can copy&paste without having any data). when I follow your tutorial on https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/scanpy/scanpy_03_integration.html; to the ; ```python; cdata = sc.external.pp.mnn_correct(alldata['covid_1'],alldata['covid_15'],alldata['covid_17'],; alldata['ctrl_5'],alldata['ctrl_13'],alldata['ctrl_14'], ; svd_dim = 50, batch_key = 'sample', save_raw = True, var_subset = var_genes); ```; line, then it said; `[1] 1764091 illegal hardware instruction (core dumped`. #### Versions. <details>. -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.2.0; bottleneck 1.3.2; cffi 1.14.5; cloudpickle 1.6.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.0; dask 2021.04.0; dateutil 2.8.1; fsspec 0.9.0; h5py 2.10.0; igraph 0.9.8; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.36.0; matplotlib 3.3.4; mkl 2.3.0; mpl_toolkits NA; natsort 8.0.0; numba 0.53.1; numexpr 2.7.3; numpy 1.20.1; packaging 20.9; pandas 1.2.4; pkg_resources NA; psutil 5.8.0; pyparsing 2.4.7; pytz 2021.1; scipy 1.6.2; six 1.15.0; sklearn 0.24.1; sphinxcontrib NA; tables 3.6.1; tblib 1.7.0; texttable 1.6.4; tlz 0.11.0; toolz 0.11.1; typing_extensions NA; wcwidth 0.2.5; yaml 5.4.1; zope NA; -----; Python 3.8.8 (default, Apr 13 2021, 19:58:26) [GCC 7.3.0]; Linux-5.11.0-38-generic-x86_64-with-glibc2.10; 64 logical CPU cores; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2044
https://github.com/scverse/scanpy/issues/2045:653,Deployability,install,installed,653,"Hello Scanpy,; I reimaged my Windows from 20H2 to 21H1 today and reinstalled the environment for scanpy. However, in the new environment, when I run the official workflow of pbmc3k by just using the official pbmc3k notebook. The UMAP becomes different from the pbmc3k tutorial like below. But all other codings generate the same results and plots as the pbmc3k tutorial.; ![image](https://user-images.githubusercontent.com/75048821/140598534-5425f05c-4bb1-4bb7-97d9-d37a0ce1f9dc.png); ![image](https://user-images.githubusercontent.com/75048821/140598551-5cd98b37-48b9-44ba-bacb-b4b2ac155576.png). Then I run the same coding on my older computer, which installed scanpy one month ago, the UMAP is the same as the standard workflow.; ![image](https://user-images.githubusercontent.com/75048821/140632101-6536d00e-f180-407d-9cd1-a79991280e8a.png). **Is it because of the packages' problem or Windows 21H1? I list the packages information here. Could you please help me to solve this issue?**. <html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/Yuanjian/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; .font5; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;}; tr; 	{mso-height-source:auto;; 	mso-ruby-visibility:none;}; col; 	{mso-width-source:auto;; 	mso-ruby-visibility:non",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2045:4378,Integrability,wrap,wrap,4378,0.2.0; bleach | 4.0.0 | 4.0.0; brotlipy | 0.7.0 | 0.7.0; cached-property | 1.5.2 | 1.5.2; certifi | 2021.5.30 | 2021.5.30; cffi | 1.14.6 | 1.14.6; charset-normalizer | 2.0.4 | 2.0.4; colorama | 0.4.4 | 0.4.4; contextvars | 2.4 | 2.4; **cryptography | 3.4.7 | 35.0.0**; cycler | 0.10.0 | 0.11.0; dataclasses | 0.8 | 0.8; decorator | 4.4.2 | 4.4.2; defusedxml | 0.7.1 | 0.7.1; entrypoints | 0.3 | 0.3; get-version | 2.1 | 2.1; h5py | 3.1.0 | 3.1.0; idna | 3.2 | 3.2; igraph | 0.9.8 | 0.9.8; immutables | 0.16 | 0.16; importlib-metadata | 4.8.1 | 4.8.1; ipykernel | 5.3.4 | 5.3.4; ipython | 7.16.1 | 7.16.1; ipython-genutils | 0.2.0 | 0.2.0; jedi | 0.17.0 | 0.17.0; **Jinja2 | 3.0.1 | 3.0.2**; joblib | 1.1.0 | 1.1.0; json5 | 0.9.6 | 0.9.6; jsonschema | 3.2.0 | 3.2.0; jupyter-client | 7.0.1 | 7.0.1; jupyter-core | 4.8.1 | 4.8.1; jupyter-server | 1.4.1 | 1.4.1; **jupyterlab | 3.1.7 | 3.2.1**; jupyterlab-pygments | 0.1.2 | 0.1.2; jupyterlab-server | 2.8.2 | 2.8.2; kiwisolver | 1.3.1 | 1.3.1; legacy-api-wrap | 1.2 | 1.2; leidenalg | 0.8.8 | 0.8.8; llvmlite | 0.36.0 | 0.36.0; MarkupSafe | 2.0.1 | 2.0.1; matplotlib | 3.3.4 | 3.3.4; mistune | 0.8.4 | 0.8.4; **natsort | 7.1.1 | 8.0.0**; nbclassic | 0.2.6 | 0.2.6; nbclient | 0.5.3 | 0.5.3; nbconvert | 6.0.7 | 6.0.7; nbformat | 5.1.3 | 5.1.3; nest-asyncio | 1.5.1 | 1.5.1; networkx | 2.5.1 | 2.5.1; notebook | 6.4.3 | 6.4.3; numba | 0.53.1 | 0.53.1; numexpr | 2.7.3 | 2.7.3; numpy | 1.19.5 | 1.19.5; packaging | 21 | 21; pandas | 1.1.5 | 1.1.5; pandocfilters | 1.4.3 | 1.4.3; parso | 0.8.2 | 0.8.2; patsy | 0.5.2 | 0.5.2; pickleshare | 0.7.5 | 0.7.5; Pillow | 8.4.0 | 8.4.0; pip | 21.0.1 | 21.2.2; prometheus-client | 0.11.0 | 0.11.0; prompt-toolkit | 3.0.20 | 3.0.20; pycparser | 2.2 | 2.2; Pygments | 2.10.0 | 2.10.0; pynndescent | 0.5.5 | 0.5.5; pyOpenSSL | 20.0.1 | 21.0.0; **pyparsing | 2.4.7 | 3.0.4**; pyrsistent | 0.17.3 | 0.17.3; PySocks | 1.7.1 | 1.7.1; python-dateutil | 2.8.2 | 2.8.2; python-igraph | 0.9.8 | 0.9.8; pytz | 2021.3 | 2021.3; ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2045:3432,Performance,cache,cached-property,3432,"to;; 	mso-protection:locked visible;; 	white-space:nowrap;; 	mso-rotate:0;}; .xl65; 	{text-align:center;}; .xl66; 	{text-align:center;; 	border:.5pt solid windowtext;}; .xl67; 	{color:red;; 	text-align:center;; 	border:.5pt solid windowtext;}; .xl68; 	{font-weight:700;; 	text-align:center;; 	border:.5pt solid windowtext;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">.   | Right UMAP | Wrong UMAP; -- | -- | --; Package | Version | Version; Anaconda | 2.1.0 | 2.1.0; Python | 3.6.13 | 3.6.13; anndata | 0.7.6 | 0.7.6; anyio | 2.2.0 | 2.2.0; argon2-cffi | 20.1.0 | 20.1.0; async-generator | 1.1 | 1.1; attrs | 21.2.0 | 21.2.0; Babel | 2.9.1 | 2.9.1; backcall | 0.2.0 | 0.2.0; bleach | 4.0.0 | 4.0.0; brotlipy | 0.7.0 | 0.7.0; cached-property | 1.5.2 | 1.5.2; certifi | 2021.5.30 | 2021.5.30; cffi | 1.14.6 | 1.14.6; charset-normalizer | 2.0.4 | 2.0.4; colorama | 0.4.4 | 0.4.4; contextvars | 2.4 | 2.4; **cryptography | 3.4.7 | 35.0.0**; cycler | 0.10.0 | 0.11.0; dataclasses | 0.8 | 0.8; decorator | 4.4.2 | 4.4.2; defusedxml | 0.7.1 | 0.7.1; entrypoints | 0.3 | 0.3; get-version | 2.1 | 2.1; h5py | 3.1.0 | 3.1.0; idna | 3.2 | 3.2; igraph | 0.9.8 | 0.9.8; immutables | 0.16 | 0.16; importlib-metadata | 4.8.1 | 4.8.1; ipykernel | 5.3.4 | 5.3.4; ipython | 7.16.1 | 7.16.1; ipython-genutils | 0.2.0 | 0.2.0; jedi | 0.17.0 | 0.17.0; **Jinja2 | 3.0.1 | 3.0.2**; joblib | 1.1.0 | 1.1.0; json5 | 0.9.6 | 0.9.6; jsonschema | 3.2.0 | 3.2.0; jupyter-client | 7.0.1 | 7.0.1; jupyter-core | 4.8.1 | 4.8.1; jupyter-server | 1.4.1 | 1.4.1; **jupyterlab | 3.1.7 | 3.2.1**; jupyterlab-pygments | 0.1.2 | 0.1.2; jupyterlab-server | 2.8.2 | 2.8.2; kiwisolver | 1.3.1 | 1.3.1; legacy-api-wrap | 1.2 | 1.2; leidenalg | 0.8.8 | 0.8.8; llvmlite | 0.36.0 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2045:5822,Testability,test,testpath,5822,"| 0.1.2; jupyterlab-server | 2.8.2 | 2.8.2; kiwisolver | 1.3.1 | 1.3.1; legacy-api-wrap | 1.2 | 1.2; leidenalg | 0.8.8 | 0.8.8; llvmlite | 0.36.0 | 0.36.0; MarkupSafe | 2.0.1 | 2.0.1; matplotlib | 3.3.4 | 3.3.4; mistune | 0.8.4 | 0.8.4; **natsort | 7.1.1 | 8.0.0**; nbclassic | 0.2.6 | 0.2.6; nbclient | 0.5.3 | 0.5.3; nbconvert | 6.0.7 | 6.0.7; nbformat | 5.1.3 | 5.1.3; nest-asyncio | 1.5.1 | 1.5.1; networkx | 2.5.1 | 2.5.1; notebook | 6.4.3 | 6.4.3; numba | 0.53.1 | 0.53.1; numexpr | 2.7.3 | 2.7.3; numpy | 1.19.5 | 1.19.5; packaging | 21 | 21; pandas | 1.1.5 | 1.1.5; pandocfilters | 1.4.3 | 1.4.3; parso | 0.8.2 | 0.8.2; patsy | 0.5.2 | 0.5.2; pickleshare | 0.7.5 | 0.7.5; Pillow | 8.4.0 | 8.4.0; pip | 21.0.1 | 21.2.2; prometheus-client | 0.11.0 | 0.11.0; prompt-toolkit | 3.0.20 | 3.0.20; pycparser | 2.2 | 2.2; Pygments | 2.10.0 | 2.10.0; pynndescent | 0.5.5 | 0.5.5; pyOpenSSL | 20.0.1 | 21.0.0; **pyparsing | 2.4.7 | 3.0.4**; pyrsistent | 0.17.3 | 0.17.3; PySocks | 1.7.1 | 1.7.1; python-dateutil | 2.8.2 | 2.8.2; python-igraph | 0.9.8 | 0.9.8; pytz | 2021.3 | 2021.3; pywin32 | 228 | 228; pywinpty | 0.5.7 | 0.5.7; pyzmq | 22.2.1 | 22.2.1; requests | 2.26.0 | 2.26.0; scanpy | 1.7.2 | 1.7.2; scikit-learn | 0.24.2 | 0.24.2; scipy | 1.5.4 | 1.5.4; seaborn | 0.11.2 | 0.11.2; Send2Trash | 1.8.0 | 1.8.0; setuptools | 58.0.4 | 58.0.4; sinfo | 0.3.4 | 0.3.4; six | 1.16.0 | 1.16.0; sniffio | 1.2.0 | 1.2.0; statsmodels | 0.12.2 | 0.12.2; stdlib-list | 0.8.0 | 0.8.0; tables | 3.6.1 | 3.6.1; terminado | 0.9.4 | 0.9.4; testpath | 0.5.0 | 0.5.0; texttable | 1.6.4 | 1.6.4; threadpoolctl | 3.0.0 | 3.0.0; tornado | 6.1 | 6.1; tqdm | 4.62.3 | 4.62.3; traitlets | 4.3.3 | 4.3.3; typing-extensions | 3.10.0.2 | 3.10.0.2; **umap-learn | 0.5.1 | 0.5.2**; urllib3 | 1.26.7 | 1.26.7; wcwidth | 0.2.5 | 0.2.5; webencodings | 0.5.1 | 0.5.1; wheel | 0.37.0 | 0.37.0; win-inet-pton | 1.1.0 | 1.1.0; wincertstore | 0.2 | 0.2; xlrd | 1.2.0 | 1.2.0; zipp | 3.6.0 | 3.6.0. </body>. </html>. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2045:5507,Usability,learn,learn,5507,"| 0.1.2; jupyterlab-server | 2.8.2 | 2.8.2; kiwisolver | 1.3.1 | 1.3.1; legacy-api-wrap | 1.2 | 1.2; leidenalg | 0.8.8 | 0.8.8; llvmlite | 0.36.0 | 0.36.0; MarkupSafe | 2.0.1 | 2.0.1; matplotlib | 3.3.4 | 3.3.4; mistune | 0.8.4 | 0.8.4; **natsort | 7.1.1 | 8.0.0**; nbclassic | 0.2.6 | 0.2.6; nbclient | 0.5.3 | 0.5.3; nbconvert | 6.0.7 | 6.0.7; nbformat | 5.1.3 | 5.1.3; nest-asyncio | 1.5.1 | 1.5.1; networkx | 2.5.1 | 2.5.1; notebook | 6.4.3 | 6.4.3; numba | 0.53.1 | 0.53.1; numexpr | 2.7.3 | 2.7.3; numpy | 1.19.5 | 1.19.5; packaging | 21 | 21; pandas | 1.1.5 | 1.1.5; pandocfilters | 1.4.3 | 1.4.3; parso | 0.8.2 | 0.8.2; patsy | 0.5.2 | 0.5.2; pickleshare | 0.7.5 | 0.7.5; Pillow | 8.4.0 | 8.4.0; pip | 21.0.1 | 21.2.2; prometheus-client | 0.11.0 | 0.11.0; prompt-toolkit | 3.0.20 | 3.0.20; pycparser | 2.2 | 2.2; Pygments | 2.10.0 | 2.10.0; pynndescent | 0.5.5 | 0.5.5; pyOpenSSL | 20.0.1 | 21.0.0; **pyparsing | 2.4.7 | 3.0.4**; pyrsistent | 0.17.3 | 0.17.3; PySocks | 1.7.1 | 1.7.1; python-dateutil | 2.8.2 | 2.8.2; python-igraph | 0.9.8 | 0.9.8; pytz | 2021.3 | 2021.3; pywin32 | 228 | 228; pywinpty | 0.5.7 | 0.5.7; pyzmq | 22.2.1 | 22.2.1; requests | 2.26.0 | 2.26.0; scanpy | 1.7.2 | 1.7.2; scikit-learn | 0.24.2 | 0.24.2; scipy | 1.5.4 | 1.5.4; seaborn | 0.11.2 | 0.11.2; Send2Trash | 1.8.0 | 1.8.0; setuptools | 58.0.4 | 58.0.4; sinfo | 0.3.4 | 0.3.4; six | 1.16.0 | 1.16.0; sniffio | 1.2.0 | 1.2.0; statsmodels | 0.12.2 | 0.12.2; stdlib-list | 0.8.0 | 0.8.0; tables | 3.6.1 | 3.6.1; terminado | 0.9.4 | 0.9.4; testpath | 0.5.0 | 0.5.0; texttable | 1.6.4 | 1.6.4; threadpoolctl | 3.0.0 | 3.0.0; tornado | 6.1 | 6.1; tqdm | 4.62.3 | 4.62.3; traitlets | 4.3.3 | 4.3.3; typing-extensions | 3.10.0.2 | 3.10.0.2; **umap-learn | 0.5.1 | 0.5.2**; urllib3 | 1.26.7 | 1.26.7; wcwidth | 0.2.5 | 0.2.5; webencodings | 0.5.1 | 0.5.1; wheel | 0.37.0 | 0.37.0; win-inet-pton | 1.1.0 | 1.1.0; wincertstore | 0.2 | 0.2; xlrd | 1.2.0 | 1.2.0; zipp | 3.6.0 | 3.6.0. </body>. </html>. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2045:6026,Usability,learn,learn,6026,"| 0.1.2; jupyterlab-server | 2.8.2 | 2.8.2; kiwisolver | 1.3.1 | 1.3.1; legacy-api-wrap | 1.2 | 1.2; leidenalg | 0.8.8 | 0.8.8; llvmlite | 0.36.0 | 0.36.0; MarkupSafe | 2.0.1 | 2.0.1; matplotlib | 3.3.4 | 3.3.4; mistune | 0.8.4 | 0.8.4; **natsort | 7.1.1 | 8.0.0**; nbclassic | 0.2.6 | 0.2.6; nbclient | 0.5.3 | 0.5.3; nbconvert | 6.0.7 | 6.0.7; nbformat | 5.1.3 | 5.1.3; nest-asyncio | 1.5.1 | 1.5.1; networkx | 2.5.1 | 2.5.1; notebook | 6.4.3 | 6.4.3; numba | 0.53.1 | 0.53.1; numexpr | 2.7.3 | 2.7.3; numpy | 1.19.5 | 1.19.5; packaging | 21 | 21; pandas | 1.1.5 | 1.1.5; pandocfilters | 1.4.3 | 1.4.3; parso | 0.8.2 | 0.8.2; patsy | 0.5.2 | 0.5.2; pickleshare | 0.7.5 | 0.7.5; Pillow | 8.4.0 | 8.4.0; pip | 21.0.1 | 21.2.2; prometheus-client | 0.11.0 | 0.11.0; prompt-toolkit | 3.0.20 | 3.0.20; pycparser | 2.2 | 2.2; Pygments | 2.10.0 | 2.10.0; pynndescent | 0.5.5 | 0.5.5; pyOpenSSL | 20.0.1 | 21.0.0; **pyparsing | 2.4.7 | 3.0.4**; pyrsistent | 0.17.3 | 0.17.3; PySocks | 1.7.1 | 1.7.1; python-dateutil | 2.8.2 | 2.8.2; python-igraph | 0.9.8 | 0.9.8; pytz | 2021.3 | 2021.3; pywin32 | 228 | 228; pywinpty | 0.5.7 | 0.5.7; pyzmq | 22.2.1 | 22.2.1; requests | 2.26.0 | 2.26.0; scanpy | 1.7.2 | 1.7.2; scikit-learn | 0.24.2 | 0.24.2; scipy | 1.5.4 | 1.5.4; seaborn | 0.11.2 | 0.11.2; Send2Trash | 1.8.0 | 1.8.0; setuptools | 58.0.4 | 58.0.4; sinfo | 0.3.4 | 0.3.4; six | 1.16.0 | 1.16.0; sniffio | 1.2.0 | 1.2.0; statsmodels | 0.12.2 | 0.12.2; stdlib-list | 0.8.0 | 0.8.0; tables | 3.6.1 | 3.6.1; terminado | 0.9.4 | 0.9.4; testpath | 0.5.0 | 0.5.0; texttable | 1.6.4 | 1.6.4; threadpoolctl | 3.0.0 | 3.0.0; tornado | 6.1 | 6.1; tqdm | 4.62.3 | 4.62.3; traitlets | 4.3.3 | 4.3.3; typing-extensions | 3.10.0.2 | 3.10.0.2; **umap-learn | 0.5.1 | 0.5.2**; urllib3 | 1.26.7 | 1.26.7; wcwidth | 0.2.5 | 0.2.5; webencodings | 0.5.1 | 0.5.1; wheel | 0.37.0 | 0.37.0; win-inet-pton | 1.1.0 | 1.1.0; wincertstore | 0.2 | 0.2; xlrd | 1.2.0 | 1.2.0; zipp | 3.6.0 | 3.6.0. </body>. </html>. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2045
https://github.com/scverse/scanpy/issues/2046:132,Availability,error,errors,132,"Hello Scanpy,; When I add parameter use_raw=False into sc.tl.rank_genes_groups() and sc.pl.rank_genes_groups_violin(), it generates errors as below.; ![image](https://user-images.githubusercontent.com/75048821/140627341-b0c08fbd-53b1-4ed8-b12d-9be71a65a6a5.png); ![image](https://user-images.githubusercontent.com/75048821/140627351-09708fcd-39ea-4602-8609-eca85ea6b843.png); ![image](https://user-images.githubusercontent.com/75048821/140627356-7faf0462-c852-436e-b69d-22f337dabae6.png). Another question is that, we shouldn't use the adata.raw for plotting becase the adata.raw doesn't regress out the mito gene expressions, should we?. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2046
https://github.com/scverse/scanpy/issues/2048:147,Deployability,release,released,147,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048
https://github.com/scverse/scanpy/issues/2048:2073,Deployability,update,updated,2073," exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-2-amd64-x86_64-with-glibc2.32; 4 logical CPU cores. Session information updated at 2021-11-10 22:03",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048
https://github.com/scverse/scanpy/issues/2048:363,Testability,test,tests,363,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048
https://github.com/scverse/scanpy/issues/2048:483,Testability,test,test,483,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048
https://github.com/scverse/scanpy/issues/2048:2034,Testability,log,logical,2034," exists on the latest version of scanpy. (Well released version); - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, I was trying to build a Debian package for scanpy 1.8.2, and unsurprisingly ran into problems with the plot tests. Most of the problems were just slight plot layout differences, but the test_embedding_plots::test_visium_default test ends up generating a blank plot. ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141199384-3696067f-c8ed-475d-b077-80bb2a0280a0.png). I can get something where the dots are visible by setting a color, but the color bar doesn't match the default.; ![master_spatial_visium_default](https://user-images.githubusercontent.com/975038/141200671-6bbb5dd3-17ac-44ac-a9d1-28549e4c90a9.png). I also tried add_outline=True which got me closer but is still not right, and still pretty hard to see. ; ![showspatial_visium_add_outline](https://user-images.githubusercontent.com/975038/141201784-4eeb070c-9be2-4db7-85c2-274f34bec6d3.png). I tried adjusting the marker size but didn't get very far. do you have any guesses what might be wrong?. Thanks. anndata 0.7.5+ds; scanpy 1.8.2; sinfo 0.3.1. PIL 8.3.2; anndata 0.7.5+ds; asciitree NA; beta_ufunc NA; binom_ufunc NA; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; fasteners NA; h5py 3.3.0; igraph 0.9.6; joblib 0.17.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.35.0; matplotlib 3.3.4; monotonic NA; mpl_toolkits NA; natsort 7.1.0; nbinom_ufunc NA; numba 0.52.0; numcodecs 0.8.1+ds; numexpr 2.7.3; numpy 1.19.5; packaging 21.0; pandas 1.1.5; pkg_resources NA; pyexpat NA; pyparsing 2.4.7; pytoml NA; pytz 2021.3; scanpy 1.8.2; scipy 1.7.1; setuptools_scm NA; sinfo 0.3.1; sitecustomize NA; six 1.16.0; sklearn 0.23.2; tables 3.6.1; texttable 1.6.3; zarr 2.10.2+ds. Python 3.9.8 (main, Nov 7 2021, 15:47:09) [GCC 11.2.0]; Linux-5.14.0-2-amd64-x86_64-with-glibc2.32; 4 logical CPU cores. Session information updated at 2021-11-10 22:03",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2048
https://github.com/scverse/scanpy/pull/2049:31,Modifiability,variab,variables,31,"Backport PR #2027: Fix finding variables with sc.pl.scatter(..., use_raw=True)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2049
https://github.com/scverse/scanpy/issues/2052:533,Availability,down,downregulated,533,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [✔] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm wondering whether it is possible to show the downregulated marker genes by sc.pl.rank_genes_groups() or other functions, so that we can export the gene list for further GSEA analysis?; I know sc.pl.rank_genes_groups_dotplot can show the downregulated genes by change n_genes to negative numbers, but it didn't work in sc.pl.rank_genes_groups().; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052
https://github.com/scverse/scanpy/issues/2052:725,Availability,down,downregulated,725,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [✔] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm wondering whether it is possible to show the downregulated marker genes by sc.pl.rank_genes_groups() or other functions, so that we can export the gene list for further GSEA analysis?; I know sc.pl.rank_genes_groups_dotplot can show the downregulated genes by change n_genes to negative numbers, but it didn't work in sc.pl.rank_genes_groups().; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052
https://github.com/scverse/scanpy/issues/2052:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [✔] Other?. <!-- Please describe your wishes below: -->; Hello Scanpy,; I'm wondering whether it is possible to show the downregulated marker genes by sc.pl.rank_genes_groups() or other functions, so that we can export the gene list for further GSEA analysis?; I know sc.pl.rank_genes_groups_dotplot can show the downregulated genes by change n_genes to negative numbers, but it didn't work in sc.pl.rank_genes_groups().; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2052
https://github.com/scverse/scanpy/issues/2053:218,Availability,Error,Error,218,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:583,Availability,toler,tolerance,583,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:2455,Availability,toler,tolerance,2455,"as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3456 if self.columns.nlevels > 1:; 3457 return self._getitem_multilevel(key); -> 3458 indexer = self.columns.get_loc(key); 3459 if is_integer(indexer):; 3460 indexer = [indexer]. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 ; 3365 if is_scalar(key) and isna(key) and not self.hasnans:. KeyError: 1; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:224,Integrability,message,messages,224,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:287,Performance,cache,cache,287,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:341,Performance,cache,cache,341,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:1470,Performance,cache,cache,1470,"nda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3456 if self.columns.nlevels > 1:; 3457 return self._getitem_multilevel(key); -> 3458 indexer = self.columns.get_loc(key); 3459 if is_integer(indexer):; 3460 indexer = [indexer]. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3361 return self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:1825,Performance,cache,cache,1825,"as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/frame.py in __getitem__(self, key); 3456 if self.columns.nlevels > 1:; 3457 return self._getitem_multilevel(key); -> 3458 indexer = self.columns.get_loc(key); 3459 if is_integer(indexer):; 3460 indexer = [indexer]. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:; -> 3363 raise KeyError(key) from err; 3364 ; 3365 if is_scalar(key) and isna(key) and not self.hasnans:. KeyError: 1; ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:979,Security,hash,hashtable,979,"I have a similar issue to [this comment](https://github.com/theislab/scanpy/issues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/issues/2053:1072,Security,hash,hashtable,1072,"ssues/1916#issuecomment-927497782). `Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids')`. Switching to `gene_symbols` didn't work. Error messages:; ```; --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance); 3360 try:; -> 3361 return self._engine.get_loc(casted_key); 3362 except KeyError as err:. ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). ~/miniconda3/envs/flng/lib/python3.8/site-packages/pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.Int64HashTable.get_item(). KeyError: 1. The above exception was the direct cause of the following exception:. KeyError Traceback (most recent call last); /tmp/ipykernel_29519/245170133.py in <module>; ----> 1 Carraro=sc.read_10x_mtx('/mnt/Carraro',var_names='gene_ids'). ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in read_10x_mtx(path, var_names, make_unique, cache, cache_compression, gex_only); 452 genefile_exists = (path / 'genes.tsv').is_file(); 453 read = _read_legacy_10x_mtx if genefile_exists else _read_v3_10x_mtx; --> 454 adata = read(; 455 str(path),; 456 var_names=var_names,. ~/miniconda3/envs/flng/lib/python3.8/site-packages/scanpy/readwrite.py in _read_legacy_10x_mtx(path, var_names, make_unique, cache, cache_compression); 491 elif var_names == 'gene_ids':; 492 adata.var_names = genes[0].values; --> 493 adata.var['gene_symbols'] = genes[1].values; 494 else:; 495 raise ValueError(""`var_names` needs to be 'gene_symbols' or 'gene_ids'""). ~/minicon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2053
https://github.com/scverse/scanpy/pull/2055:39,Modifiability,variab,variable,39,"Hi,. This is for #1876 ; I added a new variable `groupby_expand` to dotplot and baseplot to allow the function using two variables from groupby as x and y axis. ; Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2055
https://github.com/scverse/scanpy/pull/2055:121,Modifiability,variab,variables,121,"Hi,. This is for #1876 ; I added a new variable `groupby_expand` to dotplot and baseplot to allow the function using two variables from groupby as x and y axis. ; Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2055
https://github.com/scverse/scanpy/pull/2056:0,Deployability,update,updates,0,updates:; - [github.com/psf/black: 21.10b0 → 21.11b1](https://github.com/psf/black/compare/21.10b0...21.11b1),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2056
https://github.com/scverse/scanpy/issues/2057:622,Availability,error,error,622,"- [✔ ] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:1958,Availability,down,downregulated,1958,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:1510,Testability,log,logFC,1510,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:1875,Testability,log,logFC,1875,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:2001,Testability,log,logFC,2001,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:2015,Testability,log,logFC,2015,"ssary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter notebook of pbmc by setting use_raw=False in sc.tl.rank_genes_groups().; Could you please help us to solve this issue?; Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:259,Usability,guid,guide,259,"- [✔ ] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:902,Usability,learn,learn,902,"- [✔ ] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2057:1229,Usability,clear,clear,1229,"Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False). ```pytb; [Paste the error output produced by the above code here]; ```; ![image](https://user-images.githubusercontent.com/75048821/142975910-ee42c23e-976d-4980-a351-dcb53672b978.png). #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. ***************; Hello Scanpy,. Because the scRNA-seq data usually have mitochondrial gene contamination, it's reasonable to regress out mito genes by sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) and do scaling, and use this 'clear' data for determining the marker genes of each cluster by setting use_raw=False in sc.tl.rank_genes_groups(). However, I found that. 1. if using unregressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=True), the top marker genes have positive logFC, which is reasonable because these are top upregulated genes helping us to determine the annotations of clusters. ; ![image](https://user-images.githubusercontent.com/75048821/142977363-a7ce9cd6-5c2b-48f7-9e21-eccc66650f78.png). 2. the weird thing is, if using regressed data by sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon', use_raw=False), the logFC of top marker genes will become negative and even disappear, which means the downregulated genes and genes with unknown logFC (why no logFC?) becomes the marker genes, which doesn't make sense.; ![image](https://user-images.githubusercontent.com/75048821/142977508-a9d3421d-ff66-4f4c-a4f4-71bc1bbd7dda.png). This bug comes from the official jupyter not",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2057
https://github.com/scverse/scanpy/issues/2058:797,Modifiability,variab,variable,797,"- [ ✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_pcs=50, knn=True); sc.tl.leiden(adata, resolution=10); sc.tl.umap(adata); sc.pl.umap(adata, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False). ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:07); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:10); running Leiden clustering; finished: found 137 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:00:02); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:07); the obs value 'leiden' has more than 103 categories. Uniform 'grey' color will be used for all categories.; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. Hello Scanpy,; When I make >100 clusters, the 'leiden' becomes gray and cannot be changed back in the same notebook.; Could you please help me to solve this issue?; Thanks!; Best; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2058
https://github.com/scverse/scanpy/issues/2058:259,Usability,guid,guide,259,"- [ ✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_pcs=50, knn=True); sc.tl.leiden(adata, resolution=10); sc.tl.umap(adata); sc.pl.umap(adata, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False). ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:07); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:10); running Leiden clustering; finished: found 137 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:00:02); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:07); the obs value 'leiden' has more than 103 categories. Uniform 'grey' color will be used for all categories.; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. Hello Scanpy,; When I make >100 clusters, the 'leiden' becomes gray and cannot be changed back in the same notebook.; Could you please help me to solve this issue?; Thanks!; Best; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2058
https://github.com/scverse/scanpy/issues/2058:1510,Usability,learn,learn,1510,"- [ ✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python 3.8; # Your code here; ```sc.tl.pca(adata, svd_solver='arpack'); sc.pp.neighbors(adata, n_pcs=50, knn=True); sc.tl.leiden(adata, resolution=10); sc.tl.umap(adata); sc.pl.umap(adata, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False). ```pytb; computing PCA; on highly variable genes; with n_comps=50; finished (0:00:07); computing neighbors; using 'X_pca' with n_pcs = 50; finished: added to `.uns['neighbors']`; `.obsp['distances']`, distances for each pair of neighbors; `.obsp['connectivities']`, weighted adjacency matrix (0:00:10); running Leiden clustering; finished: found 137 clusters and added; 'leiden', the cluster labels (adata.obs, categorical) (0:00:02); computing UMAP; finished: added; 'X_umap', UMAP coordinates (adata.obsm) (0:00:07); the obs value 'leiden' has more than 103 categories. Uniform 'grey' color will be used for all categories.; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5. </details>. Hello Scanpy,; When I make >100 clusters, the 'leiden' becomes gray and cannot be changed back in the same notebook.; Could you please help me to solve this issue?; Thanks!; Best; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2058
https://github.com/scverse/scanpy/issues/2059:170,Performance,perform,perform,170,"In pl.pca_loagings(), there should be an option to limit the number of points plotted (basically n_points from ranking). Why: I recently used the AnnData/scanpy suite to perform some analysis on a low number of genes (less than 30, amplified by qRT-PCR).; As the number of features is less than 30 (30 being the default value for n_points in ranking(adata,*args,**kwargs), the loadings appear twice on the sc.pl.loadings() graph.; (the slices [0:15] and 5:20] are overlapping, in case you have only 20 genes. definition should be:; ```; def pca_loadings(; adata: AnnData,; components: Union[str, Sequence[int], None] = None,; n_points=30,; include_lowest: bool = True,; show: Optional[bool] = None,; save: Union[str, bool, None] = None,; ):; ```. and later in implementation; ```; ranking(; adata,; 'varm',; 'PCs',; npoints=npoints,; indices=components,; include_lowest=include_lowest,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2059
https://github.com/scverse/scanpy/issues/2059:377,Performance,load,loadings,377,"In pl.pca_loagings(), there should be an option to limit the number of points plotted (basically n_points from ranking). Why: I recently used the AnnData/scanpy suite to perform some analysis on a low number of genes (less than 30, amplified by qRT-PCR).; As the number of features is less than 30 (30 being the default value for n_points in ranking(adata,*args,**kwargs), the loadings appear twice on the sc.pl.loadings() graph.; (the slices [0:15] and 5:20] are overlapping, in case you have only 20 genes. definition should be:; ```; def pca_loadings(; adata: AnnData,; components: Union[str, Sequence[int], None] = None,; n_points=30,; include_lowest: bool = True,; show: Optional[bool] = None,; save: Union[str, bool, None] = None,; ):; ```. and later in implementation; ```; ranking(; adata,; 'varm',; 'PCs',; npoints=npoints,; indices=components,; include_lowest=include_lowest,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2059
https://github.com/scverse/scanpy/issues/2059:412,Performance,load,loadings,412,"In pl.pca_loagings(), there should be an option to limit the number of points plotted (basically n_points from ranking). Why: I recently used the AnnData/scanpy suite to perform some analysis on a low number of genes (less than 30, amplified by qRT-PCR).; As the number of features is less than 30 (30 being the default value for n_points in ranking(adata,*args,**kwargs), the loadings appear twice on the sc.pl.loadings() graph.; (the slices [0:15] and 5:20] are overlapping, in case you have only 20 genes. definition should be:; ```; def pca_loadings(; adata: AnnData,; components: Union[str, Sequence[int], None] = None,; n_points=30,; include_lowest: bool = True,; show: Optional[bool] = None,; save: Union[str, bool, None] = None,; ):; ```. and later in implementation; ```; ranking(; adata,; 'varm',; 'PCs',; npoints=npoints,; indices=components,; include_lowest=include_lowest,; ); ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2059
https://github.com/scverse/scanpy/issues/2060:506,Integrability,depend,dependency,506,"- [x] Additional function parameters / changed functionality / changed defaults?. I recently wrote up a parallelized implementation of the Mann-Whitney U test, for my own use ([gist is here](https://gist.github.com/jamestwebber/38ab26d281f97feb8196b3d93edeeb7b)). For the types of tests we tend to do in scRNAseq (lots of different features, 2d arrays) it basically scales with the number of cores you can throw at it. When you're doing a lot of tests this is very nice!. Given that `scanpy` already has a dependency on `numba` this would be a pretty simple thing to add, if you want to do so. Thought I would just point it out!. - James",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060
https://github.com/scverse/scanpy/issues/2060:154,Testability,test,test,154,"- [x] Additional function parameters / changed functionality / changed defaults?. I recently wrote up a parallelized implementation of the Mann-Whitney U test, for my own use ([gist is here](https://gist.github.com/jamestwebber/38ab26d281f97feb8196b3d93edeeb7b)). For the types of tests we tend to do in scRNAseq (lots of different features, 2d arrays) it basically scales with the number of cores you can throw at it. When you're doing a lot of tests this is very nice!. Given that `scanpy` already has a dependency on `numba` this would be a pretty simple thing to add, if you want to do so. Thought I would just point it out!. - James",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060
https://github.com/scverse/scanpy/issues/2060:281,Testability,test,tests,281,"- [x] Additional function parameters / changed functionality / changed defaults?. I recently wrote up a parallelized implementation of the Mann-Whitney U test, for my own use ([gist is here](https://gist.github.com/jamestwebber/38ab26d281f97feb8196b3d93edeeb7b)). For the types of tests we tend to do in scRNAseq (lots of different features, 2d arrays) it basically scales with the number of cores you can throw at it. When you're doing a lot of tests this is very nice!. Given that `scanpy` already has a dependency on `numba` this would be a pretty simple thing to add, if you want to do so. Thought I would just point it out!. - James",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060
https://github.com/scverse/scanpy/issues/2060:446,Testability,test,tests,446,"- [x] Additional function parameters / changed functionality / changed defaults?. I recently wrote up a parallelized implementation of the Mann-Whitney U test, for my own use ([gist is here](https://gist.github.com/jamestwebber/38ab26d281f97feb8196b3d93edeeb7b)). For the types of tests we tend to do in scRNAseq (lots of different features, 2d arrays) it basically scales with the number of cores you can throw at it. When you're doing a lot of tests this is very nice!. Given that `scanpy` already has a dependency on `numba` this would be a pretty simple thing to add, if you want to do so. Thought I would just point it out!. - James",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060
https://github.com/scverse/scanpy/issues/2060:551,Usability,simpl,simple,551,"- [x] Additional function parameters / changed functionality / changed defaults?. I recently wrote up a parallelized implementation of the Mann-Whitney U test, for my own use ([gist is here](https://gist.github.com/jamestwebber/38ab26d281f97feb8196b3d93edeeb7b)). For the types of tests we tend to do in scRNAseq (lots of different features, 2d arrays) it basically scales with the number of cores you can throw at it. When you're doing a lot of tests this is very nice!. Given that `scanpy` already has a dependency on `numba` this would be a pretty simple thing to add, if you want to do so. Thought I would just point it out!. - James",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2060
https://github.com/scverse/scanpy/pull/2061:102,Deployability,patch,patch,102,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061
https://github.com/scverse/scanpy/pull/2061:318,Usability,guid,guidelines,318,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061
https://github.com/scverse/scanpy/pull/2061:349,Usability,guid,guide,349,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). . <!--; Thanks for opening a PR to scanpy!; Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review.; -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2061
https://github.com/scverse/scanpy/issues/2062:1401,Deployability,install,installed,1401,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:914,Energy Efficiency,monitor,monitor,914,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:1316,Testability,log,logging,1316,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:1256,Usability,pause,pausefilter,1256,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:1733,Usability,learn,learn,1733,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/issues/2062:1902,Usability,learn,learn,1902,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; ```. ```pytb; Illegal instruction (core dumped); ```. #### Versions. <details>. Python 3.9.7 and scanpy 1.8.2. CPU flags including instruction sets are pasted below. fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 popcnt aes xsave avx f16c lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs xop skinit wdt lwp fma4 tce nodeid_msr tbm topoext perfctr_core perfctr_nb cpb hw_pstate ssbd ibpb vmmcall bmi1 arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold. I unfortunately cannot call scanpy.logging as I cannot import scanpy. I can, however, list the versions of all packages installed alongside scanpy. anndata 0.7.8; cycler 0.11.0; fonttools 4.28.2; h5py 3.6.0; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; matplotlib 3.5.0; natsort 8.0.0; networkx 2.6.0; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; pandas 1.3.4; patsy 0.5.2; pillow 8.4.0; pynndescent 0.5.5; python-dateutil 2.8.2; pytz 2021.3; scikit-learn 1.0.1; scipy 1.7.3; seaborn 0.11.2; setuptools-scm 6.3.2; sinfo 0.3.4; statsmodels 0.13.1; stdlib-list 0.8.0; tables 3.6.1; threadpoolctl 3.0.0; tqdm 4.62.3; umap-learn 0.5.2; xlrd-1.2.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2062
https://github.com/scverse/scanpy/pull/2063:760,Availability,error,error,760,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:21,Deployability,install,installing,21,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:73,Deployability,release,release,73,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:794,Deployability,install,installed,794,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:284,Integrability,depend,dependent,284,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:540,Integrability,depend,dependency,540,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:294,Testability,test,tests,294,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:326,Testability,test,tests,326,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:379,Testability,test,testing,379,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:481,Testability,test,test,481,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:556,Testability,test,tests,556,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2063:568,Testability,test,tests,568,"We're having trouble installing louvain on CI due to a recent setuptools release (would have been nice if setuptools had more vocal warnings about this ahead of time, but alas). See: vtraag/louvain-igraph/issues/57. This PR makes louvain optional. This was done by:. ### Skip louvain dependent tests. While these largely were tests checking that louvain works, some of these are testing other things. The biggest example here is `test_paga_paul15_subsampled.py`, which is really a test of PAGA. This should be corrected. ### Remove louvain dependency from tests. Some tests, like those for `rank_genes_groups_logreg` used louvain, but really didn't have to. `test_pbmc3k` could just have `louvain` calls replaced with `leiden` with only one plot triggering an error. ### `louvain` is no longer installed on CI. This should get around the build issue.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2063
https://github.com/scverse/scanpy/pull/2064:76,Deployability,install,installation,76,"Removes the need for a pytables dependency. * pytables has been a source of installation heisenbugs, particularly on windows (#1468, #1284, #454); * why use two hdf5 libraries; * Makes it easier to move reading 10x files into anndata or elsewhere #1387. I've edited the code as lightly as possible, since these readers were originally contributed by someone at 10X, so I assume they had better knowledge of possible edge cases. - [ ] ~~Test with h5py 2~~; - [ ] Add release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064
https://github.com/scverse/scanpy/pull/2064:466,Deployability,release,release,466,"Removes the need for a pytables dependency. * pytables has been a source of installation heisenbugs, particularly on windows (#1468, #1284, #454); * why use two hdf5 libraries; * Makes it easier to move reading 10x files into anndata or elsewhere #1387. I've edited the code as lightly as possible, since these readers were originally contributed by someone at 10X, so I assume they had better knowledge of possible edge cases. - [ ] ~~Test with h5py 2~~; - [ ] Add release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064
https://github.com/scverse/scanpy/pull/2064:32,Integrability,depend,dependency,32,"Removes the need for a pytables dependency. * pytables has been a source of installation heisenbugs, particularly on windows (#1468, #1284, #454); * why use two hdf5 libraries; * Makes it easier to move reading 10x files into anndata or elsewhere #1387. I've edited the code as lightly as possible, since these readers were originally contributed by someone at 10X, so I assume they had better knowledge of possible edge cases. - [ ] ~~Test with h5py 2~~; - [ ] Add release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064
https://github.com/scverse/scanpy/pull/2064:436,Testability,Test,Test,436,"Removes the need for a pytables dependency. * pytables has been a source of installation heisenbugs, particularly on windows (#1468, #1284, #454); * why use two hdf5 libraries; * Makes it easier to move reading 10x files into anndata or elsewhere #1387. I've edited the code as lightly as possible, since these readers were originally contributed by someone at 10X, so I assume they had better knowledge of possible edge cases. - [ ] ~~Test with h5py 2~~; - [ ] Add release note",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2064
https://github.com/scverse/scanpy/issues/2065:59,Deployability,release,release,59,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:384,Energy Efficiency,adapt,adapt,384,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:214,Integrability,depend,dependent,214,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:384,Modifiability,adapt,adapt,384,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:224,Testability,test,tests,224,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:265,Testability,test,test,265,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/issues/2065:395,Testability,test,test,395,"Louvain is being difficult to build since a new setuptools release dropped any python2 compatibility https://github.com/vtraag/louvain-igraph/issues/57. We've largely worked around this in #2063, by making louvain dependent tests optional. However, the paul15 PAGA test is difficult to extract louvian from. It checks hardcoded values based on the results of a louvain clustering. To adapt this test to use leiden, we would have to redo the tutorial and create new results. Or louvain building could be fixed, but the package is deprecated anyways.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2065
https://github.com/scverse/scanpy/pull/2066:45,Testability,test,tests,45,Backport PR #2063: Make louvain optional for tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2066
https://github.com/scverse/scanpy/issues/2067:231,Deployability,release,release,231,"Hi,. didn't see this being tracked here yet. Hope I didn't miss it.; Our PAGA implementation uses Forceatlas2, but unfortunately Forceatlas2 is not really maintained anymore and it does not yet support Python 3.9+. Well the latest release at least. The master branch may work. Sources: ; - https://github.com/bhargavchippada/forceatlas2/issues/34; - https://github.com/bhargavchippada/forceatlas2/issues/35. @gokceneraslan I saw that you contributed some code. Do you still have a connection to the maintainer?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2067
https://github.com/scverse/scanpy/issues/2068:318,Availability,error,error,318,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Hello, after clustering I am trying to use heatmap to visualize the marker gene but got below error:; could anyone help, many thanks.; ```python; ax = sc.pl.heatmap(adata,marker_genes_dict,groupby='louvain_r1',save=""0.png""); ```. ```pytb; KeyError: ""Values ['CD79A'], from ['CD79A', 'MS4A1', 'CD3D', 'CD8A', 'CD8B', 'GNLY', 'NKG7', 'CST3', 'LYZ', 'FCGR3A', 'FCER1A'], are not valid obs/ var names or indices."". ```. #### Versions. <details>; anndata 0.7.5; scanpy 1.6.1; </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2068
https://github.com/scverse/scanpy/pull/2069:0,Deployability,update,updates,0,updates:; - [github.com/psf/black: 21.11b1 → 21.12b0](https://github.com/psf/black/compare/21.11b1...21.12b0),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2069
https://github.com/scverse/scanpy/issues/2073:926,Availability,error,error,926,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:351,Deployability,install,install,351,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:389,Deployability,install,installed,389,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:1035,Testability,log,logging,1035,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:528,Usability,guid,guide,528,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:1204,Usability,learn,learn,1204,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/issues/2073:1533,Usability,learn,learn,1533,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; **Hello Scanpy,; When I'm running sc.pp.highly_variable_genes(adata, n_top_genes=5000, flavor='seurat_v3'), it asks me to install scikit-misc, which is already installed. Please see the picture below.; Could you please help me to solve this issue?; Thanks!; Best,; YJ**; **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```; ![image](https://user-images.githubusercontent.com/75048821/145125005-64f8607e-9cb0-4740-8dca-7c80e35d30ef.png). ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>3.8. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.2 pandas==1.3.4 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.2 matplotlib==3.5.0 sklearn==1.0.1 pandas==1.3.4 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.2 pandas==1.3.4 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.0 seaborn==0.11.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2073
https://github.com/scverse/scanpy/pull/2075:102,Deployability,patch,patch,102,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/pull/2075:249,Deployability,patch,patch,249,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/pull/2075:365,Deployability,patch,patch,365,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/pull/2075:405,Deployability,patch,patch,405,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/pull/2075:480,Deployability,update,updated,480,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/pull/2075:464,Usability,guid,guide,464,"When less than 30 features are present in adata.X, pca_loadings will plot some components twice.; The patch solves the problem by adding an n_point parameter (default value 30, same as anndata.ranking())that is then passed to anndata.ranking(). the patch also modifies rankings plot to account for remove the dots when all elements in order_scores are plotted; the patch replaces the previously submitted patch. ps: had to struggle a lot with gi. the contribution guide should be updated... I may work on it",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2075
https://github.com/scverse/scanpy/issues/2078:519,Availability,error,error,519,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:1381,Availability,ERROR,ERROR,1381," A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/.virtualenvs/pytorch_latest/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:7408,Deployability,update,updated,7408,"se KeyError(; 1322 ""Passing list-likes to .loc or [] with any missing labels ""; 1323 ""is no longer supported. "". KeyError: ""Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: CategoricalIndex(['1Ery'], categories=['1Ery', '2Ery', '3Ery', '4Ery', '5Ery', '6Ery', '7MEP', '8Mk', ...], ordered=False, name='paul15_clusters', dtype='category'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike""; ```. #### Versions. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.6; autoreload NA; backcall 0.2.0; cffi 1.14.5; configobj 5.0.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; git 3.1.14; gitdb 4.0.7; google NA; gpytorch 1.4.1; h5py 3.2.1; igraph 0.9.6; inferelator NA; ipykernel 5.5.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.2; scipy 1.6.3; seaborn 0.11.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; smmap 4.0.0; statsmodels 0.12.2; storemagic NA; supirfactor NA; tables 3.6.1; texttable 1.6.3; torch 1.9.0+cu102; tornado 6.1; tqdm 4.60.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; zmq 22.0.3; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.8.5 (default, Jan 27 2021, 15:41:15) [GCC 9.3.0]; Linux-5.4.0-91-generic-x86_64-with-glibc2.29; 12 logical CPU cores, x86_64; -----; Session information updated at 2021-12-10 17:16. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:6211,Modifiability,config,configobj,6211,"s/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing); 1319 ; 1320 with option_context(""display.max_seq_items"", 10, ""display.width"", 80):; -> 1321 raise KeyError(; 1322 ""Passing list-likes to .loc or [] with any missing labels ""; 1323 ""is no longer supported. "". KeyError: ""Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: CategoricalIndex(['1Ery'], categories=['1Ery', '2Ery', '3Ery', '4Ery', '5Ery', '6Ery', '7MEP', '8Mk', ...], ordered=False, name='paul15_clusters', dtype='category'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike""; ```. #### Versions. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.6; autoreload NA; backcall 0.2.0; cffi 1.14.5; configobj 5.0.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; git 3.1.14; gitdb 4.0.7; google NA; gpytorch 1.4.1; h5py 3.2.1; igraph 0.9.6; inferelator NA; ipykernel 5.5.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.2; scipy 1.6.3; seaborn 0.11.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; smmap 4.0.0; statsmodels 0.12.2; storemagic NA; supirfactor NA; tables 3.6.1; texttable 1.6.3; torch 1.9.0+cu102; tornado 6.1; tqdm 4.60.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; zmq 22.0.3; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:911,Testability,log,logfoldchanges,911,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:1004,Testability,log,logarithmized,1004," I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:1043,Testability,log,logarithmized,1043,"ot already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:1214,Testability,test,test,1214,"*: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:1323,Testability,log,logarithmize,1323,"to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:2013,Testability,log,logfoldchanges,2013," ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, values_to_plot='logfoldchanges',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:2887,Testability,log,log,2887,"8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds); 861 tl.rank_genes_groups; 862 """"""; --> 863 return _rank_genes_groups_plot(; 864 adata,; 865 plot_type='dotplot',. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 893 ; 894 maybe_call",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:3451,Testability,log,log,3451,"return_fig, gene_symbols, **kwds); 534 from .._dotplot import dotplot; 535 ; --> 536 _pl = dotplot(; 537 adata,; 538 var_names,. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in dotplot(adata, var_names, groupby, use_raw, log, num_categories, expression_cutoff, mean_only_expressed, cmap, dot_max, dot_min, standard_scale, smallest_dot, title, colorbar_title, size_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, swap_axes, dot_color_df, show, save, ax, return_fig, vmin, vmax, vcenter, norm, **kwds); 940 del kwds['color_map']; 941 ; --> 942 dp = DotPlot(; 943 adata,; 944 var_names,. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/scanpy/plotting/_dotplot.py in __init__(self, adata, var_names, groupby, use_raw, log, num_categories, categories_order, title, figsize, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, expression_cutoff, mean_only_expressed, standard_scale, dot_color_df, dot_size_df, ax, vmin, vmax, vcenter, norm, **kwds); 215 # get the same order for rows and columns in the dot_color_df; 216 # using the order from the doc_size_df; --> 217 dot_color_df = dot_color_df.loc[dot_size_df.index][dot_size_df.columns]; 218 ; 219 self.dot_color_df = dot_color_df. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in __getitem__(self, key); 893 ; 894 maybe_callable = com.apply_if_callable(key, self.obj); --> 895 return self._getitem_axis(maybe_callable, axis=axis); 896 ; 897 def _is_scalar_access(self, key: Tuple):. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis); 1111 raise ValueError(""Cannot index with multidimensional key""); 1112 ; -> 1113 return self._getitem_iterable(key, axis=axis); 1114 ; 1115 # nested tuple slicing. ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in _getitem_iterable(self, key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:5994,Testability,log,logging,5994,"g); 1264 keyarr, indexer, new_indexer = ax._reindex_non_unique(keyarr); 1265 ; -> 1266 self._validate_read_indexer(keyarr, indexer, axis, raise_missing=raise_missing); 1267 return keyarr, indexer; 1268 . ~/.virtualenvs/pytorch_latest/lib/python3.8/site-packages/pandas/core/indexing.py in _validate_read_indexer(self, key, indexer, axis, raise_missing); 1319 ; 1320 with option_context(""display.max_seq_items"", 10, ""display.width"", 80):; -> 1321 raise KeyError(; 1322 ""Passing list-likes to .loc or [] with any missing labels ""; 1323 ""is no longer supported. "". KeyError: ""Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: CategoricalIndex(['1Ery'], categories=['1Ery', '2Ery', '3Ery', '4Ery', '5Ery', '6Ery', '7MEP', '8Mk', ...], ordered=False, name='paul15_clusters', dtype='category'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike""; ```. #### Versions. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.6; autoreload NA; backcall 0.2.0; cffi 1.14.5; configobj 5.0.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; git 3.1.14; gitdb 4.0.7; google NA; gpytorch 1.4.1; h5py 3.2.1; igraph 0.9.6; inferelator NA; ipykernel 5.5.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.2; scipy 1.6.3; seaborn 0.11.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; smmap 4.0.0; statsmodels 0.12.2; storemagic NA; supirfactor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:7354,Testability,log,logical,7354,"se KeyError(; 1322 ""Passing list-likes to .loc or [] with any missing labels ""; 1323 ""is no longer supported. "". KeyError: ""Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: CategoricalIndex(['1Ery'], categories=['1Ery', '2Ery', '3Ery', '4Ery', '5Ery', '6Ery', '7MEP', '8Mk', ...], ordered=False, name='paul15_clusters', dtype='category'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike""; ```. #### Versions. <details>. sc.logging.print_versions(); WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.6; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.2.0; anndata 0.7.6; autoreload NA; backcall 0.2.0; cffi 1.14.5; configobj 5.0.6; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; git 3.1.14; gitdb 4.0.7; google NA; gpytorch 1.4.1; h5py 3.2.1; igraph 0.9.6; inferelator NA; ipykernel 5.5.3; ipython_genutils 0.2.0; ipywidgets 7.6.3; jedi 0.18.0; joblib 1.0.1; kiwisolver 1.3.1; leidenalg 0.8.4; llvmlite 0.36.0; matplotlib 3.4.1; mpl_toolkits NA; natsort 7.1.1; numba 0.53.1; numexpr 2.7.3; numpy 1.20.2; packaging 20.9; pandas 1.2.4; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.18; ptyprocess 0.7.0; pycparser 2.20; pygments 2.8.1; pynndescent 0.5.2; pyparsing 2.4.7; pytz 2021.1; scanpy 1.8.2; scipy 1.6.3; seaborn 0.11.1; sinfo 0.3.1; sitecustomize NA; six 1.15.0; sklearn 0.24.2; smmap 4.0.0; statsmodels 0.12.2; storemagic NA; supirfactor NA; tables 3.6.1; texttable 1.6.3; torch 1.9.0+cu102; tornado 6.1; tqdm 4.60.0; traitlets 5.0.5; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; zmq 22.0.3; -----; IPython 7.22.0; jupyter_client 6.1.12; jupyter_core 4.7.1; notebook 6.3.0; -----; Python 3.8.5 (default, Jan 27 2021, 15:41:15) [GCC 9.3.0]; Linux-5.4.0-91-generic-x86_64-with-glibc2.29; 12 logical CPU cores, x86_64; -----; Session information updated at 2021-12-10 17:16. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2078:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. As the title says. A specific set of combinations of keywords to rank gene groups and plotting throws an error unexpectedly. ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; n_genes=3, cmap='PiYG_r', swap_axes=True,; show=False, values_to_plot='logfoldchanges',; vmin=None, vmax=None); ```. ```pytb; WARNING: In Scanpy 0.*, this returned logarithmized data. Now it returns non-logarithmized data.; ... storing 'paul15_clusters' as categorical; Trying to set attribute `.uns` of view, copying.; WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'; WARNING: It seems you use rank_genes_groups on the raw count data. Please logarithmize your data before calling rank_genes_groups.; ERROR: the given dot_color_df data frame has a different shape thanthe data frame used for the dot size. Both data frames needto have the same index and columns; ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); <ipython-input-110-708ec3ea001f> in <module>; 1 adata = sc.datasets.paul15(); 2 sc.tl.rank_genes_groups(adata, groupby='paul15_clusters', key_added='GG', use_raw=False, reference='1Ery'); ----> 3 rax = sc.pl.rank_genes_groups_dotplot(adata, key='GG', # , rankby_abs= None,; 4 n_genes=3, cmap='PiYG_r', swap_axes=True,; 5 show=False, valu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2078
https://github.com/scverse/scanpy/issues/2080:4291,Energy Efficiency,allocate,allocate,4291,"2 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concatenate(; File ""<__array_function__ internals>"", line 5, in concatenate; numpy.core._exceptions.MemoryError: Unable to allocate 15.9 GiB for an array with shape (180000, 23752) and data type float32; ```. Thanks !!!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:1434,Safety,detect,detected,1434,"we can copy&paste without having any data). ```python; df = pd.read_csv(expfile[i], sep=""\t"" ,index_col=0); geneinfo = pd.DataFrame(df.index,index=df.index,columns=['gene_index']); cellinfo = pd.DataFrame(df.columns,index=df.columns,columns=['cell_index']); adata_tmp = sc.AnnData(df.T, obs=cellinfo, var = geneinfo); sc.pp.filter_cells(adata_tmp, min_genes=mingenes); sc.pp.filter_cells(adata_tmp, min_counts=minUMIs). if maxgenes <= 1:; maxgenes_new = np.percentile(adata_tmp.obs['n_genes'], 100*maxgenes)+1; else:; maxgenes_new = maxgenes; if maxUMIs <= 1:; maxUMIs_new = np.percentile(adata_tmp.obs['n_counts'], 100*maxUMIs)+1; else:; maxUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:1498,Safety,detect,detected,1498,"we can copy&paste without having any data). ```python; df = pd.read_csv(expfile[i], sep=""\t"" ,index_col=0); geneinfo = pd.DataFrame(df.index,index=df.index,columns=['gene_index']); cellinfo = pd.DataFrame(df.columns,index=df.columns,columns=['cell_index']); adata_tmp = sc.AnnData(df.T, obs=cellinfo, var = geneinfo); sc.pp.filter_cells(adata_tmp, min_genes=mingenes); sc.pp.filter_cells(adata_tmp, min_counts=minUMIs). if maxgenes <= 1:; maxgenes_new = np.percentile(adata_tmp.obs['n_genes'], 100*maxgenes)+1; else:; maxgenes_new = maxgenes; if maxUMIs <= 1:; maxUMIs_new = np.percentile(adata_tmp.obs['n_counts'], 100*maxUMIs)+1; else:; maxUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:1649,Safety,detect,detected,1649,"fo = pd.DataFrame(df.columns,index=df.columns,columns=['cell_index']); adata_tmp = sc.AnnData(df.T, obs=cellinfo, var = geneinfo); sc.pp.filter_cells(adata_tmp, min_genes=mingenes); sc.pp.filter_cells(adata_tmp, min_counts=minUMIs). if maxgenes <= 1:; maxgenes_new = np.percentile(adata_tmp.obs['n_genes'], 100*maxgenes)+1; else:; maxgenes_new = maxgenes; if maxUMIs <= 1:; maxUMIs_new = np.percentile(adata_tmp.obs['n_counts'], 100*maxUMIs)+1; else:; maxUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:1800,Safety,detect,detected,1800,"data_tmp, min_genes=mingenes); sc.pp.filter_cells(adata_tmp, min_counts=minUMIs). if maxgenes <= 1:; maxgenes_new = np.percentile(adata_tmp.obs['n_genes'], 100*maxgenes)+1; else:; maxgenes_new = maxgenes; if maxUMIs <= 1:; maxUMIs_new = np.percentile(adata_tmp.obs['n_counts'], 100*maxUMIs)+1; else:; maxUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:1951,Safety,detect,detected,1951,"s'], 100*maxgenes)+1; else:; maxgenes_new = maxgenes; if maxUMIs <= 1:; maxUMIs_new = np.percentile(adata_tmp.obs['n_counts'], 100*maxUMIs)+1; else:; maxUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2102,Safety,detect,detected,2102,"axUMIs_new = maxUMIs; sc.pp.filter_cells(adata_tmp, max_genes=maxgenes_new); sc.pp.filter_cells(adata_tmp, max_counts=maxUMIs_new); sc.pp.filter_genes(adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2253,Safety,detect,detected,2253,"adata_tmp, min_cells=mincells); adata_tmp.obs['sample'] = ugname[i]; adata = sc.concat([adata,adata_tmp],join='outer'); ```. ```pytb; filtered out 5508 genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2404,Safety,detect,detected,2404," genes that are detected in less than 5 cells; filtered out 5905 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2555,Safety,detect,detected,2555,"e them unique, call `.obs_names_make_unique`.; filtered out 6390 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2706,Safety,detect,detected,2706,"e them unique, call `.obs_names_make_unique`.; filtered out 5974 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:2857,Safety,detect,detected,2857,"e them unique, call `.obs_names_make_unique`.; filtered out 7136 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 16",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3008,Safety,detect,detected,3008,"e them unique, call `.obs_names_make_unique`.; filtered out 5971 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3159,Safety,detect,detected,3159,"e them unique, call `.obs_names_make_unique`.; filtered out 6234 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3310,Safety,detect,detected,3310,"e them unique, call `.obs_names_make_unique`.; filtered out 6442 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concatenate(; File ""<__array_function__ internals>"", line 5, in concatenate; numpy.core._exceptions.MemoryError: Unable to allocate 15.9 GiB for an array wit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3461,Safety,detect,detected,3461,"2 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concatenate(; File ""<__array_function__ internals>"", line 5, in concatenate; numpy.core._exceptions.MemoryError: Unable to allocate 15.9 GiB for an array with shape (180000, 23752) and data type float32; ```. Thanks !!!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3612,Safety,detect,detected,3612,"2 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concatenate(; File ""<__array_function__ internals>"", line 5, in concatenate; numpy.core._exceptions.MemoryError: Unable to allocate 15.9 GiB for an array with shape (180000, 23752) and data type float32; ```. Thanks !!!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2080:3763,Safety,detect,detected,3763,"2 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5593 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6412 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6662 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6039 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6036 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 5923 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6767 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 7077 genes that are detected in less than 5 cells; Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; filtered out 6080 genes that are detected in less than 5 cells; Traceback (most recent call last):; File ""/mypath/runMulti_scanpy.py"", line 161, in main; adata = sc.concat([adata,adata_tmp],join='outer'); File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 818, in concat; X = concat_arrays(; File ""/mypath/scanpy1.7/lib/python3.8/site-packages/anndata/_core/merge.py"", line 424, in concat_arrays; return np.concatenate(; File ""<__array_function__ internals>"", line 5, in concatenate; numpy.core._exceptions.MemoryError: Unable to allocate 15.9 GiB for an array with shape (180000, 23752) and data type float32; ```. Thanks !!!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2080
https://github.com/scverse/scanpy/issues/2085:594,Availability,error,error,594,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to ingest a CITEseq dataset into another clustered dataset. These datasets have different numbers of cells but I ran neighbors(n_neighbors=30) for both prior to running umap. I have confirmed that both datasets have the same variable names and the same number of variable names (38). Both objects look identical when a call adata.var. . I receive the error: ""all input arrays must have the same shape"". . ```; sc.pp.neighbors(CODEX_sub, n_neighbors=30) ; sc.tl.umap(CODEX_sub); sc.pp.neighbors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085
https://github.com/scverse/scanpy/issues/2085:468,Modifiability,variab,variable,468,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to ingest a CITEseq dataset into another clustered dataset. These datasets have different numbers of cells but I ran neighbors(n_neighbors=30) for both prior to running umap. I have confirmed that both datasets have the same variable names and the same number of variable names (38). Both objects look identical when a call adata.var. . I receive the error: ""all input arrays must have the same shape"". . ```; sc.pp.neighbors(CODEX_sub, n_neighbors=30) ; sc.tl.umap(CODEX_sub); sc.pp.neighbors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085
https://github.com/scverse/scanpy/issues/2085:506,Modifiability,variab,variable,506,"- [x ] I have checked that this issue has not already been reported.; - [ x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; I am trying to ingest a CITEseq dataset into another clustered dataset. These datasets have different numbers of cells but I ran neighbors(n_neighbors=30) for both prior to running umap. I have confirmed that both datasets have the same variable names and the same number of variable names (38). Both objects look identical when a call adata.var. . I receive the error: ""all input arrays must have the same shape"". . ```; sc.pp.neighbors(CODEX_sub, n_neighbors=30) ; sc.tl.umap(CODEX_sub); sc.pp.neighbors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085
https://github.com/scverse/scanpy/issues/2085:2667,Usability,learn,learn,2667,"ors(adata_sub, n_neighbors = 30); sc.tl.umap(adata_sub); sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'); ```. ```pytb; ValueError Traceback (most recent call last); <ipython-input-214-01a03312d3df> in <module>; ----> 1 sc.tl.ingest(CODEX_sub, adata_sub, obs='leiden', embedding_method='umap'). ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs); 124 labeling_method = labeling_method * len(obs); 125 ; --> 126 ing = Ingest(adata_ref, neighbors_key); 127 ing.fit(adata); 128 . ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in __init__(self, adata, neighbors_key); 383 ; 384 if neighbors_key in adata.uns:; --> 385 self._init_neighbors(adata, neighbors_key); 386 else:; 387 raise ValueError(. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_neighbors(self, adata, neighbors_key); 349 else:; 350 self._neigh_random_state = neighbors['params'].get('random_state', 0); --> 351 self._init_pynndescent(neighbors['distances']); 352 ; 353 def _init_pca(self, adata):. ~\anaconda3\envs\scenv\lib\site-packages\scanpy\tools\_ingest.py in _init_pynndescent(self, distances); 284 ; 285 first_col = np.arange(distances.shape[0])[:, None]; --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))); 287 ; 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~\anaconda3\envs\scenv\lib\site-packages\numpy\core\shape_base.py in stack(arrays, axis, out); 424 shapes = {arr.shape for arr in arrays}; 425 if len(shapes) != 1:; --> 426 raise ValueError('all input arrays must have the same shape'); 427 ; 428 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. #### Versions. scanpy==1.7.0 anndata==0.7.6 umap==0.5.1 numpy==1.21.1 scipy==1.7.0 pandas==1.2.5 scikit-learn==0.24.2 statsmodels==0.12.2 python-igraph==0.9.8. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2085
https://github.com/scverse/scanpy/issues/2088:231,Testability,test,test,231,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. In the test of the flavor, the sorting over batches is correct with respect to how Seurat actually does it:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/tests/test_highly_variable_genes.py#L138-L142. First sort by number of batches it's called a HVG and then second break ties by the median rank. In the actual function, it's the reverse:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/preprocessing/_highly_variable_genes.py#L136-L143. I propose we put in the fix (which is currently being tested with high accuracy). The simplest solution would be to call it a new flavor. Ideally this would get in as soon as possible as this is a high volume function from what I understand.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2088
https://github.com/scverse/scanpy/issues/2088:421,Testability,test,tests,421,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. In the test of the flavor, the sorting over batches is correct with respect to how Seurat actually does it:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/tests/test_highly_variable_genes.py#L138-L142. First sort by number of batches it's called a HVG and then second break ties by the median rank. In the actual function, it's the reverse:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/preprocessing/_highly_variable_genes.py#L136-L143. I propose we put in the fix (which is currently being tested with high accuracy). The simplest solution would be to call it a new flavor. Ideally this would get in as soon as possible as this is a high volume function from what I understand.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2088
https://github.com/scverse/scanpy/issues/2088:801,Testability,test,tested,801,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. In the test of the flavor, the sorting over batches is correct with respect to how Seurat actually does it:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/tests/test_highly_variable_genes.py#L138-L142. First sort by number of batches it's called a HVG and then second break ties by the median rank. In the actual function, it's the reverse:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/preprocessing/_highly_variable_genes.py#L136-L143. I propose we put in the fix (which is currently being tested with high accuracy). The simplest solution would be to call it a new flavor. Ideally this would get in as soon as possible as this is a high volume function from what I understand.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2088
https://github.com/scverse/scanpy/issues/2088:833,Usability,simpl,simplest,833,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. In the test of the flavor, the sorting over batches is correct with respect to how Seurat actually does it:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/tests/test_highly_variable_genes.py#L138-L142. First sort by number of batches it's called a HVG and then second break ties by the median rank. In the actual function, it's the reverse:. https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/preprocessing/_highly_variable_genes.py#L136-L143. I propose we put in the fix (which is currently being tested with high accuracy). The simplest solution would be to call it a new flavor. Ideally this would get in as soon as possible as this is a high volume function from what I understand.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2088
https://github.com/scverse/scanpy/pull/2089:192,Testability,log,logging,192,"Fixes #1852. In a notebook, with `rich=None, file=None` or `rich=True`, we display the HTML version. I also added docs: https://icb-scanpy--2089.com.readthedocs.build/en/2089/generated/scanpy.logging.print_versions.html. It’s just plain `<details>` and `<summary>` tags, no fancy widgets and should therefore survive rendering using nbsphinx or GitHub’s notebook renderer. Looks like this:. ![unexpanded](https://user-images.githubusercontent.com/291575/146676148-ae14ea6e-7fd2-46ea-b013-f2b55669a35c.png). after a click:. ![expanded once](https://user-images.githubusercontent.com/291575/146676159-84e26f4e-8e16-4587-a3eb-145528abc353.png). after another click:. ![expanded twice](https://user-images.githubusercontent.com/291575/146676172-e38cc3f0-dd06-48d0-91b0-66708294e214.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2089
https://github.com/scverse/scanpy/issues/2093:4056,Deployability,update,updated,4056,"toarray(), mat_neighbor10_pc19_with_pca.toarray())); ```. ```pytb; scanpy= 1.6.0; anndata= 0.7.4; numpy= 1.19.0; adata shape (20, 200); WARNING: You’re trying to run this on 200 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params. Results for `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` with and without precomputed pca are different; False. Results of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` without precomputed pca is same as results of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=19)` (19 is default `n_comps` for sc.pp.pca) with precomputed pca; True; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; importlib_metadata 1.7.0; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.52.0; numexpr 2.7.1; numpy 1.19.0; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; yaml 5.4.1; zipp NA; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.0.3; -----; Python 3.7.2 (default, Jul 16 2019, 22:54:18) [GCC 8.2.0]; Linux-3.10.0-1160.36.2.el7.x86_64-x86_64-with-centos-7.9.2009-Core; 48 logical CPU cores, x86_64; -----; Session information updated at 2021-12-24 13:42. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2093
https://github.com/scverse/scanpy/issues/2093:4002,Testability,log,logical,4002,"toarray(), mat_neighbor10_pc19_with_pca.toarray())); ```. ```pytb; scanpy= 1.6.0; anndata= 0.7.4; numpy= 1.19.0; adata shape (20, 200); WARNING: You’re trying to run this on 200 dimensions of `.X`, if you really want this, set `use_rep='X'`.; Falling back to preprocessing with `sc.pp.pca` and default params. Results for `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` with and without precomputed pca are different; False. Results of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` without precomputed pca is same as results of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=19)` (19 is default `n_comps` for sc.pp.pca) with precomputed pca; True; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.1; -----; PIL 7.2.0; anndata 0.7.4; backcall 0.2.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; decorator 4.4.2; get_version 2.1; h5py 2.10.0; igraph 0.8.3; importlib_metadata 1.7.0; ipykernel 5.3.2; ipython_genutils 0.2.0; jedi 0.17.1; joblib 0.16.0; kiwisolver 1.2.0; legacy_api_wrap 1.2; leidenalg 0.8.3; llvmlite 0.35.0; louvain 0.7.0; matplotlib 3.3.0; mpl_toolkits NA; natsort 7.0.1; numba 0.52.0; numexpr 2.7.1; numpy 1.19.0; packaging 20.4; pandas 1.0.5; parso 0.7.0; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.5; ptyprocess 0.6.0; pygments 2.6.1; pyparsing 2.4.7; pytz 2020.1; scanpy 1.6.0; scipy 1.5.1; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 0.23.1; storemagic NA; tables 3.6.1; texttable 1.6.3; tornado 6.0.4; traitlets 4.3.3; typing_extensions NA; umap 0.4.6; wcwidth 0.2.5; yaml 5.4.1; zipp NA; zmq 19.0.1; zope NA; -----; IPython 7.16.1; jupyter_client 6.1.6; jupyter_core 4.6.3; notebook 6.0.3; -----; Python 3.7.2 (default, Jul 16 2019, 22:54:18) [GCC 8.2.0]; Linux-3.10.0-1160.36.2.el7.x86_64-x86_64-with-centos-7.9.2009-Core; 48 logical CPU cores, x86_64; -----; Session information updated at 2021-12-24 13:42. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2093
https://github.com/scverse/scanpy/issues/2093:485,Usability,guid,guide,485,"- [yes] I have checked that this issue has not already been reported.; - [yes] I have confirmed this bug exists on the latest version of scanpy.; - [yes] I have confirmed this bug exists on the master branch of scanpy. Suggested fix: change line 44 in scanpy/scanpy/tools/_utils.py . https://github.com/theislab/scanpy/blob/83f90141fd18943a1795772d3d39f4e9eefd65c3/scanpy/tools/_utils.py#L44 . from `X = pca(adata.X)` to `X = pca(adata.X)[:, :n_pcs]`. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Minimal code ; import scanpy as sc; import anndata; import numpy as np; print('scanpy=', sc.__version__); print('anndata=', anndata.__version__); print('numpy=', np.__version__). np.random.seed(0); adata_raw = anndata.AnnData(np.random.randn(20,200)); print('adata shape', adata.shape). # neighbors without precomputed pca; adata = adata_raw.copy(); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15); mat_neighbor10_pc15_without_pca = adata.obsp[""connectivities""].copy(). adata = adata_raw.copy(); sc.pp.pca(adata, n_comps=15); sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15); mat_neighbor10_pc15_with_pca = adata.obsp[""connectivities""].copy(). adata = adata_raw.copy(); sc.pp.pca(adata, n_comps=19) # max n_comps for 30 cells; sc.pp.neighbors(adata, n_neighbors=10, n_pcs=19); mat_neighbor10_pc19_with_pca = adata.obsp[""connectivities""].copy(). print('\nResults for `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` '; 'with and without precomputed pca are different:'); print(np.allclose(mat_neighbor10_pc15_without_pca.toarray(), mat_neighbor10_pc15_with_pca.toarray())); print('\nResults of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=15)` without precomputed pca is same as '; 'results of `sc.pp.neighbors(adata, n_neighbors=10, n_pcs=19)` (19 is default `n_comps`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2093
https://github.com/scverse/scanpy/pull/2094:0,Deployability,update,updates,0,updates:; - [github.com/pre-commit/pre-commit-hooks: v4.0.1 → v4.1.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.0.1...v4.1.0),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2094
https://github.com/scverse/scanpy/issues/2095:626,Availability,error,errors,626,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:545,Deployability,pipeline,pipeline,545,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:1480,Modifiability,layers,layers,1480,"ranch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset the raw data by ACT_sub2's highly variable genes. KeyError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_9544/4098982234.py in <module>; ----> 1 adata = adata[:, adata.var.highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:1831,Modifiability,layers,layers,1831,"CT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset the raw data by ACT_sub2's highly variable genes. KeyError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_9544/4098982234.py in <module>; ----> 1 adata = adata[:, adata.var.highly_variable]; 2 adata. ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1114 def __getitem__(self, index: Index) -> ""AnnData"":; 1115 """"""Returns a sliced view of the object.""""""; -> 1116 oidx, vidx = self._normalize_indices(index); 1117 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1118 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1095 ; 1096 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1097 return _normalize_indices(index, se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:2035,Modifiability,variab,variable,2035,"mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset the raw data by ACT_sub2's highly variable genes. KeyError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_9544/4098982234.py in <module>; ----> 1 adata = adata[:, adata.var.highly_variable]; 2 adata. ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1114 def __getitem__(self, index: Index) -> ""AnnData"":; 1115 """"""Returns a sliced view of the object.""""""; -> 1116 oidx, vidx = self._normalize_indices(index); 1117 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1118 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1095 ; 1096 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1097 return _normalize_indices(index, self.obs_names, self.var_names); 1098 ; 1099 # TODO: this is not quite complete... ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(ind",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:1116,Security,Access,Accession,1116,"ranch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset the raw data by ACT_sub2's highly variable genes. KeyError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_9544/4098982234.py in <module>; ----> 1 adata = adata[:, adata.var.highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:1779,Security,Access,Accession,1779,"CT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset the raw data by ACT_sub2's highly variable genes. KeyError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_9544/4098982234.py in <module>; ----> 1 adata = adata[:, adata.var.highly_variable]; 2 adata. ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in __getitem__(self, index); 1114 def __getitem__(self, index: Index) -> ""AnnData"":; 1115 """"""Returns a sliced view of the object.""""""; -> 1116 oidx, vidx = self._normalize_indices(index); 1117 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1118 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1095 ; 1096 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1097 return _normalize_indices(index, se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:257,Usability,guid,guide,257,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; It's very smooth to subset the adata by HVGs when doing `adata = adata[:, adata.var.highly_variable]` in the Scanpy pipeline. But when using the same coding to subeset a new raw adata, it generate errors. Could you please help me to check this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; ACT_sub2 = sc.read('C:/Users/Park_Lab/Documents/ACT_sub2.h5ad') # Scanpy proceeded data; ACT_sub2; AnnData object with n_obs × n_vars = 2636 × 5000; obs: 'leiden', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'total_counts_rpl', 'pct_counts_rpl', 'total_counts_rps', 'pct_counts_rps'; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand', 'n_cells', 'mt', 'rpl', 'rps', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'hvg', 'leiden', 'leiden_colors', 'neighbors', 'pca', 'rank_genes_groups', 'umap'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; layers: 'ambiguous', 'matrix', 'spliced', 'unspliced'; obsp: 'connectivities', 'distances'. adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/cellsorted_Apc_Cracd_Tumor_KPVDV.loom') # raw data; adata.var_names_make_unique(); adata; AnnData object with n_obs × n_vars = 13499 × 32285; var: 'Accession', 'Chromosome', 'End', 'Start', 'Strand'; layers: 'matrix', 'ambiguous', 'spliced', 'unspliced'. adata.var['highly_variable']=ACT_sub2.var['highly_variable']; adata = adata[:, adata.var.highly_variable] # subset ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:3804,Usability,learn,learn,3804,"ckages\anndata\_core\anndata.py in __getitem__(self, index); 1114 def __getitem__(self, index: Index) -> ""AnnData"":; 1115 """"""Returns a sliced view of the object.""""""; -> 1116 oidx, vidx = self._normalize_indices(index); 1117 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1118 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1095 ; 1096 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1097 return _normalize_indices(index, self.obs_names, self.var_names); 1098 ; 1099 # TODO: this is not quite complete... ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1; 38 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 99 if np.any(positions < 0):; 100 not_found = indexer[positions < 0]; --> 101 raise KeyError(; 102 f""Values {list(not_found)}, from {list(indexer)}, ""; 103 ""are not valid obs/ var names or indices."". KeyError: 'Values [nan, nan, nan, nan, nan, nan, True,... nan, nan, True], are not valid obs/ var names or indices.'. ```. ```pytb; KeyError: 'Values [nan, nan, nan, nan, nan, nan, True,... nan, nan, True], are not valid obs/ var names or indices.'; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.3 pandas==1.3.5 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.3 matplotlib==3.5.1 sklearn==1.0.1 pandas==1.3.5 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.3 pandas==1.3.5 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.1 seaborn==0.11.2. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/issues/2095:4133,Usability,learn,learn,4133,"ckages\anndata\_core\anndata.py in __getitem__(self, index); 1114 def __getitem__(self, index: Index) -> ""AnnData"":; 1115 """"""Returns a sliced view of the object.""""""; -> 1116 oidx, vidx = self._normalize_indices(index); 1117 return AnnData(self, oidx=oidx, vidx=vidx, asview=True); 1118 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\anndata.py in _normalize_indices(self, index); 1095 ; 1096 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:; -> 1097 return _normalize_indices(index, self.obs_names, self.var_names); 1098 ; 1099 # TODO: this is not quite complete... ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\index.py in _normalize_indices(index, names0, names1); 34 ax0, ax1 = unpack_index(index); 35 ax0 = _normalize_index(ax0, names0); ---> 36 ax1 = _normalize_index(ax1, names1); 37 return ax0, ax1; 38 . ~\anaconda3\envs\Python3812\lib\site-packages\anndata\_core\index.py in _normalize_index(indexer, index); 99 if np.any(positions < 0):; 100 not_found = indexer[positions < 0]; --> 101 raise KeyError(; 102 f""Values {list(not_found)}, from {list(indexer)}, ""; 103 ""are not valid obs/ var names or indices."". KeyError: 'Values [nan, nan, nan, nan, nan, nan, True,... nan, nan, True], are not valid obs/ var names or indices.'. ```. ```pytb; KeyError: 'Values [nan, nan, nan, nan, nan, nan, True,... nan, nan, True], are not valid obs/ var names or indices.'; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.3 scipy==1.7.3 pandas==1.3.5 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 pynndescent==0.5.5; scvelo==0.2.4 scanpy==1.8.2 anndata==0.7.8 loompy==3.0.6 numpy==1.20.3 scipy==1.7.3 matplotlib==3.5.1 sklearn==1.0.1 pandas==1.3.5 ; cellrank==1.5.0 scanpy==1.8.2 anndata==0.7.8 numpy==1.20.3 numba==0.54.1 scipy==1.7.3 pandas==1.3.5 pygpcca==1.0.2 scikit-learn==1.0.1 statsmodels==0.13.1 python-igraph==0.9.8 scvelo==0.2.4 pygam==0.8.0 matplotlib==3.5.1 seaborn==0.11.2. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2095
https://github.com/scverse/scanpy/pull/2096:0,Usability,Clear,Clears,0,Clears up warnings from using the provided datasets. * Filter out the OldFormatWarnings from using anndata > 0.8; * Fixes numpy warning from ebi dataset parsing; * Fix old format warning from reading `pbmc68k_reduced` file directly,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2096
https://github.com/scverse/scanpy/issues/2098:181,Modifiability,variab,variable,181,"I'm new to scanpy, and I want to plot umap with some genes. In this tutorial, it's written below. > sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). But, I could show only highly variable genes, because other genes were discarded by the code below. > adata = adata[:, adata.var.highly_variable]. So, how can I plot umap with genes without highly variable? How can I leave all genes in anndata?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2098
https://github.com/scverse/scanpy/issues/2098:348,Modifiability,variab,variable,348,"I'm new to scanpy, and I want to plot umap with some genes. In this tutorial, it's written below. > sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). But, I could show only highly variable genes, because other genes were discarded by the code below. > adata = adata[:, adata.var.highly_variable]. So, how can I plot umap with genes without highly variable? How can I leave all genes in anndata?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2098
https://github.com/scverse/scanpy/pull/2099:28,Deployability,update,updates,28,<!--pre-commit.ci start-->; updates:; - [github.com/psf/black: 21.12b0 → 22.1.0](https://github.com/psf/black/compare/21.12b0...22.1.0); - [github.com/pre-commit/mirrors-autopep8: v1.5.7 → v1.6.0](https://github.com/pre-commit/mirrors-autopep8/compare/v1.5.7...v1.6.0); <!--pre-commit.ci end-->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2099
https://github.com/scverse/scanpy/pull/2100:142,Integrability,depend,dependency,142,Building the docs fails ever since the version of `sphinx-autodoc-typehints` increased from v1.12.0 to v1.13.0. This PR temporarily pins this dependency's version to v1.12.0. See https://github.com/theislab/scanpy/pull/1828#issuecomment-1005072811 and cc @Zethson,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2100
https://github.com/scverse/scanpy/issues/2104:313,Availability,error,error,313,**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2104
https://github.com/scverse/scanpy/issues/2104:419,Testability,log,logging,419,**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2104
https://github.com/scverse/scanpy/issues/2104:28,Usability,guid,guide,28,**Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; # Your code here; ```. ```pytb; [Paste the error output produced by the above code here]; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2104
https://github.com/scverse/scanpy/issues/2105:347,Availability,ERROR,ERROR,347,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:362,Availability,error,errored,362,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2891,Availability,error,error,2891,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:25,Deployability,install,installing,25,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:243,Deployability,install,install,243,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:310,Deployability,install,install,310,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:489,Deployability,install,install-,489,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:586,Deployability,install,install-,586,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:820,Deployability,install,install,820,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:862,Deployability,install,install-record,862,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:946,Deployability,install,install-headers,946,"Hi,. I am having trouble installing scanpy on 5.12 Manjaro with Python 3.10. I believe it is because llvmlite currently [does not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1022,Deployability,install,install-,1022,"es not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1120,Deployability,install,install,1120,"es not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1175,Deployability,install,install-,1175,"es not support python 3.10](https://github.com/numba/llvmlite/issues/804#issuecomment-1002971267). Is there a way I can install scanpy with an older version of llvmlite? . ```python; pip install --user scanpy; ```. ```pytb. ERROR: Command errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1374,Deployability,install,install-,1374,"and errored out with exit status 1:; command: /usr/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1514,Deployability,install,install-,1514,"9522a491da51d00bc9034d43e/setup.py'""'""'; __file__='""'""'/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2369,Deployability,install,install-,2369,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2489,Deployability,install,install-,2489,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2625,Deployability,install,install-,2625,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2236,Modifiability,config,config,2236,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2812,Modifiability,config,config,2812,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:2883,Modifiability,config,config,2883,"ite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, please point LLVM_CONFIG ""; RuntimeError: llvm-config failed executing, please point LLVM_CONFIG to the path for llvm-config; error: command '/usr/bin/python' failed with exit code 1; ----------------------------------------; ```. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1777,Safety,timeout,timeout,1777,"e();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, pleas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/issues/2105:1785,Safety,timeout,timeout,1785,"e();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-j38v6hmh/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/ube/.local/include/python3.10/llvmlite; cwd: /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/; Complete output (29 lines):; running install; running build; got version from file /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/llvmlite/_version.py {'version': '0.34.0', 'full': 'c5889c9e98c6b19d5d85ebdd982d64a03931f8e2'}; running build_ext; /usr/bin/python /tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py; LLVM version... Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 105, in main_posix; out = subprocess.check_output([llvm_config, '--version']); File ""/usr/lib/python3.10/subprocess.py"", line 420, in check_output; return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,; File ""/usr/lib/python3.10/subprocess.py"", line 501, in run; with Popen(*popenargs, **kwargs) as process:; File ""/usr/lib/python3.10/subprocess.py"", line 966, in __init__; self._execute_child(args, executable, preexec_fn, close_fds,; File ""/usr/lib/python3.10/subprocess.py"", line 1842, in _execute_child; raise child_exception_type(errno_num, err_msg, err_filename); FileNotFoundError: [Errno 2] No such file or directory: 'llvm-config'; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 191, in <module>; main(); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 181, in main; main_posix('linux', '.so'); File ""/tmp/pip-install-i_hyvl0s/llvmlite_d91917e9522a491da51d00bc9034d43e/ffi/build.py"", line 107, in main_posix; raise RuntimeError(""%s failed executing, pleas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2105
https://github.com/scverse/scanpy/pull/2106:7,Testability,test,tests,7,I have tests which are being flaky locally which is making it quite difficult to debug other issues. This is me trying to fix some of those problems.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2106
https://github.com/scverse/scanpy/issues/2107:704,Availability,avail,available,704,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2107:1443,Testability,log,log,1443,"u have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-eb34a0f6-5261-4234-94a4-59ee6d566090.png). The domino plot without log scale:. ![image](https://user-images.githubusercontent.com/1651067/149316905-334deb6a-aeda-46be-8261-84e09ba7ad54.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2107:2068,Testability,log,log,2068,"u have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-eb34a0f6-5261-4234-94a4-59ee6d566090.png). The domino plot without log scale:. ![image](https://user-images.githubusercontent.com/1651067/149316905-334deb6a-aeda-46be-8261-84e09ba7ad54.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2107:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2107:1727,Usability,feedback,feedback,1727,"u have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-eb34a0f6-5261-4234-94a4-59ee6d566090.png). The domino plot without log scale:. ![image](https://user-images.githubusercontent.com/1651067/149316905-334deb6a-aeda-46be-8261-84e09ba7ad54.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2107:1777,Usability,simpl,simple,1777,"u have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Hi all!. My use case for scanpy is analysis of whole-body data from a weird marine annelid. We sort of have an idea of what to expect, but a lot of the analysis is exploratory, and my main job is helping canalize the knowledge that is available in the lab into making sense of the data. In this context, dotplots are our best friend, as it provides a very nice summary of gene expression over the whole (clustered) dataset. However, yesterday we noticed a confusing edge case: let’s say gene $g$ is expressed in the same number of cells in two clusters, 4 and 23. Cluster 4 has many, many more cells than 23, therefore on the dotplot it will look like $g$; is barely expressed in 4, but a great marker for 23. Of course, combining a dotplot with a feature plot helps you see that, but you get no sense of how many cells those are (more/less/the same). To alleviate this I am proposing an extension of dotplots: instead of circles, boxes, that have a height proportional to $log(#cells_{cluster})$, are filled proportionally to how many cells express gene $g$, and are colored according to the average expression. I think this works better than violinplots. Sadly I see no good way to multiplex this and plot multiple genes at once. I am really interested in feedback - maybe I am overlooking something super simple/basic?. ![image](https://user-images.githubusercontent.com/1651067/149312386-fbabade5-fdbe-4a72-a627-599bd103a9a9.png). the corresponding dotplot:. ![image](https://user-images.githubusercontent.com/1651067/149316899-eb34a0f6-5261-4234-94a4-59ee6d566090.png). The domino plot without log scale:. ![image](https://user-images.githubusercontent.com/1651067/149316905-334deb6a-aeda-46be-8261-84e09ba7ad54.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2107
https://github.com/scverse/scanpy/issues/2108:433,Deployability,install,installed,433,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:498,Deployability,upgrade,upgrade,498,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:677,Deployability,install,install,677,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:715,Deployability,install,install,715,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:780,Deployability,install,install,780,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:835,Deployability,install,installing,835,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:1119,Deployability,upgrade,upgraded,1119,"py.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:1088,Integrability,depend,dependency,1088,"py.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:3125,Performance,load,load,3125,"s pl. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\Python38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\Python38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```. #### Versions. <details>. Package Version; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; nat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:3375,Performance,Bottleneck,Bottleneck,3375,"_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\Python38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\Python38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```. #### Versions. <details>. Package Version; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; natsort 8.0.2; nbclassic 0.2.6; nbclient 0.5.3; nbconvert 6.1.0; nbformat 5.1.3; nest-asyncio 1.5.1; networkx 2.6.3; notebook 6.4.6; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; olefile 0.46; packaging 21.3; pandas 1.3.5; pandocfilters 1.4.3; pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:1479,Testability,log,logging,1479," ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:2582,Testability,log,logging,2582," from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\Python38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\Python38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```. #### Versions. <details>. Package Version; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:2593,Testability,log,logg,2593," from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. ~\.conda\envs\Python38\lib\site-packages\scanpy\tools\_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. ~\.conda\envs\Python38\lib\site-packages\scanpy\readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (. ~\.conda\envs\Python38\lib\site-packages\tables\__init__.py in <module>; 43 ; 44 # Necessary imports to get versions stored on the cython extension; ---> 45 from .utilsextension import get_hdf5_version as _get_hdf5_version; 46 ; 47 . ImportError: DLL load failed while importing utilsextension; ```. #### Versions. <details>. Package Version; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:4110,Testability,mock,mock,4110,rtError: DLL load failed while importing utilsextension; ```. #### Versions. <details>. Package Version; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; natsort 8.0.2; nbclassic 0.2.6; nbclient 0.5.3; nbconvert 6.1.0; nbformat 5.1.3; nest-asyncio 1.5.1; networkx 2.6.3; notebook 6.4.6; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; olefile 0.46; packaging 21.3; pandas 1.3.5; pandocfilters 1.4.3; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; Pillow 8.4.0; pip 21.2.2; prometheus-client 0.12.0; prompt-toolkit 3.0.20; pycparser 2.21; Pygments 2.10.0; pynndescent 0.5.5; pyOpenSSL 21.0.0; pyparsing 3.0.4; pyrsistent 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; python-igraph 0.9.9; pytz 2021.3; pywin32 302; pywinpty 0.5.7; pyzmq 22.3.0; requests 2.27.1; scanpy 1.8.2; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; Send2Trash 1.8.0; setuptools 58.0.4; sinfo 0.3.4; sip 4.19.13; six 1.16.0; sniffio 1.2.0; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; terminado 0.9.4; testpath 0.5.0; texttable 1.6.4; threadpoolctl 2.2.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; umap-learn 0.5.2; urllib3 1.26.7; wcwidth 0.2.5; webenco,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:4959,Testability,test,testpath,4959,ion; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; natsort 8.0.2; nbclassic 0.2.6; nbclient 0.5.3; nbconvert 6.1.0; nbformat 5.1.3; nest-asyncio 1.5.1; networkx 2.6.3; notebook 6.4.6; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; olefile 0.46; packaging 21.3; pandas 1.3.5; pandocfilters 1.4.3; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; Pillow 8.4.0; pip 21.2.2; prometheus-client 0.12.0; prompt-toolkit 3.0.20; pycparser 2.21; Pygments 2.10.0; pynndescent 0.5.5; pyOpenSSL 21.0.0; pyparsing 3.0.4; pyrsistent 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; python-igraph 0.9.9; pytz 2021.3; pywin32 302; pywinpty 0.5.7; pyzmq 22.3.0; requests 2.27.1; scanpy 1.8.2; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; Send2Trash 1.8.0; setuptools 58.0.4; sinfo 0.3.4; sip 4.19.13; six 1.16.0; sniffio 1.2.0; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; terminado 0.9.4; testpath 0.5.0; texttable 1.6.4; threadpoolctl 2.2.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; umap-learn 0.5.2; urllib3 1.26.7; wcwidth 0.2.5; webencodings 0.5.1; wheel 0.37.1; win-inet-pton 1.1.0; wincertstore 0.2; xlrd 1.2.0; zipp 3.7.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:259,Usability,guid,guide,259,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:738,Usability,learn,learn,738,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; I installed Scanpy, scVelo, CellRank, bbknn 2 months ago and never upgrade the packages. They were running very smoothly until I reimage my PC and reinstall Scanpy in anaconda today (Anaconda3-2021.05-Windows-x86_64, python3.8.12).; I tired `pip install scanpy[leiden]`. Tried `conda install seaborn scikit-learn statsmodels numba pytables`, `conda install -c conda-forge python-igraph leidenalg`. Tried installing `Java` and `visual C++ 2012-2022 redistributable`. Also tried rebuilding a new environment and reinstalled everything. Whatever I try, this bug still exists when I import Scanpy.; I guess it may be the incompatibility issue of packages. Some dependency packages which were upgraded by the developer in these months caused this incompatibility issue. Could you please help me with this bug?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600); ; import matplotlib.pyplot as pl; from matplotlib import rcParams; ```. ```pytb; ImportError Traceback (most recent call last); ~\AppData\Local\Temp/ipykernel_7844/2696797780.py in <module>; 1 import numpy as np; 2 import pandas as pd; ----> 3 import scanpy as sc; 4 import scanpy.external as sce; 5 import scipy. ~\.conda\envs\Python38\lib\site-packages\scanpy\__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:4757,Usability,learn,learn,4757,ion; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; natsort 8.0.2; nbclassic 0.2.6; nbclient 0.5.3; nbconvert 6.1.0; nbformat 5.1.3; nest-asyncio 1.5.1; networkx 2.6.3; notebook 6.4.6; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; olefile 0.46; packaging 21.3; pandas 1.3.5; pandocfilters 1.4.3; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; Pillow 8.4.0; pip 21.2.2; prometheus-client 0.12.0; prompt-toolkit 3.0.20; pycparser 2.21; Pygments 2.10.0; pynndescent 0.5.5; pyOpenSSL 21.0.0; pyparsing 3.0.4; pyrsistent 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; python-igraph 0.9.9; pytz 2021.3; pywin32 302; pywinpty 0.5.7; pyzmq 22.3.0; requests 2.27.1; scanpy 1.8.2; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; Send2Trash 1.8.0; setuptools 58.0.4; sinfo 0.3.4; sip 4.19.13; six 1.16.0; sniffio 1.2.0; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; terminado 0.9.4; testpath 0.5.0; texttable 1.6.4; threadpoolctl 2.2.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; umap-learn 0.5.2; urllib3 1.26.7; wcwidth 0.2.5; webencodings 0.5.1; wheel 0.37.1; win-inet-pton 1.1.0; wincertstore 0.2; xlrd 1.2.0; zipp 3.7.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2108:5061,Usability,learn,learn,5061,ion; ------------------- ---------; anndata 0.7.8; anyio 2.2.0; argon2-cffi 20.1.0; async-generator 1.10; attrs 21.2.0; Babel 2.9.1; backcall 0.2.0; bleach 4.1.0; Bottleneck 1.3.2; brotlipy 0.7.0; certifi 2021.10.8; cffi 1.15.0; charset-normalizer 2.0.4; colorama 0.4.4; cryptography 36.0.0; cycler 0.11.0; debugpy 1.5.1; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fonttools 4.25.0; h5py 3.6.0; idna 3.3; igraph 0.9.9; importlib-metadata 4.8.2; ipykernel 6.4.1; ipython 7.29.0; ipython-genutils 0.2.0; jedi 0.18.0; Jinja2 3.0.2; joblib 1.1.0; json5 0.9.6; jsonschema 3.2.0; jupyter-client 7.1.0; jupyter-core 4.9.1; jupyter-server 1.4.1; jupyterlab 3.2.1; jupyterlab-pygments 0.1.2; jupyterlab-server 2.10.2; kiwisolver 1.3.1; leidenalg 0.8.8; llvmlite 0.37.0; MarkupSafe 2.0.1; matplotlib 3.5.0; matplotlib-inline 0.1.2; mistune 0.8.4; mkl-fft 1.3.1; mkl-random 1.2.2; mkl-service 2.4.0; mock 4.0.3; munkres 1.1.4; natsort 8.0.2; nbclassic 0.2.6; nbclient 0.5.3; nbconvert 6.1.0; nbformat 5.1.3; nest-asyncio 1.5.1; networkx 2.6.3; notebook 6.4.6; numba 0.54.1; numexpr 2.8.1; numpy 1.20.3; olefile 0.46; packaging 21.3; pandas 1.3.5; pandocfilters 1.4.3; parso 0.8.3; patsy 0.5.2; pickleshare 0.7.5; Pillow 8.4.0; pip 21.2.2; prometheus-client 0.12.0; prompt-toolkit 3.0.20; pycparser 2.21; Pygments 2.10.0; pynndescent 0.5.5; pyOpenSSL 21.0.0; pyparsing 3.0.4; pyrsistent 0.18.0; PySocks 1.7.1; python-dateutil 2.8.2; python-igraph 0.9.9; pytz 2021.3; pywin32 302; pywinpty 0.5.7; pyzmq 22.3.0; requests 2.27.1; scanpy 1.8.2; scikit-learn 1.0.2; scipy 1.7.3; seaborn 0.11.2; Send2Trash 1.8.0; setuptools 58.0.4; sinfo 0.3.4; sip 4.19.13; six 1.16.0; sniffio 1.2.0; statsmodels 0.12.2; stdlib-list 0.8.0; tables 3.6.1; terminado 0.9.4; testpath 0.5.0; texttable 1.6.4; threadpoolctl 2.2.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; umap-learn 0.5.2; urllib3 1.26.7; wcwidth 0.2.5; webencodings 0.5.1; wheel 0.37.1; win-inet-pton 1.1.0; wincertstore 0.2; xlrd 1.2.0; zipp 3.7.0. </details>,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2108
https://github.com/scverse/scanpy/issues/2109:371,Availability,error,error,371,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109
https://github.com/scverse/scanpy/issues/2109:2179,Deployability,update,updated,2179,"anpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by conda-forge | (default, Nov 27 2020, 19:31:52) [GCC 9.3.0]; Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-glibc2.10; 24 logical CPU cores, x86_64; -----; Session information updated at 2022-01-14 13:58. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109
https://github.com/scverse/scanpy/issues/2109:864,Testability,log,logging,864,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109
https://github.com/scverse/scanpy/issues/2109:2125,Testability,log,logical,2125,"anpy. ---; Hello, . I would like to derive the transition matrix with the following input:. ```python; sc.Neighbors.compute_transitions(adata); ```. The error below was produced. The anndata object was fine with sc.pp.neighbors(adata) and sc.tl.umap(adata) for UMAP plotting. Thanks. ```pytb; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/root/miniconda3/envs/scVI/lib/python3.8/site-packages/scanpy/neighbors/__init__.py"", line 911, in compute_transitions; W = self._connectivities; AttributeError: 'AnnData' object has no attribute '_connectivities'; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.5; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.0.1; absl NA; anndata 0.7.5; attr 20.3.0; cffi 1.14.4; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; deprecate 0.3.0; docrep 0.3.2; fsspec 2022.01.0; google NA; h5py 3.1.0; igraph 0.9.1; joblib 0.17.0; kiwisolver 1.3.1; leidenalg 0.8.3; llvmlite 0.37.0; matplotlib 3.3.3; mkl 2.3.0; mpl_toolkits NA; natsort 7.1.0; numba 0.54.1; numexpr 2.7.1; numpy 1.19.2; opt_einsum v3.3.0; packaging 20.7; pandas 1.1.5; pkg_resources NA; pycparser 2.20; pygments 2.7.3; pynndescent 0.5.5; pyparsing 2.4.7; pyro 1.8.0+0ec1e87; pytorch_lightning 1.3.8; pytz 2020.4; rich NA; scanpy 1.8.2; scipy 1.5.2; scvi 0.14.5; setuptools 49.6.0.post20201009; setuptools_scm NA; sinfo 0.3.1; six 1.15.0; sklearn 1.0.1; sphinxcontrib NA; tables 3.6.1; tensorboard 2.7.0; texttable 1.6.3; threadpoolctl 2.1.0; torch 1.9.0; torchmetrics 0.6.2; tqdm 4.62.3; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 5.4.1; -----; Python 3.8.6 | packaged by conda-forge | (default, Nov 27 2020, 19:31:52) [GCC 9.3.0]; Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-glibc2.10; 24 logical CPU cores, x86_64; -----; Session information updated at 2022-01-14 13:58. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2109
https://github.com/scverse/scanpy/issues/2110:703,Availability,down,downstream,703,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110
https://github.com/scverse/scanpy/issues/2110:647,Deployability,release,released,647,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110
https://github.com/scverse/scanpy/issues/2110:749,Testability,log,log-transformed,749,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110
https://github.com/scverse/scanpy/issues/2110:1038,Testability,log,logFC,1038,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hello Scanpy,; In @LuckyMD 's amazing paper (https://www.embopress.org/doi/full/10.15252/msb.20188746), Table 1 shows that using raw data to calculate the maker genes of clusters is the appropriate way. But the raw data was not regressed out with mitochondrial genes, gene counts, cell cycle scores...So there will be so many mito genes ranked on the top of the marker gene list. What shall we do with these mito genes, because usually they represent the dead cell-released RNA contaminations?. In Seurat, they did every downstream analysis and plotting by using the log-transformed and scaled data (see below, the scaled dots in Seurat violin plot). Scanpy draws all plots by setting use_raw=True. I'm wondering which method is better?; ![image](https://user-images.githubusercontent.com/75048821/149461003-ed8d62d9-8aa9-4b5a-905d-e22bd10a1345.png). BTW, logFC will become negative and disappear for the marker genes of clusters when we set `use_raw=False` in `sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon'`. Please check this https://github.com/theislab/scanpy/issues/2057. Thanks!; Best,; YJ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2110
https://github.com/scverse/scanpy/pull/2111:42,Testability,test,test,42,This should allow us to use the dedicated test runner UI. See: https://github.com/tonybaloney/pytest-azurepipelines,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2111
https://github.com/scverse/scanpy/issues/2113:112,Availability,error,error,112,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:663,Availability,error,errors,663,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:2342,Availability,avail,available,2342,"ule>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/prepr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:3969,Availability,avail,available,3969,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:22,Deployability,install,install,22,"Hey, . I am trying to install scanpy through a Docker image. I get stuck in importing scanpy; It seems that the error has some link to numba but I am not sure!; ; ### Minimal code sample:. ```python; python -c ""from numba.caching import _UserProvidedCacheLocator; print(_UserProvidedCacheLocator(lambda x:x, 'string').get_cache_path())""; python -c ""import numba;print(numba.__version__)""; python -c ""import anndata;print(anndata.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import librosa;print(librosa.__version__)""; python -c ""import torch;print(torch.__version__)""; python -c ""import scanpy;print(scanpy.__version__)""; ```. ### errors:. ```python; /workspace; /opt/conda/bin/python; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; ModuleNotFoundError: No module named 'numba.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:1836,Integrability,wrap,wrapper,1836,"a.caching'; 0.53.1; 0.7.8; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/librosa/__init__.py"", line 211, in <module>; from . import core; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/__init__.py"", line 5, in <module>; from .convert import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py"", line 7, in <module>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:3450,Integrability,wrap,wrapper,3450,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:2299,Performance,cache,cache,2299,"ule>; from . import notation; File ""/opt/conda/lib/python3.7/site-packages/librosa/core/notation.py"", line 8, in <module>; from ..util.exceptions import ParameterError; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/__init__.py"", line 83, in <module>; from .utils import * # pylint: disable=wildcard-import; File ""/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py"", line 1848, in <module>; def __shear_dense(X, factor=+1, axis=-1):; File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/prepr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:3352,Performance,cache,cache,3352,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2113:3913,Performance,cache,cache,3913,"_path)); RuntimeError: cannot cache function '__shear_dense': no locator available for file '/opt/conda/lib/python3.7/site-packages/librosa/util/utils.py'; 1.10.1+cu102; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/opt/conda/lib/python3.7/site-packages/scanpy/__init__.py"", line 14, in <module>; from . import tools as tl; File ""/opt/conda/lib/python3.7/site-packages/scanpy/tools/__init__.py"", line 1, in <module>; from ..preprocessing import pca; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/__init__.py"", line 1, in <module>; from ._recipes import recipe_zheng17, recipe_weinreb17, recipe_seurat; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_recipes.py"", line 7, in <module>; from ._deprecated.highly_variable_genes import (; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_deprecated/highly_variable_genes.py"", line 11, in <module>; from .._utils import _get_mean_var; File ""/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py"", line 45, in <module>; @numba.njit(cache=True); File ""/opt/conda/lib/python3.7/site-packages/numba/core/decorators.py"", line 214, in wrapper; disp.enable_caching(); File ""/opt/conda/lib/python3.7/site-packages/numba/core/dispatcher.py"", line 812, in enable_caching; self._cache = FunctionCache(self.py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 610, in __init__; self._impl = self._impl_class(py_func); File ""/opt/conda/lib/python3.7/site-packages/numba/core/caching.py"", line 348, in __init__; ""for file %r"" % (qualname, source_path)); RuntimeError: cannot cache function 'sparse_mean_var_minor_axis': no locator available for file '/opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_utils.py'. ```. I would highly appreciate if you could please point out how to fix this issue. . Thank you in advance!. Best wishes,; Abdelrahman . ```. #### Versions. <details>. numba==0.53.1; scanpy==1.8.1. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2113
https://github.com/scverse/scanpy/issues/2114:473,Deployability,install,installed,473,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; This BUG is quite weird. It starts since we installed Anaconda3-v2021.11 on 3 individual Windows PCs. We run the same dataset by the same coding. However, it generates 3 different UMAPs. The coding is as below.; UMAP of Windows PC2 is consistent with our previous UMAPs done on PC1 and PC2 in November with Anaconda3-v2021.05.; Could you please help us with this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/Tumor.loom'); adata.var_names_make_unique(); adata; sc.pl.highest_expr_genes(adata, n_top=20); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=25); adata.var['mt'] = adata.var_names.str.startswith('mt-'); adata.var['rpl'] = adata.var_names.str.startswith('Rpl'); adata.var['rps'] = adata.var_names.str.startswith('Rps'); adata; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','rpl','rps'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, keys=['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_rpl','pct_counts_rps'], jitter=0.4, multi_panel=True); adata; sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rpl'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rps'); sc.pl.scatter(adata, x='total_cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:15098,Integrability,wrap,wrapt,15098,".0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:15115,Integrability,wrap,wrapt,15115,".5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:au",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:15132,Integrability,wrap,wrapt,15132," 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name=Generator content=""Microsoft Excel 15"">; <link id=Main-File rel=Main-File; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip.htm"">; <link rel=File-List; href=""file:///C:/Users/hyjfo/AppData/Local/Temp/msohtmlclip1/01/clip_filelist.xml"">; <style>; <!--table; 	{mso-displayed-decimal-separator:""\."";; 	mso-displayed-thousand-separator:""\,"";}; @page; 	{margin:.75in .7in .75in .7in;; 	mso-header-margin:.3in;; 	mso-footer-margin:.3in;}; tr; 	{mso-height-source:auto;; 	mso-ruby-vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:6271,Safety,timeout,timeout,6271,"font-family:""Var\(--jp-code-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl68; 	{text-align:center;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Windows PC1 |   | Windows PC2 |   | Windows PC3 |  ; -- | -- | -- | -- | -- | --; adjustText | 0.7.3 | adjustText | 0.7.3 | adjustText | 0.7.3; aiohttp | 3.8.1 | aiohttp | 3.8.1 | aiohttp | 3.8.1; aiosignal | 1.2.0 | aiosignal | 1.2.0 | aiosignal | 1.2.0; anndata | 0.7.8 | anndata | 0.7.8 | anndata | 0.7.8; anyio | 2.2.0 | anyio | 2.2.0 | anyio | 2.2.0; arboreto | 0.1.6 | arboreto | 0.1.6 | arboreto | 0.1.6; argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0; async-generator | 1.1 | async-generator | 1.1 | async-generator | 1.1; async-timeout | 4.0.2 | async-timeout | 4.0.2 | async-timeout | 4.0.2; attrs | 21.4.0 | attrs | 21.2.0 | attrs | 21.4.0; Babel | 2.9.1 | Babel | 2.9.1 | Babel | 2.9.1; backcall | 0.2.0 | backcall | 0.2.0 | backcall | 0.2.0; bleach | 4.1.0 | bleach | 4.1.0 | bleach | 4.1.0; bokeh | 2.4.2 | bokeh | 2.4.2 | bokeh | 2.4.2; boltons | 21.0.0 | boltons | 21.0.0 | boltons | 21.0.0; brotlipy | 0.7.0 | brotlipy | 0.7.0 | brotlipy | 0.7.0; cellrank | 1.5.1 | cellrank | 1.5.1 | cellrank | 1.5.1; certifi | 2020.6.20 | certifi | 2020.6.20 | certifi | 2020.6.20; cffi | 1.15.0 | cffi | 1.15.0 | cffi | 1.15.0; charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4; click | 8.0.3 | click | 8.0.3 | click | 8.0.3; cloudpickle | 2.0.0 | cloudpickle | 2.0.0 | cloudpickle | 2.0.0; colorama | 0.4.4 | colorama | 0.4.4 | colorama | 0.4.4; cryptography | 36.0.0 | cryptography | 36.0.0 | cryptography | 36.0.0; ctxcore | 0.1.1 | ctxcore | 0.1.1 | ctxcore | 0.1.1; cycler | 0.11.0 | cycler | 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:6295,Safety,timeout,timeout,6295,"ode-font-family\)"", sans-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl68; 	{text-align:center;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Windows PC1 |   | Windows PC2 |   | Windows PC3 |  ; -- | -- | -- | -- | -- | --; adjustText | 0.7.3 | adjustText | 0.7.3 | adjustText | 0.7.3; aiohttp | 3.8.1 | aiohttp | 3.8.1 | aiohttp | 3.8.1; aiosignal | 1.2.0 | aiosignal | 1.2.0 | aiosignal | 1.2.0; anndata | 0.7.8 | anndata | 0.7.8 | anndata | 0.7.8; anyio | 2.2.0 | anyio | 2.2.0 | anyio | 2.2.0; arboreto | 0.1.6 | arboreto | 0.1.6 | arboreto | 0.1.6; argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0; async-generator | 1.1 | async-generator | 1.1 | async-generator | 1.1; async-timeout | 4.0.2 | async-timeout | 4.0.2 | async-timeout | 4.0.2; attrs | 21.4.0 | attrs | 21.2.0 | attrs | 21.4.0; Babel | 2.9.1 | Babel | 2.9.1 | Babel | 2.9.1; backcall | 0.2.0 | backcall | 0.2.0 | backcall | 0.2.0; bleach | 4.1.0 | bleach | 4.1.0 | bleach | 4.1.0; bokeh | 2.4.2 | bokeh | 2.4.2 | bokeh | 2.4.2; boltons | 21.0.0 | boltons | 21.0.0 | boltons | 21.0.0; brotlipy | 0.7.0 | brotlipy | 0.7.0 | brotlipy | 0.7.0; cellrank | 1.5.1 | cellrank | 1.5.1 | cellrank | 1.5.1; certifi | 2020.6.20 | certifi | 2020.6.20 | certifi | 2020.6.20; cffi | 1.15.0 | cffi | 1.15.0 | cffi | 1.15.0; charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4; click | 8.0.3 | click | 8.0.3 | click | 8.0.3; cloudpickle | 2.0.0 | cloudpickle | 2.0.0 | cloudpickle | 2.0.0; colorama | 0.4.4 | colorama | 0.4.4 | colorama | 0.4.4; cryptography | 36.0.0 | cryptography | 36.0.0 | cryptography | 36.0.0; ctxcore | 0.1.1 | ctxcore | 0.1.1 | ctxcore | 0.1.1; cycler | 0.11.0 | cycler | 0.11.0 | cycler | 0.11.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:6319,Safety,timeout,timeout,6319,"-serif;; 	mso-font-charset:0;; 	text-align:center;}; .xl68; 	{text-align:center;}; ruby; 	{ruby-align:left;}; rt; 	{color:windowtext;; 	font-size:9.0pt;; 	font-weight:400;; 	font-style:normal;; 	text-decoration:none;; 	font-family:等线;; 	mso-generic-font-family:auto;; 	mso-font-charset:134;; 	mso-char-type:none;; 	display:none;}; -->; </style>; </head>. <body link=""#0563C1"" vlink=""#954F72"">. Windows PC1 |   | Windows PC2 |   | Windows PC3 |  ; -- | -- | -- | -- | -- | --; adjustText | 0.7.3 | adjustText | 0.7.3 | adjustText | 0.7.3; aiohttp | 3.8.1 | aiohttp | 3.8.1 | aiohttp | 3.8.1; aiosignal | 1.2.0 | aiosignal | 1.2.0 | aiosignal | 1.2.0; anndata | 0.7.8 | anndata | 0.7.8 | anndata | 0.7.8; anyio | 2.2.0 | anyio | 2.2.0 | anyio | 2.2.0; arboreto | 0.1.6 | arboreto | 0.1.6 | arboreto | 0.1.6; argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0 | argon2-cffi | 20.1.0; async-generator | 1.1 | async-generator | 1.1 | async-generator | 1.1; async-timeout | 4.0.2 | async-timeout | 4.0.2 | async-timeout | 4.0.2; attrs | 21.4.0 | attrs | 21.2.0 | attrs | 21.4.0; Babel | 2.9.1 | Babel | 2.9.1 | Babel | 2.9.1; backcall | 0.2.0 | backcall | 0.2.0 | backcall | 0.2.0; bleach | 4.1.0 | bleach | 4.1.0 | bleach | 4.1.0; bokeh | 2.4.2 | bokeh | 2.4.2 | bokeh | 2.4.2; boltons | 21.0.0 | boltons | 21.0.0 | boltons | 21.0.0; brotlipy | 0.7.0 | brotlipy | 0.7.0 | brotlipy | 0.7.0; cellrank | 1.5.1 | cellrank | 1.5.1 | cellrank | 1.5.1; certifi | 2020.6.20 | certifi | 2020.6.20 | certifi | 2020.6.20; cffi | 1.15.0 | cffi | 1.15.0 | cffi | 1.15.0; charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4 | charset-normalizer | 2.0.4; click | 8.0.3 | click | 8.0.3 | click | 8.0.3; cloudpickle | 2.0.0 | cloudpickle | 2.0.0 | cloudpickle | 2.0.0; colorama | 0.4.4 | colorama | 0.4.4 | colorama | 0.4.4; cryptography | 36.0.0 | cryptography | 36.0.0 | cryptography | 36.0.0; ctxcore | 0.1.1 | ctxcore | 0.1.1 | ctxcore | 0.1.1; cycler | 0.11.0 | cycler | 0.11.0 | cycler | 0.11.0; cytoolz | 0.11.0 | cyto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:1042,Testability,log,logging,1042,"lready been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; This BUG is quite weird. It starts since we installed Anaconda3-v2021.11 on 3 individual Windows PCs. We run the same dataset by the same coding. However, it generates 3 different UMAPs. The coding is as below.; UMAP of Windows PC2 is consistent with our previous UMAPs done on PC1 and PC2 in November with Anaconda3-v2021.05.; Could you please help us with this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/Tumor.loom'); adata.var_names_make_unique(); adata; sc.pl.highest_expr_genes(adata, n_top=20); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=25); adata.var['mt'] = adata.var_names.str.startswith('mt-'); adata.var['rpl'] = adata.var_names.str.startswith('Rpl'); adata.var['rps'] = adata.var_names.str.startswith('Rps'); adata; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','rpl','rps'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, keys=['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_rpl','pct_counts_rps'], jitter=0.4, multi_panel=True); adata; sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rpl'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rps'); sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts'); adata = adata[a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14087,Testability,test,testpath,14087,.27.1; scanpy | 1.8.2 | scanpy | 1.8.2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore |,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14106,Testability,test,testpath,14106,8.2 | scanpy | 1.8.2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14125,Testability,test,testpath,14125,2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:257,Usability,guid,guide,257,"- [✔] I have checked that this issue has not already been reported.; - [✔] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello Scanpy,; This BUG is quite weird. It starts since we installed Anaconda3-v2021.11 on 3 individual Windows PCs. We run the same dataset by the same coding. However, it generates 3 different UMAPs. The coding is as below.; UMAP of Windows PC2 is consistent with our previous UMAPs done on PC1 and PC2 in November with Anaconda3-v2021.05.; Could you please help us with this issue?; Thanks!; Best,; YJ. ### Minimal code sample (that we can copy&paste without having any data). ```python; import numpy as np; import pandas as pd; import scanpy as sc; import scanpy.external as sce; import scipy; sc.settings.verbosity = 3; sc.logging.print_header(); sc.set_figure_params(dpi=100, dpi_save=600). adata = sc.read_loom(filename='C:/Users/Park_Lab/Documents/Tumor.loom'); adata.var_names_make_unique(); adata; sc.pl.highest_expr_genes(adata, n_top=20); sc.pp.filter_cells(adata, min_genes=100); sc.pp.filter_genes(adata, min_cells=25); adata.var['mt'] = adata.var_names.str.startswith('mt-'); adata.var['rpl'] = adata.var_names.str.startswith('Rpl'); adata.var['rps'] = adata.var_names.str.startswith('Rps'); adata; sc.pp.calculate_qc_metrics(adata, qc_vars=['mt','rpl','rps'], percent_top=None, log1p=False, inplace=True); sc.pl.violin(adata, keys=['n_genes_by_counts', 'total_counts', 'pct_counts_mt','pct_counts_rpl','pct_counts_rps'], jitter=0.4, multi_panel=True); adata; sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rpl'); sc.pl.scatter(adata, x='total_counts', y='pct_counts_rps'); sc.pl.scatter(adata, x='total_cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:13156,Usability,learn,learn,13156,ygpcca | 1.0.3 | pygpcca | 1.0.3; pynndescent | 0.5.5 | pynndescent | 0.5.5 | pynndescent | 0.5.5; pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0; pyparsing | 3.0.4 | pyparsing | 3.0.4 | pyparsing | 3.0.4; pyrsistent | 0.18.0 | pyrsistent | 0.18.0 | pyrsistent | 0.18.0; pyscenic | 0.11.2 | pyscenic | 0.11.2 | pyscenic | 0.11.2; PySocks | 1.7.1 | PySocks | 1.7.1 | PySocks | 1.7.1; python-dateutil | 2.8.2 | python-dateutil | 2.8.2 | python-dateutil | 2.8.2; python-igraph | 0.9.9 | python-igraph | 0.9.9 | python-igraph | 0.9.9; python-utils | 3.1.0 | python-utils | 3.1.0 | python-utils | 3.1.0;   |   | pytoml | 0.1.21 |   |  ; pytz | 2021.3 | pytz | 2021.3 | pytz | 2021.3; pywin32 | 302 | pywin32 | 302 | pywin32 | 302; pywinpty | 0.5.7 | pywinpty | 0.5.7 | pywinpty | 0.5.7; PyYAML | 6 | PyYAML | 6 | PyYAML | 6; pyzmq | 22.3.0 | pyzmq | 22.3.0 | pyzmq | 22.3.0; requests | 2.27.1 | requests | 2.27.1 | requests | 2.27.1; scanpy | 1.8.2 | scanpy | 1.8.2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:13179,Usability,learn,learn,13179,ca | 1.0.3; pynndescent | 0.5.5 | pynndescent | 0.5.5 | pynndescent | 0.5.5; pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0; pyparsing | 3.0.4 | pyparsing | 3.0.4 | pyparsing | 3.0.4; pyrsistent | 0.18.0 | pyrsistent | 0.18.0 | pyrsistent | 0.18.0; pyscenic | 0.11.2 | pyscenic | 0.11.2 | pyscenic | 0.11.2; PySocks | 1.7.1 | PySocks | 1.7.1 | PySocks | 1.7.1; python-dateutil | 2.8.2 | python-dateutil | 2.8.2 | python-dateutil | 2.8.2; python-igraph | 0.9.9 | python-igraph | 0.9.9 | python-igraph | 0.9.9; python-utils | 3.1.0 | python-utils | 3.1.0 | python-utils | 3.1.0;   |   | pytoml | 0.1.21 |   |  ; pytz | 2021.3 | pytz | 2021.3 | pytz | 2021.3; pywin32 | 302 | pywin32 | 302 | pywin32 | 302; pywinpty | 0.5.7 | pywinpty | 0.5.7 | pywinpty | 0.5.7; PyYAML | 6 | PyYAML | 6 | PyYAML | 6; pyzmq | 22.3.0 | pyzmq | 22.3.0 | pyzmq | 22.3.0; requests | 2.27.1 | requests | 2.27.1 | requests | 2.27.1; scanpy | 1.8.2 | scanpy | 1.8.2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:13202,Usability,learn,learn,13202, | 0.5.5 | pynndescent | 0.5.5 | pynndescent | 0.5.5; pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0 | pyOpenSSL | 21.0.0; pyparsing | 3.0.4 | pyparsing | 3.0.4 | pyparsing | 3.0.4; pyrsistent | 0.18.0 | pyrsistent | 0.18.0 | pyrsistent | 0.18.0; pyscenic | 0.11.2 | pyscenic | 0.11.2 | pyscenic | 0.11.2; PySocks | 1.7.1 | PySocks | 1.7.1 | PySocks | 1.7.1; python-dateutil | 2.8.2 | python-dateutil | 2.8.2 | python-dateutil | 2.8.2; python-igraph | 0.9.9 | python-igraph | 0.9.9 | python-igraph | 0.9.9; python-utils | 3.1.0 | python-utils | 3.1.0 | python-utils | 3.1.0;   |   | pytoml | 0.1.21 |   |  ; pytz | 2021.3 | pytz | 2021.3 | pytz | 2021.3; pywin32 | 302 | pywin32 | 302 | pywin32 | 302; pywinpty | 0.5.7 | pywinpty | 0.5.7 | pywinpty | 0.5.7; PyYAML | 6 | PyYAML | 6 | PyYAML | 6; pyzmq | 22.3.0 | pyzmq | 22.3.0 | pyzmq | 22.3.0; requests | 2.27.1 | requests | 2.27.1 | requests | 2.27.1; scanpy | 1.8.2 | scanpy | 1.8.2 | scanpy | 1.8.2; scikit-learn | 1.0.2 | scikit-learn | 1.0.2 | scikit-learn | 1.0.2;   |   | scikit-misc | 0.1.4 |   |  ; scipy | 1.7.3 | scipy | 1.7.3 | scipy | 1.7.3; scvelo | 0.2.4 | scvelo | 0.2.4 | scvelo | 0.2.4; seaborn | 0.11.2 | seaborn | 0.11.2 | seaborn | 0.11.2; Send2Trash | 1.8.0 | Send2Trash | 1.8.0 | Send2Trash | 1.8.0; setuptools | 58.0.4 | setuptools | 58.0.4 | setuptools | 58.0.4;   |   | setuptools-scm | 6.3.2 |   |  ; sinfo | 0.3.4 | sinfo | 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14595,Usability,learn,learn,14595,"| 0.3.4 | sinfo | 0.3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14616,Usability,learn,learn,14616,"3.4; six | 1.16.0 | six | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Exc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2114:14637,Usability,learn,learn,14637,"ix | 1.16.0 | six | 1.16.0; sniffio | 1.2.0 | sniffio | 1.2.0 | sniffio | 1.2.0; sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0 | sortedcontainers | 2.4.0; statsmodels | 0.13.1 | statsmodels | 0.13.1 | statsmodels | 0.13.1; stdlib-list | 0.8.0 | stdlib-list | 0.8.0 | stdlib-list | 0.8.0; tables | 3.6.1 | tables | 3.6.1 | tables | 3.6.1; tblib | 1.7.0 | tblib | 1.7.0 | tblib | 1.7.0; terminado | 0.9.4 | terminado | 0.9.4 | terminado | 0.9.4; testpath | 0.5.0 | testpath | 0.5.0 | testpath | 0.5.0; texttable | 1.6.4 | texttable | 1.6.4 | texttable | 1.6.4; threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0 | threadpoolctl | 3.0.0;   |   | tomli | 2.0.0 |   |  ; toolz | 0.11.1 | toolz | 0.11.1 | toolz | 0.11.1; tornado | 6.1 | tornado | 6.1 | tornado | 6.1; tqdm | 4.62.3 | tqdm | 4.62.3 | tqdm | 4.62.3; traitlets | 5.1.1 | traitlets | 5.1.1 | traitlets | 5.1.1; typing_extensions | 4.0.1 | typing_extensions | 4.0.1 | typing_extensions | 4.0.1; umap-learn | 0.5.2 | umap-learn | 0.5.2 | umap-learn | 0.5.2; urllib3 | 1.26.7 | urllib3 | 1.26.7 | urllib3 | 1.26.7; wcwidth | 0.2.5 | wcwidth | 0.2.5 | wcwidth | 0.2.5; webencodings | 0.5.1 | webencodings | 0.5.1 | webencodings | 0.5.1; wheel | 0.37.1 | wheel | 0.37.1 | wheel | 0.37.1; widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2 | widgetsnbextension | 3.5.2; win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0 | win-inet-pton | 1.1.0; wincertstore | 0.2 | wincertstore | 0.2 | wincertstore | 0.2; wrapt | 1.13.3 | wrapt | 1.13.3 | wrapt | 1.13.3; xlrd | 1.2.0 | xlrd | 1.2.0 | xlrd | 1.2.0; yarl | 1.7.2 | yarl | 1.7.2 | yarl | 1.7.2; zict | 2.0.0 | zict | 2.0.0 | zict | 2.0.0; zipp | 3.7.0 | zipp | 3.7.0 | zipp | 3.7.0. </body>. </html>. These packages are different among these 3 PCs :<html xmlns:v=""urn:schemas-microsoft-com:vml""; xmlns:o=""urn:schemas-microsoft-com:office:office""; xmlns:x=""urn:schemas-microsoft-com:office:excel""; xmlns=""http://www.w3.org/TR/REC-html40"">. <head>. <meta name=ProgId content=Excel.Sheet>; <meta name",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2114
https://github.com/scverse/scanpy/issues/2115:453,Modifiability,extend,extend,453,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; Hi, . In the original Coifman/Lafon paper on diffusion maps they introduce a family of kernels index by some alpha. I'm just wondering what value of alpha is implemented in scanpy. I assume it's alpha=0, based on the documentation but its a bit unclear. Is there any plans to extend it to other values of alpha? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2115
https://github.com/scverse/scanpy/issues/2118:107,Availability,error,error,107,"`sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True)`. always get the error. ```; TypeError Traceback (most recent call last); <ipython-input-40-5bc1cab6ebf2> in <module>; ----> 1 sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True). ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_stacked_violin.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 717 return vp; 718 else:; --> 719 vp.make_figure(); 720 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 721 show = settings.autoshow if show is None else show. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in make_figure(self); 738 if self.legends_width > 0:; 739 legend_ax = self.fig.add_subplot(gs[0, 1]); --> 740 self._plot_legend(legend_ax, return_ax_dict, normalize); 741 ; 742 self.ax_dict = return_ax_dict. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 535 color_legend_ax = fig.add_subplot(legend_gs[1]); 536 ; --> 537 self._plot_colorbar(color_legend_ax, normalize); 538 return_ax_dict['color_legend_ax'] = color_legend_ax; 539 . ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_colorbar(self, color_legend_ax, normalize); 508 import matplotlib.colorbar; 509 ; --> 510 matplotlib.colorbar.Colorbar(; 511 color_legend_ax, orientation='horizontal', cmap=cmap, norm=normalize; 512 ). TypeError: __init__() missing 1 required positional argument: 'mappable'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118
https://github.com/scverse/scanpy/issues/2118:435,Testability,log,log,435,"`sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True)`. always get the error. ```; TypeError Traceback (most recent call last); <ipython-input-40-5bc1cab6ebf2> in <module>; ----> 1 sc.pl.stacked_violin(adata_pl, var_names=check_terms, groupby='ct_cond', swap_axes=True). ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_stacked_violin.py in stacked_violin(adata, var_names, groupby, log, use_raw, num_categories, title, colorbar_title, figsize, dendrogram, gene_symbols, var_group_positions, var_group_labels, standard_scale, var_group_rotation, layer, stripplot, jitter, size, scale, yticklabels, order, swap_axes, show, save, return_fig, row_palette, cmap, ax, vmin, vmax, vcenter, norm, **kwds); 717 return vp; 718 else:; --> 719 vp.make_figure(); 720 savefig_or_show(StackedViolin.DEFAULT_SAVE_PREFIX, show=show, save=save); 721 show = settings.autoshow if show is None else show. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in make_figure(self); 738 if self.legends_width > 0:; 739 legend_ax = self.fig.add_subplot(gs[0, 1]); --> 740 self._plot_legend(legend_ax, return_ax_dict, normalize); 741 ; 742 self.ax_dict = return_ax_dict. ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_legend(self, legend_ax, return_ax_dict, normalize); 535 color_legend_ax = fig.add_subplot(legend_gs[1]); 536 ; --> 537 self._plot_colorbar(color_legend_ax, normalize); 538 return_ax_dict['color_legend_ax'] = color_legend_ax; 539 . ~\Apps\Miniconda3\envs\work38\lib\site-packages\scanpy\plotting\_baseplot_class.py in _plot_colorbar(self, color_legend_ax, normalize); 508 import matplotlib.colorbar; 509 ; --> 510 matplotlib.colorbar.Colorbar(; 511 color_legend_ax, orientation='horizontal', cmap=cmap, norm=normalize; 512 ). TypeError: __init__() missing 1 required positional argument: 'mappable'; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2118
https://github.com/scverse/scanpy/pull/2119:26,Security,certificate,certificates,26,"I have some problems with certificates. I can't find what is the default certificate location for urllib, but it is certainly not certifi location. This tries opening with standard certificates as before and if it fails it tries to use certifi.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2119
https://github.com/scverse/scanpy/pull/2119:73,Security,certificate,certificate,73,"I have some problems with certificates. I can't find what is the default certificate location for urllib, but it is certainly not certifi location. This tries opening with standard certificates as before and if it fails it tries to use certifi.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2119
https://github.com/scverse/scanpy/pull/2119:181,Security,certificate,certificates,181,"I have some problems with certificates. I can't find what is the default certificate location for urllib, but it is certainly not certifi location. This tries opening with standard certificates as before and if it fails it tries to use certifi.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2119
https://github.com/scverse/scanpy/issues/2121:428,Availability,error,error,428,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:491,Availability,down,down,491,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:3312,Availability,Mask,MaskedArray,3312,"ols/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds); 376 if self.stats is None:; 377 idx = pd.MultiIndex.from_tuples([(group_name, first_col)]); --> 378 self.stats = pd.DataFrame(columns=idx); 379 ; 380 if n_genes_user is not None:. /usr/local/lib/python3.8/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 433 ); 434 elif isinstance(data, dict):; --> 435 mgr = init_dict(data, index, columns, dtype=dtype); 436 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:4322,Availability,down,downgrade,4322,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:4301,Deployability,install,installs,4301,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:4438,Deployability,install,install,4438,"construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; nbformat 5.0.8; numba 0.55.0; numexpr 2.7.3; numpy 1.21.5; numpy_groupies 0.9.13; packaging 21.3; pandas 1.0.4; parso 0.7.1; patsy 0.5.2; pex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:6263,Deployability,update,updated,6263,"nstalls and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; nbformat 5.0.8; numba 0.55.0; numexpr 2.7.3; numpy 1.21.5; numpy_groupies 0.9.13; packaging 21.3; pandas 1.0.4; parso 0.7.1; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.8; psutil 5.9.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; scipy 1.4.1; seaborn 0.11.2; send2trash NA; setuptools_scm NA; sitecustomize NA; six 1.14.0; sklearn 0.22.2.post1; statsmodels 0.13.0rc0; storemagic NA; tables 3.7.0; tblib 1.7.0; terminado 0.9.1; texttable 1.6.4; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.3.10; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; jupyterlab 3.2.8; notebook 6.1.5; -----; Python 3.8.12 (default, Oct 22 2021, 18:39:35) [Clang 13.0.0 (clang-1300.0.29.3)]; macOS-12.1-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2022-01-25 07:11. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:26,Integrability,protocol,protocol,26,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:116,Integrability,protocol,protocol-CLI,116,"I am following the SCENIC protocol (https://github.com/aertslab/SCENICprotocol/blob/master/notebooks/PBMC10k_SCENIC-protocol-CLI.ipynb) with an admittedly different data set, but still using 10x data of similar type. I have to admit that I am relatively new to the python world and don't know yet where to turn to... ; haven't found any way to debug any further I conclude that this is a scanpy issue, at a minimal level at the error reporting stage as the information doesn't help me track down what is wrong. thanks for your time! . adata. ```; AnnData object with n_obs × n_vars = 4578 × 3389; obs: 'nGene', 'nUMI', 'n_genes', 'percent_mito', 'n_counts', 'louvain', 'leiden'; var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'; uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap', 'louvain', 'leiden', 'louvain_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeEr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:4383,Integrability,message,message,4383,"ds. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; nbformat 5.0.8; numba 0.55.0; numexpr 2.7.3; numpy 1.21.5; numpy_groupies 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:4282,Safety,avoid,avoid,4282,"6 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/construction.py in init_dict(data, index, columns, dtype); 237 else:; 238 nan_dtype = dtype; --> 239 val = construct_1d_arraylike_from_scalar(np.nan, len(index), nan_dtype); 240 arrays.loc[missing] = [val] * missing.sum(); 241 . /usr/local/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1438 else:; 1439 if not isinstance(dtype, (np.dtype, type(np.dtype))):; -> 1440 dtype = dtype.dtype; 1441 ; 1442 if length and is_integer_dtype(dtype) and isna(value):. AttributeError: type object 'object' has no attribute 'dtype'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:1856,Testability,test,test,1856,"in_colors', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap', 'X_tsne'; varm: 'PCs'; obsp: 'distances', 'connectivities'; ```. my adata.raw.X looks like this:. ```; <4578x18247 sparse matrix of type '<class 'numpy.float32'>'; 	with 9236127 stored elements in Compressed Sparse Row format>; ```. adatat.X. ```; array([[ 0.23202083, 0.07064813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-50-04ed1c1ca569> in <module>; 1 # find marker genes; 2 #pdb.set_trace(); ----> 3 sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); 4 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); 5 . /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:2188,Testability,test,test,2188,"64813, -0.05003222, ..., 1.4681866 ,; -0.21488723, 2.620106 ],; [ 0.09879599, 0.03607919, -0.08120057, ..., -0.3384455 ,; -0.19780253, 2.0771198 ],; [-0.5213845 , -0.1292537 , -0.1755099 , ..., -0.23126683,; -0.10592338, 0.02626752],; ...,; [ 2.4987383 , -0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-50-04ed1c1ca569> in <module>; 1 # find marker genes; 2 #pdb.set_trace(); ----> 3 sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); 4 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); 5 . /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds); 376 if self.stats is None:; 377 idx = pd.MultiIndex.from_tuples([(group_name, first_col)]); --> 378 self.stats = pd.DataFrame(columns=idx); 379 ; 380 if n_genes_user is not None:. /usr/local/lib/python3.8/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:2516,Testability,log,logg,2516,"-0.14190508, -0.20776471, ..., -0.20877847,; -0.10354204, 0.14313072],; [ 0.1960011 , 0.06290449, -0.07691702, ..., -0.34954828,; 2.5718384 , 2.468825 ],; [-0.53571457, -0.13106212, -0.20085879, ..., -0.21621887,; -0.10943384, 0.05686853]], dtype=float32); ```. ### Minimal code sample (that we can copy&paste without having any data). ```python; # find marker genes; sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); ```. ```pytb; ranking genes; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-50-04ed1c1ca569> in <module>; 1 # find marker genes; 2 #pdb.set_trace(); ----> 3 sc.tl.rank_genes_groups(adata, 'louvain', method='t-test', reference = 'rest'); 4 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False); 5 . /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds); 581 logg.debug(f'with sizes: {np.count_nonzero(test_obj.groups_masks, axis=1)}'); 582 ; --> 583 test_obj.compute_statistics(; 584 method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds; 585 ). /usr/local/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in compute_statistics(self, method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds); 376 if self.stats is None:; 377 idx = pd.MultiIndex.from_tuples([(group_name, first_col)]); --> 378 self.stats = pd.DataFrame(columns=idx); 379 ; 380 if n_genes_user is not None:. /usr/local/lib/python3.8/site-packages/pandas/core/frame.py in __init__(self, data, index, columns, dtype, copy); 433 ); 434 elif isinstance(data, dict):; --> 435 mgr = init_dict(data, index, columns, dtype=dtype); 436 elif isinstance(data, ma.MaskedArray):; 437 import numpy.ma.mrecords as mrecords. /usr/local/lib/python3.8/site-packages/pandas/core/internals/constr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2121:6211,Testability,log,logical,6211,"nstalls and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.4; scanpy 1.6.0; sinfo 0.3.4; -----; MulticoreTSNE NA; PIL 8.0.1; appnope 0.1.2; attr 20.3.0; backcall 0.2.0; cffi 1.14.4; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; cytoolz 0.11.2; dask 2022.01.0; dateutil 2.8.1; decorator 4.4.2; dunamai 1.7.0; fsspec 2022.01.0; get_version 3.5.3; google NA; h5py 2.10.0; idna 2.10; igraph 0.9.6; ipykernel 5.3.4; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.17.2; jinja2 2.11.2; joblib 1.0.1; jsonschema 3.2.0; jupyter_server 1.13.3; kiwisolver 1.3.1; legacy_api_wrap 1.2; leidenalg 0.8.0; llvmlite 0.38.0; loompy 3.0.6; louvain 0.7.0; markupsafe 1.1.1; matplotlib 3.3.3; mpl_toolkits NA; natsort 7.1.1; nbformat 5.0.8; numba 0.55.0; numexpr 2.7.3; numpy 1.21.5; numpy_groupies 0.9.13; packaging 21.3; pandas 1.0.4; parso 0.7.1; patsy 0.5.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.8; psutil 5.9.0; ptyprocess 0.6.0; pvectorc NA; pycparser 2.20; pygments 2.7.2; pyparsing 2.4.7; pyrsistent NA; pytz 2020.4; scipy 1.4.1; seaborn 0.11.2; send2trash NA; setuptools_scm NA; sitecustomize NA; six 1.14.0; sklearn 0.22.2.post1; statsmodels 0.13.0rc0; storemagic NA; tables 3.7.0; tblib 1.7.0; terminado 0.9.1; texttable 1.6.4; tlz 0.11.2; toolz 0.11.2; tornado 6.1; traitlets 5.0.5; typing_extensions NA; umap 0.3.10; wcwidth 0.2.5; yaml 5.3.1; zmq 20.0.0; -----; IPython 7.19.0; jupyter_client 6.1.7; jupyter_core 4.7.0; jupyterlab 3.2.8; notebook 6.1.5; -----; Python 3.8.12 (default, Oct 22 2021, 18:39:35) [Clang 13.0.0 (clang-1300.0.29.3)]; macOS-12.1-x86_64-i386-64bit; 12 logical CPU cores, i386; -----; Session information updated at 2022-01-25 07:11. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2121
https://github.com/scverse/scanpy/issues/2122:776,Availability,error,error,776,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello !. I'm not sure whether this is a bug or it is enforced intentionally but even though users can use the kwargs to pass on to `sc.pl.embedding` any additional argument for `matplotlib.pyplot.scatter()`, trying to change the marker style doesn't work. As you can see below, the marker style is hardcoded in `sc.pl.embedding` to always be ""."" thus raising an error when trying to use another marker style due to `scatter()` being fed with the keyword argument `marker` multiple times.; Best,. Jules. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import anndata. adata = anndata.AnnData(X=np.random.rand(1000, 20)); sc.pp.neighbors(adata); sc.tl.umap(adata, min_dist=0.2); sc.pl.umap(adata,show=True, marker=""^""); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_10129/876858932.py in <module>; 5 sc.pp.neighbors(adata); 6 sc.tl.umap(adata, min_dist=0.2); ----> 7 sc.pl.umap(adata,show=True, marker=""^""). ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:2726,Availability,down,downgrade,2726,"niconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:2705,Deployability,install,installs,2705,"niconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:2842,Deployability,install,install,2842,"ort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.9.0; ptyprocess 0.7.0; pycparser ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:4613,Deployability,update,updated,4613,"PI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.4; pyparsing 2.4.7; pyreadr 0.4.4; pytz 2021.3; scipy 1.7.1; seaborn 0.11.2; six 1.16.0; sklearn 1.0; sphinxcontrib NA; statsmodels 0.13.0; storemagic NA; tables 3.6.1; threadpoolctl 3.0.0; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; yaml 5.4.1; zipp NA; zmq 22.3.0; -----; IPython 7.28.0; jupyter_client 7.0.6; jupyter_core 4.8.1; notebook 6.4.4; -----; Python 3.7.2 (default, Dec 29 2018, 06:19:36) [GCC 7.3.0]; Linux-4.15.0-70-generic-x86_64-with-debian-buster-sid; 4 logical CPU cores, x86_64; -----; Session information updated at 2022-01-25 10:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:2787,Integrability,message,message,2787,"ots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:2686,Safety,avoid,avoid,2686,"niconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs); 383 rasterized=settings._vector_friendly,; 384 norm=normalize,; --> 385 **kwargs,; 386 ); 387 . TypeError: functools.partial object got multiple values for keyword argument 'marker'; ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`!; The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:4559,Testability,log,logical,4559,"PI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info.; -----; anndata 0.7.6; scanpy 1.8.1; sinfo 0.3.4; -----; PIL 8.3.2; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.14.6; cloudpickle 2.0.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dask 2021.09.1; dateutil 2.8.2; debugpy 1.5.0; decorator 5.1.0; defusedxml 0.7.1; entrypoints 0.3; fsspec 2021.10.0; google NA; h5py 3.4.0; ipykernel 6.4.1; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.0; jinja2 3.0.2; joblib 1.1.0; kiwisolver 1.3.2; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.4.3; matplotlib_inline NA; mpl_toolkits NA; mudata 0.1.0; muon 0.1.1; natsort 7.1.1; nbinom_ufunc NA; numba 0.54.1; numexpr 2.7.3; numpy 1.20.3; packaging 21.0; pandas 1.3.3; parso 0.8.2; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 2.0.10; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.20; pydev_ipython NA; pydevconsole NA; pydevd 2.4.1; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pynndescent 0.5.4; pyparsing 2.4.7; pyreadr 0.4.4; pytz 2021.3; scipy 1.7.1; seaborn 0.11.2; six 1.16.0; sklearn 1.0; sphinxcontrib NA; statsmodels 0.13.0; storemagic NA; tables 3.6.1; threadpoolctl 3.0.0; tlz 0.11.1; toolz 0.11.1; tornado 6.1; tqdm 4.62.3; traitlets 5.1.0; typing_extensions NA; umap 0.5.1; wcwidth 0.2.5; yaml 5.4.1; zipp NA; zmq 22.3.0; -----; IPython 7.28.0; jupyter_client 7.0.6; jupyter_core 4.8.1; notebook 6.4.4; -----; Python 3.7.2 (default, Dec 29 2018, 06:19:36) [GCC 7.3.0]; Linux-4.15.0-70-generic-x86_64-with-debian-buster-sid; 4 logical CPU cores, x86_64; -----; Session information updated at 2022-01-25 10:12. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2122:257,Usability,guid,guide,257,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hello !. I'm not sure whether this is a bug or it is enforced intentionally but even though users can use the kwargs to pass on to `sc.pl.embedding` any additional argument for `matplotlib.pyplot.scatter()`, trying to change the marker style doesn't work. As you can see below, the marker style is hardcoded in `sc.pl.embedding` to always be ""."" thus raising an error when trying to use another marker style due to `scatter()` being fed with the keyword argument `marker` multiple times.; Best,. Jules. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; import anndata. adata = anndata.AnnData(X=np.random.rand(1000, 20)); sc.pp.neighbors(adata); sc.tl.umap(adata, min_dist=0.2); sc.pl.umap(adata,show=True, marker=""^""); ```. ```pytb; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_10129/876858932.py in <module>; 5 sc.pp.neighbors(adata); 6 sc.tl.umap(adata, min_dist=0.2); ----> 7 sc.pl.umap(adata,show=True, marker=""^""). ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs); 657 tl.umap; 658 """"""; --> 659 return embedding(adata, 'umap', **kwargs); 660 ; 661 . ~/miniconda3/envs/uhler/lib/python3.7/site-packages/scanpy/plotting/_tools/scatterplots.py in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, layer, projection, scale_factor, color_map, cmap, palette, na_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2122
https://github.com/scverse/scanpy/issues/2123:719,Availability,down,downstream,719,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [✔] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hello Scanpy,; I'm not sure whether Scanpy already has this function. For example, if we have `query` and `ref` data, we can use `ingest` to map the `query` onto the embedding of `ref`. Then, we can get similar UMAPs between these 2 data and do downstream analysis (like scVelo) based on these 2 UMAPs (coding below). In this way, because the UMAP is similar, we can have a more clear answer about how different these 2 date is.; ```python; ref = sc.read('ref.h5ad'); query = sc.read('query.h5ad'); var_names = query.var_names.intersection(ref.var_names); query = query[:, var_names]; ref = ref[:, var_names]; sc.tl.ingest(adata=query, adata_ref=ref, obs='leiden'); sc.pl.umap(query, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False) # this step will generate new obs['leiden'] and obsm['X_umap'] for query, which is a similar embedding with ref. adata = sc.read_loom(filename='queryraw.loom'); adata.obs['leiden']=query.obs['leiden'] # copy ingested leiden to raw data; adata.obsm['X_umap']=query.obsm['X_umap'] # copy ingested X_umap to raw data; # then do scVelo on this adata by using this embedding.; ```. However, `ingest` doesn't remove the batch effect. `BBKNN` does. After `BBKNN`, both `query` and `ref` will have new UMAPs stored at the same obsm['X_umap']. I'm wondering whether it is possible to split these 2 UMAPs? For example, store `query` UMAP in obsm['X_query_umap'] and `ref` UMAP in obsm['X_ref_umap'] so that we can copy each into a raw data. ![image](https://user-images.git",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2123
https://github.com/scverse/scanpy/issues/2123:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [✔] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hello Scanpy,; I'm not sure whether Scanpy already has this function. For example, if we have `query` and `ref` data, we can use `ingest` to map the `query` onto the embedding of `ref`. Then, we can get similar UMAPs between these 2 data and do downstream analysis (like scVelo) based on these 2 UMAPs (coding below). In this way, because the UMAP is similar, we can have a more clear answer about how different these 2 date is.; ```python; ref = sc.read('ref.h5ad'); query = sc.read('query.h5ad'); var_names = query.var_names.intersection(ref.var_names); query = query[:, var_names]; ref = ref[:, var_names]; sc.tl.ingest(adata=query, adata_ref=ref, obs='leiden'); sc.pl.umap(query, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False) # this step will generate new obs['leiden'] and obsm['X_umap'] for query, which is a similar embedding with ref. adata = sc.read_loom(filename='queryraw.loom'); adata.obs['leiden']=query.obs['leiden'] # copy ingested leiden to raw data; adata.obsm['X_umap']=query.obsm['X_umap'] # copy ingested X_umap to raw data; # then do scVelo on this adata by using this embedding.; ```. However, `ingest` doesn't remove the batch effect. `BBKNN` does. After `BBKNN`, both `query` and `ref` will have new UMAPs stored at the same obsm['X_umap']. I'm wondering whether it is possible to split these 2 UMAPs? For example, store `query` UMAP in obsm['X_query_umap'] and `ref` UMAP in obsm['X_ref_umap'] so that we can copy each into a raw data. ![image](https://user-images.git",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2123
https://github.com/scverse/scanpy/issues/2123:853,Usability,clear,clear,853,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [✔] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; ...; Hello Scanpy,; I'm not sure whether Scanpy already has this function. For example, if we have `query` and `ref` data, we can use `ingest` to map the `query` onto the embedding of `ref`. Then, we can get similar UMAPs between these 2 data and do downstream analysis (like scVelo) based on these 2 UMAPs (coding below). In this way, because the UMAP is similar, we can have a more clear answer about how different these 2 date is.; ```python; ref = sc.read('ref.h5ad'); query = sc.read('query.h5ad'); var_names = query.var_names.intersection(ref.var_names); query = query[:, var_names]; ref = ref[:, var_names]; sc.tl.ingest(adata=query, adata_ref=ref, obs='leiden'); sc.pl.umap(query, color=['leiden'], legend_loc='on data', frameon=False, title='', use_raw=False) # this step will generate new obs['leiden'] and obsm['X_umap'] for query, which is a similar embedding with ref. adata = sc.read_loom(filename='queryraw.loom'); adata.obs['leiden']=query.obs['leiden'] # copy ingested leiden to raw data; adata.obsm['X_umap']=query.obsm['X_umap'] # copy ingested X_umap to raw data; # then do scVelo on this adata by using this embedding.; ```. However, `ingest` doesn't remove the batch effect. `BBKNN` does. After `BBKNN`, both `query` and `ref` will have new UMAPs stored at the same obsm['X_umap']. I'm wondering whether it is possible to split these 2 UMAPs? For example, store `query` UMAP in obsm['X_query_umap'] and `ref` UMAP in obsm['X_ref_umap'] so that we can copy each into a raw data. ![image](https://user-images.git",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2123
https://github.com/scverse/scanpy/issues/2124:822,Availability,error,error,822,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2124:1167,Availability,error,error,1167," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2124:1189,Availability,Error,Error,1189," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2124:2001,Deployability,update,updated,2001," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2124:403,Testability,test,tests,403,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2124:1947,Testability,log,logical,1947," not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The URL specified for the included `pbmc3k` data is throwing a 404. URL: https://falexwolf.me/data/pbmc3k_raw.h5ad. I happen to use this data for lots of unit and regression tests (probably not the best idea on my part). . Is there by chance a backup location I could mirror the same object from?. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); ```. ```pytb; ... 'http', request, response, code, msg, hdrs); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 569, in error; return self._call_chain(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 503, in _call_chain; result = func(*args); File ""/home/jacob/bin/anaconda/envs/scnym_public/lib/python3.7/urllib/request.py"", line 649, in http_error_default; raise HTTPError(req.full_url, code, msg, hdrs, fp); urllib.error.HTTPError: HTTP Error 404: Not Found; ```. #### Versions. -----; anndata 0.7.4; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.1; google NA; h5py 2.10.0; igraph 0.9.7; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.0; llvmlite 0.32.1; louvain 0.7.0; matplotlib 3.4.3; mpl_toolkits NA; natsort 7.1.1; numba 0.49.1; numexpr 2.7.3; numpy 1.18.2; packaging 21.0; pandas 1.0.4; pkg_resources NA; pyparsing 2.4.7; pytz 2021.3; scipy 1.4.1; setuptools_scm NA; six 1.14.0; sklearn 0.22.2.post1; tables 3.6.1; texttable 1.6.4; typing_extensions NA; wcwidth 0.2.5; yaml 5.3.1; zipp NA; -----; Python 3.7.10 | packaged by conda-forge | (default, Oct 13 2021, 21:01:18) [GCC 9.4.0]; Linux-4.15.0-142-generic-x86_64-with-debian-buster-sid; 16 logical CPU cores, x86_64; -----; Session information updated at 2022-01-28 10:52. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2124
https://github.com/scverse/scanpy/issues/2125:523,Testability,log,logging,523,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.logging.print_header(); adata = sc.datasets.pbmc68k_reduced(); sc.tl.dendrogram(adata, groupby='bulk_labels'); sc.pl.dendrogram(adata); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [3], in <module>; 2 sc.logging.print_header(); 3 adata = sc.datasets.pbmc68k_reduced(); ----> 4 sc.tl.dendrogram(adata, groupby='bulk_labels'); 5 sc.pl.dendrogram(adata); 6 markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py:139, in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 136 from scipy.spatial import distance; 138 corr_matrix = mean_df.T.corr(method=cor_method); --> 139 corr_condensed = distance.squareform(1 - corr_matrix); 140 z_var = sch.linkage(; 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering; 142 ); 143 dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True). File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scipy/spatial/distance.py:2362, in squareform(X, force, checks); 2360 raise ValueError('The matrix argument must be square.'); 2361 if checks:; -> 2362 is_valid_dm(X, throw=True, name='X'); 2364 # One-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125
https://github.com/scverse/scanpy/issues/2125:960,Testability,log,logging,960,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.logging.print_header(); adata = sc.datasets.pbmc68k_reduced(); sc.tl.dendrogram(adata, groupby='bulk_labels'); sc.pl.dendrogram(adata); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [3], in <module>; 2 sc.logging.print_header(); 3 adata = sc.datasets.pbmc68k_reduced(); ----> 4 sc.tl.dendrogram(adata, groupby='bulk_labels'); 5 sc.pl.dendrogram(adata); 6 markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py:139, in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 136 from scipy.spatial import distance; 138 corr_matrix = mean_df.T.corr(method=cor_method); --> 139 corr_condensed = distance.squareform(1 - corr_matrix); 140 z_var = sch.linkage(; 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering; 142 ); 143 dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True). File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scipy/spatial/distance.py:2362, in squareform(X, force, checks); 2360 raise ValueError('The matrix argument must be square.'); 2361 if checks:; -> 2362 is_valid_dm(X, throw=True, name='X'); 2364 # One-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125
https://github.com/scverse/scanpy/issues/2125:257,Usability,guid,guide,257,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; sc.logging.print_header(); adata = sc.datasets.pbmc68k_reduced(); sc.tl.dendrogram(adata, groupby='bulk_labels'); sc.pl.dendrogram(adata); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [3], in <module>; 2 sc.logging.print_header(); 3 adata = sc.datasets.pbmc68k_reduced(); ----> 4 sc.tl.dendrogram(adata, groupby='bulk_labels'); 5 sc.pl.dendrogram(adata); 6 markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py:139, in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 136 from scipy.spatial import distance; 138 corr_matrix = mean_df.T.corr(method=cor_method); --> 139 corr_condensed = distance.squareform(1 - corr_matrix); 140 z_var = sch.linkage(; 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering; 142 ); 143 dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True). File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scipy/spatial/distance.py:2362, in squareform(X, force, checks); 2360 raise ValueError('The matrix argument must be square.'); 2361 if checks:; -> 2362 is_valid_dm(X, throw=True, name='X'); 2364 # One-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125
https://github.com/scverse/scanpy/issues/2125:2611,Usability,learn,learn,2611,"'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); Input In [3], in <module>; 2 sc.logging.print_header(); 3 adata = sc.datasets.pbmc68k_reduced(); ----> 4 sc.tl.dendrogram(adata, groupby='bulk_labels'); 5 sc.pl.dendrogram(adata); 6 markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']. File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py:139, in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace); 136 from scipy.spatial import distance; 138 corr_matrix = mean_df.T.corr(method=cor_method); --> 139 corr_condensed = distance.squareform(1 - corr_matrix); 140 z_var = sch.linkage(; 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering; 142 ); 143 dendro_info = sch.dendrogram(z_var, labels=list(categories), no_plot=True). File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scipy/spatial/distance.py:2362, in squareform(X, force, checks); 2360 raise ValueError('The matrix argument must be square.'); 2361 if checks:; -> 2362 is_valid_dm(X, throw=True, name='X'); 2364 # One-side of the dimensions is set here.; 2365 d = s[0]. File ~/miniconda3/envs/scanpy/lib/python3.8/site-packages/scipy/spatial/distance.py:2443, in is_valid_dm(D, tol, throw, name, warning); 2441 if not (D[range(0, s[0]), range(0, s[0])] == 0).all():; 2442 if name:; -> 2443 raise ValueError(('Distance matrix \'%s\' diagonal must '; 2444 'be zero.') % name); 2445 else:; 2446 raise ValueError('Distance matrix diagonal must be zero.'). ValueError: Distance matrix 'X' diagonal must be zero.; ```. #### Versions. <details>. scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.21.5 scipy==1.7.3 pandas==1.4.0 scikit-learn==1.0.2 statsmodels==0.13.1 python-igraph==0.9.9 pynndescent==0.5.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2125
https://github.com/scverse/scanpy/issues/2126:643,Testability,log,logreg,643,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. If you us rank_genes_group with a subset of groups and change the order the reported output is messed up. In the example below the second result is like the fist result. However in the plot so cluster 2 has now the genes of cluster 1 and vice versa. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, groupby=""louvain"",groups=[""0"",""1"",""2""], method=""logreg"", use_raw= False); sc.tl.rank_genes_groups(adata, groupby=""louvain"",groups=[""0"",""2"",""1""], method=""logreg"", use_raw= False); ```. #### Versions. <details>; anndata==0.7.8; scanpy==1.8.2; sinfo==0.3.4; IPython==7.30.1; jupyter_client==7.1.0; jupyter_core==4.9.1; notebook==6.4.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2126
https://github.com/scverse/scanpy/issues/2126:748,Testability,log,logreg,748,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. If you us rank_genes_group with a subset of groups and change the order the reported output is messed up. In the example below the second result is like the fist result. However in the plot so cluster 2 has now the genes of cluster 1 and vice versa. ### Minimal code sample (that we can copy&paste without having any data). ```python; sc.tl.rank_genes_groups(adata, groupby=""louvain"",groups=[""0"",""1"",""2""], method=""logreg"", use_raw= False); sc.tl.rank_genes_groups(adata, groupby=""louvain"",groups=[""0"",""2"",""1""], method=""logreg"", use_raw= False); ```. #### Versions. <details>; anndata==0.7.8; scanpy==1.8.2; sinfo==0.3.4; IPython==7.30.1; jupyter_client==7.1.0; jupyter_core==4.9.1; notebook==6.4.6. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2126
https://github.com/scverse/scanpy/issues/2127:704,Deployability,continuous,continuous,704,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Categorical legends can be removed from embedding plots by passing the argument `'none`' to `legend_loc` (e.g. `sc.pp.umap(adata, color=""CellType"", legend_loc='none')`. It would be useful if the drawn colorbar is omitted when plotting continuous data if `legend_loc='none'` is passed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2127
https://github.com/scverse/scanpy/issues/2127:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. Categorical legends can be removed from embedding plots by passing the argument `'none`' to `legend_loc` (e.g. `sc.pp.umap(adata, color=""CellType"", legend_loc='none')`. It would be useful if the drawn colorbar is omitted when plotting continuous data if `legend_loc='none'` is passed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2127
https://github.com/scverse/scanpy/issues/2128:382,Deployability,update,update,382,"## Description. In the docs for `scanpy.read_10x_mtx`, the mentioned file extensions and files are all uncompressed, _e.g._, `matrix.mtx`. However, when specifying a path which does not include the required file the `FileNotFoundError` calls it `matrix.mtx.gz`. For consistency, I think it'd be good to use either the compressed or uncompressed format in both cases, _i.e._, either update the docs or the `FileNotFoundError`. Otherwise, users might think they might have to compress the file (if there is a small typo in the provided path, for example).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2128
https://github.com/scverse/scanpy/pull/2129:4,Testability,test,tests,4,"The tests and docs now fail due to https://github.com/theislab/scanpy/issues/2125.; For some reason, this https://github.com/theislab/scanpy/blob/b69015e9e7007193c9ac461d5c6fbf845b3d6962/scanpy/tools/_dendrogram.py#L139; has small values instead of 0s on the diagonal and thus fails the check of `is_valid_dm` inside `squareform` if `checks=True`. I don't understand why small values instead of 0s are there. New version of pandas? numpy?; This fix just sets `checks=False`, not sure if it is a good idea actually.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2129
https://github.com/scverse/scanpy/issues/2130:88,Testability,test,tests,88,https://github.com/theislab/scanpy/blob/8736fc3b02a6af3b7214481c2cf78a3f8f5e06bd/scanpy/tests/test_read_10x.py#L105,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2130
https://github.com/scverse/scanpy/issues/2131:88,Availability,down,downsampling,88,"Hello Team,; I'm using the **sc.pp.downsample_counts** function on my adata in hopes of downsampling it to match that of another dataset. Running the function doesn't give any errors or seem to fail but when I check the total counts, there seems to be no change. . I'm wondering if there is a problem with my application or there is more going on. `sc.pp.downsample_counts(adata, total_counts=6900, random_state=0, replace=False, copy=False)`. My average total counts before and after running the function is 10000.; Any inputs would be greatly appreciated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131
https://github.com/scverse/scanpy/issues/2131:176,Availability,error,errors,176,"Hello Team,; I'm using the **sc.pp.downsample_counts** function on my adata in hopes of downsampling it to match that of another dataset. Running the function doesn't give any errors or seem to fail but when I check the total counts, there seems to be no change. . I'm wondering if there is a problem with my application or there is more going on. `sc.pp.downsample_counts(adata, total_counts=6900, random_state=0, replace=False, copy=False)`. My average total counts before and after running the function is 10000.; Any inputs would be greatly appreciated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2131
https://github.com/scverse/scanpy/pull/2134:32,Security,secur,securing,32,"This is a long term solution to securing the image files on the tutorials page, addressing https://github.com/theislab/scanpy/issues/2132.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2134
https://github.com/scverse/scanpy/issues/2135:2375,Deployability,update,updated,2375,"ne); assert out is None; ```. Should return an axis, as stated in the docs. ```; Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`.; ```. Temporary workaround for those wanting a solution: . ```; ax = sc.pl.violin(adata, keys=['CD8A', 'CD8B'], ax=None, show=False); ```. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; igraph 0.9.8; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packaging 21.3; pandas 1.1.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.24; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 3.0.6; pytz 2021.3; scanpy 1.8.2; scipy 1.5.3; scprep 1.1.0; seaborn 0.11.2; setuptools 58.0.4; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.13.1; tables 3.6.1; texttable 1.6.4; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zmq 22.3.0; -----; IPython 8.0.0; jupyter_client 6.1.12; jupyter_core 4.9.1; jupyterlab 3.2.8; notebook 6.4.7; -----; Python 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]; Linux-5.4.0-1064-gcp-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2022-02-10 16:29; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2135
https://github.com/scverse/scanpy/issues/2135:424,Testability,assert,assert,424,"- [X] I have checked that this issue has not already been reported.; - [X] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; import scanpy as sc; adata = sc.datasets.pbmc3k(); out = sc.pl.violin(adata, keys=['CD8A', 'CD8B'], ax=None); assert out is None; ```. Should return an axis, as stated in the docs. ```; Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`.; ```. Temporary workaround for those wanting a solution: . ```; ax = sc.pl.violin(adata, keys=['CD8A', 'CD8B'], ax=None, show=False); ```. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; igraph 0.9.8; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packaging 21.3; pandas 1.1.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.24; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 3.0.6; pytz 2021.3; scanpy 1.8.2; scipy 1.5.3; scprep 1.1.0; seaborn 0.11.2; setuptools 58.0.4; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.13.1; tables 3.6.1; texttable 1.6.4; tornado 6.1; tq",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2135
https://github.com/scverse/scanpy/issues/2135:2329,Testability,log,logical,2329,"ne); assert out is None; ```. Should return an axis, as stated in the docs. ```; Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`.; ```. Temporary workaround for those wanting a solution: . ```; ax = sc.pl.violin(adata, keys=['CD8A', 'CD8B'], ax=None, show=False); ```. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; igraph 0.9.8; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packaging 21.3; pandas 1.1.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.24; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 3.0.6; pytz 2021.3; scanpy 1.8.2; scipy 1.5.3; scprep 1.1.0; seaborn 0.11.2; setuptools 58.0.4; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.13.1; tables 3.6.1; texttable 1.6.4; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zmq 22.3.0; -----; IPython 8.0.0; jupyter_client 6.1.12; jupyter_core 4.9.1; jupyterlab 3.2.8; notebook 6.4.7; -----; Python 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]; Linux-5.4.0-1064-gcp-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2022-02-10 16:29; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2135
https://github.com/scverse/scanpy/issues/2136:3991,Availability,error,error,3991,"ewidth=self.linewidth). AttributeError: 'numpy.ndarray' object has no attribute 'fill_betweenx'; ```. #### Option 2: group with two keys, passing first of two axes. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, axes = plt.subplots(1, 2); sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes[0]); ```. No traceback, but the second axis is simply not plotted. <img width=""388"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453540-76f48a6b-8d22-40bd-86fe-435d0878deb3.png"">. #### Option 3: group with two keys, passing one axis. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, ax = plt.subplots(); sc.pl.violin(adata, keys=['CD8A', 'CD8B'], groupby=""group"", ax=ax); ```. No traceback, even though this should error. Plots just the first of the two keys. <img width=""377"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; idna 3.1; igraph 0.9.8; importlib_resources NA; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.4.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; nbformat 5.1.3; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packagi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:1898,Deployability,update,update,1898,"ts(1, 2); ----> 6 sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes). File /opt/conda/envs/analysis/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:835, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 833 axs = [ax]; 834 for ax, y, ylab in zip(axs, ys, ylabel):; --> 835 ax = sns.violinplot(; 836 x=x,; 837 y=y,; 838 data=obs_tidy,; 839 order=order,; 840 orient='vertical',; 841 scale=scale,; 842 ax=ax,; 843 **kwds,; 844 ); 845 if stripplot:; 846 ax = sns.stripplot(; 847 x=x,; 848 y=y,; (...); 854 ax=ax,; 855 ). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/_decorators.py:46, in _deprecate_positional_args.<locals>.inner_f(*args, **kwargs); 36 warnings.warn(; 37 ""Pass the following variable{} as {}keyword arg{}: {}. ""; 38 ""From version 0.12, the only valid positional argument ""; (...); 43 FutureWarning; 44 ); 45 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 46 return f(**kwargs). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:2408, in violinplot(x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation, ax, **kwargs); 2405 if ax is None:; 2406 ax = plt.gca(); -> 2408 plotter.plot(ax); 2409 return ax. File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:1043, in _ViolinPlotter.plot(self, ax); 1041 def plot(self, ax):; 1042 """"""Make the violin plot.""""""; -> 1043 self.draw_violins(ax); 1044 self.annotate_axes(ax); 1045 if self.orient == ""h"":. File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:761, in _ViolinPlotter.draw_violins(self, ax); 759 def draw_violins(self, ax):; 760 """"""Draw the violins onto `ax`.""""""; --> 761 fill_func = ax.fill_betweenx if self.orient == ""v"" else ax.fill_between; 762 for i, group_data in enumerate(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:6027,Deployability,update,updated,6027,"ttps://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; idna 3.1; igraph 0.9.8; importlib_resources NA; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.4.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; nbformat 5.1.3; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packaging 21.3; pandas 1.1.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.24; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pvectorc NA; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 3.0.6; pyrsistent NA; pytz 2021.3; scanpy 1.8.2; scipy 1.5.3; scprep 1.1.0; seaborn 0.11.2; send2trash NA; setuptools 58.0.4; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.13.1; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.0.0; jupyter_client 6.1.12; jupyter_core 4.9.1; jupyterlab 3.2.8; notebook 6.4.7; -----; Python 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]; Linux-5.4.0-1064-gcp-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2022-02-10 16:38; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:1758,Modifiability,variab,variable,1758,"ecent call last); Input In [51], in <module>; 4 adata2.obs['group'] = adata2.obs.index.to_series().str.startswith(""A"").astype(str); 5 fig, axes = plt.subplots(1, 2); ----> 6 sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes). File /opt/conda/envs/analysis/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:835, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 833 axs = [ax]; 834 for ax, y, ylab in zip(axs, ys, ylabel):; --> 835 ax = sns.violinplot(; 836 x=x,; 837 y=y,; 838 data=obs_tidy,; 839 order=order,; 840 orient='vertical',; 841 scale=scale,; 842 ax=ax,; 843 **kwds,; 844 ); 845 if stripplot:; 846 ax = sns.stripplot(; 847 x=x,; 848 y=y,; (...); 854 ax=ax,; 855 ). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/_decorators.py:46, in _deprecate_positional_args.<locals>.inner_f(*args, **kwargs); 36 warnings.warn(; 37 ""Pass the following variable{} as {}keyword arg{}: {}. ""; 38 ""From version 0.12, the only valid positional argument ""; (...); 43 FutureWarning; 44 ); 45 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 46 return f(**kwargs). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:2408, in violinplot(x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color, palette, saturation, ax, **kwargs); 2405 if ax is None:; 2406 ax = plt.gca(); -> 2408 plotter.plot(ax); 2409 return ax. File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:1043, in _ViolinPlotter.plot(self, ax); 1041 def plot(self, ax):; 1042 """"""Make the violin plot.""""""; -> 1043 self.draw_violins(ax); 1044 self.annotate_axes(ax); 1045 if self.orient == ""h"":. File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:761, in _ViolinPlotter.draw_violins(self, ax); 759 def draw_violins(self, ax):",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:1128,Testability,log,log,1128,"nch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). #### Option 1: group with two keys, passing two axes. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, axes = plt.subplots(1, 2); sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes); ```. ```pytb; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Input In [51], in <module>; 4 adata2.obs['group'] = adata2.obs.index.to_series().str.startswith(""A"").astype(str); 5 fig, axes = plt.subplots(1, 2); ----> 6 sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes). File /opt/conda/envs/analysis/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:835, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds); 833 axs = [ax]; 834 for ax, y, ylab in zip(axs, ys, ylabel):; --> 835 ax = sns.violinplot(; 836 x=x,; 837 y=y,; 838 data=obs_tidy,; 839 order=order,; 840 orient='vertical',; 841 scale=scale,; 842 ax=ax,; 843 **kwds,; 844 ); 845 if stripplot:; 846 ax = sns.stripplot(; 847 x=x,; 848 y=y,; (...); 854 ax=ax,; 855 ). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/_decorators.py:46, in _deprecate_positional_args.<locals>.inner_f(*args, **kwargs); 36 warnings.warn(; 37 ""Pass the following variable{} as {}keyword arg{}: {}. ""; 38 ""From version 0.12, the only valid positional argument ""; (...); 43 FutureWarning; 44 ); 45 kwargs.update({k: arg for k, arg in zip(sig.parameters, args)}); ---> 46 return f(**kwargs). File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:2408, in violinplot(x, y, hue, data, order, hue_order, bw, cut, scale, scale_hue, gridsize, width, inner, split, dodge, orient, linewidth, color,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:5981,Testability,log,logical,5981,"ttps://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.0; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; django 4.0; executing 0.8.2; google NA; h5py 2.10.0; idna 3.1; igraph 0.9.8; importlib_resources NA; ipykernel 6.7.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; jinja2 3.0.3; joblib 1.1.0; jsonschema 4.4.0; jupyter_server 1.13.3; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.37.0; markupsafe 2.0.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.0.2; nbformat 5.1.3; numba 0.54.1; numexpr 2.8.0; numpy 1.19.5; packaging 21.3; pandas 1.1.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prometheus_client NA; prompt_toolkit 3.0.24; psutil 5.8.0; ptyprocess 0.7.0; pure_eval 0.2.1; pvectorc NA; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.10.0; pyparsing 3.0.6; pyrsistent NA; pytz 2021.3; scanpy 1.8.2; scipy 1.5.3; scprep 1.1.0; seaborn 0.11.2; send2trash NA; setuptools 58.0.4; setuptools_scm NA; sinfo 0.3.1; six 1.16.0; sklearn 0.24.2; sphinxcontrib NA; stack_data 0.1.4; statsmodels 0.13.1; tables 3.6.1; terminado 0.12.1; texttable 1.6.4; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 8.0.0; jupyter_client 6.1.12; jupyter_core 4.9.1; jupyterlab 3.2.8; notebook 6.4.7; -----; Python 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]; Linux-5.4.0-1064-gcp-x86_64-with-glibc2.10; 16 logical CPU cores; -----; Session information updated at 2022-02-10 16:38; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2136:3464,Usability,simpl,simply,3464,"41 def plot(self, ax):; 1042 """"""Make the violin plot.""""""; -> 1043 self.draw_violins(ax); 1044 self.annotate_axes(ax); 1045 if self.orient == ""h"":. File /opt/conda/envs/analysis/lib/python3.8/site-packages/seaborn/categorical.py:761, in _ViolinPlotter.draw_violins(self, ax); 759 def draw_violins(self, ax):; 760 """"""Draw the violins onto `ax`.""""""; --> 761 fill_func = ax.fill_betweenx if self.orient == ""v"" else ax.fill_between; 762 for i, group_data in enumerate(self.plot_data):; 764 kws = dict(edgecolor=self.gray, linewidth=self.linewidth). AttributeError: 'numpy.ndarray' object has no attribute 'fill_betweenx'; ```. #### Option 2: group with two keys, passing first of two axes. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, axes = plt.subplots(1, 2); sc.pl.violin(adata2, keys=['CD8A', 'CD8B'], groupby=""group"", ax=axes[0]); ```. No traceback, but the second axis is simply not plotted. <img width=""388"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453540-76f48a6b-8d22-40bd-86fe-435d0878deb3.png"">. #### Option 3: group with two keys, passing one axis. ```python; import scanpy as sc; import matplotlib.pyplot as plt; adata = sc.datasets.pbmc3k(); adata.obs['group'] = adata.obs.index.to_series().str.startswith(""A"").astype(str); fig, ax = plt.subplots(); sc.pl.violin(adata, keys=['CD8A', 'CD8B'], groupby=""group"", ax=ax); ```. No traceback, even though this should error. Plots just the first of the two keys. <img width=""377"" alt=""image"" src=""https://user-images.githubusercontent.com/84813314/153453748-b402e8f7-9ac1-4fd8-b8ce-682cd25ea082.png"">. #### Versions. <details>. ```; WARNING: If you miss a compact list, please try `print_header`!; -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 8.4.0; anndata 0.7.8; asttokens NA; attr 21.2.0; backcall 0.2.0; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2136
https://github.com/scverse/scanpy/issues/2137:936,Availability,error,error,936,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137
https://github.com/scverse/scanpy/issues/2137:484,Integrability,depend,dependency,484,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137
https://github.com/scverse/scanpy/issues/2137:1263,Security,validat,validation,1263,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137
https://github.com/scverse/scanpy/issues/2137:1589,Usability,learn,learn,1589,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello, . This may be a problem outside the realm of scanpy functionality, but I thought it best to bring up in case it is relevant or in case anyone here has seen something before while trying to use scanpy. It looks like I can having trouble importing a dependency of the sc.pp.regress() function. I don't think the data here is relevant, just something in my set up. I tried updating all the libraries so that everything is up to date. This problem just started occurring today (2/10/21) and had no issue yesterday, so I figure it was a change on the scanpy end that I didn't keep up with proprely. ```python; sc.pp.regress_out(merged_adata, ['pct_counts_mt', 'pct_counts_rp']); ```. yields the following error. ```pytb; /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/site-packages/statsmodels/tsa/filters/filtertools.py in <module>; 16 import scipy.fftpack as fft; 17 from scipy import signal; ---> 18 from scipy.signal.signaltools import _centered as trim_centered; 19 ; 20 from statsmodels.tools.validation import array_like, PandasWrapper. ImportError: cannot import name '_centered' from 'scipy.signal.signaltools' (/home/unix/jjeang/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py); ```. #### Versions. <details>. scanpy==1.6.0 anndata==0.7.8 umap==0.3.10 numpy==1.22.2 scipy==1.8.0 pandas==1.2.5 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.9.9 louvain==0.7.0 leidenalg==0.8.0. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2137
https://github.com/scverse/scanpy/issues/2138:54,Availability,error,error,54,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:291,Availability,error,error,291,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:146,Deployability,install,installed,146,"I am trying to import scanpy but I am running into an error:. Also, a bit of a noob to python in general, but I think I have most required things installed. ```python; import scanpy as sc; ```; I am using Python 3.7 in a virtual environment (potato37); The above code gives me the following error:. ```pytb; InvalidVersion Traceback (most recent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:1341,Testability,log,logging,1341,"ecent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:1352,Testability,log,logg,1352,"ecent call last); /tmp/ipykernel_4345/4007328772.py in <module>; ----> 1 import scanpy as sc; 2 import anndata; 3 from scipy import io; 4 from scipy.sparse import coo_matrix, csr_matrix; 5 import numpy as np. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/__init__.py in <module>; 12 # (start with settings as several tools are using it); 13 from ._settings import settings, Verbosity; ---> 14 from . import tools as tl; 15 from . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:1857,Testability,test,tests,1857,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:1886,Testability,test,test,1886,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:1976,Testability,test,tests,1976,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:2038,Testability,test,tests,2038,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:2089,Testability,test,tests,2089,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:2113,Testability,test,test,2113,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2138:2198,Testability,test,tests,2198,"m . import preprocessing as pp; 16 from . import plotting as pl. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/__init__.py in <module>; 15 from ._leiden import leiden; 16 from ._louvain import louvain; ---> 17 from ._sim import sim; 18 from ._score_genes import score_genes, score_genes_cell_cycle; 19 from ._dendrogram import dendrogram. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/tools/_sim.py in <module>; 21 from anndata import AnnData; 22 ; ---> 23 from .. import _utils, readwrite, logging as logg; 24 from .._settings import settings; 25 from .._compat import Literal. /data/personal_folders/user/potato37/lib/python3.7/site-packages/scanpy/readwrite.py in <module>; 8 import pandas as pd; 9 from matplotlib.image import imread; ---> 10 import tables; 11 import anndata; 12 from anndata import (; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/__init__.py in <module>; 51 from .unimplemented import UnImplemented, Unknown; 52 from .expression import Expr; ---> 53 from .tests import print_versions, test; 54 ; 55 ; ; /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/__init__.py in <module>; 7 """"""; 8 ; ----> 9 from tables.tests.common import print_versions; 10 from tables.tests.test_suite import test, suite. /data/personal_folders/user/potato37/lib/python3.7/site-packages/tables/tests/common.py in <module>; 18 from tables.req_versions import min_blosc_bitshuffle_version; 19 ; ---> 20 hdf5_version = Version(tb.hdf5_version); 21 blosc_version = Version(tb.which_lib_version(""blosc"")[1]); 22 . /data/personal_folders/user/potato37/lib/python3.7/site-packages/packaging/version.py in __init__(self, version); 264 match = self._regex.search(version); 265 if not match:; --> 266 raise InvalidVersion(f""Invalid version: '{version}'""); 267 ; 268 # Store the parsed out pieces of the version. InvalidVersion: Invalid version: '1.10.0-patch1'; ```. Any help will be appreciated :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2138
https://github.com/scverse/scanpy/issues/2139:272,Availability,error,error,272,"Hello everyone !. I would like to use a custom distance when trying to compute the neighbors graph with `scanpy.pp.neighbors`.; So let's suppose I have a pre-existing distance matrix somewhere, and I just want to use it in the graph generation. Currently, I am getting an error when exceeding 4096 observations in my AnnData object.; I do not have such error when directly using the`umap` python package. ### Full error; ```bash; Traceback (most recent call last):; File ""/home/paul/Documents/Curie/Immunopeptidomics/minimal_bug_scanpy.py"", line 72, in <module>; sc.pp.neighbors(xd,; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:353,Availability,error,error,353,"Hello everyone !. I would like to use a custom distance when trying to compute the neighbors graph with `scanpy.pp.neighbors`.; So let's suppose I have a pre-existing distance matrix somewhere, and I just want to use it in the graph generation. Currently, I am getting an error when exceeding 4096 observations in my AnnData object.; I do not have such error when directly using the`umap` python package. ### Full error; ```bash; Traceback (most recent call last):; File ""/home/paul/Documents/Curie/Immunopeptidomics/minimal_bug_scanpy.py"", line 72, in <module>; sc.pp.neighbors(xd,; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:414,Availability,error,error,414,"Hello everyone !. I would like to use a custom distance when trying to compute the neighbors graph with `scanpy.pp.neighbors`.; So let's suppose I have a pre-existing distance matrix somewhere, and I just want to use it in the graph generation. Currently, I am getting an error when exceeding 4096 observations in my AnnData object.; I do not have such error when directly using the`umap` python package. ### Full error; ```bash; Traceback (most recent call last):; File ""/home/paul/Documents/Curie/Immunopeptidomics/minimal_bug_scanpy.py"", line 72, in <module>; sc.pp.neighbors(xd,; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:1651,Availability,error,errors,1651,"s/__init__.py"", line 139, in neighbors; neighbors.compute_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:2012,Availability,error,error,2012,"hbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:2181,Availability,error,error,2181," nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.6.0; igraph 0.9.8; joblib 1.1.0; kiwisolv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:1695,Deployability,pipeline,pipeline,1695,"l/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 791, in compute_neighbors; knn_indices, knn_distances, forest = compute_neighbors_umap(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/scanpy/neighbors/__init__.py"", line 305, in compute_neighbors_umap; knn_indices, knn_dists, forest = nearest_neighbors(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/umap/umap_.py"", line 328, in nearest_neighbors; knn_search_index = NNDescent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py"", line 875, in __init__; self._neighbor_graph = nn_descent(; File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 468, in _compile_for_args; error_rewrite(e, 'typing'); File ""/home/paul/venv/xomx/lib/python3.9/site-packages/numba/core/dispatcher.py"", line 409, in error_rewrite; raise e.with_traceback(None); numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2139:3680,Testability,log,logical,3680,"tend); non-precise type pyobject; During: typing of argument at /home/paul/venv/xomx/lib/python3.9/site-packages/pynndescent/pynndescent_.py (330). File ""../pynndescent/pynndescent_.py"", line 330:; def nn_descent(; <source elided>. if init_graph[0].shape[0] == 1: # EMPTY_GRAPH; ^ . This error may have been caused by the following argument(s):; - argument 4: Cannot determine Numba type of <class 'function'>; ```. ### Minimal code sample to reproduce the error. ```python; import scanpy as sc; import numpy as np. def custom_distance(x1, x2):; return dist_mat[int(x1), int(x2)]. n = 4096. # generate a fake distance matrix for n elements; dist_mat = np.random.rand(n, n); # make it symmetrical; dist_mat= np.tril(dist_mat) + np.tril(dist_mat, -1).T; # zeros on the diagonal; for i in range(len(dist_mat)):; dist_mat[i][i] = 0. xd = sc.AnnData(shape=(n, 1)); xd.obs_names = [i for i in range(n)]; xd.X = np.empty((xd.n_obs, xd.n_vars)); for i in range(xd.n_obs):; xd.X[i, 0] = i; print(""computing connectivity graph...""); rng = np.random.RandomState(0); sc.pp.neighbors(xd,; n_neighbors=10,; n_pcs=None,; use_rep='X',; random_state=rng,; metric=custom_distance). print(""Success""); ```. ### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.4; -----; PIL 8.4.0; beta_ufunc NA; binom_ufunc NA; cffi 1.15.0; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; defusedxml 0.7.1; h5py 3.6.0; igraph 0.9.8; joblib 1.1.0; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; mpl_toolkits NA; natsort 8.0.2; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.1; numpy 1.21.5; packaging 21.3; pandas 1.3.5; pkg_resources NA; pyexpat NA; pyparsing 3.0.6; pytz 2021.3; scipy 1.7.3; sitecustomize NA; six 1.16.0; sklearn 1.0.1; tables 3.6.1; texttable 1.6.4; threadpoolctl 3.0.0; typing_extensions NA; wcwidth 0.2.5; -----; Python 3.9.9 (main, Nov 16 2021, 03:08:02) [GCC 9.3.0]; Linux-5.4.0-99-generic-x86_64-with-glibc2.31; 8 logical CPU cores, x86_64; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2139
https://github.com/scverse/scanpy/issues/2141:258,Usability,guid,guide,258,"- [✔] I have checked that this issue has not already been reported.; - [✔ ] I have confirmed this bug exists on the latest version of scanpy.; - [✔] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug.; Hello Scanpy,; I'm using the DPT. Every function works fine except `sc.pl.dpt_timeseries(adata)`. I got no colors of the plot.; Could you please help me with this issue?; Thanks!; Best,; YJ; ![image](https://user-images.githubusercontent.com/75048821/154160553-19347b63-38e9-4f50-a4a3-f57780ed4545.png). ### Minimal code sample (that we can copy&paste without having any data). ```python; adata = sc.datasets.paul15(); adata; sc.pp.log1p(adata); sc.pp.neighbors(adata, n_neighbors=20, use_rep='X', method='umap'). sc.tl.diffmap(adata); sc.tl.dpt(adata, n_dcs=10, n_branchings=1). sc.pl.diffmap(adata, color=['dpt_pseudotime', 'dpt_groups', 'paul15_clusters']); sc.pl.dpt_groups_pseudotime(adata); sc.pl.dpt_timeseries(adata, color_map='viridis', show=True); ```. #### Versions. <details>. sc.pl.dpt_timeseries(adata, color_map='viridis', show=True). </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2141
https://github.com/scverse/scanpy/issues/2142:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [x] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->; Would be great if `sc.pp.scale` could support scaling within a user-defined category - for example scaling the cells generated using 3' vs 5' 10X technology can be used to account for this source of batch effect. If this is easy to implement of your side, I think this option will be useful for many applications.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2142
https://github.com/scverse/scanpy/issues/2143:500,Availability,error,error,500,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:863,Availability,down,downloaded,863,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:1014,Availability,error,error,1014,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:1380,Availability,down,downloaded,1380,"html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray. ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /tmp/ipykernel_134148/2515279522.py in <module>; 1 embedding_anterior = np.concatenate(integrated_anterior, axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:242,Deployability,Integrat,Integrating,242,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:368,Deployability,integrat,integration-scanorama,368,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:400,Deployability,integrat,integration-and-label-transfer-from-scRNA-seq-dataset,400,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:896,Deployability,integrat,integration,896,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:242,Integrability,Integrat,Integrating,242,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:368,Integrability,integrat,integration-scanorama,368,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:400,Integrability,integrat,integration-and-label-transfer-from-scRNA-seq-dataset,400,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:896,Integrability,integrat,integration,896,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. When running the `Integrating spatial data with scRNA-seq using scanorama` [tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration-and-label-transfer-from-scRNA-seq-dataset) with the provided sample data, the following error occurs. This may be related to the following warning I also see. `<string>:6: VisibleDeprecationWarning: Creating an ndarray from nested sequences exceeding the maximum number of dimensions of 32 is deprecated. If you mean to do this, you must specify 'dtype=object' when creating the ndarray.`. How can I overcome this issue?. Example code below has how I downloaded the data in the `Data integration and label transfer from scRNA-seq dataset` section of the tutorial and then just the code block where the error actually occurs. ---. ### Minimal code sample (that we can copy&paste without having any data). ![scanorama_error](https://user-images.githubusercontent.com/52245296/154322971-c45606d2-54d7-42da-8ac6-85f91359e3c8.png). ```python. import subprocess; from pathlib import Path. if Path('./downloaded_data/adata_processed.h5ad').is_file():; print(""Data previously downloaded, skipping to next step""); else:; subprocess.run(['wget', '-O', './downloaded_data/adata_processed.h5ad', 'https://hmgubox.helmholtz-muenchen.de/f/4ef254675e2a41f89835/?dl=1']). adata_cortex = sc.read(""./downloaded_data/adata_processed.h5ad""). embedding_anterior = np.concatenate(integrated_anterior, axis=0); adata_cortex_anterior.obsm[""scanorama_embedding""] = embedding_anterior. embedding_posterior = np.concatenate(integrated_posterior, axis=0); adata_cortex_posterior.obsm[""scanorama_embedding""] = embedding_posterior; ```. ```pytb. <string>:6: VisibleDeprecationWarning: Creating an ndarray from nested se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2143:5491,Testability,log,logical,5491,"assed for key 'scanorama_embedding' is of incorrect shape. Values of obsm must match dimensions (0,) of parent. Value had shape (22272, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1) while it should have had (23238,). ```. #### Versions. <details>. -----; anndata 0.7.8; scanpy 1.8.2; sinfo 0.3.1; -----; PIL 9.0.1; anndata 0.7.8; annoy NA; backcall 0.2.0; beta_ufunc NA; binom_ufunc NA; cached_property 1.5.2; cffi 1.15.0; colorama 0.4.4; cycler 0.10.0; cython_runtime NA; dateutil 2.8.2; debugpy 1.5.1; decorator 5.1.1; defusedxml 0.7.1; entrypoints 0.4; fbpca NA; h5py 3.6.0; igraph 0.9.9; intervaltree NA; ipykernel 6.9.0; ipython_genutils 0.2.0; ipywidgets 7.6.5; jedi 0.18.1; joblib 1.1.0; jupyter_server 1.13.5; kiwisolver 1.3.2; leidenalg 0.8.8; llvmlite 0.38.0; louvain 0.7.1; matplotlib 3.5.1; matplotlib_inline NA; mpl_toolkits NA; natsort 8.1.0; nbinom_ufunc NA; numba 0.55.1; numexpr 2.8.0; numpy 1.21.5; packaging 21.3; pandas 1.3.5; parso 0.8.3; pexpect 4.8.0; pickleshare 0.7.5; pkg_resources NA; prompt_toolkit 3.0.27; psutil 5.9.0; ptyprocess 0.7.0; pycparser 2.21; pydev_ipython NA; pydevconsole NA; pydevd 2.6.0; pydevd_concurrency_analyser NA; pydevd_file_utils NA; pydevd_plugins NA; pydevd_tracing NA; pygments 2.11.2; pynndescent 0.5.6; pyparsing 3.0.7; pytz 2021.3; scanorama 1.7.1; scanpy 1.8.2; scipy 1.7.3; seaborn 0.11.2; setuptools 59.8.0; sinfo 0.3.1; six 1.16.0; sklearn 1.0.2; sortedcontainers 2.4.0; sphinxcontrib NA; statsmodels 0.13.2; storemagic NA; tables 3.7.0; texttable 1.6.4; threadpoolctl 3.1.0; tornado 6.1; tqdm 4.62.3; traitlets 5.1.1; typing_extensions NA; umap 0.5.2; wcwidth 0.2.5; yaml 6.0; zipp NA; zmq 22.3.0; -----; IPython 7.31.1; jupyter_client 7.1.2; jupyter_core 4.9.1; jupyterlab 3.2.9; notebook 6.4.8; -----; Python 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]; Linux-3.10.0-1062.1.2.el7.x86_64-x86_64-with-debian-10.10; 72 logical CPU cores; -----. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2143
https://github.com/scverse/scanpy/issues/2144:627,Availability,error,error,627,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:333,Deployability,install,install,333,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:388,Deployability,install,installation,388,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:410,Deployability,install,install-instructions,410,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:520,Deployability,install,install,520,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:974,Integrability,depend,dependencies,974,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:1310,Usability,learn,learn,1310,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/issues/2144:1420,Usability,learn,learn,1420,"- [x] I have checked that this issue has not already been reported.; - [x] I have confirmed this bug exists on the latest version of scanpy.; - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I clone the scanpy repository and I am on commit b69015e. I follow the instructions for a developmental install here:; https://scanpy.readthedocs.io/en/stable/installation.html#dev-install-instructions . ### Minimal code sample (that we can copy&paste without having any data). ```bash; pip install beni; beni pyproject.toml > environment.yml; conda env create -f environment.yml; ```. this is the error I get. ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - seaborn-split; ```. #### `environment.yml`. Here is the content of `environment.yml` which contains the strange package `seaborn-split`. So maybe the issue is upstream with beni?. <details>. ```; channels:; - conda-forge; dependencies:; - pip:; - flit; - bbknn; - scanpydoc>=0.7.4; - harmonypy; - magic-impute>=2.0; - cudf>=0.9; - cuml>=0.9; - cugraph>=0.9; - scanorama; - scrublet; - python>=3.7; - pip; - anndata>=0.7.4; - numpy>=1.17.0; - matplotlib-base>=3.1.2; - pandas>=0.21; - scipy>=1.4; - seaborn-split; - h5py>=2.10.0; - pytables; - tqdm; - scikit-learn>=0.22; - statsmodels>=0.10.0rc2; - patsy; - networkx>=2.3; - natsort; - joblib; - numba>=0.41.0; - umap-learn>=0.3.10; - packaging; - sinfo; - setuptools-scm; - black>=20.8b1; - docutils; - sphinx<4.2,>=4.1; - sphinx_rtd_theme>=0.3.1; - python-igraph; - leidenalg; - louvain!=0.6.2,>=0.6; - scikit-misc>=0.1.3; - pytest>=4.4; - pytest-nunit; - dask-core!=2.17.0; - fsspec; - zappy; - - zarr; - profimp; - flit-core; name: scanpy; ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2144
https://github.com/scverse/scanpy/pull/2145:2579,Deployability,release,release-notes,2579,"; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17; 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11; 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11; 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09; ```. This also extends to enrichment queries (this is what I wanted originally):. ```python; sc.queries.enrich(adata, ""1"", n_top_genes=10); ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:149,Integrability,interface,interface,149,"This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:; ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)); ```; output is just the top 2 genes of the list.; ```; names scores logfoldchanges pvals pvals_adj; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:2223,Modifiability,extend,extends,2223,"; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.936039 4.998127e-18 8.312102e-17; 19 9 HMGB2 15.229477 5.016804 3.184879e-12 4.060720e-11; 20 10 HNRNPA1 18.405415 2.040915 1.570832e-12 1.560632e-11; 21 10 NPM1 14.230449 2.183721 3.424469e-10 3.046185e-09; ```. This also extends to enrichment queries (this is what I wanted originally):. ```python; sc.queries.enrich(adata, ""1"", n_top_genes=10); ```. For enrichment queries, I added to the doc string that a pval threshold of 0.05 is used. Previously, this was not obvious to me (and for cluster marker genes, this might not always be sensible). I didn't add anything to `docs/release-notes/`, yet. I first wanted to get your opinion. Is it useful, what is still needed here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:252,Testability,log,logfc,252,"This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:; ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)); ```; output is just the top 2 genes of the list.; ```; names scores logfoldchanges pvals pvals_adj; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:647,Testability,log,logfoldchanges,647,"This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:; ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)); ```; output is just the top 2 genes of the list.; ```; names scores logfoldchanges pvals pvals_adj; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:935,Testability,log,logfoldchanges,935,"This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:; ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)); ```; output is just the top 2 genes of the list.; ```; names scores logfoldchanges pvals pvals_adj; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/pull/2145:142,Usability,simpl,simple,142,"This PR addresses https://scanpy.discourse.group/t/workflow-for-selecting-number-of-marker-genes-in-sc-queries-enrich/286. I wanted to have a simple interface to get the top n marker genes. Right now, `rank_genes_groups_df` only allows to threshold on logfc and pval, but especially for marker genes pval computation might not be statistically meaningful. It adds the following kind of functionality:; ```python; import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'louvain'). print(sc.get.rank_genes_groups_df(adata, ""1"", n_top_genes=2)); ```; output is just the top 2 genes of the list.; ```; names scores logfoldchanges pvals pvals_adj; 0 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; ```. it also works for multiple groups:. ```python; print(sc.get.rank_genes_groups_df(adata, None, n_top_genes=2)); ```; ```; group names scores logfoldchanges pvals pvals_adj; 0 0 CD3D 26.250046 3.859759 4.379061e-75 2.233321e-73; 1 0 LDHB 21.207499 2.134979 1.488480e-67 5.993089e-66; 2 1 FCGR3A 47.682064 5.891937 3.275554e-141 3.579712e-139; 3 1 FTL 45.653259 2.497682 9.003150e-208 6.887410e-205; 4 2 LYZ 38.981312 5.096991 1.697105e-172 1.298285e-169; 5 2 CST3 34.241749 4.388617 1.448193e-149 5.539337e-147; 6 3 NKG7 34.214161 6.089183 2.356710e-55 2.575547e-53; 7 3 CTSW 24.584066 5.091688 2.026294e-39 9.118324e-38; 8 4 CD79A 52.583344 6.626956 4.032974e-84 7.713062e-82; 9 4 CD79B 32.102913 4.990217 1.958507e-51 1.872822e-49; 10 5 FTL 26.084383 1.844273 1.236398e-74 2.364611e-72; 11 5 LST1 25.554073 3.170759 5.653851e-81 4.325196e-78; 12 6 LYZ 31.497107 4.328516 9.041131e-106 6.916466e-103; 13 6 CST3 23.850258 3.281016 2.491629e-83 9.530482e-81; 14 7 CST3 33.024582 4.195395 5.768439e-136 4.412856e-133; 15 7 LYZ 31.264187 4.267053 9.712334e-101 1.485987e-98; 16 8 PPIB 39.260998 3.990153 7.159966e-47 3.651583e-45; 17 8 MZB1 33.305500 8.979518 7.611322e-26 1.878278e-24; 18 9 STMN1 27.133045 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2145
https://github.com/scverse/scanpy/issues/2146:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. Hello Scanpy team,. I was wondering should it be possible to rotate the gene symbols in the output of `scanpy.pl.rank_genes_groups`? I don't think anybody enjoys looking at them sideways :) I might be wrong of course... Maybe I'm missing something and you can swap axes in the sub-plots? . Thank you in advance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2146
https://github.com/scverse/scanpy/issues/2147:2545,Availability,error,error,2545,"n highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2660,Availability,error,error,2660,"n highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2934,Availability,error,error,2934,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2991,Availability,error,error,2991,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3284,Availability,down,downloaded,3284,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1068,Modifiability,layers,layers,1068,"After going through the comment, _Originally posted by @LuckyMD in https://github.com/theislab/scanpy/issues/220#issuecomment-408332060_ , I have opened this issue. I am facing problem with `sc.pl.highest_expr_genes(adata_orig, n_top=20)` as well. Attaching some details:; I started by reading in the file as:. `adata_orig = sc.read_h5ad('covid_portal_210320_with_raw.h5ad', backed = 'r')`. After printing the `adata_orig` object, i get the following output:. ```; AnnData object with n_obs × n_vars = 647366 × 24929 backed at 'covid_portal_210320_with_raw.h5ad'; obs: 'sample_id', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'; var: 'feature_types'; uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'; obsm: 'X_pca', 'X_pca_harmony', 'X_umap'; layers: 'raw'; ```. After this, when I tried running the command:; `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-c4ab6dadfa42> in <module>; ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1947,Modifiability,layers,layers,1947,"me', 'patient_id'; var: 'feature_types'; uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'; obsm: 'X_pca', 'X_pca_harmony', 'X_umap'; layers: 'raw'; ```. After this, when I tried running the command:; `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-c4ab6dadfa42> in <module>; ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2896,Modifiability,layers,layers,2896,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3348,Performance,perform,perform,3348,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:1572,Testability,log,log,1572,"l_counts_mt', 'pct_counts_mt', 'full_clustering', 'initial_clustering', 'Resample', 'Collection_Day', 'Sex', 'Age_interval', 'Swab_result', 'Status', 'Smoker', 'Status_on_day_collection', 'Status_on_day_collection_summary', 'Days_from_onset', 'Site', 'time_after_LPS', 'Worst_Clinical_Status', 'Outcome', 'patient_id'; var: 'feature_types'; uns: 'hvg', 'leiden', 'neighbors', 'pca', 'umap'; obsm: 'X_pca', 'X_pca_harmony', 'X_umap'; layers: 'raw'; ```. After this, when I tried running the command:; `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-c4ab6dadfa42> in <module>; ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:2090,Testability,log,logg,2090," ```. After this, when I tried running the command:; `sc.pl.highest_expr_genes(adata_orig, n_top=20, )`. I get the following output:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-22-c4ab6dadfa42> in <module>; ----> 1 sc.pl.highest_expr_genes(adata_orig ). C:\ProgramData\Anaconda3\lib\site-packages\scanpy\plotting\_qc.py in highest_expr_genes(adata, n_top, show, save, ax, gene_symbols, log, **kwds); 65 ; 66 # compute the percentage of each gene per cell; ---> 67 norm_dict = normalize_total(adata, target_sum=100, inplace=False); 68 ; 69 # identify the genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; --------------------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2147:3583,Usability,learn,learn,3583,"genes with the highest mean. C:\ProgramData\Anaconda3\lib\site-packages\scanpy\preprocessing\_normalization.py in normalize_total(adata, target_sum, exclude_highly_expressed, max_fraction, key_added, layer, layers, layer_norm, inplace, copy); 174 counts_per_cell = X[:, gene_subset].sum(1); 175 else:; --> 176 counts_per_cell = X.sum(1); 177 start = logg.info(msg); 178 counts_per_cell = np.ravel(counts_per_cell). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```; And when I run the command:; `type(adata_orig.X)`; I get the output as:; `anndata._core.sparse_dataset.SparseDataset`. After reading your comment, I feel that earlier the scanpy module was expecting the sparse dataset as the input, but you have changed it to expect the dense format , and maybe that's the reason for this error? I am just two days into the world of scanpy and any help would be highly appreciated, in order to make this error go away. Also, to help you in debugging, I'd like to mention that the raw data in this dataset is present in the layer, which has the name 'raw' and the adata_orig.raw is set to null as of now. and when i try to run : `adata_orig.layers['raw'].sum(1)` it runs with no error. While running: `adata_orig.X.sum(1)` gives me the error as : ; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); <ipython-input-23-951a31c71c45> in <module>; ----> 1 adata_orig.X.sum(1). AttributeError: 'SparseDataset' object has no attribute 'sum'; ```. PS: I downloaded this` .h5ad` file from a published research paper to perform some analysis over it, would be happy to provide you the link to same if required. . Also this is the environment that I am working in:; `scanpy==1.8.2 anndata==0.7.8 umap==0.5.2 numpy==1.20.1 scipy==1.6.2 pandas==1.2.4 scikit-learn==0.24.1 statsmodels==0.12.2 python-igraph==0.9.1 pynndescent==0.5.6`. Hello @LuckyMD, tagging you for just in case you might be knowing the resolution.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2147
https://github.com/scverse/scanpy/issues/2149:541,Availability,error,error,541,"Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:746,Availability,Avail,Available,746,"Hello! This might seem like a basic question, but when I try to import the molecule_info.h5 file from this dataset:. https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1096,Availability,avail,available,1096,"cs.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1132,Availability,error,error,1132,"cs.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:3029,Availability,Avail,Available,3029,"t 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-15-2e1cefb9ad47> in <module>; ----> 1 h5_info = scanpy.read_10x_h5(molecule_info_file). ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only, backup_url); 194 adata = adata.copy(); 195 else:; --> 196 adata = _read_legacy_10x_h5(filename, genome=genome, start=start); 197 return adata; 198 . ~/miniconda3/envs/jupyter.py3/lib/python3.9/site-packages/scanpy/readwrite.py in _read_legacy_10x_h5(filename, genome, start); 207 if not genome:; 208 if len(children) > 1:; --> 209 raise ValueError(; 210 f""'{filename}' contains more than one genome. For legacy 10x h5 ""; 211 ""files you must specify the genome if more than one is present. "". ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```. #### Versions. <details>. 1.8.2. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2149:1138,Integrability,message,message,1138,"cs.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5. https://www.10xgenomics.com/resources/datasets/5-k-mouse-e-18-combined-cortex-hippocampus-and-subventricular-zone-nuclei-3-1-standard-6-0-0 . Using this function, . ```; scanpy.read_10x_h5(filename, genome=None, gex_only=True, backup_url=None); ```. I get the following error, ; ```; ValueError: 'SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5' contains more than one genome. For legacy 10x h5 files you must specify the genome if more than one is present. Available genomes are: ['barcode_idx', 'barcode_info', 'barcodes', 'count', 'feature_idx', 'features', 'gem_group', 'library_idx', 'library_info', 'metrics_json', 'umi', 'umi_type']; ```; and I don't know how to fix this. The dataset is only from mouse. This is not a legacy h5 file. The data are output from CR v6.0.0. Can you please assist? . The ""available genomes"" suggested in the error message are not genome, but columns in the h5. Ideally, I want to import all of these. Are we really only allowed to select 1? Even selecting one, does not seem fix the problem. . ```; h5_info = scanpy.read_10x_h5(molecule_info_file,genome='umi_type'); ```; ```; TypeError: node ``/umi_type`` is not a group; ```. - [X ] I have checked that this issue has not already been reported.; - [X ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python; h5_info = scanpy.read_10x_h5(molecule_info_file, backup_url=""https://cf.10xgenomics.com/samples/cell-exp/6.0.0/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex/SC3_v3_NextGem_DI_Nuclei_5K_Multiplex_count_raw_molecule_info.h5""); ```. ```pytb; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); <ipython-input-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2149
https://github.com/scverse/scanpy/issues/2151:1000,Deployability,integrat,integration,1000,"I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:; I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default?. I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:1000,Integrability,integrat,integration,1000,"I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:; I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default?. I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/issues/2151:224,Security,expose,expose,224,"I would like to get an opinion from @gokceneraslan, @adamgayoso (who implemented this originally), or someone else more familiar in hvg selection here. I feel like we should probably have multiple methods for this, which we expose via a kwarg. I'm not confident median rank makes sense as a value here. I think there are assumptions about what kinds of values a rank can have that get broken by taking the median. Is the method for aggregating hvgs from multiple batches here reasonable? For reference, a similar code block can be found in `_highly_variable_genes_seurat_v3`, which says this is the method used in `SelectIntegrationFeatures` from Seurat. _Originally posted by @ivirshup in https://github.com/theislab/scanpy/pull/1715#discussion_r736690390_. @jlause commented:; I agree that exposing multiple options could make sense here. Any opinion @gokceneraslan and @adamgayoso which ones we should implement / which one should be the default?. I just copied this part from the seurat_v3 batch integration, so I don't have an expert opinion - but if I remember correctly, the other flavors use dispersions_norm to break ties instead of using the median rank. If I read the code correctly, this is the within-batch dispersion averaged over batches. We could also do something similar here: Compute residual variance within each batch, take the average across batches, and use that to break ties instead of using median rank.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2151
https://github.com/scverse/scanpy/pull/2152:59,Testability,test,tests,59,Backport PR #2150: Remove global state changes in plotting tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2152
https://github.com/scverse/scanpy/issues/2153:1505,Integrability,wrap,wrapper,1505," I have checked that this issue has not already been reported.; - [ ] I have confirmed this bug exists on the latest version of scanpy.; - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---; We ran across a case where score genes does not work for one specific gene, but works for others; the gene is in anndata. The same code works on other datasets preprocessed in the same way. ```pytb; genes=['INS']; score_name='ins'; 'INS' in adata_rawnorm.var_names; True; IndexError Traceback (most recent call last); Input In [109], in <module>; ----> 1 sc.tl.score_genes(adata_rawnorm, gene_list=genes, score_name=score_name+'_score', use_raw=False). File ~/miniconda3/envs/block/lib/python3.8/site-packages/scanpy/tools/_score_genes.py:167, in score_genes(adata, gene_list, ctrl_size, gene_pool, n_bins, score_name, random_state, copy, use_raw); 164 else:; 165 X_list = np.nanmean(X_list, axis=1, dtype='float64'); --> 167 X_control = _adata[:, control_genes].X; 168 if issparse(X_control):; 169 X_control = np.array(_sparse_nanmean(X_control, axis=1)).flatten(). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/anndata.py:625, in AnnData.X(self); 622 X = _subset(X, (self._oidx, self._vidx)); 623 elif self.is_view:; 624 X = as_view(; --> 625 _subset(self._adata_ref.X, (self._oidx, self._vidx)),; 626 ElementRef(self, ""X""),; 627 ); 628 else:; 629 X = self._X. File ~/miniconda3/envs/block/lib/python3.8/functools.py:875, in singledispatch.<locals>.wrapper(*args, **kw); 871 if not args:; 872 raise TypeError(f'{funcname} requires at least '; 873 '1 positional argument'); --> 875 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/block/lib/python3.8/site-packages/anndata/_core/index.py:127, in _subset(a, subset_idx); 125 if all(isinstance(x, cabc.Iterable) for x in subset_idx):; 126 subset_idx = np.ix_(*subset_idx); --> 127 return a[subset_idx]. IndexError: arrays used as indices must be of integer (or boolean) type; ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2153
https://github.com/scverse/scanpy/issues/2154:928,Integrability,wrap,wrapper,928,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2154:167,Usability,simpl,simple,167,"<!-- What kind of feature would you like to request? -->; - [ ] Additional function parameters / changed functionality / changed defaults?; - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`?; - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`?; - [ ] External tools: Do you know an existing package that should go into `sc.external.*`?; - [ ] Other?. <!-- Please describe your wishes below: -->. PyMDE is a nice visualization method that to me seems to effectively serve the same purpose as UMAP in analyses (discussion about appropriateness of these methods can be in another issue :) ). It's super fast because after running pynndescent it puts the graph on the GPU optionally (using pytorch). I would love to see this in scanpy. There might be a way to use the scanpy neighbors graph from `sc.pp.neighbors` directly in pymde as the function below is a wrapper of some internal classes. <img width=""2431"" alt=""Screen Shot 2022-02-24 at 12 38 25 PM"" src=""https://user-images.githubusercontent.com/10859440/155603698-7f0e975e-2f4b-4a95-97eb-f119522c2510.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2154
https://github.com/scverse/scanpy/issues/2155:424,Availability,down,downsampling,424,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:465,Availability,robust,robustness,465,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:270,Modifiability,variab,variability,270,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:476,Testability,test,test,476,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2155:498,Usability,feedback,feedback,498,"<!--; ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠; If you want to know about design decisions and the like, please ask below:; -->; ...; Hi ; if samples contribute a different number of cells to my object, how to control for variability among samples? ; How to make sure that any difference between conditions I found is caused by biology and not because of samples variation? . downsampling, upsampling, bootstrapping, robustness test . Appreciate any feedback and any references for this issue. ![image](https://user-images.githubusercontent.com/23288387/155648374-f0d6178f-7024-4ecd-88c0-37547c5e7e19.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2155
https://github.com/scverse/scanpy/issues/2156:167,Availability,error,error,167,"Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error?. Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:248,Availability,error,error,248,"Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error?. Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:2799,Testability,log,logging,2799,"mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(data, index, dtype, copy, raise_cast_failure=True); 306 ; 307 data = SingleBlockManager(data, index, fastpath=True). ~/anaconda3/lib/python3.8/site-packages/pandas/core/construction.py in sanitize_array(data, index, dtype, copy, raise_cast_failure); 463 value = maybe_cast_to_datetime(value, dtype); 464 ; --> 465 subarr = construct_1d_arraylike_from_scalar(value, len(index), dtype); 466 ; 467 else:. ~/anaconda3/lib/python3.8/site-packages/pandas/core/dtypes/cast.py in construct_1d_arraylike_from_scalar(value, length, dtype); 1459 value = ensure_str(value); 1460 ; -> 1461 subarr = np.empty(length, dtype=dtype); 1462 subarr.fill(value); 1463 . TypeError: Cannot interpret '<attribute 'dtype' of 'numpy.generic' objects>' as a data type; ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2156:296,Usability,guid,guide,296,"Hello, . I am trying to calculate the cell cycle score for my 2 datasets by merging them together (using concatenate function) from the beginning and I am facing this error. Could anyone help me with this and explain what is the reason(s) for this error?. Thank you . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python; ## Mouse; folder = ""/home/pawandeep/Desktop/D2 Mdx/Macosko_cell_cycle_genes.txt""; cc_genes = pd.read_table(folder, delimiter='\t'); #cc_genes = pd.read_table(Macosko_cell_cycle_genes, delimiter='\t'); s_genes = cc_genes['S'].dropna(); g2m_genes = cc_genes['G2.M'].dropna(). s_genes_mm = [gene.lower().upper() for gene in s_genes]; g2m_genes_mm = [gene.lower().upper() for gene in g2m_genes]. s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False); ```. ```pytb; Traceback (most recent call last); /tmp/ipykernel_2938/2560507023.py in <module>; 11 s_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, s_genes_mm)]; 12 g2m_genes_mm_ens = adata.var.index[np.in1d(adata.var.index, g2m_genes_mm)]; ---> 13 sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes_mm_ens, g2m_genes=s_genes_mm_ens, use_raw=False). ~/anaconda3/lib/python3.8/site-packages/scanpy/tools/_score_genes.py in score_genes_cell_cycle(adata, s_genes, g2m_genes, copy, **kwargs); 255 ; 256 # default phase is S; --> 257 phase = pd.Series('S', index=scores.index); 258 ; 259 # if G2M is higher than S, it's G2M. ~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath); 303 data = data.copy(); 304 else:; --> 305 data = sanitize_array(dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2156
https://github.com/scverse/scanpy/issues/2158:176,Deployability,install,install,176,"https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
https://github.com/scverse/scanpy/issues/2158:211,Deployability,install,install,211,"https://github.com/theislab/scanpy/blob/0fde3f6cf93806bb1be1ac5fa4449da8a670fcf3/scanpy/tests/test_plotting.py#L1504. should it be moved in tests externals? if not, then `flit install -s --deps=develop` doesn't install scrublet whereas it should imho otherwise test fails for fail import",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2158
