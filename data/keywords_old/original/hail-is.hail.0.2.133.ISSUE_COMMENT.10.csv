id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/hail-is/hail/pull/13551#issuecomment-1709453126:158,Testability,test,testImolemebtation,158,Hmm. I’ll have to sort this out tomorrow. Not sure what’s going on with that. It seems like the shadowTestJar target is probably not correctly pulling in the testImolemebtation configuration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1709453126
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:479,Deployability,configurat,configurations,479,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:505,Deployability,configurat,configurations,505,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:479,Modifiability,config,configurations,479,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:505,Modifiability,config,configurations,505,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:78,Testability,test,test,78,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:146,Testability,test,test,146,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:439,Testability,test,test,439,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:464,Testability,test,test,464,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695:520,Testability,test,testRuntimeClasspath,520,"Ah, OK, this is actually quite sensible. I have to tell gradle that this is a test jar, I do that by saying I want my class path to look like the test class path at runtime. A wrinkle is that I have to explicitly request our own code too (that's the first diff line). I'm actually quite pleased that our grade file has become a bit more standard and less custom.; ```diff; task shadowTestJar(type: ShadowJar) {; archiveClassifier = 'spark-test'; + from sourceSets.test.output; + configurations = [project.configurations.testRuntimeClasspath]; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710347695
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:811,Availability,error,error,811,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:75,Deployability,configurat,configuration,75,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:148,Deployability,configurat,configuration,148,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:338,Integrability,depend,dependencies,338,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:701,Integrability,depend,dependencies,701,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:75,Modifiability,config,configuration,75,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:122,Modifiability,inherit,inherit,122,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:148,Modifiability,config,configuration,148,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:626,Modifiability,plugin,plugin,626,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:90,Testability,test,testCompileOnly,90,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:402,Testability,test,tests,402,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:546,Testability,test,test,546,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:739,Testability,test,tests,739,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:762,Testability,test,testCompile,762,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563
https://github.com/hail-is/hail/pull/13551#issuecomment-1710705353:96,Testability,test,test,96,Alright alright jeez I can't program any more. I also needed to explicitly request that all the test and main classes from our project should be in the JAR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710705353
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:209,Availability,error,error,209,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:215,Integrability,message,message,215,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:253,Integrability,message,messages,253,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:45,Testability,log,logs,45,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:113,Testability,log,logs,113,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:179,Testability,log,logs,179,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:249,Testability,log,log,249,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:305,Testability,log,logs,305,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516
https://github.com/hail-is/hail/issues/13554#issuecomment-1737433569:651,Availability,down,down,651,"It looks like permissions for deleting disks and VMs are broken for the `delete_batch_instances` CI step. This job also hung for a long time and then got restarted. There's some other wonky things about this PR, but it just seems like the main issue was the Batch deployment was cancelled mid-run and the driver didn't have time to cleanup those 2 VMs that weren't responding before being shut off. Then the cleanup step isn't actually working so they didn't get cleaned up. The only remaining question I have is why these VMs weren't starting up correctly. There were at least 5 in this one PR that didn't start up in time before the driver was shut down. https://batch.hail.is/batches/7908998/jobs/207",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737433569
https://github.com/hail-is/hail/issues/13554#issuecomment-1737433569:264,Deployability,deploy,deployment,264,"It looks like permissions for deleting disks and VMs are broken for the `delete_batch_instances` CI step. This job also hung for a long time and then got restarted. There's some other wonky things about this PR, but it just seems like the main issue was the Batch deployment was cancelled mid-run and the driver didn't have time to cleanup those 2 VMs that weren't responding before being shut off. Then the cleanup step isn't actually working so they didn't get cleaned up. The only remaining question I have is why these VMs weren't starting up correctly. There were at least 5 in this one PR that didn't start up in time before the driver was shut down. https://batch.hail.is/batches/7908998/jobs/207",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737433569
https://github.com/hail-is/hail/issues/13554#issuecomment-1737439794:92,Testability,test,test-gsa-key,92,@daniel-goldstein Does this command in `gcloud -q auth activate-service-account --key-file=/test-gsa-key/key.json` in a `delete_gcp_batch_instances` CI job still work after your auth changes?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737439794
https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758:92,Energy Efficiency,power,powerful,92,"That command should be unaffected, but `test-gsa-key` in PR namespaces is no longer the all-powerful `test-665@hail-vdc.iam.gserviceaccount.com` (which I would like to make not all-powerful), but is now `testns-test-418@hail-vdc.iam.gserviceaccount.com` which probably won't have that permission. My bad for missing that. Two questions:. - ~~Shouldn't `delete_gcp_batch_instances` fail if the vm deletion commands fail?~~ Ah there's a `set +e`, we should make that less permissive; - Can that step instead use the batch identity in the PR namespace? The batch identity should by definition have the ability to delete VMs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758
https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758:181,Energy Efficiency,power,powerful,181,"That command should be unaffected, but `test-gsa-key` in PR namespaces is no longer the all-powerful `test-665@hail-vdc.iam.gserviceaccount.com` (which I would like to make not all-powerful), but is now `testns-test-418@hail-vdc.iam.gserviceaccount.com` which probably won't have that permission. My bad for missing that. Two questions:. - ~~Shouldn't `delete_gcp_batch_instances` fail if the vm deletion commands fail?~~ Ah there's a `set +e`, we should make that less permissive; - Can that step instead use the batch identity in the PR namespace? The batch identity should by definition have the ability to delete VMs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758
https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758:40,Testability,test,test-gsa-key,40,"That command should be unaffected, but `test-gsa-key` in PR namespaces is no longer the all-powerful `test-665@hail-vdc.iam.gserviceaccount.com` (which I would like to make not all-powerful), but is now `testns-test-418@hail-vdc.iam.gserviceaccount.com` which probably won't have that permission. My bad for missing that. Two questions:. - ~~Shouldn't `delete_gcp_batch_instances` fail if the vm deletion commands fail?~~ Ah there's a `set +e`, we should make that less permissive; - Can that step instead use the batch identity in the PR namespace? The batch identity should by definition have the ability to delete VMs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758
https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758:102,Testability,test,test-,102,"That command should be unaffected, but `test-gsa-key` in PR namespaces is no longer the all-powerful `test-665@hail-vdc.iam.gserviceaccount.com` (which I would like to make not all-powerful), but is now `testns-test-418@hail-vdc.iam.gserviceaccount.com` which probably won't have that permission. My bad for missing that. Two questions:. - ~~Shouldn't `delete_gcp_batch_instances` fail if the vm deletion commands fail?~~ Ah there's a `set +e`, we should make that less permissive; - Can that step instead use the batch identity in the PR namespace? The batch identity should by definition have the ability to delete VMs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758
https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758:204,Testability,test,testns-test-,204,"That command should be unaffected, but `test-gsa-key` in PR namespaces is no longer the all-powerful `test-665@hail-vdc.iam.gserviceaccount.com` (which I would like to make not all-powerful), but is now `testns-test-418@hail-vdc.iam.gserviceaccount.com` which probably won't have that permission. My bad for missing that. Two questions:. - ~~Shouldn't `delete_gcp_batch_instances` fail if the vm deletion commands fail?~~ Ah there's a `set +e`, we should make that less permissive; - Can that step instead use the batch identity in the PR namespace? The batch identity should by definition have the ability to delete VMs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737449758
https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046:38,Availability,error,error,38,"1. I'm not sure why we don't throw an error. My bash isn't good enough to run both commands and then detect if either failed if the exit code is indeed not equal to 0. My only thought is that maybe the exit code isn't 0 if there are no VMs or disks to delete. 2. Yes, I'll see if I can PR the fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046
https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046:101,Safety,detect,detect,101,"1. I'm not sure why we don't throw an error. My bash isn't good enough to run both commands and then detect if either failed if the exit code is indeed not equal to 0. My only thought is that maybe the exit code isn't 0 if there are no VMs or disks to delete. 2. Yes, I'll see if I can PR the fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1737459046
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:182,Availability,echo,echo,182,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:261,Availability,echo,echo,261,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:385,Availability,echo,echo,385,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:464,Availability,echo,echo,464,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:840,Availability,ERROR,ERROR,840,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:1355,Availability,Error,ErrorInfo,1355,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:1577,Availability,echo,echo,1577,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:65,Deployability,pipeline,pipeline,65,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268:22,Safety,detect,detect,22,Are you asking how to detect that one command of many in a bash *pipeline* failed? We need pipe fail enabled for that:. ```bash; # bad; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 0; ```; ```bash; # good; (base) dking@wm28c-761 ~ % set -o pipefail; (base) dking@wm28c-761 ~ % ls fdsafds | xargs echo hello; ls: fdsafds: No such file or directory; (base) dking@wm28c-761 ~ % echo $?; 1; ```. Permissions issues indeed fail the `gcloud` command:; ```; (base) dking@wm28c-761 ~ % gcloud compute instances list --project notmyproject; API [compute.googleapis.com] not enabled on project [notmyproject]. Would you ; like to enable and retry (this will take a few minutes)? (y/N)? y. Enabling service [compute.googleapis.com] on project [notmyproject]...; ERROR: (gcloud.compute.instances.list) PERMISSION_DENIED: Permission denied to enable service [compute.googleapis.com]; Help Token: AVzH8v0NCN6UR5g5Xtu_gFde3SeZCmToYDDOlz7hp5HiVvGHKX8aeJ-kn0N0n72nMovbuw4ksm8MB0OifqPrdxlc6lWwJJKi0CsIJon1a7SSlF_H; - '@type': type.googleapis.com/google.rpc.PreconditionFailure; violations:; - subject: ?error_code=110002&service=serviceusage.googleapis.com&permission=serviceusage.services.enable&resource=notmyproject; type: googleapis.com; - '@type': type.googleapis.com/google.rpc.ErrorInfo; domain: serviceusage.googleapis.com; metadata:; permission: serviceusage.services.enable; resource: notmyproject; service: serviceusage.googleapis.com; reason: AUTH_PERMISSION_DENIED; (base) dking@wm28c-761 ~ % echo $?; 1; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1743472268
https://github.com/hail-is/hail/issues/13558#issuecomment-1707150748:170,Performance,cache,cache,170,"Regardless, we should publish `hailgenetics/hail` for each supported Python version. We should probably use that by default instead of python-dill and we should probably cache the most recent version on the workers since it's almost certainly the most popular image.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13558#issuecomment-1707150748
https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201:37,Testability,test,test-dataproc,37,"For a bit of extra confidence, I ran test-dataproc on this branch: https://ci.hail.is/batches/7960963. The clusters created successfully and the tests are running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201
https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201:145,Testability,test,tests,145,"For a bit of extra confidence, I ran test-dataproc on this branch: https://ci.hail.is/batches/7960963. The clusters created successfully and the tests are running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201
https://github.com/hail-is/hail/pull/13573#issuecomment-1709205959:0,Testability,test,test-dataproc,0,test-dataproc passed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13573#issuecomment-1709205959
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13576#issuecomment-1709450787
https://github.com/hail-is/hail/issues/13577#issuecomment-1737522562:75,Usability,simpl,simple,75,How long did these jobs run for? I was able to reproduce the OOM with this simple example and the resource usage file was present in GCS albeit with only 8 bytes written (the header). We don't show plots in the UI with just the header and no data. Do you have example Hail Query code that would generate an OOM more slowly?. ```python3; hl.eval(hl.range(1024 * 1024).map(lambda _: hl.range(1024 * 1024))); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13577#issuecomment-1737522562
https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167:81,Deployability,pipeline,pipeline,81,gnomAD is also exhausting memory (exit code 137) on their frequencies generating pipeline. They’re still exhausting memory after eliminating fork-joins in their pipeline. They were unintentionally invoking densification four times. We’ll need to sort out why even the simple frequencies blows memory.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167
https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167:161,Deployability,pipeline,pipeline,161,gnomAD is also exhausting memory (exit code 137) on their frequencies generating pipeline. They’re still exhausting memory after eliminating fork-joins in their pipeline. They were unintentionally invoking densification four times. We’ll need to sort out why even the simple frequencies blows memory.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167
https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167:268,Usability,simpl,simple,268,gnomAD is also exhausting memory (exit code 137) on their frequencies generating pipeline. They’re still exhausting memory after eliminating fork-joins in their pipeline. They were unintentionally invoking densification four times. We’ll need to sort out why even the simple frequencies blows memory.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1712493167
https://github.com/hail-is/hail/issues/13584#issuecomment-1738201066:29,Deployability,pipeline,pipeline,29,I'm closing this because the pipeline causing these issues had a number of other complicating issues. We can re-open if/when we find a pipeline whose issues we're confident are due to a large alleles array rather than something else.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1738201066
https://github.com/hail-is/hail/issues/13584#issuecomment-1738201066:135,Deployability,pipeline,pipeline,135,I'm closing this because the pipeline causing these issues had a number of other complicating issues. We can re-open if/when we find a pipeline whose issues we're confident are due to a large alleles array rather than something else.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13584#issuecomment-1738201066
https://github.com/hail-is/hail/pull/13588#issuecomment-1710521152:66,Deployability,integrat,integrated,66,"Also, I forgot making sure all of the Docker images are valid and integrated into CI like the vep images.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13588#issuecomment-1710521152
https://github.com/hail-is/hail/pull/13588#issuecomment-1710521152:66,Integrability,integrat,integrated,66,"Also, I forgot making sure all of the Docker images are valid and integrated into CI like the vep images.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13588#issuecomment-1710521152
https://github.com/hail-is/hail/pull/13594#issuecomment-1710921838:17,Usability,clear,clear,17,"To be abundantly clear: this is strictly a rename. Originally I had some changes in Python, but I've backed them out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13594#issuecomment-1710921838
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:164,Availability,recover,recovery,164,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:302,Availability,recover,recovery,302,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:164,Safety,recover,recovery,164,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:302,Safety,recover,recovery,302,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:58,Security,password,password,58,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767:237,Testability,log,log,237,"We now use an API token linked to hailgenetics instead of password auth. In order to do the org request, Daniel set up 2FA. There's no way to set up 2FA. There are recovery codes in the ""usual place"". No one besides Daniel can currently log into hailgenetics PyPI account as a result (other than using recovery codes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1808759767
https://github.com/hail-is/hail/issues/13598#issuecomment-1839221748:9,Deployability,update,updates,9,still no updates,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13598#issuecomment-1839221748
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:145,Modifiability,variab,variable,145,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:366,Modifiability,variab,variable,366,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:392,Modifiability,variab,variables,392,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:475,Modifiability,variab,variable,475,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:503,Modifiability,variab,variables,503,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:608,Modifiability,variab,variables,608,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:834,Modifiability,variab,variable,834,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:1192,Modifiability,variab,variables,1192,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:301,Usability,learn,learn,301,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:689,Usability,learn,learn,689,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:741,Usability,learn,learn,741,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:1230,Usability,learn,learn,1230,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413:1268,Usability,learn,learn,1268,"After some reading, I am still not sure what exactly the difference is between dummy coding and one-hot encoding. Suppose there is a categorical variable with $n$ categories. The [referenced Stack Exchange question](https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn) suggests that a one-hot encoding converts the categorical variable to $n$ indicator variables (one for each category) and that a dummy coding converts the categorical variable to $n-1$ indicator variables. With these definitions, the dummy coding is the one-hot encoding without one of the indicator variables. However, from the prototype implementation in this issue, the [scikit-learn one-hot encoder documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), and the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)), I get the impression that dummy coding and one-hot encoding are synonyms and that there is no real distinction. Anyway, I would like to work on this issue. I will base my implementation on the prototype, and perhaps we can add a parameter to drop one of the indicator variables similar to what the [scikit-learn one-hot encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) has.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13601#issuecomment-1932779413
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:828,Availability,echo,echo,828,"I forgot that we still had cron jobs running gcr-cleaner daily. This could have been conflicting with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2670,Availability,echo,echo,2670,"c/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hai",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:195,Deployability,configurat,configurations,195,"I forgot that we still had cron jobs running gcr-cleaner daily. This could have been conflicting with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1147,Deployability,install,installed-,1147," reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1209,Deployability,install,installed-,1209,"ere before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/ba",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2989,Deployability,install,installed-,2989,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3051,Deployability,install,installed-,3051,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1349,Energy Efficiency,monitor,monitoring,1349,"v/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/b",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1681,Energy Efficiency,monitor,monitoring,1681,"/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-d",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3191,Energy Efficiency,monitor,monitoring,3191,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3523,Energy Efficiency,monitor,monitoring,3523,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:195,Modifiability,config,configurations,195,"I forgot that we still had cron jobs running gcr-cleaner daily. This could have been conflicting with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2063,Performance,cache,cache-pr,2063,"ker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:556,Testability,benchmark,benchmark,556,"I forgot that we still had cron jobs running gcr-cleaner daily. This could have been conflicting with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1098,Testability,test,tests,1098,"ing with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1634,Testability,test,test-ci,1634,"-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1676,Testability,test,test-monitoring,1676,"/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-d",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1726,Testability,test,test-benchmark,1726,"l/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pk",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2398,Testability,benchmark,benchmark,2398,"ok"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pk",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:2940,Testability,test,tests,2940,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3476,Testability,test,test-ci,3476,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3518,Testability,test,test-monitoring,3518,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:3568,Testability,test,test-benchmark,3568,"hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello""],""grace"":""48h"",""recursive"":true}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545
https://github.com/hail-is/hail/issues/13606#issuecomment-1717799683:24,Deployability,pipeline,pipeline,24,Here is a straight-line pipeline that replicates the high memory use. In my experience this can get up to 100GiB of RAM use. https://gist.github.com/danking/3432deabd997ce08515b2088e202a039. The VDS file is privileged. Next steps:. - [ ] replicate on a public VDS like the HGDP/1KG VDS.; - [ ] delete as much code as possible from this file to reduce the possible causes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13606#issuecomment-1717799683
https://github.com/hail-is/hail/issues/13606#issuecomment-1717799683:344,Energy Efficiency,reduce,reduce,344,Here is a straight-line pipeline that replicates the high memory use. In my experience this can get up to 100GiB of RAM use. https://gist.github.com/danking/3432deabd997ce08515b2088e202a039. The VDS file is privileged. Next steps:. - [ ] replicate on a public VDS like the HGDP/1KG VDS.; - [ ] delete as much code as possible from this file to reduce the possible causes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13606#issuecomment-1717799683
https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597:395,Availability,error,error,395,I checked the database and was surprised to see the SKUs weren't necessarily unique to a specific region. But it makes sense when I looked at their API here: https://cloud.google.com/billing/docs/reference/rest/v1/services.skus/list#sku. I think we should put this in and address what happens if they change the SKU of a particular region if that occurs in the future. We'll just get a bunch of error messages with no price updates and it shouldn't impact users. ~~I will also manually check this in Azure.~~ I checked in both GCP and Azure and the updates looked fine with no errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597
https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597:577,Availability,error,errors,577,I checked the database and was surprised to see the SKUs weren't necessarily unique to a specific region. But it makes sense when I looked at their API here: https://cloud.google.com/billing/docs/reference/rest/v1/services.skus/list#sku. I think we should put this in and address what happens if they change the SKU of a particular region if that occurs in the future. We'll just get a bunch of error messages with no price updates and it shouldn't impact users. ~~I will also manually check this in Azure.~~ I checked in both GCP and Azure and the updates looked fine with no errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597
https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597:424,Deployability,update,updates,424,I checked the database and was surprised to see the SKUs weren't necessarily unique to a specific region. But it makes sense when I looked at their API here: https://cloud.google.com/billing/docs/reference/rest/v1/services.skus/list#sku. I think we should put this in and address what happens if they change the SKU of a particular region if that occurs in the future. We'll just get a bunch of error messages with no price updates and it shouldn't impact users. ~~I will also manually check this in Azure.~~ I checked in both GCP and Azure and the updates looked fine with no errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597
https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597:549,Deployability,update,updates,549,I checked the database and was surprised to see the SKUs weren't necessarily unique to a specific region. But it makes sense when I looked at their API here: https://cloud.google.com/billing/docs/reference/rest/v1/services.skus/list#sku. I think we should put this in and address what happens if they change the SKU of a particular region if that occurs in the future. We'll just get a bunch of error messages with no price updates and it shouldn't impact users. ~~I will also manually check this in Azure.~~ I checked in both GCP and Azure and the updates looked fine with no errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597
https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597:401,Integrability,message,messages,401,I checked the database and was surprised to see the SKUs weren't necessarily unique to a specific region. But it makes sense when I looked at their API here: https://cloud.google.com/billing/docs/reference/rest/v1/services.skus/list#sku. I think we should put this in and address what happens if they change the SKU of a particular region if that occurs in the future. We'll just get a bunch of error messages with no price updates and it shouldn't impact users. ~~I will also manually check this in Azure.~~ I checked in both GCP and Azure and the updates looked fine with no errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1726229597
https://github.com/hail-is/hail/pull/13607#issuecomment-1736105248:528,Safety,risk,risk,528,"> I don't see how a hard coded list in the repo is any different than a compare and swap with the SKU stored in the database. I don't think we can get around parsing the description in some form when we initialize the product. . I think I'm missing context here, especially surrounding what the source of truth is for a ""product"". Maybe we should have a meeting or discussion in a different forum at some point? I don't know how volatile the product descriptions are, but my current understanding is that this is all pretty low risk/priority. For posterity, my main concern is around reproducibility. Assume a description change happens tomorrow and now however we're parsing the description ends up pointing at a different SKU. Now at any point in the future, if we have some data loss and have to rebuild these tables, the SKU will suddenly change, but only because we rebuilt the database not because of some actual change in GCP. Or if we or anyone else stands up a new batch cluster, they will get a SKU that differs from what we have currently in `hail-vdc`, just because they started up their cluster at a different point in time. With my current understanding that is an undesirable scenario, but I don't actually know what the implications of such a scenario are.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736105248
https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579:309,Availability,error,error,309,"Discussion in a different forum sounds good. This came up with the GPU branch as there was a question on whether we can trust what we are parsing as a resource or did we need to hardcode the SKUs explicitly. This was my proposed solution for us at least knowing that something has changed with lots of driver error messages and to not try and do any updates if the invariants of the ""SKU"" don't hold.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579
https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579:350,Deployability,update,updates,350,"Discussion in a different forum sounds good. This came up with the GPU branch as there was a question on whether we can trust what we are parsing as a resource or did we need to hardcode the SKUs explicitly. This was my proposed solution for us at least knowing that something has changed with lots of driver error messages and to not try and do any updates if the invariants of the ""SKU"" don't hold.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579
https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579:315,Integrability,message,messages,315,"Discussion in a different forum sounds good. This came up with the GPU branch as there was a question on whether we can trust what we are parsing as a resource or did we need to hardcode the SKUs explicitly. This was my proposed solution for us at least knowing that something has changed with lots of driver error messages and to not try and do any updates if the invariants of the ""SKU"" don't hold.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736209579
https://github.com/hail-is/hail/pull/13607#issuecomment-1736214789:84,Security,secur,security,84,Very reasonable! I think that makes a lot of sense and am glad we'll have the extra security.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13607#issuecomment-1736214789
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:197,Deployability,pipeline,pipeline,197,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:595,Deployability,pipeline,pipeline,595,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:640,Deployability,pipeline,pipeline,640,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:24,Usability,simpl,simpler,24,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:87,Usability,simpl,simplifier,87,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:564,Usability,simpl,simplifier,564,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103:582,Usability,simpl,simplify,582,"FWIW, I finally found a simpler reproducer. It really takes some doing to convince the simplifier to apply this rule. This operation should use a constant ~1GiB of RAM (in reality, in a non-broken pipeline it uses closer to 8GiB, but, still, a constant amount of RAM), but in reality memory use grows with each row processed. ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.key_by(); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```; The simplifier cannot simplify the pipeline if the key is still present so this pipeline is sufficient to restore normal memory usage:; ```python3; import hail as hl; ht = hl.utils.range_table(1); ht = ht.select(rows = hl.range(10)); ht = ht.explode('rows'); ht = ht.annotate(garbage=hl.range(1024 ** 3)); ht.write('/tmp/foo.ht', overwrite=True); ```. The ""bad"" `WritePartition` body IR looks like this:; ```; (StreamFlatMap __iruid_447; (StreamRange -1 True; (GetField start (Ref __iruid_446)); (GetField end (Ref __iruid_446)); (I32 1)); (StreamMap __iruid_448; (StreamRange 1 False (I32 0) (I32 10) (I32 1)); (InsertFields; (Literal Struct{} <literal value>); (""rows"" ""garbage""); (rows (Ref __iruid_448)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1))))))); ```; The ""good"" IR looks like this:; ```; (StreamFlatMap __iruid_480; (StreamRange -1 True; (GetField start (Ref __iruid_479)); (GetField end (Ref __iruid_479)); (I32 1)); (Let __iruid_481; (MakeStruct; (idx (Ref __iruid_480)); (rows; (ToArray; (StreamRange 1 False (I32 0) (I32 10) (I32 1))))); (StreamMap __iruid_482; (ToStream True (GetField rows (Ref __iruid_481))); (InsertFields; (Ref __iruid_481); (""idx"" ""rows"" ""garbage""); (rows (Ref __iruid_482)); (garbage; (ToArray; (StreamRange 2 False; (I32 0); (I32 1073741824); (I32 1)))))))); ```. Notice, in particular, that the `StreamMap` inside the `StreamFlatMap` uses memory management because",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13619#issuecomment-1720022103
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:775,Modifiability,config,configfile,775,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:799,Modifiability,plugin,plugins,799,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:851,Safety,timeout,timeout-,851,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:51,Testability,test,tests,51,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:128,Testability,test,tests,128,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:238,Testability,test,tests,238,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:288,Testability,test,tests,288,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:479,Testability,test,test,479,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:564,Testability,test,test,564,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:769,Testability,test,test,769,"> I kinda prefer a fresh file with freshly written tests? I feel like it's a bit hard to get a total view of what is and is not tests when we're using annotations. I agree a single file feels nice, but I'm a little hesitant to copy paste tests. Unless you think I should move where these tests are? That also feels weird. Does the following pytest invocation make you feel better about markers?. ```; (hail) dgoldste@wmce3-cb7 hail % pytest --collect-only -m qobtest hail/python/test; ============================================================================== test session starts ===============================================================================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunct",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1568,Testability,Test,Tests,1568,"=======================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function tes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1577,Testability,Test,TestCaseFunction,1577,"=======================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function tes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1614,Testability,Test,TestCaseFunction,1614,"=======================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function tes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1653,Testability,Test,TestCaseFunction,1653,"=======================; platform darwin -- Python 3.9.17, pytest-7.4.0, pluggy-1.3.0; rootdir: /Users/dgoldste/hail/hail/python/test; configfile: pytest.ini; plugins: anyio-4.0.0, xdist-2.5.0, instafail-0.5.0, timeout-2.1.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, forked-1.6.0; asyncio: mode=auto; collected 8218 items / 8133 deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function tes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1979,Testability,Test,Tests,1979,deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module t,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:1988,Testability,Test,TestCaseFunction,1988,deselected / 85 selected. <Package hail>; <Module test_context.py>; <Function test_init_hail_context_twice>; <Function test_top_level_functions_are_do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module t,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2078,Testability,Test,Tests,2078,do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2087,Testability,Test,TestCaseFunction,2087,do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2132,Testability,Test,TestCaseFunction,2132,do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2172,Testability,Test,TestCaseFunction,2172,do_not_error>; <Function test_tmpdir_runs>; <Module test_randomness.py>; <Function test_table_explode>; <Package backend>; <Module test_service_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2274,Testability,Test,Tests,2274,ice_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package ut,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2283,Testability,Test,TestCaseFunction,2283,ice_backend.py>; <Function test_tiny_driver_has_tiny_memory>; <Function test_big_driver_has_big_memory>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package ut,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2371,Testability,Test,TestCaseFunction,2371,ry>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function t,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2401,Testability,Test,TestCaseFunction,2401,ry>; <Function test_tiny_worker_has_tiny_memory>; <Function test_big_worker_has_big_memory>; <Function test_regions>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function t,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2473,Testability,Test,Tests,2473,>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <F,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2482,Testability,Test,TestCaseFunction,2482,>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <F,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2517,Testability,Test,TestCaseFunction,2517,>; <Package expr>; <Module test_expr.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregators>; <TestCaseFunction test_densify_table>; <TestCaseFunction test_scan>; <Package genetics>; <Module test_reference_genome.py>; <Function test_reference_genome>; <Function test_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <F,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2718,Testability,Test,Tests,2718,t_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2727,Testability,Test,TestCaseFunction,2727,t_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:2777,Testability,Test,TestCaseFunction,2777,t_reference_genome_sequence>; <Function test_reference_genome_liftover>; <Function test_read_custom_reference_genome>; <Package matrixtable>; <Module test_grouped_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_joins_work_correctly>; <Module test_matrix_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:3068,Testability,Test,TestCaseFunction,3068,e Tests>; <TestCaseFunction test_collect_cols_by_key>; <TestCaseFunction test_naive_coalesce>; <TestCaseFunction test_range_count>; <Package methods>; <Module test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_e,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:3143,Testability,Test,Tests,3143,ule test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[lo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:3152,Testability,Test,TestCaseFunction,3152,ule test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[lo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:3188,Testability,Test,TestCaseFunction,3188,ule test_family_methods.py>; <UnitTestCase Tests>; <TestCaseFunction test_trio_matrix_1>; <Module test_impex.py>; <UnitTestCase VCFTests>; <TestCaseFunction test_glob>; <TestCaseFunction test_import_gvcfs>; <Module test_qc.py>; <UnitTestCase Tests>; <TestCaseFunction test_sample_qc>; <TestCaseFunction test_variant_qc>; <Module test_skat.py>; <Function test_logistic_skat_phenotypes_are_binary>; <Function test_logistic_skat_no_weights_R_truth>; <Module test_statgen.py>; <UnitTestCase Tests>; <TestCaseFunction test_impute_sex_same_as_plink>; <TestCaseFunction test_linreg_basic>; <Package relatedness>; <Module test_identity_by_descent.py>; <Function test_ibd_default_arguments>; <Module test_pc_relate.py>; <Function test_pc_relate_simple_example>; <Package table>; <Module test_grouped_table.py>; <UnitTestCase GroupedTableTests>; <TestCaseFunction test_aggregate_by>; <Module test_table.py>; <UnitTestCase Tests>; <TestCaseFunction test_aggregate1>; <TestCaseFunction test_annotate>; <Function test_lowered_persist>; <Function test_lowered_shuffle>; <Package utils>; <Module test_hl_hadoop_and_hail_fs.py>; <Function test_hadoop_methods_1[remote]>; <Function test_hadoop_methods_1[local]>; <Function test_hadoop_methods_2[remote]>; <Function test_hadoop_methods_2[local]>; <Function test_hadoop_methods_3[remote]>; <Function test_hadoop_methods_3[local]>; <Function test_read_overwrite[remote]>; <Function test_read_overwrite[local]>; <Function test_hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[lo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4277,Testability,Test,Tests,4277,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4286,Testability,Test,TestCaseFunction,4286,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4321,Testability,Test,TestCaseFunction,4321,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4360,Testability,Test,TestCaseFunction,4360,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4427,Testability,Test,TestCaseFunction,4427,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4464,Testability,Test,TestCaseFunction,4464,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4505,Testability,Test,TestCaseFunction,4505,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4544,Testability,Test,TestCaseFunction,4544,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4604,Testability,Test,TestCaseFunction,4604,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4643,Testability,Test,TestCaseFunction,4643,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4683,Testability,Test,TestCaseFunction,4683,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4718,Testability,Test,TestCaseFunction,4718,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4778,Testability,Test,TestCaseFunction,4778,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4820,Testability,Test,TestCaseFunction,4820,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4862,Testability,Test,TestCaseFunction,4862,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4920,Testability,Test,TestCaseFunction,4920,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:4962,Testability,Test,TestCaseFunction,4962,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5002,Testability,Test,TestCaseFunction,5002,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5042,Testability,Test,TestCaseFunction,5042,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5084,Testability,Test,TestCaseFunction,5084,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5134,Testability,Test,TestCaseFunction,5134,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5171,Testability,Test,TestCaseFunction,5171,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5209,Testability,Test,TestCaseFunction,5209,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5247,Testability,Test,TestCaseFunction,5247,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5284,Testability,Test,TestCaseFunction,5284,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5344,Testability,Test,TestCaseFunction,5344,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851:5576,Testability,test,tests,5576,hadoop_exists[remote]>; <Function test_hadoop_exists[local]>; <Function test_hadoop_is_file[remote]>; <Function test_hadoop_is_file[local]>; <Function test_hadoop_stat[remote]>; <Function test_hadoop_stat[local]>; <Function test_subdirs[remote]>; <Function test_subdirs[local]>; <Function test_rmtree_empty_is_ok[remote]>; <Function test_rmtree_empty_is_ok[local]>; <Function test_rmtree_empty_subdir_is_ok[remote]>; <Function test_rmtree_empty_subdir_is_ok[local]>; <Function test_remove_and_rmtree[remote]>; <Function test_remove_and_rmtree[local]>; <Module test_utils.py>; <UnitTestCase Tests>; <TestCaseFunction test_escape_id>; <TestCaseFunction test_escape_string>; <TestCaseFunction test_expr_exception_results_in_hail_user_error>; <TestCaseFunction test_frozen_dict>; <TestCaseFunction test_hadoop_copy_log>; <TestCaseFunction test_hadoop_exists>; <TestCaseFunction test_hadoop_glob_heterogenous_structure>; <TestCaseFunction test_hadoop_is_dir>; <TestCaseFunction test_hadoop_is_file>; <TestCaseFunction test_hadoop_ls>; <TestCaseFunction test_hadoop_ls_file_that_does_not_exist>; <TestCaseFunction test_hadoop_ls_glob_1>; <TestCaseFunction test_hadoop_ls_glob_2>; <TestCaseFunction test_hadoop_ls_glob_no_slash_in_group>; <TestCaseFunction test_hadoop_ls_simple>; <TestCaseFunction test_hadoop_methods>; <TestCaseFunction test_hadoop_mkdir_p>; <TestCaseFunction test_hadoop_mkdir_p_2>; <TestCaseFunction test_hadoop_no_glob_in_bucket>; <TestCaseFunction test_hadoop_stat>; <TestCaseFunction test_interval_ops>; <TestCaseFunction test_json_encoder>; <TestCaseFunction test_linked_list>; <TestCaseFunction test_range_matrix_table_n_lt_partitions>; <TestCaseFunction test_struct_ops>; <Package vds>; <Module test_combiner.py>; <Function test_combiner_works>; <Module test_vds.py>; <Function test_multi_write>. =============================================================== 85/8218 tests collected (8133 deselected) in 5.04s ===============================================================; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1720268851
https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570:48,Testability,test,tests,48,I think my ideal is a file with freshly written tests that state what we expect of QoB. The current state of our tests is just a kind of jungle of things we've ever thought were important at some point. I'm not sure how to incentivize us to curate our test suite a bit more intentionally.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570
https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570:113,Testability,test,tests,113,I think my ideal is a file with freshly written tests that state what we expect of QoB. The current state of our tests is just a kind of jungle of things we've ever thought were important at some point. I'm not sure how to incentivize us to curate our test suite a bit more intentionally.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570
https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570:252,Testability,test,test,252,I think my ideal is a file with freshly written tests that state what we expect of QoB. The current state of our tests is just a kind of jungle of things we've ever thought were important at some point. I'm not sure how to incentivize us to curate our test suite a bit more intentionally.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13624#issuecomment-1720219145
https://github.com/hail-is/hail/pull/13627#issuecomment-1724263938:157,Usability,clear,clear,157,"Good call, done. It would be nice to factor out the common parts of handling refs, whether they're normal children or the only node in a block, but it's not clear how to do that without a pretty big structural change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13627#issuecomment-1724263938
https://github.com/hail-is/hail/pull/13632#issuecomment-1781834758:161,Usability,feedback,feedback,161,"@daniel-goldstein sorry for the slow review turnaround! the code looks good to me, and i'll try it out tomorrow morning to make sure i don't have any additional feedback. thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1781834758
https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092:269,Deployability,install,install,269,"to be included in the dev docs:. the devserver uses the `default_namespace` configured via `hailctl dev config`, so make sure to change that to your dev namespace or the default namespace as desired. whatever service you're trying to hack on the UI of needs to be `pip install`ed, as well as `web_common` and `gear`; for example, `pip install -e web_common gear batch`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092
https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092:335,Deployability,install,install,335,"to be included in the dev docs:. the devserver uses the `default_namespace` configured via `hailctl dev config`, so make sure to change that to your dev namespace or the default namespace as desired. whatever service you're trying to hack on the UI of needs to be `pip install`ed, as well as `web_common` and `gear`; for example, `pip install -e web_common gear batch`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092
https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092:76,Modifiability,config,configured,76,"to be included in the dev docs:. the devserver uses the `default_namespace` configured via `hailctl dev config`, so make sure to change that to your dev namespace or the default namespace as desired. whatever service you're trying to hack on the UI of needs to be `pip install`ed, as well as `web_common` and `gear`; for example, `pip install -e web_common gear batch`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092
https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092:104,Modifiability,config,config,104,"to be included in the dev docs:. the devserver uses the `default_namespace` configured via `hailctl dev config`, so make sure to change that to your dev namespace or the default namespace as desired. whatever service you're trying to hack on the UI of needs to be `pip install`ed, as well as `web_common` and `gear`; for example, `pip install -e web_common gear batch`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13632#issuecomment-1783089092
https://github.com/hail-is/hail/pull/13653#issuecomment-1725701826:42,Testability,test,test,42,"This all seems fine to me, but all of the test jobs failed spectacularly on Azure -- timed out. There must be another place the key is used?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13653#issuecomment-1725701826
https://github.com/hail-is/hail/pull/13653#issuecomment-1781474810:21,Deployability,release,release,21,WIP until I sort the release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13653#issuecomment-1781474810
https://github.com/hail-is/hail/pull/13653#issuecomment-1883522250:30,Security,password,password,30,Turns out you need a key or a password. Closing this for now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13653#issuecomment-1883522250
https://github.com/hail-is/hail/issues/13656#issuecomment-1737882692:152,Usability,clear,clear,152,Working on it! #12848 will be merged soon and #12849 will be reopened subsequently. The next steps after the billing tables are fully populated are not clear to me and we might want to discuss after stand up once the other two are merged.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13656#issuecomment-1737882692
https://github.com/hail-is/hail/pull/13659#issuecomment-1725696869:253,Deployability,release,release,253,@danking That's because we weren't actually respecting the `HAIL_GENETICS_HAIL_IMAGE` for the default python image and always referencing Dockerhub. This didn't manifest until now because we were using the `python-dill` images which do not change every release,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13659#issuecomment-1725696869
https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619:82,Availability,Error,Error,82,This failed in Azure when compiling the JVM Entryway. ```; > Task :compileScala; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:126: error: cannot find symbol; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:153: error: cannot find symbol; javac exited with exit code 1. > Task :compileScala FAILED; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619
https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619:156,Availability,error,error,156,This failed in Azure when compiling the JVM Entryway. ```; > Task :compileScala; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:126: error: cannot find symbol; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:153: error: cannot find symbol; javac exited with exit code 1. > Task :compileScala FAILED; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619
https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619:184,Availability,Error,Error,184,This failed in Azure when compiling the JVM Entryway. ```; > Task :compileScala; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:126: error: cannot find symbol; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:153: error: cannot find symbol; javac exited with exit code 1. > Task :compileScala FAILED; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619
https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619:258,Availability,error,error,258,This failed in Azure when compiling the JVM Entryway. ```; > Task :compileScala; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:126: error: cannot find symbol; [Error] /io/batch/jvm-entryway/src/main/java/is/hail/JVMEntryway.java:153: error: cannot find symbol; javac exited with exit code 1. > Task :compileScala FAILED; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13664#issuecomment-1728404619
https://github.com/hail-is/hail/pull/13670#issuecomment-1726542573:111,Testability,test,tested,111,"This can be thought of as a step toward a fully local development version of batch. I tried to keep the not-ci-tested `create_local_database.py` script as small as possible and reuse components of the tested `create_database.py`, but it's still adding yet-another-random-script into the mix. @jigold @danking Do you think this is worthwhile on its own?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13670#issuecomment-1726542573
https://github.com/hail-is/hail/pull/13670#issuecomment-1726542573:201,Testability,test,tested,201,"This can be thought of as a step toward a fully local development version of batch. I tried to keep the not-ci-tested `create_local_database.py` script as small as possible and reuse components of the tested `create_database.py`, but it's still adding yet-another-random-script into the mix. @jigold @danking Do you think this is worthwhile on its own?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13670#issuecomment-1726542573
https://github.com/hail-is/hail/pull/13674#issuecomment-1734185921:376,Testability,assert,assertion,376,"> Whoops, sorry clipboard malfunction. I meant [here](https://github.com/hail-is/hail/blob/e6728b812e73a8bd636046bed22f97c5b47a5f12/hail/src/main/scala/is/hail/lir/X.scala#L416), when trying to add code to an lir block after a terminating control op. This was turning into quite a hairy change. I'm going to merge this as its own thing and work on fixing the fallout from the assertion in a follow-up change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13674#issuecomment-1734185921
https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156:167,Performance,optimiz,optimization-guide,167,Maybe we can use GraalVM Native Image? https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/Limitations/#native-image-compatibility-and-optimization-guide,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156
https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156:180,Usability,guid,guide,180,Maybe we can use GraalVM Native Image? https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/Limitations/#native-image-compatibility-and-optimization-guide,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13675#issuecomment-1728007156
https://github.com/hail-is/hail/issues/13675#issuecomment-1728033312:5,Availability,checkpoint,checkpoint-restore,5,CRIU/checkpoint-restore using Eclipse OpenJ9 JVM https://blog.openj9.org/2022/09/26/getting-started-with-openj9-criu-support/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13675#issuecomment-1728033312
https://github.com/hail-is/hail/pull/13676#issuecomment-1728108189:1393,Usability,clear,clear,1393,"Adding zulip thread for posterity:. Patrick Schultz (he/him); [12:38 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392155787); Ah, that's what I thought, originally FastSeq returned a Seq: https://github.com/hail-is/hail/commit/be415a850eb145c69a830e485d3192331799f14f#diff-75be823f33bdb7bc10ab85e3b954c91a4a7bd48176c2a39f2e3d2e7f7e30fab4. daniel king (he/him); [12:40 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156010); huh, I wonder when/why that changed. Patrick Schultz (he/him); [12:40 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156041); [toFastSeq](https://github.com/hail-is/hail/blob/995994c862b93406bc4b5fc37c7f022f7426cd52/hail/src/main/scala/is/hail/utils/richUtils/RichIterator.scala#L145) still does. If you make this change, you should get rid of toFastIndexedSeq too. [ 12:41 pm](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156191); daniel king (he/him) [said](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/FastIndexedSeq/near/392156010):. huh, I wonder when/why that changed. [a month later](https://github.com/hail-is/hail/commit/e2458973ad2bb9b065a56f480e986554b40eed79#diff-75be823f33bdb7bc10ab85e3b954c91a4a7bd48176c2a39f2e3d2e7f7e30fab4), not clear why",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13676#issuecomment-1728108189
https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933:18,Availability,failure,failures,18,"It seems the test failures are due to:; 1. TemporaryDirectory (and TemporaryFilename); 2. `hailtop.batch.backend.ServiceBackend` absolutely should not use sync `BatchClient`, the async one is right there!; 3. `hailctl batch submit` is broken because of (2); 4. `test_callback` should use async `BatchClient` b/c it is async. TemporaryDirectory & TemporaryFilename use `hailtop.fs`, which is sync. This is nearly the async FS API except:; 1. `isfile` vs `is_file`; 2. `isdir` vs `is_dir`; 3. `stat` returns a `FileListEntry` instead of a `FileStatus`.; 4. `listfiles` vs `ls`. `hailtop.fs.router_fs.RouterFS` is a sync shim between these APIs. So there's basically sync-vs-async and Python-vs-Hail FS APIs. We have:; 1. sync, Python: `hailtop.fs.FS`.; 2. async, Python: does not exist.; 3. async, Hail: `hailtop.aiotools.fs.FS`.; 4. sync, Hail: `hailtop.fs.router_fs.RouterFS`. If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in `hail.backend.ServiceBackend`). The high-level need is that we gotta be careful about not interleaving async-sync-async. Your PR reveals that we were inadvertently violating that rule. It seems best to follow the rule and only use `nest_asyncio` when we're in a Jupyter Notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933
https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933:598,Integrability,Rout,RouterFS,598,"It seems the test failures are due to:; 1. TemporaryDirectory (and TemporaryFilename); 2. `hailtop.batch.backend.ServiceBackend` absolutely should not use sync `BatchClient`, the async one is right there!; 3. `hailctl batch submit` is broken because of (2); 4. `test_callback` should use async `BatchClient` b/c it is async. TemporaryDirectory & TemporaryFilename use `hailtop.fs`, which is sync. This is nearly the async FS API except:; 1. `isfile` vs `is_file`; 2. `isdir` vs `is_dir`; 3. `stat` returns a `FileListEntry` instead of a `FileStatus`.; 4. `listfiles` vs `ls`. `hailtop.fs.router_fs.RouterFS` is a sync shim between these APIs. So there's basically sync-vs-async and Python-vs-Hail FS APIs. We have:; 1. sync, Python: `hailtop.fs.FS`.; 2. async, Python: does not exist.; 3. async, Hail: `hailtop.aiotools.fs.FS`.; 4. sync, Hail: `hailtop.fs.router_fs.RouterFS`. If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in `hail.backend.ServiceBackend`). The high-level need is that we gotta be careful about not interleaving async-sync-async. Your PR reveals that we were inadvertently violating that rule. It seems best to follow the rule and only use `nest_asyncio` when we're in a Jupyter Notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933
https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933:866,Integrability,Rout,RouterFS,866,"It seems the test failures are due to:; 1. TemporaryDirectory (and TemporaryFilename); 2. `hailtop.batch.backend.ServiceBackend` absolutely should not use sync `BatchClient`, the async one is right there!; 3. `hailctl batch submit` is broken because of (2); 4. `test_callback` should use async `BatchClient` b/c it is async. TemporaryDirectory & TemporaryFilename use `hailtop.fs`, which is sync. This is nearly the async FS API except:; 1. `isfile` vs `is_file`; 2. `isdir` vs `is_dir`; 3. `stat` returns a `FileListEntry` instead of a `FileStatus`.; 4. `listfiles` vs `ls`. `hailtop.fs.router_fs.RouterFS` is a sync shim between these APIs. So there's basically sync-vs-async and Python-vs-Hail FS APIs. We have:; 1. sync, Python: `hailtop.fs.FS`.; 2. async, Python: does not exist.; 3. async, Hail: `hailtop.aiotools.fs.FS`.; 4. sync, Hail: `hailtop.fs.router_fs.RouterFS`. If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in `hail.backend.ServiceBackend`). The high-level need is that we gotta be careful about not interleaving async-sync-async. Your PR reveals that we were inadvertently violating that rule. It seems best to follow the rule and only use `nest_asyncio` when we're in a Jupyter Notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933
https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933:13,Testability,test,test,13,"It seems the test failures are due to:; 1. TemporaryDirectory (and TemporaryFilename); 2. `hailtop.batch.backend.ServiceBackend` absolutely should not use sync `BatchClient`, the async one is right there!; 3. `hailctl batch submit` is broken because of (2); 4. `test_callback` should use async `BatchClient` b/c it is async. TemporaryDirectory & TemporaryFilename use `hailtop.fs`, which is sync. This is nearly the async FS API except:; 1. `isfile` vs `is_file`; 2. `isdir` vs `is_dir`; 3. `stat` returns a `FileListEntry` instead of a `FileStatus`.; 4. `listfiles` vs `ls`. `hailtop.fs.router_fs.RouterFS` is a sync shim between these APIs. So there's basically sync-vs-async and Python-vs-Hail FS APIs. We have:; 1. sync, Python: `hailtop.fs.FS`.; 2. async, Python: does not exist.; 3. async, Hail: `hailtop.aiotools.fs.FS`.; 4. sync, Hail: `hailtop.fs.router_fs.RouterFS`. If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in `hail.backend.ServiceBackend`). The high-level need is that we gotta be careful about not interleaving async-sync-async. Your PR reveals that we were inadvertently violating that rule. It seems best to follow the rule and only use `nest_asyncio` when we're in a Jupyter Notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933
https://github.com/hail-is/hail/pull/13677#issuecomment-1743370832:459,Integrability,Rout,RouterFS,459,"@danking I agree we shouldn't do this whole interleaving. > If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in hail.backend.ServiceBackend). Do you mean that `FS` should have async variants for its methods? I could write `__aenter__` and `__aexit__` methods for `TemporaryDirectory` or `TemporaryFilename`. I think that would require restricting their `FS` field to a `RouterFS` and using that to grab the `RouterAsyncFS` to get at async implementations for the methods. Kinda gross.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743370832
https://github.com/hail-is/hail/pull/13677#issuecomment-1743370832:497,Integrability,Rout,RouterAsyncFS,497,"@danking I agree we shouldn't do this whole interleaving. > If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in hail.backend.ServiceBackend). Do you mean that `FS` should have async variants for its methods? I could write `__aenter__` and `__aexit__` methods for `TemporaryDirectory` or `TemporaryFilename`. I think that would require restricting their `FS` field to a `RouterFS` and using that to grab the `RouterAsyncFS` to get at async implementations for the methods. Kinda gross.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743370832
https://github.com/hail-is/hail/pull/13677#issuecomment-1747702915:71,Integrability,Rout,RouterFS,71,"Yeah, adding an `async` copy of each method of `FS` seems right to me. RouterFS is pretty close to having that anyway. `HadoopFS` can just delegate to its sync methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1747702915
https://github.com/hail-is/hail/pull/13677#issuecomment-1769152362:82,Usability,guid,guiding,82,"@daniel-goldstein I think these changes resolve the problems in hailtop.batch. My guiding philosophy there was sync methods are always shims around async methods. https://github.com/daniel-goldstein/hail/compare/fix-nest-asyncio-apply...danking:hail:fix-nest-asyncio-apply. The issue in Query is deeper. We lazily compute the type of IRs, but to know the type of reading a Table, MatrixTable, or BlockMatrix, we must make a network request to read the metadata from that object. I'm not exactly sure what to do here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1769152362
https://github.com/hail-is/hail/pull/13677#issuecomment-1779897341:146,Deployability,release,release,146,I think this PR still has good changes. We should avoid nesting when possible; I fear it leads to confusing situations. I'm gonna take it off the release 0.2.125 checklist though,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1779897341
https://github.com/hail-is/hail/pull/13677#issuecomment-1779897341:50,Safety,avoid,avoid,50,I think this PR still has good changes. We should avoid nesting when possible; I fear it leads to confusing situations. I'm gonna take it off the release 0.2.125 checklist though,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1779897341
https://github.com/hail-is/hail/pull/13677#issuecomment-1794917590:62,Safety,avoid,avoids,62,@danking This is passing now. This is now primarily a PR that avoids async / sync / async.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1794917590
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:1495,Availability,error,error,1495,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:25,Deployability,patch,patch,25,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:53,Deployability,a/b,a/batch,53,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:157,Deployability,a/b,a/batch,157,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:274,Modifiability,config,config,274,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:468,Modifiability,Config,Config,468,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448:404,Testability,assert,assert,404,"When I try applying this patch:. ```diff; diff --git a/batch/batch/worker/worker.py b/batch/batch/worker/worker.py; index 9d3d89498b..a9106b7a60 100644; --- a/batch/batch/worker/worker.py; +++ b/batch/batch/worker/worker.py; @@ -1228,22 +1228,28 @@ class Container:; return config; ; async def _get_in_container_user(self) -> Tuple[int, int]:; + # https://docs.docker.com/engine/reference/builder/#user; assert self.image.image_config; user = self.image.image_config['Config']['User']; if not user:; return 0, 0; if "":"" in user:; - uid, gid = user.split("":""); - else:; - uid, gid = await self._read_user_from_rootfs(user); - return int(uid), int(gid); + user, group = user.split("":""); + try:; + return int(user), int(group); + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); + try:; + return int(user), 0; + except ValueError:; + return await self._read_uid_gid_from_rootfs(user); ; - async def _read_user_from_rootfs(self, user) -> Tuple[str, str]:; + async def _read_uid_gid_from_rootfs(self, user: str) -> Tuple[int, int]:; with open(f'{self.image.rootfs_path}/etc/passwd', 'r', encoding='utf-8') as passwd:; for record in passwd:; if record.startswith(user):; _, _, uid, gid, _, _, _ = record.split("":""); - return uid, gid; + return int(uid), int(gid); raise ValueError(""Container user not found in image's /etc/passwd""); ; def _mounts(self, uid: int, gid: int) -> List[MountSpecification]:; ```. I can run the container successfully but it fails with the following error:. ```; mkdir: cannot create directory '/io/batch': Permission denied; ```. Which is caused by the following line inserted by the `hailtop.batch` client library:. ```; mkdir -p /io/batch/4c8107/NjztN; ```. so images with non-existent users would fail to run on batch regardless of whether we were using crun / docker / podman, because Batch assumes that the user in the container will have permission to write to `/io`, regardless of whether the job requires input/output files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13679#issuecomment-1728424448
https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749:35,Usability,progress bar,progress bar,35,"The change regarding the copy tool progress bar is because on non-verbose mode (like in the local backend) it was generating some weird whitespace by just creating the progress bar not disabled even though none of the tasks were visible. In jupyter notebooks, whitespace rendered as `5l` in the jupyter output.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749
https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749:168,Usability,progress bar,progress bar,168,"The change regarding the copy tool progress bar is because on non-verbose mode (like in the local backend) it was generating some weird whitespace by just creating the progress bar not disabled even though none of the tasks were visible. In jupyter notebooks, whitespace rendered as `5l` in the jupyter output.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13681#issuecomment-1729901749
https://github.com/hail-is/hail/issues/13688#issuecomment-1734193173:17,Availability,error,error,17,Lindo reports an error with a side-length of 177860. Cal reports a side length of 544768. The square of both is larger than 2^32.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734193173
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3658,Availability,checkpoint,checkpoint,3658,"computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3802,Availability,checkpoint,checkpoint,3802,"on3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-package",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4350,Availability,checkpoint,checkpoint,4350,"b/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:11591,Availability,Error,Error,11591,a.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:350); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:495); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:494); 	at jdk.internal.reflect.GeneratedMethodAccessor109.invoke(Unknown Source); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182); 	at py4j.ClientServerConnection.run(ClientServerConnection.java:106); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.122-be9d88a80695; Error summary: ArrayIndexOutOfBoundsException: Index 177860 out of bounds for length 177860; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:9486,Energy Efficiency,adapt,adapted,9486,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:677,Integrability,wrap,wrapper,677,"```; FatalError Traceback (most recent call last); /tmp/ipykernel_10092/1120523425.py in <cell line: 8>(); 6 # Connection refused: qc-sw-nvpv.c.covid-19-wgs-analysis.internal/10.128.0.182:7337; 7 # https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/pc_related.2E.20how.20slow.3F; ----> 8 relatedness_ht = hl.pc_relate(hq_mt_subset.GT, 0.01, k=10, statistics='kin',; 9 include_self_kinship=include_kinself, block_size=2048); 10 . <decorator-gen-1794> in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, include_self_kinship). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_exp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:728,Integrability,wrap,wrapper,728,"```; FatalError Traceback (most recent call last); /tmp/ipykernel_10092/1120523425.py in <cell line: 8>(); 6 # Connection refused: qc-sw-nvpv.c.covid-19-wgs-analysis.internal/10.128.0.182:7337; 7 # https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/pc_related.2E.20how.20slow.3F; ----> 8 relatedness_ht = hl.pc_relate(hq_mt_subset.GT, 0.01, k=10, statistics='kin',; 9 include_self_kinship=include_kinself, block_size=2048); 10 . <decorator-gen-1794> in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, include_self_kinship). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_exp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:957,Integrability,wrap,wrapper,957,"```; FatalError Traceback (most recent call last); /tmp/ipykernel_10092/1120523425.py in <cell line: 8>(); 6 # Connection refused: qc-sw-nvpv.c.covid-19-wgs-analysis.internal/10.128.0.182:7337; 7 # https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/pc_related.2E.20how.20slow.3F; ----> 8 relatedness_ht = hl.pc_relate(hq_mt_subset.GT, 0.01, k=10, statistics='kin',; 9 include_self_kinship=include_kinself, block_size=2048); 10 . <decorator-gen-1794> in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, include_self_kinship). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_exp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:1543,Integrability,wrap,wrapper,1543,"_self_kinship). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-pac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:1594,Integrability,wrap,wrapper,1594,"_self_kinship). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-pac",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:1823,Integrability,wrap,wrapper,1823,"pper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/relatedness/pc_relate.py in pc_relate(call_expr, min_individual_maf, k, scores_expr, min_kinship, statistics, block_size, ; include_self_kinship); 314 ; 315 if k and scores_expr is None:; --> 316 _, scores, _ = hwe_normalized_pca(call_expr, k, compute_loadings=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:2249,Integrability,wrap,wrapper,2249,"s=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Pers",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:2300,Integrability,wrap,wrapper,2300,"s=False); 317 scores_expr = scores[mt.col_key].scores; 318 elif not k and scores_expr is not None:. <decorator-gen-1778> in hwe_normalized_pca(call_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Pers",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:2529,Integrability,wrap,wrapper,2529,"expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in hwe_normalized_pca(call_expr, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:2893,Integrability,wrap,wrapper,2893,"r, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/minicon",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:2944,Integrability,wrap,wrapper,2944,"r, k, compute_loadings); 99 return _hwe_normalized_blanczos(call_expr, k, compute_loadings); 100 ; --> 101 return pca(hwe_normalize(call_expr),; 102 k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/minicon",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3173,Integrability,wrap,wrapper,3173," k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3993,Integrability,wrap,wrapper,3993,"heck_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__origina",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4044,Integrability,wrap,wrapper,4044,"heck_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__origina",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4273,Integrability,wrap,wrapper,4273," /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/minico",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4875,Integrability,wrap,wrapper,4875,"/opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); 1378 ; 1379 @typecheck_method(output=str,. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 80 return (value, timings) if timed else value; 81 except FatalError as e:; ---> 82 raise e.maybe_user_error(ir) from None; 83 ; 84 async def _async_execute(self, ir, timed=False):. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4926,Integrability,wrap,wrapper,4926,"/opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); 1378 ; 1379 @typecheck_method(output=str,. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 80 return (value, timings) if timed else value; 81 except FatalError as e:; ---> 82 raise e.maybe_user_error(ir) from None; 83 ; 84 async def _async_execute(self, ir, timed=False):. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:5155,Integrability,wrap,wrapper,5155,"func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); 1378 ; 1379 @typecheck_method(output=str,. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 80 return (value, timings) if timed else value; 81 except FatalError as e:; ---> 82 raise e.maybe_user_error(ir) from None; 83 ; 84 async def _async_execute(self, ir, timed=False):. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 74 # print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 75 try:; ---> 76 result_tuple = self._jbackend.executeEncode(jir, strea",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:8074,Integrability,Wrap,WrappedMatrixToTableFunction,8074,opy.dcopy(blas.f); 	at org.netlib.arpack.Dsaitr.dsaitr(arpack.f); 	at org.netlib.arpack.Dsaup2.dsaup2(arpack.f); 	at org.netlib.arpack.Dsaupd.dsaupd(arpack.f); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupdK(F2jARPACK.java:189); 	at dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd(AbstractARPACK.java:560); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupd(F2jARPACK.java:30); 	at dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd(AbstractARPACK.java:536); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupd(F2jARPACK.java:30); 	at org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106); 	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeSVD(RowMatrix.scala:385); 	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeSVD(RowMatrix.scala:311); 	at org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.computeSVD(IndexedRowMatrix.scala:231); 	at is.hail.methods.PCA.execute(PCA.scala:41); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:52); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:3379); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:61); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:865); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:8,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:8552,Modifiability,rewrite,rewrite,8552,jARPACK.dsaupd(F2jARPACK.java:30); 	at org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106); 	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeSVD(RowMatrix.scala:385); 	at org.apache.spark.mllib.linalg.distributed.RowMatrix.computeSVD(RowMatrix.scala:311); 	at org.apache.spark.mllib.linalg.distributed.IndexedRowMatrix.computeSVD(IndexedRowMatrix.scala:231); 	at is.hail.methods.PCA.execute(PCA.scala:41); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:52); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:3379); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:61); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:865); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreac,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:9486,Modifiability,adapt,adapted,9486,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:95,Availability,failure,failure,95,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:255,Availability,error,error,255,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:407,Availability,error,error,407,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:3960,Security,access,access,3960,"nNull(v);; requireNonNull(iparam);; requireNonNull(ipntr);; requireNonNull(workd);; requireNonNull(info);; checkIndex(offsetresid + n - 1, resid.length);; checkIndex(offsetv + n * ncv - 1, v.length); // HERE; checkIndex(offsetiparam + 11 - 1, iparam.length);; checkIndex(offsetipntr + 11 - 1, ipntr.length);; checkIndex(offsetworkd + 3 * n - 1, workd.length);; checkIndex(offsetworkl + lworkl - 1, workl.length);; dsaupdK(ido, bmat, n, which, nev, tol, resid, offsetresid, ncv, v, offsetv, ldv, iparam, offsetiparam, ipntr, offsetipntr, workd, offsetworkd, workl, offsetworkl, lworkl, info);; }; ```; where `v.length = 177860`, `n = 8893`, and `ncv = 20`. `checkIndex` is; ```; private void checkIndex(int index, int length) {; if (index < 0 || index >= length) {; throw new IndexOutOfBoundsException(String.format(""Index %s out of bounds for length %s"", index, length));; }; }; ```; which a) shouldn't throw in this case, b) throws an `IndexOutOfBoundsException`, not an `ArrayIndexOutOfBoundsException`, and c) isn't the root of the stacktrace; ```; 	at org.netlib.blas.Dcopy.dcopy(blas.f); 	at org.netlib.arpack.Dsaitr.dsaitr(arpack.f); 	at org.netlib.arpack.Dsaup2.dsaup2(arpack.f); 	at org.netlib.arpack.Dsaupd.dsaupd(arpack.f); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupdK(F2jARPACK.java:189); 	at dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd(AbstractARPACK.java:560); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupd(F2jARPACK.java:30); 	at dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd(AbstractARPACK.java:536); 	at dev.ludovic.netlib.arpack.F2jARPACK.dsaupd(F2jARPACK.java:30); 	at org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106); ```; So it looks like somehow bad indices are making it through all these checks and a bad array access is hapenning deep in blas?. So I'm at a complete loss. If anybody else could take a stab at it with a fresh perspective, I'd be happy to discuss, but I'm low on bandwidth to keep digging myself.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:696,Testability,test,test,696,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:1025,Testability,assert,assertEvalsTo,1025,"s would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < nev && nev < n);; checkArgum",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313:689,Usability,simpl,simple,689,"Another set of eyes on this would be great. My current thoughts on this:. I only looked at the failure in PCA. I was never able to reproduce. My next step to try to reproduce was to run PCA on Lindo's full dataset on dataproc (can't use batch because the error is in spark PCA). I did look carefully through the stack trace, trying to understand what could possibly be happening. The number 177860 from the error isn't either matrix dimension, which is 210234 by 8893. Everything in `org.apache.spark.mllib.linalg.EigenValueDecomposition$.symmetricEigs(EigenValueDecomposition.scala:106)` is independent of the number of rows, so only the number 8893 of cols should be relevent. I wrote a simple test to execute spark PCA with 8893 rows in scala, so I could step through with a debugger:; ```scala; var mt = rangeMatrix(10000, 8893); mt = MatrixMapEntries(mt, InsertFields(Ref(""g"", mt.typ.entryType), Seq(""a"" -> F64(1)))); val t = MatrixToTableApply(mt, PCA(""a"", 10, false)); val n = TableToValueApply(t, ForceCountTable()); assertEvalsTo(n, 8893L); ```; The array `v` in `symmetricEigs` has length 177860 = 8893*20, and I didn't find anything else with that size. The only line I could find that could generate an exception that looks like this is line 555 of `dev.ludovic.netlib.arpack.AbstractARPACK.dsaupd`; ```scala; public void dsaupd(org.netlib.util.intW ido, String bmat, int n, String which, int nev, org.netlib.util.doubleW tol, double[] resid, int offsetresid, int ncv, double[] v, int offsetv, int ldv, int[] iparam, int offsetiparam, int[] ipntr, int offsetipntr, double[] workd, int offsetworkd, double[] workl, int offsetworkl, int lworkl, org.netlib.util.intW info) {; if (debug) System.err.println(""dsaupd"");; checkArgument(""DSAUPD"", 2, lsame(""I"", bmat) || lsame(""G"", bmat));; checkArgument(""DSAUPD"", 3, n >= 0);; checkArgument(""DSAUPD"", 4, lsame(""LA"", which) || lsame(""SA"", which) || lsame(""LM"", which) || lsame(""SM"", which) || lsame(""BE"", which));; checkArgument(""DSAUPD"", 5, 0 < ne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1760360313
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:762,Availability,error,error,762,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1415,Availability,error,error,1415,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1659,Availability,reliab,reliable,1659,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:335,Deployability,pipeline,pipeline,335,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1204,Deployability,upgrade,upgraded,1204,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1478,Deployability,pipeline,pipelines,1478,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1508,Deployability,release,release,1508,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1587,Deployability,release,releases,1587,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:934,Security,integrity,integrity,934,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1572,Testability,test,testing,1572,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114
https://github.com/hail-is/hail/issues/13689#issuecomment-1759998425:121,Availability,down,down,121,"Still don't know what's happening with this. I met with Zan a couple weeks ago and gave them some ideas to try to narrow down to a smaller example that reproduces the issue, but I haven't heard from them since.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13689#issuecomment-1759998425
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:738,Availability,avail,available,738,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:270,Performance,load,loaded,270,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:116,Testability,test,test,116,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:341,Testability,log,log,341,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:373,Testability,log,logging,373,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:919,Testability,LOG,LOGGING,919,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216:990,Testability,log,log,990,"local notebook works fine for me as well, looks to be just dataproc that's not working as expected. submitting that test command as a script finished in 36.2s. notebook is currently still hanging with this output (it's been 11 minutes):; ```; BokehJS 3.2.2 successfully loaded.; Initializing Hail with default parameters...; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; SPARKMONITOR_LISTENER: Started SparkListener for Jupyter Notebook; SPARKMONITOR_LISTENER: Port obtained from environment: 55989; SPARKMONITOR_LISTENER: Application Started: application_1695402030462_0001 ...Start Time: 1695402594764; Running on Apache Spark version 3.3.0; SparkUI available at http://notebook-slowdown-repro-m.c.broad-ctsa.internal:43055/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-ee7fef6fc40d; LOGGING: writing to /home/hail/hail-20230922-1709-0.2.124-ee7fef6fc40d.log; [Stage 0:> (0 + 2) / 2]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731791216
https://github.com/hail-is/hail/issues/13690#issuecomment-1731820793:31,Testability,log,log,31,@iris-garden can you grab that log file and upload here? it should live on the `CLUSTER_NAME-m` machine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731820793
https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811:129,Deployability,pipeline,pipeline,129,Nothing suspicious there. Something is going wrong in the executors. I think the only way we're gonna solve this is by running a pipeline and looking at the executor logs. I'm at a complete loss for how Jupyter could affect what happens on the executors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811
https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811:166,Testability,log,logs,166,Nothing suspicious there. Something is going wrong in the executors. I think the only way we're gonna solve this is by running a pipeline and looking at the executor logs. I'm at a complete loss for how Jupyter could affect what happens on the executors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811
https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187:487,Availability,down,downgrading,487,"okay, so this makes no sense to me, and i don't understand gradle at all really, but i tried reproducing the issue with each recent release until i found the one where it started presenting (0.2.123), then tried it on every commit in between the previous release and that one, and found that the issue started presenting after https://github.com/hail-is/hail/pull/13551 merged. i tried reverting that commit on the current `main` and confirmed the issue stopped showing up. i also tried downgrading just the `google-cloud-storage` version back to 2.17.1, since that was bumped in that commit, but the issue still presented.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187
https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187:132,Deployability,release,release,132,"okay, so this makes no sense to me, and i don't understand gradle at all really, but i tried reproducing the issue with each recent release until i found the one where it started presenting (0.2.123), then tried it on every commit in between the previous release and that one, and found that the issue started presenting after https://github.com/hail-is/hail/pull/13551 merged. i tried reverting that commit on the current `main` and confirmed the issue stopped showing up. i also tried downgrading just the `google-cloud-storage` version back to 2.17.1, since that was bumped in that commit, but the issue still presented.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187
https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187:255,Deployability,release,release,255,"okay, so this makes no sense to me, and i don't understand gradle at all really, but i tried reproducing the issue with each recent release until i found the one where it started presenting (0.2.123), then tried it on every commit in between the previous release and that one, and found that the issue started presenting after https://github.com/hail-is/hail/pull/13551 merged. i tried reverting that commit on the current `main` and confirmed the issue stopped showing up. i also tried downgrading just the `google-cloud-storage` version back to 2.17.1, since that was bumped in that commit, but the issue still presented.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1737808187
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:560,Availability,avail,available,560,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:452,Deployability,release,released,452,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:517,Deployability,release,release-notes,517,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:676,Deployability,release,release-,676,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:836,Deployability,release,releases,836,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:1094,Deployability,upgrade,upgrade,1094,"kes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one and see if that fixes things. If that works, let's just merge and forget this happene",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:1459,Deployability,release,release-,1459,"2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one and see if that fixes things. If that works, let's just merge and forget this happened. If that *doesn't* work, we gotta wade into the Lovecraftian horror of JARs. Most likely we're not fully relocating the dependencies pulled in by the Google Cloud Storage client libraries and they conflict with what Dataproc produces.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:1632,Deployability,release,releases,1632,"2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one and see if that fixes things. If that works, let's just merge and forget this happened. If that *doesn't* work, we gotta wade into the Lovecraftian horror of JARs. Most likely we're not fully relocating the dependencies pulled in by the Google Cloud Storage client libraries and they conflict with what Dataproc produces.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:714,Integrability,depend,depends,714,"Wow, talk about a *tour de force* of debugging, well done!!. ---. OK, so this kinda makes sense. We are importing our own copies of the GCS libraries and renaming them all to `is.hail.relocated....`. We do this so that we're not stuck with whatever version Dataproc is including. We pin our dataproc image version to `2.1.2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645:2208,Integrability,depend,dependencies,2208,"2-debian11` (see [here](https://github.com/hail-is/hail/blob/main/hail/python/hailtop/hailctl/dataproc/start.py#L147)) which [was released in January 2023](https://cloud.google.com/dataproc/docs/release-notes#January_23_2023). The latest available version of [Dataproc's Debian images](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) is 2.1.25-debian11 which depends on GoogleCloudDataproc hadoop connector version [2.2.15](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/2.2.15) which relies on Google Cloud Storage client library version [2.22.3](https://github.com/GoogleCloudDataproc/hadoop-connectors/commit/8b79f025ef5e8231de827f4c620cd23e230c3489). I have [a PR](https://github.com/hail-is/hail/pull/13732) to upgrade us to 2.27.1 because the library broke retries in versions [2.25.0, 2.27.0). AFAICT, Google's image version page only shows the most recent five. There's no way to go back further in time. Luckily, the way back machine has [a March 2023 capture](https://web.archive.org/web/20230307225815/https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.1) which includes our version. 2.1.2-debian11 used Google Cloud Dataproc hadoop connector version [2.2.9](https://github.com/GoogleCloudDataproc/hadoop-connectors/releases/tag/v2.2.9) This version of the hadoop connector was [using some alpha version of a gRPC version of the cloud storage library](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/18f6e9f1c745e1854d76bea9362e2332898d8895/pom.xml#L96C1-L97C1). I'm not sure what's up with that. OK, here's my proposal: let's change that IMAGE_VERSION to the latest one and see if that fixes things. If that works, let's just merge and forget this happened. If that *doesn't* work, we gotta wade into the Lovecraftian horror of JARs. Most likely we're not fully relocating the dependencies pulled in by the Google Cloud Storage client libraries and they conflict with what Dataproc produces.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1738196645
https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203:61,Availability,reliab,reliable,61,We fixed all the known issues and install-editable now seems reliable and fast.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203
https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203:34,Deployability,install,install-editable,34,We fixed all the known issues and install-editable now seems reliable and fast.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13691#issuecomment-1758609203
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5,Availability,Error,Error,5,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4453,Availability,ERROR,ERROR,4453,tive_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4138,Energy Efficiency,adapt,adapted,4138,6_290(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region4_318(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region2_501(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4138,Modifiability,adapt,adapted,4138,6_290(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region4_318(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region2_501(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:310,Performance,concurren,concurrent,310,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:428,Performance,concurren,concurrent,428,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:493,Performance,concurren,concurrent,493,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:870,Performance,concurren,concurrent,870,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:947,Performance,concurren,concurrent,947,"```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.Goo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:1009,Performance,concurren,concurrent,1009,"aceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.GoogleStorageFS$$",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:1086,Performance,concurren,concurrent,1086,"s/batch/worker/worker.py"", line 2272, in run; await self.jvm.execute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.retryingRead(GoogleStorageFS.scala:220); 	at is.hail.io.fs.GoogleStora",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:1148,Performance,concurren,concurrent,1148,"xecute(; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 2872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.retryingRead(GoogleStorageFS.scala:220); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.readHandlingRequesterPays(GoogleStorageFS.scala:2",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:1233,Performance,concurren,concurrent,1233,"872, in execute; raise JVMUserError(exception); JVMUserError: java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at is.hail.JVMEntryway.retrieveException(JVMEntryway.java:253); 	at is.hail.JVMEntryway.finishFutures(JVMEntryway.java:215); 	at is.hail.JVMEntryway.main(JVMEntryway.java:185); Caused by: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:122); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: java.lang.IllegalArgumentException: bound must be positive; 	at java.util.Random.nextInt(Random.java:388); 	at scala.util.Random.nextInt(Random.scala:70); 	at is.hail.services.package$.delayMsForTry(package.scala:47); 	at is.hail.services.package$.retryTransientErrors(package.scala:186); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.retryingRead(GoogleStorageFS.scala:220); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.readHandlingRequesterPays(GoogleStorageFS.scala:226); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.fill(GoogleStorageFS.scala:257); 	at i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4926,Performance,concurren,concurrent,4926,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5018,Performance,concurren,concurrent,5018,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5095,Performance,concurren,concurrent,5095,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5187,Performance,concurren,concurrent,5187,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5264,Performance,concurren,concurrent,5264,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:5364,Performance,concurren,concurrent,5364,hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4398,Testability,Log,Logs,4398,ource); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolEx,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888:4410,Testability,Log,Log,4410,ource); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. Logs; Main; Log ; 2023-09-24 17:23:30.055 JVMEntryway: ERROR: Exception encountered in QoB cancel thread.; org.newsclub.net.unix.SocketClosedException: Not open; 	at org.newsclub.net.unix.AFCore.validFdOrException(AFCore.java:90) ~[jvm-entryway.jar:?]; 	at org.newsclub.net.unix.AFSocketImpl$AFInputStreamImpl.read(AFSocketImpl.java:510) ~[jvm-entryway.jar:?]; 	at java.io.DataInputStream.readInt(DataInputStream.java:388) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$2.run(JVMEntryway.java:136) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolEx,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13704#issuecomment-1734170888
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:303,Deployability,configurat,configuration,303,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:573,Deployability,configurat,configuration,573,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:749,Deployability,configurat,configuration,749,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:827,Deployability,configurat,configuration,827,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:231,Integrability,depend,dependency,231,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:845,Integrability,depend,dependencies,845,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1025,Integrability,depend,dependencies,1025,"](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1359,Integrability,depend,dependencies,1359,"d another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; im",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1417,Integrability,depend,dependencies,1417,"rn gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linal",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1766,Integrability,depend,dependencies,1766,"pile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.readers.{TabixReader => HtsjdkTabixReader}; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWri",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:3998,Integrability,depend,depend,3998,"n, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.json4s.JValue; import org.json4s.JsonAST._; import org.json4s._; import org.json4s.jackson.JsonMethods; import org.json4s.jackson.JsonMethods._; import org.json4s.jackson.Serialization; import org.json4s.jackson.{JsonMethods, Serialization}; import org.json4s.{DefaultFormats, Formats}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. We explicitly depend on; - `htsjdk`; - `breeze`; - `json4s`. That leaves:. ```; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import org.apache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:303,Modifiability,config,configuration,303,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:573,Modifiability,config,configuration,573,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:749,Modifiability,config,configuration,749,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:786,Modifiability,Plugin,Plugin,786,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:827,Modifiability,config,configuration,827,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:3953,Performance,concurren,concurrent,3953,"pache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.json4s.JValue; import org.json4s.JsonAST._; import org.json4s._; import org.json4s.jackson.JsonMethods; import org.json4s.jackson.JsonMethods._; import org.json4s.jackson.Serialization; import org.json4s.jackson.{JsonMethods, Serialization}; import org.json4s.{DefaultFormats, Formats}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. We explicitly depend on; - `htsjdk`; - `breeze`; - `json4s`. That leaves:. ```; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import org.apache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:5052,Performance,concurren,concurrent,5052,"apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.json4s.JValue; import org.json4s.JsonAST._; import org.json4s._; import org.json4s.jackson.JsonMethods; import org.json4s.jackson.JsonMethods._; import org.json4s.jackson.Serialization; import org.json4s.jackson.{JsonMethods, Serialization}; import org.json4s.{DefaultFormats, Formats}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. We explicitly depend on; - `htsjdk`; - `breeze`; - `json4s`. That leaves:. ```; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import org.apache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. I could try to carefully figure out which one of `shadow` are needed for tests and which are not, but that seems annoying. Fix [here](https://github.com/hail-is/hail/pull/13740).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:358,Testability,test,testCompile,358,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1539,Testability,test,testRuntimeClasspath,1539,"te about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import ht",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1601,Testability,test,testCompileClasspath,1601,"serguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.read",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1727,Testability,test,testCompileOnly,1727,"pile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.readers.{TabixReader => HtsjdkTabixReader}; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWri",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1916,Testability,test,testImplementation,1916," will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.readers.{TabixReader => HtsjdkTabixReader}; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import or",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1959,Testability,test,test,1959," will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.readers.{TabixReader => HtsjdkTabixReader}; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import or",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:2000,Testability,test,test,2000,"encies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, DenseVector => BDV}; import breeze.linalg.{DenseMatrix => BDM, _}; import breeze.linalg.{DenseMatrix => BDM}; import breeze.linalg.{DenseMatrix, DenseVector, eigSym, svd}; import breeze.linalg.{DenseMatrix, DenseVector}; import breeze.linalg.{DenseMatrix, Matrix, Vector}; import breeze.linalg.{Vector => BVector}; import htsjdk.samtools.reference.ReferenceSequenceFileFactory; import htsjdk.samtools.util.BlockCompressedFilePointerUtil; import htsjdk.tribble.readers.{TabixReader => HtsjdkTabixReader}; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import org.apache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistributi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:5156,Testability,test,tests,5156,"apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.json4s.JValue; import org.json4s.JsonAST._; import org.json4s._; import org.json4s.jackson.JsonMethods; import org.json4s.jackson.JsonMethods._; import org.json4s.jackson.Serialization; import org.json4s.jackson.{JsonMethods, Serialization}; import org.json4s.{DefaultFormats, Formats}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. We explicitly depend on; - `htsjdk`; - `breeze`; - `json4s`. That leaves:. ```; import org.apache.avro.SchemaBuilder; import org.apache.avro.file.DataFileWriter; import org.apache.avro.generic.{GenericDatumWriter, GenericRecord, GenericRecordBuilder}; import org.apache.commons.io.IOUtils; import org.apache.commons.math3.distribution.ChiSquaredDistribution; import org.apache.commons.math3.distribution.{ChiSquaredDistribution, NormalDistribution}; import org.apache.commons.math3.random.JDKRandomGenerator; import org.apache.commons.math3.util.CombinatoricsUtils.factorialLog; import org.apache.hadoop; import org.apache.log4j.{ConsoleAppender, PatternLayout}; import org.apache.spark.SparkContext; import org.apache.spark.SparkException; import org.apache.spark.mllib.linalg.Vectors; import org.apache.spark.mllib.linalg.distributed.{DistributedMatrix, IndexedRow, IndexedRowMatrix}; import org.apache.spark.rdd.RDD; import org.apache.spark.sql.Row; import org.apache.spark.storage.StorageLevel; import org.apache.{hadoop => hd}; import org.sparkproject.guava.util.concurrent.MoreExecutors; ```. I could try to carefully figure out which one of `shadow` are needed for tests and which are not, but that seems annoying. Fix [here](https://github.com/hail-is/hail/pull/13740).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:117,Usability,clear,clearly,117,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:261,Usability,simpl,simplification,261,"The [TextInputFormat](https://hadoop.apache.org/docs/stable/api/org/apache/hadoop/mapred/TextInputFormat.html) class clearly comes from hadoop. It's no longer in the location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741:1121,Usability,learn,learn,1121,"he location from which we import it. We must get it from some other dependency. OK. So, before my simplification of build.gradle, we used a configuration called `compile` and another one called `testCompile`. [Neither of those exist in modern gradle, apparently](https://docs.gradle.org/current/userguide/java_library_plugin.html#sec:java_library_configurations_graph). I found a side-note about the `compile` configuration [here](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:java_dependency_management_overview) (search for ""compile""):. > **Why no compile configuration?**; > The Java Library Plugin has historically used the compile configuration for dependencies that are required to both compile and run a project’s production code. It is now deprecated, and will issue warnings when used, because it doesn’t distinguish between dependencies that impact the public API of a Java library project and those that don’t. You can learn more about the importance of this distinction in [Building Java libraries](https://docs.gradle.org/current/userguide/building_java_projects.html#sec:building_java_libraries). OK, so, we used to just dump everything into our runtime dependencies. I changed it so that we have three kinds of dependencies:; 1. `shadow`: these are provided by Dataproc/QoB at run-time. They are not in any JAR. They are not on the `testRuntimeClasspath` or `runtimeClasspath`. They are on the `testCompileClasspath` because I [explicitly requested](https://github.com/hail-is/hail/blob/main/hail/build.gradle#L98) that `testCompileOnly` bring in our `shadow` dependencies.; 2. `implementation`: these are included in all class paths and in shadow JARs (but not ""thin"" jars generated by `./gradlew jar`).; 3. `testImplementation`: these are included in test class paths and in shadow JARs. Our test code references these third-party classes:; ```; import breeze.linalg.DenseMatrix; import breeze.linalg._; import breeze.linalg.{*, diag, DenseMatrix => BDM, D",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13706#issuecomment-1738232741
https://github.com/hail-is/hail/issues/13712#issuecomment-1743500460:102,Deployability,deploy,deploying,102,"The root cause of large memory usage is https://github.com/hail-is/hail/issues/13748 but we should be deploying Hail in a manner that has enough RAM (in this case, 4GiB is plenty). I'm following up with GVS to determine whether the JVM indeed has enough RAM.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13712#issuecomment-1743500460
https://github.com/hail-is/hail/issues/13712#issuecomment-1757862008:384,Security,hash,hash,384,Dataproc submission bash script: https://gist.github.com/mcovarr/06eaecad849e979d608adf43e2118f5a; Python script: https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/filter_VDS_and_shard_by_contig.py. A few things 0.2.123 introduced:; - new gradle (which has caused other dataproc issues); - SemanticHash. My guess is the combination of semantic hash and large JSON literals is pushing us past the 50GiB limit.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13712#issuecomment-1757862008
https://github.com/hail-is/hail/issues/13712#issuecomment-1785301300:12,Deployability,release,released,12,"0.2.125 was released with a fix, but it also contained a critical correctness bug. We will try again with 0.2.126.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13712#issuecomment-1785301300
https://github.com/hail-is/hail/pull/13719#issuecomment-1737802239:59,Availability,error,error,59,Hmmm... we do give these labels to disks. Maybe that's the error when no orphaned disks are found with any labels,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13719#issuecomment-1737802239
https://github.com/hail-is/hail/pull/13719#issuecomment-1737810077:19,Availability,error,error,19,> Maybe that's the error when no orphaned disks are found with any labels. Ya I interpret this as the query just returned no results.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13719#issuecomment-1737810077
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:78,Availability,error,error,78,"I observed this in my namespace while testing fixes for a different transient error.; https://internal.hail.is/dking/batch/batches/5/jobs/7034 (this URL will obviously not last long). The worker actually successfully wrote the correct output to GCS, but it received this error anyway which caused the job to fail. Since QoB checks for the results files first, it didn't even notice that the worker job had failed. That seems not great. We should probably fail if an worker job fails, even if we find output because that output could be corrupt. ```; (base) dking@wm28c-761 hail % hexdump -C foo ; 00000000 01 82 00 00 00 7e 00 00 00 67 73 3a 2f 2f 31 2d |.....~...gs://1-|; 00000010 64 61 79 2f 74 6d 70 2f 68 61 69 6c 2f 54 53 4f |day/tmp/hail/TSO|; 00000020 66 4f 72 67 5a 55 6d 62 56 69 78 6e 52 69 4b 57 |fOrgZUmbVixnRiKW|; 00000030 51 46 42 2f 61 67 67 72 65 67 61 74 65 5f 69 6e |QFB/aggregate_in|; 00000040 74 65 72 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:271,Availability,error,error,271,"I observed this in my namespace while testing fixes for a different transient error.; https://internal.hail.is/dking/batch/batches/5/jobs/7034 (this URL will obviously not last long). The worker actually successfully wrote the correct output to GCS, but it received this error anyway which caused the job to fail. Since QoB checks for the results files first, it didn't even notice that the worker job had failed. That seems not great. We should probably fail if an worker job fails, even if we find output because that output could be corrupt. ```; (base) dking@wm28c-761 hail % hexdump -C foo ; 00000000 01 82 00 00 00 7e 00 00 00 67 73 3a 2f 2f 31 2d |.....~...gs://1-|; 00000010 64 61 79 2f 74 6d 70 2f 68 61 69 6c 2f 54 53 4f |day/tmp/hail/TSO|; 00000020 66 4f 72 67 5a 55 6d 62 56 69 78 6e 52 69 4b 57 |fOrgZUmbVixnRiKW|; 00000030 51 46 42 2f 61 67 67 72 65 67 61 74 65 5f 69 6e |QFB/aggregate_in|; 00000040 74 65 72 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:1936,Availability,failure,failure,1936,"2 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 2: /batch/83e7aee9e9244f6884b8a84ea81b4c7a; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 3: /batch/83e7aee9e9244f6884b8a84ea81b4c7a/log; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 4: gs://hail-test-ezlis/dking/jars/ch4g3zvqceyo/09526a168d57dac1a26f8caa4ab49593931ed2ef.jar; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 5: worker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:6333,Availability,ERROR,ERROR,6333,"-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=72126, cache hits=72121; 2023-09-27 16:44:22.622 : INFO: RegionPool: FREE: 59.4M allocated (25.2M blocks / 34.2M chunks), regions.size = 11, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.623 WorkerTimer$: INFO: executeFunction took 71843.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(T",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:3621,Energy Efficiency,allocate,allocated,3621,"ker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-27 16:43:10.393 Worker$: INFO: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/9060 at root gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:3799,Energy Efficiency,allocate,allocated,3799,"FO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-27 16:43:10.393 Worker$: INFO: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/9060 at root gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:3977,Energy Efficiency,allocate,allocated,3977,"O: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/9060 at root gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4155,Energy Efficiency,allocate,allocated,4155,"ithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4334,Energy Efficiency,allocate,allocated,4334,"g google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4514,Energy Efficiency,allocate,allocated,4514,"d for thread 10: pool-2-thread-2; 2023-09-27 16:43:10.787 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (192.0K blocks / 2.0M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4694,Energy Efficiency,allocate,allocated,4694,"ts, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=7212",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4874,Energy Efficiency,allocate,allocated,4874,", thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=72126, cache hits=72121; 2023-09-27 16:44:22.622 : INFO: RegionPool: FREE: 59.4M allocated (25.2M blocks / 34.2M chunks), regions.size = 11, 0 current java objects, thread 10: pool-2-t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:5777,Energy Efficiency,allocate,allocated,5777,"ad 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=72126, cache hits=72121; 2023-09-27 16:44:22.622 : INFO: RegionPool: FREE: 59.4M allocated (25.2M blocks / 34.2M chunks), regions.size = 11, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.623 WorkerTimer$: INFO: executeFunction took 71843.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hai",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14595,Energy Efficiency,adapt,adapted,14595,931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:11914,Integrability,Synchroniz,SynchronizedBufferedWritableByteChannel,11914,ByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2e,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12167,Integrability,wrap,wrapIOException,12167,eChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14210,Integrability,Rout,RouterFS,14210,p.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14229,Integrability,Rout,RouterFS,14229,cala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14595,Modifiability,adapt,adapted,14595,931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:5703,Performance,cache,cache,5703,"76.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=72126, cache hits=72121; 2023-09-27 16:44:22.622 : INFO: RegionPool: FREE: 59.4M allocated (25.2M blocks / 34.2M chunks), regions.size = 11, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.623 WorkerTimer$: INFO: executeFunction took 71843.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:6862,Performance,concurren,concurrent,6862, 10: pool-2-thread-2; 2023-09-27 16:44:22.623 WorkerTimer$: INFO: executeFunction took 71843.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:6954,Performance,concurren,concurrent,6954,.446957 ms.; 2023-09-27 16:44:22.623 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< conte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:7031,Performance,concurren,concurrent,7031,ion: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjT,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:7123,Performance,concurren,concurrent,7123,result.7028; 2023-09-27 16:44:22.668 GoogleStorageFS$: INFO: close: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPq,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:7200,Performance,concurren,concurrent,7200,y/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=/result.7028; 2023-09-27 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessi,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:7300,Performance,concurren,concurrent,7300,7 16:44:33.788 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_382]; 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_382]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:38,Testability,test,testing,38,"I observed this in my namespace while testing fixes for a different transient error.; https://internal.hail.is/dking/batch/batches/5/jobs/7034 (this URL will obviously not last long). The worker actually successfully wrote the correct output to GCS, but it received this error anyway which caused the job to fail. Since QoB checks for the results files first, it didn't even notice that the worker job had failed. That seems not great. We should probably fail if an worker job fails, even if we find output because that output could be corrupt. ```; (base) dking@wm28c-761 hail % hexdump -C foo ; 00000000 01 82 00 00 00 7e 00 00 00 67 73 3a 2f 2f 31 2d |.....~...gs://1-|; 00000010 64 61 79 2f 74 6d 70 2f 68 61 69 6c 2f 54 53 4f |day/tmp/hail/TSO|; 00000020 66 4f 72 67 5a 55 6d 62 56 69 78 6e 52 69 4b 57 |fOrgZUmbVixnRiKW|; 00000030 51 46 42 2f 61 67 67 72 65 67 61 74 65 5f 69 6e |QFB/aggregate_in|; 00000040 74 65 72 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:2102,Testability,test,test-,2102,"|wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 2: /batch/83e7aee9e9244f6884b8a84ea81b4c7a; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 3: /batch/83e7aee9e9244f6884b8a84ea81b4c7a/log; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 4: gs://hail-test-ezlis/dking/jars/ch4g3zvqceyo/09526a168d57dac1a26f8caa4ab49593931ed2ef.jar; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 5: worker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-27 16:43:10.393 Worker$: INFO: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/90",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:2436,Testability,log,log,2436,"'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 2: /batch/83e7aee9e9244f6884b8a84ea81b4c7a; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 3: /batch/83e7aee9e9244f6884b8a84ea81b4c7a/log; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 4: gs://hail-test-ezlis/dking/jars/ch4g3zvqceyo/09526a168d57dac1a26f8caa4ab49593931ed2ef.jar; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 5: worker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-27 16:43:10.393 Worker$: INFO: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/9060 at root gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 Wo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:2497,Testability,test,test-ezlis,2497," vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar; 2023-09-27 16:43:10.389 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 2: /batch/83e7aee9e9244f6884b8a84ea81b4c7a; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 3: /batch/83e7aee9e9244f6884b8a84ea81b4c7a/log; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 4: gs://hail-test-ezlis/dking/jars/ch4g3zvqceyo/09526a168d57dac1a26f8caa4ab49593931ed2ef.jar; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 5: worker; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 6: gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g=; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 7: 7028; 2023-09-27 16:43:10.390 JVMEntryway: INFO: 8: 9060; 2023-09-27 16:43:10.390 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-27 16:43:10.393 Worker$: INFO: is.hail.backend.service.Worker 09526a168d57dac1a26f8caa4ab49593931ed2ef; 2023-09-27 16:43:10.394 Worker$: INFO: running job 7028/9060 at root gs://1-day/parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g= with scratch directory '/batch/83e7aee9e9244f6884b8a84ea81b4c7a'; 2023-09-27 16:43:10.398 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-27 16:43:10.779 WorkerTimer$: INFO: readInputs took 384.743327 ms.; 2023-09-27 16:43:10.779 : INFO: RegionPool: initial",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:8301,Testability,test,test-,8301,r$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:8562,Testability,test,test-,8562,upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-S,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:8822,Testability,test,test-,8822,qmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:9057,Testability,test,test-,9057,1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:9274,Testability,test,test-,9274,test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-e,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:9498,Testability,test,test-,9498,ailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_0952,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:9699,Testability,test,test-,9699,sionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:9907,Testability,test,test-,9907,.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQueryTask.java:100) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChanne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:10096,Testability,test,test-,10096,3931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.query(JsonResumableSession.java:57) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:10296,Testability,test,test-,10296,c1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.lambda$put$0(JsonResumableSession.java:73) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hai,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:10487,Testability,test,test-,10487,_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.lambda$run$0(Retrying.java:102) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dkin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:10702,Testability,test,test-,10702,ceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:10958,Testability,test,test-,10958,r.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:11213,Testability,test,test-,11213,yHelper.runWithRetries(RetryHelper.java:50) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:99) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_ja,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:11500,Testability,test,test-,11500,a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSession.put(JsonResumableSession.java:68) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:11746,Testability,test,test-,11746,d2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.internalWrite(ApiaryUnbufferedWritableByteChannel.java:114) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStor,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12002,Testability,test,test-,12002,d2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.sca,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12222,Testability,test,test-,12222,9526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12445,Testability,test,test-,12445,ession.java:40) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12644,Testability,test,test-,12644,eByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(Filter,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:12850,Testability,test,test-,12850,gle.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:13049,Testability,test,test-,13049,ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:44,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:13339,Testability,test,test-,13339,rage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:13527,Testability,test,test-,13527,hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:13774,Testability,test,test-,13774,uesterPays(GoogleStorageFS.scala:280) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:13932,Testability,test,test-,13932,hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:310) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14091,Testability,test,test-,14091,31ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14259,Testability,test,test-,14259,.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezl,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14442,Testability,test,test-,14442,ageFS$$anon$2.close(GoogleStorageFS.scala:308) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14633,Testability,test,test-,14633,close(FilterOutputStream.java:159) ~[?:1.8.0_382]; 	at is.hail.utils.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:14817,Testability,test,test-,14817,.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:15107,Testability,test,test-,15107,.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:15279,Testability,test,test-,15279,.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:15446,Testability,test,test-,15446,.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:15609,Testability,test,test-,15609,.package$.using(package.scala:677) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS(FS.scala:441) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FS.writePDOS$(FS.scala:440) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$4$adapted(Worker.scala:124) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:178) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:177) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:7909,Usability,Resume,Resume,7909,.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) ~[?:1.8.0_382]; 	at java.lang.Thread.run(Thread.java:750) ~[?:1.8.0_382]; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/1-day/o?name=parallelizeAndComputeWithIndex/al3OJfYZMMNoi9F2jvcAf0jBirVTayRVqro03dnIa1g%3D/result.7028&uploadType=resumable&upload_id=ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdv7y3A6GjTh6Kv7vrUu2ap2Kv0peLVWsVTAghIs7RCZk9X3fI1BDkeHag1cd9g3etP2sS4f13bN6iJPU_sbnRnyRE91VPtjUpuYLPqmOq13; 	| ; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:185) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:117) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionFailureScenario.toStorageException(JsonResumableSessionFailureScenario.java:98) ~[gs:__hail-test-ezlis_dking_jars_ch4g3zvqceyo_09526a168d57dac1a26f8caa4ab49593931ed2ef.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.JsonResumableSessionQueryTask.call(JsonResumableSessionQ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943
https://github.com/hail-is/hail/issues/13722#issuecomment-1737675608:56,Deployability,pipeline,pipelines,56,Labelling as a bug because this can adversely affect CI pipelines.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13722#issuecomment-1737675608
https://github.com/hail-is/hail/pull/13728#issuecomment-1738332294:72,Deployability,release,released,72,Also looks like we might need to go to 1.1.0 b/c that’s all that’s been released to Apt https://packages.cloud.google.com/apt/dists/gcsfuse-jammy/main/binary-amd64/Packages,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1738332294
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:70,Availability,avail,available,70,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:537,Availability,echo,echo,537,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:655,Availability,echo,echo,655,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:146,Deployability,update,update,146,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:153,Deployability,deploy,deployment,153,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502:494,Security,access,access,494,"Looking at the `…/Packages` URL in the previous comment, 1.2.0 is now available (and 1.1.0 does not appear to be there). In our recent local hail update deployment, the `batch_worker_image` job failed repeatedly due to GoogleCloudPlatform/gcsfuse#1424. We worked around this as initially suggested on that issue with populationgenomics/hail@607408bee752dabca48d9a2732b14d32813ace9f, but later comments on the issue suggest that the better approach would be this PR with an additional change to access the apt repo via https:. ```diff; - echo ""deb http://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; + echo ""deb https://packages.cloud.google.com/apt $GCSFUSE_REPO main"" | tee /etc/apt/sources.list.d/gcsfuse.list && \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1763644502
https://github.com/hail-is/hail/pull/13728#issuecomment-1769060386:76,Deployability,release,release,76,@jigold can I remove the WIP tag? I'd like this to make it into the 0.2.125 release so that AUS can check out a tagged release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769060386
https://github.com/hail-is/hail/pull/13728#issuecomment-1769060386:119,Deployability,release,release,119,@jigold can I remove the WIP tag? I'd like this to make it into the 0.2.125 release so that AUS can check out a tagged release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769060386
https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:128,Availability,error,errors,128,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759
https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:59,Testability,log,logs,59,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759
https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:74,Testability,test,test,74,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759
https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:174,Testability,log,logging,174,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759
https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759:278,Testability,log,logs,278,Yes with the caveat that I was going to look at the worker logs in the PR test namespace just to make sure there were no hidden errors that would be problematic. I broke the logging query generator -- fixed in #13813 -- and didn't think this was urgent. I'll take a look at the logs now without that fix in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769106759
https://github.com/hail-is/hail/pull/13728#issuecomment-1769117923:49,Availability,error,errors,49,I forgot I turned off the syslog so we won't see errors there from while the worker is running. Up to you on whether you think this change needs more scrutiny.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769117923
https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622:215,Availability,failure,failure,215,"It's not so much so that **we** can check out a tagged release, as we have already worked around the problem. But I would expect that you and any other installations will also run into the same `batch_worker_image` failure. We have been running our production instance using gcsfuse 1.2.0 for about a week now, and I think @illusional will agree with me that we haven't seen any problems from it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622
https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622:55,Deployability,release,release,55,"It's not so much so that **we** can check out a tagged release, as we have already worked around the problem. But I would expect that you and any other installations will also run into the same `batch_worker_image` failure. We have been running our production instance using gcsfuse 1.2.0 for about a week now, and I think @illusional will agree with me that we haven't seen any problems from it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622
https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622:152,Deployability,install,installations,152,"It's not so much so that **we** can check out a tagged release, as we have already worked around the problem. But I would expect that you and any other installations will also run into the same `batch_worker_image` failure. We have been running our production instance using gcsfuse 1.2.0 for about a week now, and I think @illusional will agree with me that we haven't seen any problems from it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13728#issuecomment-1769212622
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1124,Availability,echo,echo,1124,"___________ test_callback _________________________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 26",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1178,Availability,echo,echo,1178,"lient = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:779,Testability,test,test,779,"@jigold , so, I know how to fix this this, but why didn't it fail in the PR that made this change?; ```; ________________________________ test_callback _________________________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182',",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1004,Testability,test,test,1004,"I know how to fix this this, but why didn't it fail in the PR that made this change?; ```; ________________________________ test_callback _________________________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1619,Testability,assert,assert,1619,"f callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1668,Testability,test,test,1668,".0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1696,Testability,test,test,1696,".0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1941,Testability,Assert,AssertionError,1941,".0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2062,Testability,test,test,2062,".0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2111,Testability,assert,assert,2111,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2139,Testability,test,test,2139,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2166,Testability,test,test,2166,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2473,Testability,test,test,2473,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2500,Testability,test,test,2500,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:2795,Testability,test,test,2795,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:3047,Testability,test,test,3047,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:3394,Testability,test,test,3394,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:3646,Testability,test,test,3646,"er': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}; E assert {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'name': 'test_callback', 'foo': 'bar', 'client_job': '8051758-182'}} == {'id': 260, 'user': 'test', 'billing_project': 'test', 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg', 'state': 'success', 'complete': True, 'closed': True, 'n_jobs': 2, 'n_completed': 2, 'n_succeeded': 2, 'n_failed': 0, 'n_cancelled': 0, 'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Common items:; E {'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test'}; E Differing items:; E {'attributes': {'client_job': '8051758-182', 'foo': 'bar', 'name': 'test_callback'}} != {'attributes': {'foo': 'bar', 'name': 'test_callback'}}; E Full diff:; E {; E - 'attributes': {'foo': 'bar',; E + 'attributes': {'client_job': '8051758-182',; E + 'foo': 'bar',; E 'name': 'test_callback'},; E 'billing_project': 'test',; E 'closed': True,; E 'complete': True,; E 'id': 260,; E 'n_cancelled': 0,; E 'n_completed': 2,; E 'n_failed': 0,; E 'n_jobs': 2,; E 'n_succeeded': 2,; E 'state': 'success',; E 'token': 'dL_z32z_mbXzpd2hcI3aVy3rySdAOjxPQoqAdERnyzg',; E 'user': 'test',; E }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427
https://github.com/hail-is/hail/pull/13744#issuecomment-1739576643:13,Usability,feedback,feedback,13,"What kind of feedback would you like? At a high-level, I think constructing these URLs and embedding links like this into the PR page is a great idea. Love how little code it takes to do this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13744#issuecomment-1739576643
https://github.com/hail-is/hail/pull/13745#issuecomment-1739787547:24,Availability,error,errors,24,"Unassigning until I fix errors in CI, apologies for the noise",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13745#issuecomment-1739787547
https://github.com/hail-is/hail/issues/13748#issuecomment-1791063434:24,Deployability,pipeline,pipeline,24,GVS team confirms their pipeline containing interval literals went from >50 GB (crashing at that point) to less than 11GB! 👏,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13748#issuecomment-1791063434
https://github.com/hail-is/hail/pull/13749#issuecomment-1743389871:102,Deployability,pipeline,pipelines---the,102,"That's what the literal was doing. The problem is the result is being used in two completely separate pipelines---the variants and reference. The right thing is probably to collect with `localize=False`, and use the result to annotate globals on both sides, but we still don't support referencing the local environment in MapGlobals.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13749#issuecomment-1743389871
https://github.com/hail-is/hail/pull/13749#issuecomment-1743497768:50,Deployability,pipeline,pipelines,50,"Ah, right, OK, I forget that we have two parallel pipelines here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13749#issuecomment-1743497768
https://github.com/hail-is/hail/pull/13750#issuecomment-1781474949:21,Deployability,release,release,21,WIP until I sort the release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13750#issuecomment-1781474949
https://github.com/hail-is/hail/pull/13751#issuecomment-1781475011:21,Deployability,release,release,21,WIP until I sort the release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13751#issuecomment-1781475011
https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491:191,Deployability,deploy,deployment,191,"There remain a couple questions that a solution should answer:; 1. TCP or Unix Domain Socket? Current consensus feels that TCP is a reasonable and more portable way to go (allows for backend deployment over the web/in K8s for example); 2. Should we use just TCP or also use HTTP? If the Java backends can multiplex requests, HTTP sounds favorable, otherwise it's unclear to me what advantages it would give us over TCP + JSON. Ergonomically HTTP might be easier, but one tends have certain default expectations of HTTP servers (I would *assume* an HTTP server should be able to serve requests concurrently, are we just going to use all `POST`s?, etc.). Either way this feels like a minor adjustment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491
https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491:152,Modifiability,portab,portable,152,"There remain a couple questions that a solution should answer:; 1. TCP or Unix Domain Socket? Current consensus feels that TCP is a reasonable and more portable way to go (allows for backend deployment over the web/in K8s for example); 2. Should we use just TCP or also use HTTP? If the Java backends can multiplex requests, HTTP sounds favorable, otherwise it's unclear to me what advantages it would give us over TCP + JSON. Ergonomically HTTP might be easier, but one tends have certain default expectations of HTTP servers (I would *assume* an HTTP server should be able to serve requests concurrently, are we just going to use all `POST`s?, etc.). Either way this feels like a minor adjustment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491
https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491:593,Performance,concurren,concurrently,593,"There remain a couple questions that a solution should answer:; 1. TCP or Unix Domain Socket? Current consensus feels that TCP is a reasonable and more portable way to go (allows for backend deployment over the web/in K8s for example); 2. Should we use just TCP or also use HTTP? If the Java backends can multiplex requests, HTTP sounds favorable, otherwise it's unclear to me what advantages it would give us over TCP + JSON. Ergonomically HTTP might be easier, but one tends have certain default expectations of HTTP servers (I would *assume* an HTTP server should be able to serve requests concurrently, are we just going to use all `POST`s?, etc.). Either way this feels like a minor adjustment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13756#issuecomment-1743481491
https://github.com/hail-is/hail/issues/13756#issuecomment-1791063795:24,Deployability,pipeline,pipeline,24,GVS team confirms their pipeline containing interval literals went from >50 GB (crashing at that point) to less than 11GB! 👏,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13756#issuecomment-1791063795
https://github.com/hail-is/hail/issues/13757#issuecomment-1791063901:24,Deployability,pipeline,pipeline,24,GVS team confirms their pipeline containing interval literals went from >50 GB (crashing at that point) to less than 11GB! 👏,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13757#issuecomment-1791063901
https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792:169,Deployability,upgrade,upgrades,169,"my strategy here was just to undo everything added in [this commit](https://github.com/hail-is/hail/commit/12e0f497db0f3e5453f870495e48e44191b315f4), except the version upgrades, so i'm not sure if there are some changes i'm making here that are unnecessary or produce weird results as far as what all ends up in the jar or anything. from running `jar -tf` on the jar produced by the current `main` and the one produced by the commit prior to the one i'm partially reverting, it looked like the updates to the config only added things to the jar, rather than removing any, so hopefully that should be fine",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792
https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792:495,Deployability,update,updates,495,"my strategy here was just to undo everything added in [this commit](https://github.com/hail-is/hail/commit/12e0f497db0f3e5453f870495e48e44191b315f4), except the version upgrades, so i'm not sure if there are some changes i'm making here that are unnecessary or produce weird results as far as what all ends up in the jar or anything. from running `jar -tf` on the jar produced by the current `main` and the one produced by the commit prior to the one i'm partially reverting, it looked like the updates to the config only added things to the jar, rather than removing any, so hopefully that should be fine",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792
https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792:510,Modifiability,config,config,510,"my strategy here was just to undo everything added in [this commit](https://github.com/hail-is/hail/commit/12e0f497db0f3e5453f870495e48e44191b315f4), except the version upgrades, so i'm not sure if there are some changes i'm making here that are unnecessary or produce weird results as far as what all ends up in the jar or anything. from running `jar -tf` on the jar produced by the current `main` and the one produced by the commit prior to the one i'm partially reverting, it looked like the updates to the config only added things to the jar, rather than removing any, so hopefully that should be fine",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792
https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792:29,Usability,undo,undo,29,"my strategy here was just to undo everything added in [this commit](https://github.com/hail-is/hail/commit/12e0f497db0f3e5453f870495e48e44191b315f4), except the version upgrades, so i'm not sure if there are some changes i'm making here that are unnecessary or produce weird results as far as what all ends up in the jar or anything. from running `jar -tf` on the jar produced by the current `main` and the one produced by the commit prior to the one i'm partially reverting, it looked like the updates to the config only added things to the jar, rather than removing any, so hopefully that should be fine",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1743654792
https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178:102,Availability,error,error,102,"@danking i'm also not really certain why this works haha, i pretty much just did a bunch of trial and error. it would probably be worth taking a deeper look at how we manage our jvm dependencies (especially spark) at some point, but i figured it made sense to just revert a couple lines to fix the bug in the short term",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178
https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178:182,Integrability,depend,dependencies,182,"@danking i'm also not really certain why this works haha, i pretty much just did a bunch of trial and error. it would probably be worth taking a deeper look at how we manage our jvm dependencies (especially spark) at some point, but i figured it made sense to just revert a couple lines to fix the bug in the short term",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13759#issuecomment-1745640178
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13762#issuecomment-1749693044
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13763#issuecomment-1749693210
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13766#issuecomment-1749693288
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13768#issuecomment-1749695164
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13769#issuecomment-1749695237
https://github.com/hail-is/hail/pull/13776#issuecomment-1747578071:98,Deployability,pipeline,pipeline,98,"The per-element code seems to end up in a separate method. Is that not standard? For example, the pipeline I'm using is an array of struct and the struct is always in a separate method",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13776#issuecomment-1747578071
https://github.com/hail-is/hail/pull/13776#issuecomment-1749445909:45,Testability,test,test,45,I'm gonna see if this code works on the full test suite. I'm finding it pretty tricky to work with this stuff. The code I wrote for the last remaining elements in the non-required case seems to be wrong.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13776#issuecomment-1749445909
https://github.com/hail-is/hail/issues/13784#issuecomment-1904656977:118,Energy Efficiency,charge,charge,118,"I didn't realize there are two prices for spot instances versus standard instances. We can support both (we currently charge the non-preemptible price), but is that something we want to do? Should still be relatively straightforward. https://cloud.google.com/vpc/pricing-announce-external-ips",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13784#issuecomment-1904656977
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:122,Availability,FAILURE,FAILURES,122,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:16,Testability,test,test,16,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:266,Testability,test,testing,266,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:656,Testability,assert,assert,656,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:685,Testability,Assert,AssertionError,685,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:701,Testability,assert,assert,701,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401
https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102:149,Performance,tune,tune,149,Should be ready to go now. I'll add a better description in the morning. I also haven't benchmarked anything yet; would be good to do that and maybe tune things like amount of unrolling. @danking Could you share how you created the datatset you were using for benchmarking?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102
https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102:88,Testability,benchmark,benchmarked,88,Should be ready to go now. I'll add a better description in the morning. I also haven't benchmarked anything yet; would be good to do that and maybe tune things like amount of unrolling. @danking Could you share how you created the datatset you were using for benchmarking?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102
https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102:260,Testability,benchmark,benchmarking,260,Should be ready to go now. I'll add a better description in the morning. I also haven't benchmarked anything yet; would be good to do that and maybe tune things like amount of unrolling. @danking Could you share how you created the datatset you were using for benchmarking?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756261102
https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633:1835,Safety,safe,safe,1835,"Seems to average 60MB/s. No clear culprits. Zstd decoding is the top hit right now. The hottest generated code is inplace decoding of an optional array of optional int32. Really sucks because things like `LA` are somehow getting written as element optional, even though, by construction their elements are not optional. ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:; +EArray[EBaseStruct{; LA:EArray[EInt32]; ,LGT:EInt32; ,LAD:EArray[EInt32]; ,LPGT:EInt32; ,LPL:EArray[EInt32]; ,RGQ:EInt32,; gvcf_info: EBaseStruct{; AC:EArray[EInt32]; ,AF:EArray[EFloat64]; ,AN:EInt32,AS_BaseQRankSum:EArray[EFloat64]; ,AS_FS:EArray[EFloat64]; ,AS_InbreedingCoeff:EArray[EFloat64]; ,AS_MQ:EArray[EFloat64]; ,AS_MQRankSum:EArray[EFloat64]; ,AS_QD:EArray[EFloat64]; ,AS_QUALapprox:EArray[EInt32]; ,AS_RAW_BaseQRankSum:EBinary,AS_RAW_MQ:EArray[EFloat64]; ,AS_RAW_MQRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_RAW_ReadPosRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_ReadPosRankSum:EArray[EFloat64]; ,AS_SB_TABLE:EArray[EArray[EInt32]]; ,AS_SOR:EArray[EFloat64]; ,AS_VarDP:EArray[EInt32]; ,BaseQRankSum:EFloat64,ExcessHet:EFloat64,FS:EFloat64,InbreedingCoeff:EFloat64,MQ:EFloat64,MQRankSum:EFloat64,MQ_DP:EInt32,QD:EFloat64,QUALapprox:EInt32,RAW_GT_COUNT:EArray[EInt32]; ,RAW_MQandDP:EArray[EInt32]; ,ReadPosRankSum:EFloat64,SOR:EFloat64,VarDP:EInt32}; ,DP:EInt32; ,GQ:EInt32; ,MIN_DP:EInt32; ,PID:EBinary; ,PS:EInt32; ,SB:EArray[EInt32]; }; ]; }; ```. Async profiler periodic sampling:; <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 06 38"" src=""https://github.com/hail-is/hail/assets/106194/ee5df1c7-9c4a-4a4c-9ff4-caf599f1883b"">; <img width=""517"" alt=""Screenshot 2023-10-10 at 18 07 10"" src=""https://github.com/hail-is/hail/assets/106194/2bb5ba37-dab4-4b29-bb03-6cc2b08dafb9"">; Sync profiler (note safe point bias); <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 32 14"" src=""https://github.com/hail-is/hail/assets/106194/85f1c1b6-3ac1-4b87-9e32-e6abdd02bb49"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633
https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633:28,Usability,clear,clear,28,"Seems to average 60MB/s. No clear culprits. Zstd decoding is the top hit right now. The hottest generated code is inplace decoding of an optional array of optional int32. Really sucks because things like `LA` are somehow getting written as element optional, even though, by construction their elements are not optional. ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:; +EArray[EBaseStruct{; LA:EArray[EInt32]; ,LGT:EInt32; ,LAD:EArray[EInt32]; ,LPGT:EInt32; ,LPL:EArray[EInt32]; ,RGQ:EInt32,; gvcf_info: EBaseStruct{; AC:EArray[EInt32]; ,AF:EArray[EFloat64]; ,AN:EInt32,AS_BaseQRankSum:EArray[EFloat64]; ,AS_FS:EArray[EFloat64]; ,AS_InbreedingCoeff:EArray[EFloat64]; ,AS_MQ:EArray[EFloat64]; ,AS_MQRankSum:EArray[EFloat64]; ,AS_QD:EArray[EFloat64]; ,AS_QUALapprox:EArray[EInt32]; ,AS_RAW_BaseQRankSum:EBinary,AS_RAW_MQ:EArray[EFloat64]; ,AS_RAW_MQRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_RAW_ReadPosRankSum:EArray[EBaseStruct{`0`:EFloat64,`1`:EInt32}]; ,AS_ReadPosRankSum:EArray[EFloat64]; ,AS_SB_TABLE:EArray[EArray[EInt32]]; ,AS_SOR:EArray[EFloat64]; ,AS_VarDP:EArray[EInt32]; ,BaseQRankSum:EFloat64,ExcessHet:EFloat64,FS:EFloat64,InbreedingCoeff:EFloat64,MQ:EFloat64,MQRankSum:EFloat64,MQ_DP:EInt32,QD:EFloat64,QUALapprox:EInt32,RAW_GT_COUNT:EArray[EInt32]; ,RAW_MQandDP:EArray[EInt32]; ,ReadPosRankSum:EFloat64,SOR:EFloat64,VarDP:EInt32}; ,DP:EInt32; ,GQ:EInt32; ,MIN_DP:EInt32; ,PID:EBinary; ,PS:EInt32; ,SB:EArray[EInt32]; }; ]; }; ```. Async profiler periodic sampling:; <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 06 38"" src=""https://github.com/hail-is/hail/assets/106194/ee5df1c7-9c4a-4a4c-9ff4-caf599f1883b"">; <img width=""517"" alt=""Screenshot 2023-10-10 at 18 07 10"" src=""https://github.com/hail-is/hail/assets/106194/2bb5ba37-dab4-4b29-bb03-6cc2b08dafb9"">; Sync profiler (note safe point bias); <img width=""2032"" alt=""Screenshot 2023-10-10 at 18 32 14"" src=""https://github.com/hail-is/hail/assets/106194/85f1c1b6-3ac1-4b87-9e32-e6abdd02bb49"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13787#issuecomment-1756358633
https://github.com/hail-is/hail/issues/13788#issuecomment-1755689086:4,Availability,error,error,4,The error should come from logistic_regression_rows and it should complain that row_idx is row-indexed not col-indexed..,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13788#issuecomment-1755689086
https://github.com/hail-is/hail/issues/13792#issuecomment-1758518398:62,Usability,simpl,simple,62,"So, here's a profile of the no-leb dataset. I applied all the simple tricks I could think of. We memcpy runs of present ints or floats in arrays. Patrick's improvements. A few other little cleanups. Read bandwidth with one core is ~60MB/s (of uncompressed bytes). Zstd is getting ~28% of our core. A comment from 2019 claimed [200 MB/s](https://github.com/luben/zstd-jni/issues/94#issuecomment-471114842) from the Zstd JNI library we're using. That roughly tracks (0.28 * 200 = 56). The native C library, on a 400MB/s link (roughly my SSD's link) claims closer to 1000 MB/s (of uncompressed bytes) (see [my sheet](https://docs.google.com/spreadsheets/d/1uDYfXWDIwt_-XiclFWdLDiXamVbxhswt_D-v8fVrlRU/edit#gid=0)). I suspect we need either different on-disk formats, different in-memory formats, or vectorized storage to substantially improve the speed. Reading all these tiny arrays is unfortunately really branchy. If we had a PType and EType for arrays that was memcpy-able, that might give us a big win? In particular, suppose we could determine the bytesize of a nested structure including arrays. We write that size into the stream, then write all the bytes. Decoding is: read size, read that many bytes, done. <img width=""1545"" alt=""Screenshot 2023-10-11 at 16 36 27"" src=""https://github.com/hail-is/hail/assets/106194/afaeeacc-ab07-4e2c-9638-8d007276333d"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1758518398
https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107:950,Energy Efficiency,reduce,reduce,950,"> Struct decoding (the fourth generated code one, with 399 own time and 229 samples) is pretty branchy: it checks a bit for each field. I'm not sure how to speed this up. Consider a struct of 8 optional fields. There are 2^8 possible missingness pattern. Each pattern corresponds to a different sequence of field-decoders. I suppose we could generate 256 different patterns and jump to them? That seems excessive. We could maybe generate 16 patterns but that only saves 3/4 of the branches. Maybe that's enough for a substantial speedup?. With the array decoding, I suspect a lot of the speedup wasn't from avoiding branches, but from avoiding a bunch of extra operations handling missing bits one at a time, especially computing the address of the containing byte and loading it from memory every time. We should be able to do something similar for structs, though it will be more complicated. I think that's worth trying independently of trying to reduce branches.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107
https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107:769,Performance,load,loading,769,"> Struct decoding (the fourth generated code one, with 399 own time and 229 samples) is pretty branchy: it checks a bit for each field. I'm not sure how to speed this up. Consider a struct of 8 optional fields. There are 2^8 possible missingness pattern. Each pattern corresponds to a different sequence of field-decoders. I suppose we could generate 256 different patterns and jump to them? That seems excessive. We could maybe generate 16 patterns but that only saves 3/4 of the branches. Maybe that's enough for a substantial speedup?. With the array decoding, I suspect a lot of the speedup wasn't from avoiding branches, but from avoiding a bunch of extra operations handling missing bits one at a time, especially computing the address of the containing byte and loading it from memory every time. We should be able to do something similar for structs, though it will be more complicated. I think that's worth trying independently of trying to reduce branches.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107
https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107:607,Safety,avoid,avoiding,607,"> Struct decoding (the fourth generated code one, with 399 own time and 229 samples) is pretty branchy: it checks a bit for each field. I'm not sure how to speed this up. Consider a struct of 8 optional fields. There are 2^8 possible missingness pattern. Each pattern corresponds to a different sequence of field-decoders. I suppose we could generate 256 different patterns and jump to them? That seems excessive. We could maybe generate 16 patterns but that only saves 3/4 of the branches. Maybe that's enough for a substantial speedup?. With the array decoding, I suspect a lot of the speedup wasn't from avoiding branches, but from avoiding a bunch of extra operations handling missing bits one at a time, especially computing the address of the containing byte and loading it from memory every time. We should be able to do something similar for structs, though it will be more complicated. I think that's worth trying independently of trying to reduce branches.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107
https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107:635,Safety,avoid,avoiding,635,"> Struct decoding (the fourth generated code one, with 399 own time and 229 samples) is pretty branchy: it checks a bit for each field. I'm not sure how to speed this up. Consider a struct of 8 optional fields. There are 2^8 possible missingness pattern. Each pattern corresponds to a different sequence of field-decoders. I suppose we could generate 256 different patterns and jump to them? That seems excessive. We could maybe generate 16 patterns but that only saves 3/4 of the branches. Maybe that's enough for a substantial speedup?. With the array decoding, I suspect a lot of the speedup wasn't from avoiding branches, but from avoiding a bunch of extra operations handling missing bits one at a time, especially computing the address of the containing byte and loading it from memory every time. We should be able to do something similar for structs, though it will be more complicated. I think that's worth trying independently of trying to reduce branches.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1761652107
https://github.com/hail-is/hail/issues/13792#issuecomment-1761891070:20,Performance,load,loading,20,I made an issue for loading the bytes less often. https://github.com/hail-is/hail/issues/13811,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13792#issuecomment-1761891070
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:987,Availability,down,down,987,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:41,Modifiability,config,configure,41,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:204,Modifiability,refactor,refactor,204,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:322,Modifiability,refactor,refactor,322,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:791,Modifiability,config,configuring,791,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995:854,Performance,perform,performed,854,"@danking Looks like I'm still failing to configure a couple of settings related to references on the `ServiceBackend` but you can feel free to start looking. You'll notice that I made quite a substantial refactor in `ServiceBackend.scala` in an attempt to harmonize the scala backends a bit more. The rationale behind the refactor is I was having a hard time working with the various thunks passed around there. I saw them as a bit of poor-man's-object way to capture some state from the input file while keeping the `ServiceBackend` stateless. IMO there's no harm in keeping the `ServiceBackend` just as stateful as the other backends since it is single use. So I lifted a lot of that state into backend-creation time and created a harder delineation between which part of the input is for configuring the backend and which part is for the action being performed. This made it easier to reuse a couple of methods like `tableType` and such. I'm happy to take suggestions on ways to trim down this PR, but I thought you'd want to take a look at the whole thing given the time-sensitivity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13797#issuecomment-1766521995
https://github.com/hail-is/hail/pull/13804#issuecomment-1771696190:284,Energy Efficiency,green,green,284,"@danking Can you take another look? The only thing I didn't address is the `Phenotypes -> List[Phenotype], VariantChunks -> List[VariantChunk]`. I don't want to rip it out yet in case Wei comes out with the new SAIGE implementation with phenotype groupings. Again, just looking for a green light to start testing it. We can figure out the question about the CLI later on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1771696190
https://github.com/hail-is/hail/pull/13804#issuecomment-1771696190:305,Testability,test,testing,305,"@danking Can you take another look? The only thing I didn't address is the `Phenotypes -> List[Phenotype], VariantChunks -> List[VariantChunk]`. I don't want to rip it out yet in case Wei comes out with the new SAIGE implementation with phenotype groupings. Again, just looking for a green light to start testing it. We can figure out the question about the CLI later on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1771696190
https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553:267,Availability,checkpoint,checkpoint,267,"I don't think I addressed all of your comments, but I'd like you to take another look. I rewrote the `io.py` component and fixed the parallelism and context managers. I also figure out where to write files to based on the checkpoint_dir argument. We need to `results.checkpoint()` at the end because I decided to treat the raw SAIGE output as temp files (or checkpoints) and the results as a hail table is the thing people want to save to an output directory. I can make the output directory optional as well and not checkpoint that. The issue is that if we write the raw SAIGE results to a temp dir, when the context manager exits, the results HailTable won't be able to read the data once it's returned back to the user.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553
https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553:358,Availability,checkpoint,checkpoints,358,"I don't think I addressed all of your comments, but I'd like you to take another look. I rewrote the `io.py` component and fixed the parallelism and context managers. I also figure out where to write files to based on the checkpoint_dir argument. We need to `results.checkpoint()` at the end because I decided to treat the raw SAIGE output as temp files (or checkpoints) and the results as a hail table is the thing people want to save to an output directory. I can make the output directory optional as well and not checkpoint that. The issue is that if we write the raw SAIGE results to a temp dir, when the context manager exits, the results HailTable won't be able to read the data once it's returned back to the user.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553
https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553:517,Availability,checkpoint,checkpoint,517,"I don't think I addressed all of your comments, but I'd like you to take another look. I rewrote the `io.py` component and fixed the parallelism and context managers. I also figure out where to write files to based on the checkpoint_dir argument. We need to `results.checkpoint()` at the end because I decided to treat the raw SAIGE output as temp files (or checkpoints) and the results as a hail table is the thing people want to save to an output directory. I can make the output directory optional as well and not checkpoint that. The issue is that if we write the raw SAIGE results to a temp dir, when the context manager exits, the results HailTable won't be able to read the data once it's returned back to the user.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1779917553
https://github.com/hail-is/hail/pull/13804#issuecomment-1781180710:103,Usability,feedback,feedback,103,"I did not fix the variant chunks or phenotypes classes to not be actual classes. But I would like your feedback on the rewritten `io.py`. It still might be overkill, but getting closer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13804#issuecomment-1781180710
https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602:151,Availability,error,errors,151,"I would also suggest the following as necessary for an upcoming release:. * #13728. Google's gcsfuse APT repository currently produces 502 Bad Gateway errors when accessed via http, which shows no sign of being resolved any time soon. I've commented on #13728 noting how this PR can work around the problem. At present (since early October), the `batch_worker_image` job always fails with 502 during a hail deployment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602
https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602:64,Deployability,release,release,64,"I would also suggest the following as necessary for an upcoming release:. * #13728. Google's gcsfuse APT repository currently produces 502 Bad Gateway errors when accessed via http, which shows no sign of being resolved any time soon. I've commented on #13728 noting how this PR can work around the problem. At present (since early October), the `batch_worker_image` job always fails with 502 during a hail deployment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602
https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602:407,Deployability,deploy,deployment,407,"I would also suggest the following as necessary for an upcoming release:. * #13728. Google's gcsfuse APT repository currently produces 502 Bad Gateway errors when accessed via http, which shows no sign of being resolved any time soon. I've commented on #13728 noting how this PR can work around the problem. At present (since early October), the `batch_worker_image` job always fails with 502 during a hail deployment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602
https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602:163,Security,access,accessed,163,"I would also suggest the following as necessary for an upcoming release:. * #13728. Google's gcsfuse APT repository currently produces 502 Bad Gateway errors when accessed via http, which shows no sign of being resolved any time soon. I've commented on #13728 noting how this PR can work around the problem. At present (since early October), the `batch_worker_image` job always fails with 502 during a hail deployment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13806#issuecomment-1763650602
https://github.com/hail-is/hail/pull/13807#issuecomment-1765336270:313,Testability,test,tests,313,"@patrick-schultz I wrote this up when debugging some other stuff. With this, my other stuff encounters hard to debug array index issues. That makes me a bit apprehensive to merge it b/c I can't tell if those issues are in my other stuff or real BM issues. . My specific question: how comfortable are you with the tests of BlockMatrix. Do you think it's well tested enough to just trust this PR is correct?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1765336270
https://github.com/hail-is/hail/pull/13807#issuecomment-1765336270:358,Testability,test,tested,358,"@patrick-schultz I wrote this up when debugging some other stuff. With this, my other stuff encounters hard to debug array index issues. That makes me a bit apprehensive to merge it b/c I can't tell if those issues are in my other stuff or real BM issues. . My specific question: how comfortable are you with the tests of BlockMatrix. Do you think it's well tested enough to just trust this PR is correct?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1765336270
https://github.com/hail-is/hail/pull/13807#issuecomment-1766527794:137,Testability,test,tested,137,"Between `BlockMatrixIRSuite.scala`, `test_linalg.py`, and the methods that use BlockMatrix, I think the BlockMatrix lowering is decently tested. And this change is certainly one we have to make. I can give it a careful review to look for potential issues.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766527794
https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634:232,Availability,error,errors,232,"~Actually, this does appear to be a gap in our test coverage. I put in a failing assertion, and both `BlockMatrixIRSuite.scala` and `test_linalg.py` passed.~ Never mind, just forgot to run in local mode. I didn't notice any obvious errors in your code, but I don't think this is the right way to do it, so I tried writing it myself. I'll try to write a test that exercises this path and test both implementations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634
https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634:47,Testability,test,test,47,"~Actually, this does appear to be a gap in our test coverage. I put in a failing assertion, and both `BlockMatrixIRSuite.scala` and `test_linalg.py` passed.~ Never mind, just forgot to run in local mode. I didn't notice any obvious errors in your code, but I don't think this is the right way to do it, so I tried writing it myself. I'll try to write a test that exercises this path and test both implementations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634
https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634:81,Testability,assert,assertion,81,"~Actually, this does appear to be a gap in our test coverage. I put in a failing assertion, and both `BlockMatrixIRSuite.scala` and `test_linalg.py` passed.~ Never mind, just forgot to run in local mode. I didn't notice any obvious errors in your code, but I don't think this is the right way to do it, so I tried writing it myself. I'll try to write a test that exercises this path and test both implementations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634
https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634:353,Testability,test,test,353,"~Actually, this does appear to be a gap in our test coverage. I put in a failing assertion, and both `BlockMatrixIRSuite.scala` and `test_linalg.py` passed.~ Never mind, just forgot to run in local mode. I didn't notice any obvious errors in your code, but I don't think this is the right way to do it, so I tried writing it myself. I'll try to write a test that exercises this path and test both implementations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634
https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634:387,Testability,test,test,387,"~Actually, this does appear to be a gap in our test coverage. I put in a failing assertion, and both `BlockMatrixIRSuite.scala` and `test_linalg.py` passed.~ Never mind, just forgot to run in local mode. I didn't notice any obvious errors in your code, but I don't think this is the right way to do it, so I tried writing it myself. I'll try to write a test that exercises this path and test both implementations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766662634
https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503:292,Availability,error,errors,292,"#13839 is I think the right way to implement this. It passes `test_block_matrix_entries`, which is the only test I could find that exercises this path. Others that should, like `test_to_table`, can't yet be fully lowered. Maybe try rebasing on my branch and see if you still see the indexing errors?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503
https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503:108,Testability,test,test,108,"#13839 is I think the right way to implement this. It passes `test_block_matrix_entries`, which is the only test I could find that exercises this path. Others that should, like `test_to_table`, can't yet be fully lowered. Maybe try rebasing on my branch and see if you still see the indexing errors?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766713503
https://github.com/hail-is/hail/pull/13807#issuecomment-1766743037:23,Availability,error,error,23,"I still have the index error, so it must be inherent to my branch. Let's close and go with your implementation instead.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13807#issuecomment-1766743037
https://github.com/hail-is/hail/pull/13810#issuecomment-1810311153:312,Availability,down,down,312,"I looked at this again and I think we can do this with `online: true`. It's a quick enough migration where it shouldn't impact the driver for too long that it's trying to query the long tables. If there's a problem and the driver can't make forward progress once the database migration is done, we can just shut down the deployment to 0 replicas. Thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1810311153
https://github.com/hail-is/hail/pull/13810#issuecomment-1810311153:321,Deployability,deploy,deployment,321,"I looked at this again and I think we can do this with `online: true`. It's a quick enough migration where it shouldn't impact the driver for too long that it's trying to query the long tables. If there's a problem and the driver can't make forward progress once the database migration is done, we can just shut down the deployment to 0 replicas. Thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1810311153
https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995:68,Deployability,update,update,68,Doesn't the batch driver need to schedule the `deploy_batch` job to update itself? How can it eventually get to deploying the new / compatible code?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995
https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995:112,Deployability,deploy,deploying,112,Doesn't the batch driver need to schedule the `deploy_batch` job to update itself? How can it eventually get to deploying the new / compatible code?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995
https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995:33,Energy Efficiency,schedul,schedule,33,Doesn't the batch driver need to schedule the `deploy_batch` job to update itself? How can it eventually get to deploying the new / compatible code?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812763995
https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477:57,Availability,toler,tolerate,57,I think we need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. The only parts that would be referencing the wrong tables are in the `Canceller` and `notify_batch_complete`. I think scheduling and MJC would just work because we update those stored procedures and don't change the child code. We can shut batch down though for the migration. Seems safest although more of a pain.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477
https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477:381,Availability,down,down,381,I think we need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. The only parts that would be referencing the wrong tables are in the `Canceller` and `notify_batch_complete`. I think scheduling and MJC would just work because we update those stored procedures and don't change the child code. We can shut batch down though for the migration. Seems safest although more of a pain.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477
https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477:299,Deployability,update,update,299,I think we need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. The only parts that would be referencing the wrong tables are in the `Canceller` and `notify_batch_complete`. I think scheduling and MJC would just work because we update those stored procedures and don't change the child code. We can shut batch down though for the migration. Seems safest although more of a pain.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477
https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477:253,Energy Efficiency,schedul,scheduling,253,I think we need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. The only parts that would be referencing the wrong tables are in the `Canceller` and `notify_batch_complete`. I think scheduling and MJC would just work because we update those stored procedures and don't change the child code. We can shut batch down though for the migration. Seems safest although more of a pain.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477
https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477:418,Safety,safe,safest,418,I think we need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. The only parts that would be referencing the wrong tables are in the `Canceller` and `notify_batch_complete`. I think scheduling and MJC would just work because we update those stored procedures and don't change the child code. We can shut batch down though for the migration. Seems safest although more of a pain.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812841477
https://github.com/hail-is/hail/pull/13810#issuecomment-1812859285:48,Availability,toler,tolerate,48,> need it to be offline unless we're willing to tolerate up to 5-10 mins of not being able to cancel a batch and some alerts. I want as much as possible for alerts to mean something unexpected is going wrong. If we can I think this should just be done offline.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13810#issuecomment-1812859285
https://github.com/hail-is/hail/issues/13811#issuecomment-1989182606:101,Performance,load,loadByte,101,This shouldn't be too hard. The only issue I can forsee is needing to convert the `Code[Byte]` from `loadByte` to `Code[Int]`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13811#issuecomment-1989182606
https://github.com/hail-is/hail/pull/13812#issuecomment-1772965095:218,Integrability,interface,interface,218,"I think we might need a different name than ""mount"". In Docker, you can only use the same destination mount once. i.e. you can't have this. `--mount file1:/ --mount file2:/`. . @danking Do you have any thoughts on the interface for this?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1772965095
https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987:11,Availability,failure,failure,11,bump. Test failure was unrelated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987
https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987:6,Testability,Test,Test,6,bump. Test failure was unrelated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1798877987
https://github.com/hail-is/hail/pull/13812#issuecomment-1834495397:25,Availability,error,error,25,I couldn't replicate the error locally. It seems to be transient because at least one of the CI builds succeeded.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1834495397
https://github.com/hail-is/hail/pull/13812#issuecomment-1836784494:299,Availability,resilien,resilient,299,"> Supporting `file://` seems to suggest that we would support URIs in general (e.g. `--files gs://foo/bar:/baz`); AFAICT we don't support the latter, right? What's the motivation to support `file://`?. I didn't know what we currently support with regards to file paths, so I just made it that we're resilient to someone adding file://",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1836784494
https://github.com/hail-is/hail/pull/13812#issuecomment-1836784929:61,Availability,error,error,61,I'm not sure what to do about the invalid block id transient error...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1836784929
https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683:358,Availability,error,errors,358,"This took me an incredibly long time to figure out, but I'm pretty sure the issue is that my last test copies the same file twice. Once explicitly as a single file and the second time as part of the directory to copy recursively. I don't think our copier code interacts correctly with Azure Blob Storage in this case and we end up with invalid block ID list errors. I'm still stewing over which option is the best to address this. I could either not have `submit.py` ask to copy the same file twice or I can modify the copier to have a lock on the create blob writer stream so that we don't have this issue. However, I'm worried about deadlocks with our extensive use of semaphores and parallelism. Thoughts?? I think the right thing to do is fix it for now in `submit.py` so we can get this in and then make an issue to make a more durable fix to the copier.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683
https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683:98,Testability,test,test,98,"This took me an incredibly long time to figure out, but I'm pretty sure the issue is that my last test copies the same file twice. Once explicitly as a single file and the second time as part of the directory to copy recursively. I don't think our copier code interacts correctly with Azure Blob Storage in this case and we end up with invalid block ID list errors. I'm still stewing over which option is the best to address this. I could either not have `submit.py` ask to copy the same file twice or I can modify the copier to have a lock on the create blob writer stream so that we don't have this issue. However, I'm worried about deadlocks with our extensive use of semaphores and parallelism. Thoughts?? I think the right thing to do is fix it for now in `submit.py` so we can get this in and then make an issue to make a more durable fix to the copier.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1881894683
https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862:613,Availability,error,error,613,"@jigold https://azure.github.io/Storage/docs/application-and-user-data/code-samples/concurrent-uploads-with-versioning. Looks like this is the expected behavior from Azure Blob Storage when concurrently uploading blobs. It seems like *all* blocks are purged when any single upload succeeds. Unfortunately, it doesn't seem possible to distinguish between a truly invalid block list and this transiently invalid block list. I dislike this interface, but it is what we have. It seems to me that the right fix is to deduplicate the file list before uploading. Multiple files uploading to the same target should be an error if they're different source files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862
https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862:437,Integrability,interface,interface,437,"@jigold https://azure.github.io/Storage/docs/application-and-user-data/code-samples/concurrent-uploads-with-versioning. Looks like this is the expected behavior from Azure Blob Storage when concurrently uploading blobs. It seems like *all* blocks are purged when any single upload succeeds. Unfortunately, it doesn't seem possible to distinguish between a truly invalid block list and this transiently invalid block list. I dislike this interface, but it is what we have. It seems to me that the right fix is to deduplicate the file list before uploading. Multiple files uploading to the same target should be an error if they're different source files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862
https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862:84,Performance,concurren,concurrent-uploads-with-versioning,84,"@jigold https://azure.github.io/Storage/docs/application-and-user-data/code-samples/concurrent-uploads-with-versioning. Looks like this is the expected behavior from Azure Blob Storage when concurrently uploading blobs. It seems like *all* blocks are purged when any single upload succeeds. Unfortunately, it doesn't seem possible to distinguish between a truly invalid block list and this transiently invalid block list. I dislike this interface, but it is what we have. It seems to me that the right fix is to deduplicate the file list before uploading. Multiple files uploading to the same target should be an error if they're different source files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862
https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862:190,Performance,concurren,concurrently,190,"@jigold https://azure.github.io/Storage/docs/application-and-user-data/code-samples/concurrent-uploads-with-versioning. Looks like this is the expected behavior from Azure Blob Storage when concurrently uploading blobs. It seems like *all* blocks are purged when any single upload succeeds. Unfortunately, it doesn't seem possible to distinguish between a truly invalid block list and this transiently invalid block list. I dislike this interface, but it is what we have. It seems to me that the right fix is to deduplicate the file list before uploading. Multiple files uploading to the same target should be an error if they're different source files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1882088862
https://github.com/hail-is/hail/pull/13812#issuecomment-1883649177:57,Testability,Test,Tests,57,@iris-garden Can you review again when you get a chance? Tests are all passing now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13812#issuecomment-1883649177
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:15240,Availability,Error,Error,15240,ge$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.executeToEncoded(LocalBackend.scala:208); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$2(LocalBackend.scala:237); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$1(LocalBackend.scala:236); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.backend.local.LocalBackend.executeEncode(LocalBackend.scala:234); E 	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E 	at py4j.Gateway.invoke(Gateway.java:282); E 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E 	at py4j.commands.CallCommand.execute(CallCommand.java:79); E 	at py4j.GatewayConnection.run(GatewayConnection.java:238); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E Hail version: 0.2.124-b31f1dcea5d2; E Error summary: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8341,Energy Efficiency,adapt,adapted,8341,nfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:11101,Energy Efficiency,adapt,adapted,11101,ackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); E 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); E 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:10); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:157); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:12504,Energy Efficiency,adapt,adapted,12504,cute$1(EvalRelationalLets.scala:10); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:157); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.apply(LoweringPass.scala:151); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); E 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); E 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:150); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:189); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeToEncoded$1(LocalBackend.scala:209); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteCon,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:999,Integrability,wrap,wrapper,999," still isn't quite right?. I also saw some issues with sockets timing out but I don't know what to make of those yet.; ```; _______________________________ test_union_rows1 _______________________________. @test_timeout(local=3 * 60); def test_union_rows1():; vds = hl.vds.read_vds(os.path.join(resource('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncod",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:1299,Integrability,wrap,wrapper,1299,"rce('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:1596,Integrability,wrap,wrapper,1596,"')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeExce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3069,Integrability,protocol,protocol,3069,"b/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8573,Integrability,Wrap,WrappedArray,8573, E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8594,Integrability,Wrap,WrappedArray,8594,pr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:6204,Modifiability,Rewrite,RewriteBottomUp,6204,__m92846DECODE_o_dict_of_o_struct_of_o_binaryANDo_int32END_TO_SIndexablePointer(Unknown Source); E 	at __C92844etypeDecode.apply(Unknown Source); E 	at is.hail.io.CompiledDecoder.readRegionValue(Decoder.scala:31); E 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays(CodecSpec.scala:57); E 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays$(CodecSpec.scala:54); E 	at is.hail.io.TypedCodecSpec.decodeArrays(TypedCodecSpec.scala:19); E 	at is.hail.expr.ir.Interpret$.$anonfun$run$1(Interpret.scala:80); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:79); E 	at is.hail.expr.ir.Interpret$.interpret$1(Interpret.scala:67); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:110); E 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTi,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:6238,Modifiability,Rewrite,RewriteBottomUp,6238,o_struct_of_o_binaryANDo_int32END_TO_SIndexablePointer(Unknown Source); E 	at __C92844etypeDecode.apply(Unknown Source); E 	at is.hail.io.CompiledDecoder.readRegionValue(Decoder.scala:31); E 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays(CodecSpec.scala:57); E 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays$(CodecSpec.scala:54); E 	at is.hail.io.TypedCodecSpec.decodeArrays(TypedCodecSpec.scala:19); E 	at is.hail.expr.ir.Interpret$.$anonfun$run$1(Interpret.scala:80); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:79); E 	at is.hail.expr.ir.Interpret$.interpret$1(Interpret.scala:67); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:110); E 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:6473,Modifiability,Rewrite,RewriteBottomUp,6473,decSpec.scala:57); E 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays$(CodecSpec.scala:54); E 	at is.hail.io.TypedCodecSpec.decodeArrays(TypedCodecSpec.scala:19); E 	at is.hail.expr.ir.Interpret$.$anonfun$run$1(Interpret.scala:80); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:79); E 	at is.hail.expr.ir.Interpret$.interpret$1(Interpret.scala:67); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:110); E 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.Execut,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:6496,Modifiability,Rewrite,RewriteBottomUp,6496, 	at is.hail.io.AbstractTypedCodecSpec.decodeArrays$(CodecSpec.scala:54); E 	at is.hail.io.TypedCodecSpec.decodeArrays(TypedCodecSpec.scala:19); E 	at is.hail.expr.ir.Interpret$.$anonfun$run$1(Interpret.scala:80); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:79); E 	at is.hail.expr.ir.Interpret$.interpret$1(Interpret.scala:67); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:110); E 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(Execu,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8341,Modifiability,adapt,adapted,8341,nfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:9892,Modifiability,Rewrite,RewriteBottomUp,9892,he.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:158); E 	at is.hail.backend.local.LocalBackend.lowerDistributedSort(LocalBackend.scala:331); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:67); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteSh,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:9926,Modifiability,Rewrite,RewriteBottomUp,9926,unction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:158); E 	at is.hail.backend.local.LocalBackend.lowerDistributedSort(LocalBackend.scala:331); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:67); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(Lowering,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:10161,Modifiability,Rewrite,RewriteBottomUp,10161,ileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:158); E 	at is.hail.backend.local.LocalBackend.lowerDistributedSort(LocalBackend.scala:331); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:67); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.Re,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:10184,Modifiability,Rewrite,RewriteBottomUp,10184,:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:158); E 	at is.hail.backend.local.LocalBackend.lowerDistributedSort(LocalBackend.scala:331); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:67); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreac,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:11101,Modifiability,adapt,adapted,11101,ackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); E 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); E 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:10); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:157); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:12504,Modifiability,adapt,adapted,12504,cute$1(EvalRelationalLets.scala:10); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); E 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:157); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.apply(LoweringPass.scala:151); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); E 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); E 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:150); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:189); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeToEncoded$1(LocalBackend.scala:209); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteCon,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3811,Performance,load,loadInt,3811,"1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3871,Performance,load,loadInt,3871,"on.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(U",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7066,Performance,Optimiz,Optimize,7066,ed(Interpret.scala:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.Loweri,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7093,Performance,Optimiz,Optimize,7093,:58); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(Lowe,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7135,Performance,Optimiz,Optimize,7135,$foldConstants$1(FoldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7162,Performance,Optimiz,Optimize,7162,oldConstants.scala:47); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7270,Performance,Optimiz,Optimize,7270,ail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7289,Performance,Optimiz,Optimize,7289,kSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7331,Performance,Optimiz,Optimize,7331,s.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$app,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7358,Performance,Optimiz,Optimize,7358,Safe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); E 	at is.hail.expr.ir.FoldConstants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(Lower,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7544,Performance,Optimiz,Optimize,7544,Constants$.foldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7560,Performance,Optimiz,Optimize,7560,oldConstants(FoldConstants.scala:13); E 	at is.hail.expr.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collecti,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:7611,Performance,Optimiz,OptimizePass,7611,.ir.FoldConstants$.$anonfun$apply$1(FoldConstants.scala:10); E 	at is.hail.backend.ExecuteContext$.$anonfun$scopedNewRegion$1(ExecuteContext.scala:86); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); E 	at is.hail.backend.ExecuteContext$.scopedNewRegion(ExecuteContext.scala:83); E 	at is.hail.expr.ir.FoldConstants$.apply(FoldConstants.scala:9); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$4(Optimize.scala:22); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8140,Performance,Optimiz,OptimizePass,8140,anonfun$apply$1(Optimize.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.runOpt$1(Optimize.scala:15); E 	at is.hail.expr.ir.Optimize$.$anonfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:2514,Security,access,access,2514,"return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:2650,Security,access,access,2650,"return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:2767,Security,access,access,2767,"ocal/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3514,Security,access,access,3514,"0000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844e",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:3649,Security,access,access,3649,"26574/00000004: not in 7f15e9ffb1f8/00010000'; full = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000\n\tat is.h...ava:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E ; E Java stack trace:; E java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; E 	at is.hail.annotations.Memory.checkAddress(Memory.java:226); E 	at is.hail.annotations.Memory.loadInt(Memory.java:140); E 	at is.hail.annotations.Region$.loadInt(Region.scala:20); E 	at __C92844etypeDecode.__m92863ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92862ord_compareNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92861ord_ltNonnull(Unknown Source); E 	at __C92844etypeDecode.__m92860ord_lt(Unknown Source); E 	at __C92844etypeDecode.__m92857arraySorter_merge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source); E 	at __C92844etypeDecode.__m92864arraySorter_splitMerge(Unknown Source",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:15288,Security,access,access,15288,ge$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.executeToEncoded(LocalBackend.scala:208); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$2(LocalBackend.scala:237); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); E 	at is.hail.utils.package$.using(package.scala:657); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$1(LocalBackend.scala:109); E 	at is.hail.backend.local.LocalBackend.$anonfun$executeEncode$1(LocalBackend.scala:236); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.backend.local.LocalBackend.executeEncode(LocalBackend.scala:234); E 	at sun.reflect.GeneratedMethodAccessor5.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E 	at py4j.Gateway.invoke(Gateway.java:282); E 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E 	at py4j.commands.CallCommand.execute(CallCommand.java:79); E 	at py4j.GatewayConnection.run(GatewayConnection.java:238); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E Hail version: 0.2.124-b31f1dcea5d2; E Error summary: RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:705,Testability,assert,assert,705,"Hmm. Seems like the ArraySorter still isn't quite right?. I also saw some issues with sockets timing out but I don't know what to make of those yet.; ```; _______________________________ test_union_rows1 _______________________________. @test_timeout(local=3 * 60); def test_union_rows1():; vds = hl.vds.read_vds(os.path.join(resource('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:774,Testability,test,test,774,"Hmm. Seems like the ArraySorter still isn't quite right?. I also saw some issues with sockets timing out but I don't know what to make of those yet.; ```; _______________________________ test_union_rows1 _______________________________. @test_timeout(local=3 * 60); def test_union_rows1():; vds = hl.vds.read_vds(os.path.join(resource('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198
https://github.com/hail-is/hail/pull/13814#issuecomment-1778262286:85,Usability,simpl,simpler,85,"Hmm. What's special about `hl.concordance`... The other issue seems like it might be simpler, we're just setting a bad type on a field:; ```; E java.lang.ClassFormatError: Invalid signature for field in class __C8802Compiled referenced from constant pool index 1605 in method __C8802Compiled.addAndDecodeLiterals_region0_0(L__C9346addAndDecodeLiteralsSpills;)V; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1778262286
https://github.com/hail-is/hail/issues/13816#issuecomment-1775716804:16,Usability,simpl,simple,16,"This seems very simple, I'm just not sure how to modify the job creation to do what we want it to. https://github.com/hail-is/hail/blob/86f21400e3f2ac127f084f15ab72594a6add6f15/hail/python/hailtop/batch/backend.py#L799-L807",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13816#issuecomment-1775716804
https://github.com/hail-is/hail/issues/13816#issuecomment-1781573998:83,Testability,test,test,83,"Whenever I can't remember how to do something with the aioclient, I look at `batch/test/test_batch.py`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13816#issuecomment-1781573998
https://github.com/hail-is/hail/pull/13822#issuecomment-1777724435:18,Modifiability,config,config,18,Let's make this a config parameter in the future so we can specify which migrations need more cores. This also makes it self-documenting for our future selves.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13822#issuecomment-1777724435
https://github.com/hail-is/hail/issues/13823#issuecomment-1764943591:71,Availability,Echo,Echo,71,https://hail.zulipchat.com/#narrow/stream/379853-Hail.2FVariants/topic/Echo.20VDS/near/396801065,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13823#issuecomment-1764943591
https://github.com/hail-is/hail/issues/13823#issuecomment-1765051388:143,Energy Efficiency,consumption,consumption,143,Chris points out the `__uid_3` is created by `_same`. That's the entries array. There is no bug; just that `_same` was not intended for public consumption and therefore does some funky things.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13823#issuecomment-1765051388
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:62,Testability,test,test,62,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:168,Testability,Test,TestFailedException,168,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:219,Testability,test,test-ezlis,219,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:324,Testability,Assert,Assertions,324,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:363,Testability,Assert,Assertions,363,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:404,Testability,Assert,Assertions,404,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:444,Testability,Assert,Assertions,444,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:485,Testability,test,testng,485,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:492,Testability,Test,TestNGSuite,492,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:532,Testability,Test,TestNGSuite,532,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:573,Testability,Assert,Assertions,573,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:584,Testability,Assert,AssertionsHelper,584,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:613,Testability,Assert,Assertions,613,https://batch.hail.is/batches/8062723/jobs/204; ```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1176,Testability,test,testng,1176,xception: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/376b0a1e-ee61-43ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.t,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1269,Testability,test,testng,1269,3ab-abb4-d67a0978ee46/791.suffix; 	at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1333,Testability,test,testng,1333,ewAssertionFailedException(Assertions.scala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.te,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1401,Testability,test,testng,1401,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1471,Testability,test,testng,1471,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1487,Testability,Test,TestMethodWorker,1487,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1522,Testability,Test,TestMethodWorker,1522,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1558,Testability,test,testng,1558,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1574,Testability,Test,TestMethodWorker,1574,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1595,Testability,Test,TestMethodWorker,1595,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1631,Testability,test,testng,1631,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1638,Testability,Test,TestRunner,1638,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1660,Testability,Test,TestRunner,1660,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1690,Testability,test,testng,1690,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1697,Testability,Test,TestRunner,1697,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1712,Testability,Test,TestRunner,1712,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1742,Testability,test,testng,1742,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1800,Testability,test,testng,1800,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1866,Testability,test,testng,1866,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1927,Testability,test,testng,1927,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:1981,Testability,test,testng,1981,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2051,Testability,test,testng,2051,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2116,Testability,test,testng,2116,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2123,Testability,Test,TestNG,2123,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2152,Testability,Test,TestNG,2152,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2179,Testability,test,testng,2179,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2186,Testability,Test,TestNG,2186,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2210,Testability,Test,TestNG,2210,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2237,Testability,test,testng,2237,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2244,Testability,Test,TestNG,2244,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2255,Testability,Test,TestNG,2255,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2282,Testability,test,testng,2282,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2289,Testability,Test,TestNG,2289,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2308,Testability,Test,TestNG,2308,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2335,Testability,test,testng,2335,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2342,Testability,Test,TestNG,2342,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277:2354,Testability,Test,TestNG,2354,ala:528); 	at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); 	at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); 	at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:413); 	at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:398); 	at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1769490277
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:14,Testability,test,test,14,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:120,Testability,Test,TestFailedException,120,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:171,Testability,test,test-ezlis,171,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:276,Testability,Assert,Assertions,276,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:315,Testability,Assert,Assertions,315,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:355,Testability,Assert,Assertions,355,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:395,Testability,Assert,Assertions,395,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:435,Testability,test,testng,435,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:442,Testability,Test,TestNGSuite,442,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:482,Testability,Test,TestNGSuite,482,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:522,Testability,Assert,Assertions,522,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:533,Testability,Assert,AssertionsHelper,533,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:562,Testability,Assert,Assertions,562,```; starting test is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations...; Exception:; org.scalatest.exceptions.TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1117,Testability,test,testng,1117,TestFailedException: files not deleted:; gs://hail-test-ezlis/fs-suite/delete-many-files/72e64985-c4b9-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRun,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1219,Testability,test,testng,1219,-46ff-9191-93b8c4589083/1890.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1244,Testability,Test,TestInvoker,1244,.suffix; at org.scalatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSui,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1269,Testability,Test,TestInvoker,1269,alatest.Assertions.newAssertionFailedException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorke,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1299,Testability,test,testng,1299,ledException(Assertions.scala:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRun,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1324,Testability,Test,TestInvoker,1324,a:528); at org.scalatest.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1353,Testability,Test,TestInvoker,1353,test.Assertions.newAssertionFailedException$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1383,Testability,test,testng,1383,ception$(Assertions.scala:527); at org.scalatest.testng.TestNGSuite.newAssertionFailedException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1465,Testability,test,testng,1465,iledException(TestNGSuite.scala:67); at org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at or,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1490,Testability,Test,TestInvoker,1490, org.scalatest.Assertions$AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1531,Testability,Test,TestInvoker,1531,AssertionsHelper.macroAssert(Assertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1561,Testability,test,testng,1561,sertions.scala:501); at is.hail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1586,Testability,Test,TestInvoker,1586,ail.io.fs.FSSuite.largeDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(T,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1616,Testability,Test,TestInvoker,1616,geDirectoryOperations(FSSuite.scala:445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1646,Testability,test,testng,1646,445); at is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:13,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1671,Testability,Test,TestMethodWorker,1671,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1706,Testability,Test,TestMethodWorker,1706,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1741,Testability,test,testng,1741,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1766,Testability,Test,TestMethodWorker,1766,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1787,Testability,Test,TestMethodWorker,1787,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1875,Testability,test,testng,1875,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1882,Testability,Test,TestRunner,1882,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1904,Testability,Test,TestRunner,1904,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1933,Testability,test,testng,1933,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1940,Testability,Test,TestRunner,1940,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1955,Testability,Test,TestRunner,1955,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:1984,Testability,test,testng,1984,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2041,Testability,test,testng,2041,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2106,Testability,test,testng,2106,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2166,Testability,test,testng,2166,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2219,Testability,test,testng,2219,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2288,Testability,test,testng,2288,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2352,Testability,test,testng,2352,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2359,Testability,Test,TestNG,2359,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2388,Testability,Test,TestNG,2388,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2414,Testability,test,testng,2414,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2421,Testability,Test,TestNG,2421,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2445,Testability,Test,TestNG,2445,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2471,Testability,test,testng,2471,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2478,Testability,Test,TestNG,2478,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2495,Testability,Test,TestNG,2495,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2521,Testability,test,testng,2521,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2528,Testability,Test,TestNG,2528,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2539,Testability,Test,TestNG,2539,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2565,Testability,test,testng,2565,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2572,Testability,Test,TestNG,2572,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2591,Testability,Test,TestNG,2591,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2617,Testability,test,testng,2617,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2624,Testability,Test,TestNG,2624,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547:2636,Testability,Test,TestNG,2636,is.hail.io.fs.FSSuite.largeDirectoryOperations$(FSSuite.scala:430); at is.hail.io.fs.GoogleStorageFSSuite.largeDirectoryOperations(GoogleStorageFSSuite.scala:10); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:136); at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:658); at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:219); at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50); at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:923); at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:192); at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128); at java.util.ArrayList.forEach(ArrayList.java:1259); at org.testng.TestRunner.privateRun(TestRunner.java:808); at org.testng.TestRunner.run(TestRunner.java:603); at org.testng.SuiteRunner.runTest(SuiteRunner.java:429); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:423); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:383); at org.testng.SuiteRunner.run(SuiteRunner.java:326); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1249); at org.testng.TestNG.runSuitesLocally(TestNG.java:1169); at org.testng.TestNG.runSuites(TestNG.java:1092); at org.testng.TestNG.run(TestNG.java:1060); at org.testng.TestNG.privateMain(TestNG.java:1403); at org.testng.TestNG.main(TestNG.java:1367); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13827#issuecomment-1957725547
https://github.com/hail-is/hail/pull/13832#issuecomment-1781334414:19,Deployability,release,release,19,Making way for the release fix,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1781334414
https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993:342,Deployability,update,updated,342,"There is occasional use of this in other projects, e.g., gnomad_methods (`SimpleRichProgressBar` in this case). Do you consider these classes to be part of the API? Was it intended to rename these without any compatibility shim, e.g., having the old names as aliases for a while?. It's not the end of the world and gnomad_methods has already updated accordingly. It does however mean that older gnomad_methods is only compatible with hail ≤ 0.2.125 and newer gnomad_methods is only compatible with hail ≥ 0.2.126, which is an otherwise unnecessary lock-step restriction. ETA: gnomad_methods have now updated by removing the (apparently unused) progress bar reference, so now newer gnomad_methods is compatible with hail both ≤ 0.2.125 and ≥ 0.2.126 again. So this is no longer a significant problem for gnomad_methods, but remains FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993
https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993:600,Deployability,update,updated,600,"There is occasional use of this in other projects, e.g., gnomad_methods (`SimpleRichProgressBar` in this case). Do you consider these classes to be part of the API? Was it intended to rename these without any compatibility shim, e.g., having the old names as aliases for a while?. It's not the end of the world and gnomad_methods has already updated accordingly. It does however mean that older gnomad_methods is only compatible with hail ≤ 0.2.125 and newer gnomad_methods is only compatible with hail ≥ 0.2.126, which is an otherwise unnecessary lock-step restriction. ETA: gnomad_methods have now updated by removing the (apparently unused) progress bar reference, so now newer gnomad_methods is compatible with hail both ≤ 0.2.125 and ≥ 0.2.126 again. So this is no longer a significant problem for gnomad_methods, but remains FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993
https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993:74,Usability,Simpl,SimpleRichProgressBar,74,"There is occasional use of this in other projects, e.g., gnomad_methods (`SimpleRichProgressBar` in this case). Do you consider these classes to be part of the API? Was it intended to rename these without any compatibility shim, e.g., having the old names as aliases for a while?. It's not the end of the world and gnomad_methods has already updated accordingly. It does however mean that older gnomad_methods is only compatible with hail ≤ 0.2.125 and newer gnomad_methods is only compatible with hail ≥ 0.2.126, which is an otherwise unnecessary lock-step restriction. ETA: gnomad_methods have now updated by removing the (apparently unused) progress bar reference, so now newer gnomad_methods is compatible with hail both ≤ 0.2.125 and ≥ 0.2.126 again. So this is no longer a significant problem for gnomad_methods, but remains FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993
https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993:644,Usability,progress bar,progress bar,644,"There is occasional use of this in other projects, e.g., gnomad_methods (`SimpleRichProgressBar` in this case). Do you consider these classes to be part of the API? Was it intended to rename these without any compatibility shim, e.g., having the old names as aliases for a while?. It's not the end of the world and gnomad_methods has already updated accordingly. It does however mean that older gnomad_methods is only compatible with hail ≤ 0.2.125 and newer gnomad_methods is only compatible with hail ≥ 0.2.126, which is an otherwise unnecessary lock-step restriction. ETA: gnomad_methods have now updated by removing the (apparently unused) progress bar reference, so now newer gnomad_methods is compatible with hail both ≤ 0.2.125 and ≥ 0.2.126 again. So this is no longer a significant problem for gnomad_methods, but remains FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993
https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525:642,Availability,echo,echo,642,Hey @mhebrard !. I'm really sorry Hail has been such a pain to install. This looks to me like a Scala version incompatibility. In your Makefile you specified this:; ```; ... SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```; [EMR's docs](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-691-release.html) confirms that Scala 2.12.15 should be installed. I think my next questions are:; 1. Which `spark-shell` is that?; 2. What latent JVMs are around?; 3. What's the class path and what's on it?; 4. What scala executables are around?. ```; which spark-shell; spark-shell --version; which java; java -version; which scala; scala -version; echo $CLASSPATH; ```. That `SettingsOps` is an implicit nested class of the `MutableSettings` object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525
https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525:63,Deployability,install,install,63,Hey @mhebrard !. I'm really sorry Hail has been such a pain to install. This looks to me like a Scala version incompatibility. In your Makefile you specified this:; ```; ... SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```; [EMR's docs](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-691-release.html) confirms that Scala 2.12.15 should be installed. I think my next questions are:; 1. Which `spark-shell` is that?; 2. What latent JVMs are around?; 3. What's the class path and what's on it?; 4. What scala executables are around?. ```; which spark-shell; spark-shell --version; which java; java -version; which scala; scala -version; echo $CLASSPATH; ```. That `SettingsOps` is an implicit nested class of the `MutableSettings` object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525
https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525:274,Deployability,Release,ReleaseGuide,274,Hey @mhebrard !. I'm really sorry Hail has been such a pain to install. This looks to me like a Scala version incompatibility. In your Makefile you specified this:; ```; ... SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```; [EMR's docs](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-691-release.html) confirms that Scala 2.12.15 should be installed. I think my next questions are:; 1. Which `spark-shell` is that?; 2. What latent JVMs are around?; 3. What's the class path and what's on it?; 4. What scala executables are around?. ```; which spark-shell; spark-shell --version; which java; java -version; which scala; scala -version; echo $CLASSPATH; ```. That `SettingsOps` is an implicit nested class of the `MutableSettings` object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525
https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525:295,Deployability,release,release,295,Hey @mhebrard !. I'm really sorry Hail has been such a pain to install. This looks to me like a Scala version incompatibility. In your Makefile you specified this:; ```; ... SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```; [EMR's docs](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-691-release.html) confirms that Scala 2.12.15 should be installed. I think my next questions are:; 1. Which `spark-shell` is that?; 2. What latent JVMs are around?; 3. What's the class path and what's on it?; 4. What scala executables are around?. ```; which spark-shell; spark-shell --version; which java; java -version; which scala; scala -version; echo $CLASSPATH; ```. That `SettingsOps` is an implicit nested class of the `MutableSettings` object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525
https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525:347,Deployability,install,installed,347,Hey @mhebrard !. I'm really sorry Hail has been such a pain to install. This looks to me like a Scala version incompatibility. In your Makefile you specified this:; ```; ... SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; ```; [EMR's docs](https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-691-release.html) confirms that Scala 2.12.15 should be installed. I think my next questions are:; 1. Which `spark-shell` is that?; 2. What latent JVMs are around?; 3. What's the class path and what's on it?; 4. What scala executables are around?. ```; which spark-shell; spark-shell --version; which java; java -version; which scala; scala -version; echo $CLASSPATH; ```. That `SettingsOps` is an implicit nested class of the `MutableSettings` object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1766477525
https://github.com/hail-is/hail/issues/13837#issuecomment-1767473029:309,Availability,error,error,309,"@danking , no worry. I am aware that my current EMR environment is not as clean as we wish. Not easy to find the right alignment of version of all the components. Thanks for your pointers. ; `spark-shell --version` was the right spot. It appears that I am runing on `scala 2.12.13` and that would explain the error as you mentioned above . > That SettingsOps is an implicit nested class of the MutableSettings object. It is definitely present in [2.13](https://github.com/scala/scala/blob/2.13.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L70-L88) and [2.12](https://github.com/scala/scala/blob/2.12.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L83-L94). It appears to be missing in [2.11](https://github.com/scala/scala/blob/2.11.x/src/reflect/scala/reflect/internal/settings/MutableSettings.scala#L64-L68). It appears to have arrived in [2.12.14](https://github.com/scala/scala/commit/3bd24299fc34e5c3a480206c9798c055ca3a3439). Let me work on that and find a compatible scala version.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767473029
https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000:742,Availability,down,downgraded,742,"Some progress and new blocker on this topic. I moved to emr-6.11.1 that come with spark 3.3.2 & scala 2.12.15.; I upgraded the environment to get python 3.9 and java 11. * `emr-6.11.1`; * Java: java -version `11.0.20` (/usr/bin/java); * Python: python --version `3.9.18` (/usr/bin/python3); * Hadoop: hadoop version `3.3.3` (/usr/bin/hadoop); * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.15` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. But then once I build hail on this environment, the spark version is downgraded to 2.12.13 and the Java error above come back. ```sh; cd /tmp; git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```. * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.13` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. If I purposly build Hail for scala 2.12.13, the Java error above come back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000
https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000:777,Availability,error,error,777,"Some progress and new blocker on this topic. I moved to emr-6.11.1 that come with spark 3.3.2 & scala 2.12.15.; I upgraded the environment to get python 3.9 and java 11. * `emr-6.11.1`; * Java: java -version `11.0.20` (/usr/bin/java); * Python: python --version `3.9.18` (/usr/bin/python3); * Hadoop: hadoop version `3.3.3` (/usr/bin/hadoop); * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.15` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. But then once I build hail on this environment, the spark version is downgraded to 2.12.13 and the Java error above come back. ```sh; cd /tmp; git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```. * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.13` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. If I purposly build Hail for scala 2.12.13, the Java error above come back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000
https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000:1381,Availability,error,error,1381,"Some progress and new blocker on this topic. I moved to emr-6.11.1 that come with spark 3.3.2 & scala 2.12.15.; I upgraded the environment to get python 3.9 and java 11. * `emr-6.11.1`; * Java: java -version `11.0.20` (/usr/bin/java); * Python: python --version `3.9.18` (/usr/bin/python3); * Hadoop: hadoop version `3.3.3` (/usr/bin/hadoop); * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.15` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. But then once I build hail on this environment, the spark version is downgraded to 2.12.13 and the Java error above come back. ```sh; cd /tmp; git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```. * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.13` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. If I purposly build Hail for scala 2.12.13, the Java error above come back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000
https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000:114,Deployability,upgrade,upgraded,114,"Some progress and new blocker on this topic. I moved to emr-6.11.1 that come with spark 3.3.2 & scala 2.12.15.; I upgraded the environment to get python 3.9 and java 11. * `emr-6.11.1`; * Java: java -version `11.0.20` (/usr/bin/java); * Python: python --version `3.9.18` (/usr/bin/python3); * Hadoop: hadoop version `3.3.3` (/usr/bin/hadoop); * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.15` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. But then once I build hail on this environment, the spark version is downgraded to 2.12.13 and the Java error above come back. ```sh; cd /tmp; git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```. * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.13` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. If I purposly build Hail for scala 2.12.13, the Java error above come back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000
https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000:917,Deployability,install,install-on-cluster,917,"Some progress and new blocker on this topic. I moved to emr-6.11.1 that come with spark 3.3.2 & scala 2.12.15.; I upgraded the environment to get python 3.9 and java 11. * `emr-6.11.1`; * Java: java -version `11.0.20` (/usr/bin/java); * Python: python --version `3.9.18` (/usr/bin/python3); * Hadoop: hadoop version `3.3.3` (/usr/bin/hadoop); * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.15` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. But then once I build hail on this environment, the spark version is downgraded to 2.12.13 and the Java error above come back. ```sh; cd /tmp; git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```. * Spark: spark-shell --version `3.3.2` (usr/bin/spark-shell); * Scala: spark-shell --version `2.12.13` (usr/bin/spark-shell). ```sh; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.20.1; ```. If I purposly build Hail for scala 2.12.13, the Java error above come back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1767910000
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:101,Deployability,install,installing,101,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:124,Deployability,install,install-on-cluster,124,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:177,Deployability,install,install-on-cluster,177,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:348,Deployability,install,install,348,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:396,Deployability,install,install,396,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:512,Deployability,install,install-on-cluster,512,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:587,Deployability,install,installed,587,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:627,Deployability,install,installed,627,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:689,Deployability,install,installed,689,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:710,Deployability,install,installed,710,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:813,Deployability,install,install-on-cluster,813,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:891,Deployability,install,installed,891,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:878,Integrability,depend,dependencies,878,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:433,Modifiability,config,config,433,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906:159,Safety,avoid,avoid,159,"@mhebrard The only way I can imagine that we would mutate your environment is if we are accidentally installing `pyspark`. `install-on-cluster` takes pains to avoid that:; ```; install-on-cluster: $(WHEEL) check-pip-lockfile; 	sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$$' | tr '\n' '\0' | xargs -0 $(PIP) install -U; 	-$(PIP) uninstall -y hail; 	$(PIP) install $(WHEEL) --no-deps; 	hailctl config set query/backend spark; ```. But that is broken somehow? When you ran `install-on-cluster` did you see a `pip` output indicating that pyspark got installed?. Can you check if pyspark is installed via pip now? `pip show pyspark` (should say its not installed). If it is installed, try uninstalling it `pip uninstall pyspark`. You might also try removing the first line of `install-on-cluster` entirely. That will leave you without Hail's dependencies installed, but if `pyspark-shell` is still the right version of Scala, then I suspect the issue is that line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1769053906
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1477,Availability,down,downgraded,1477,"`/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1763,Availability,echo,echo,1763,"file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:2076,Availability,echo,echo,2076,"on=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_note",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:2130,Availability,echo,echo,2130,"s.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:2960,Availability,echo,echo,2960,"t to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3080,Availability,echo,echo,3080,"ython/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3222,Availability,echo,echo,3222," 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.propertie",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3798,Availability,echo,echo,3798,"hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT bu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3866,Availability,echo,echo,3866,"ny.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3930,Availability,echo,echo,3930,"aproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternati",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4032,Availability,echo,echo,4032,".sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4096,Availability,echo,echo,4096,"proc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4174,Availability,echo,echo,4174,"ailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:4245,Availability,echo,echo,4245,"ay/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/et",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15405,Availability,Down,Downloading,15405,"td=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/FS.d -MT build/FS.o -c FS.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/ibs.o build/Decoder.o build/Encoder.o build/Logging.o build/Na; tiveCodeSuite.o build/NativeLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16960,Availability,avail,available,16960,"t :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; adding 'hail/experimental/codec.py'; adding 'hail/experimental/compile.py'; adding 'hail/experimental/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:17006,Availability,avail,available,17006,other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; adding 'hail/experimental/codec.py'; adding 'hail/experimental/compile.py'; adding 'hail/experimental/datasets.json'; adding 'hail/experimental/datasets.py'; a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29302,Availability,Down,Downloading,29302,ctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29452,Availability,Down,Downloading,29452,tils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29523,Availability,Down,Downloading,29523,"ils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, cli",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29985,Availability,Down,Downloading,29985,"24.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; +",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30140,Availability,Down,Downloading,30140,"&& bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30226,Availability,Down,Downloading,30226,"ite-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30317,Availability,Down,Downloading,30317,"ng pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinne",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30400,Availability,Down,Downloading,30400,"kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30772,Availability,avail,available,30772,"0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44428,Availability,avail,available,44428,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44922,Availability,avail,available,44922,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44,Deployability,install,installation,44,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:232,Deployability,install,installed,232,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:410,Deployability,deploy,deploy,410,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:542,Deployability,RELEASE,RELEASE,542,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:636,Deployability,release,release,636,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:671,Deployability,release,release,671,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:703,Deployability,release,release,703,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:757,Deployability,release,release,757,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1233,Deployability,deploy,deploy,1233,"alled as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; pr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:2947,Deployability,deploy,deploy,2947,"f ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.prop",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3003,Deployability,deploy,deploy,3003,"t to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3193,Deployability,deploy,deploy,3193,"on; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3359,Deployability,deploy,deploy,3359,"on=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MOD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3427,Deployability,deploy,deploy,3427,"n.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:3589,Deployability,deploy,deploy,3589,"-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" > env/wheel_cloud_path; rm -f python/hailtop/hailctl/deploy.yaml; echo ""dataproc:"" >> python/hailtop/hailctl/deploy.yaml; for FILE in vep-GRCh37.sh vep-GRCh38.sh init_notebook.py; do \; echo "" $FILE: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/$FILE"" >> python/hailtop/hailctl/deploy.yaml || exit 1; done; echo "" wheel: gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any.whl"" >> python/hailtop/hailctl/deploy.yaml; printf "" pip_dependencies: "" >> python/hailtop/hailctl/deploy.yaml; cat python/pinned-requirements.txt | sed '/^[[:blank:]]*#/d;s/#.*//' | grep -v pyspark | tr ""\n"" ""|||"" | tr -d '[:space:]' >> python/hailtop/hailctl/deploy.yaml; BRANCH is set to ""HEAD"" which is different from old value """"; printf ""HEAD"" > env/BRANCH; SPARK_VERSION is set to ""3.3.2"" which is different from old value """"; printf ""3.3.2"" > env/SPARK_VERSION; echo '[Build Metadata]' > src/main/resources/build-info.properties; echo 'user=hadoop' >> src/main/resources/build-info.properties; echo 'revision=13536b531342a263b24a7165bfeec7bd02723e4b' >> src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tm",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15692,Deployability,release,release,15692,"extra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/ibs.o build/Decoder.o build/Encoder.o build/Logging.o build/Na; tiveCodeSuite.o build/NativeLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15836,Deployability,release,release-notes,15836,"clude/linux build/ibs.o build/Decoder.o build/Encoder.o build/Logging.o build/Na; tiveCodeSuite.o build/NativeLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before buildi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16452,Deployability,deploy,deploy,16452,"zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16475,Deployability,deploy,deploy,16475,"zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16498,Deployability,deploy,deploy,16498,"zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16532,Deployability,deploy,deploy,16532,".........50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/_",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16790,Deployability,deploy,deploy,16790,"3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16865,Deployability,deploy,deploy,16865,"3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:17018,Deployability,install,installing,17018,sk :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; adding 'hail/experimental/codec.py'; adding 'hail/experimental/compile.py'; adding 'hail/experimental/datasets.json'; adding 'hail/experimental/datasets.py'; adding 'hail/experimental/db.py'; addi,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26757,Deployability,deploy,deploy,26757,; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29120,Deployability,install,install,29120,nit__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00;,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29212,Deployability,install,installation,29212,py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30451,Deployability,Install,Installing,30451,"wnloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtrackin",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30588,Deployability,install,installed,30588,"wnloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtrackin",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30754,Deployability,release,release,30754,"0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30811,Deployability,update,update,30811,"py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:spa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30831,Deployability,install,install,30831,"d: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:30841,Deployability,upgrade,upgrade,30841,"d: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:31871,Deployability,install,install,31871,ython/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with stat,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:31902,Deployability,install,installation,31902,ython/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with stat,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32573,Deployability,Install,Installing,32573,Ew8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32613,Deployability,Install,Installing,32613,Ew8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41653,Deployability,Install,Installing,41653,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:42752,Deployability,install,installation,42752,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:42866,Deployability,install,installed,42866,"gger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 por",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44410,Deployability,release,release,44410,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44467,Deployability,update,update,44467,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44487,Deployability,install,install,44487,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44497,Deployability,upgrade,upgrade,44497,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44580,Deployability,install,installed,44580,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44607,Deployability,install,install,44607,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44621,Deployability,deploy,deploy,44621,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44693,Deployability,install,installation,44693,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44772,Deployability,deploy,deploy,44772,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44815,Deployability,Install,Installing,44815,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44865,Deployability,install,installed,44865,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44904,Deployability,release,release,44904,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44961,Deployability,update,update,44961,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44981,Deployability,install,install,44981,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44991,Deployability,upgrade,upgrade,44991,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15731,Energy Efficiency,Reduce,Reduced,15731,"extra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/ibs.o build/Decoder.o build/Encoder.o build/Logging.o build/Na; tiveCodeSuite.o build/NativeLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:31386,Integrability,depend,dependency,31386,"ipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; + for package in '$@'; + reqs=python/requirements.txt; + pinned=python/pinned-requirements.txt; ++ mktemp; + new_pinned=/tmp/tmp.YoVBQEw8XF; ++ mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32590,Integrability,depend,dependencies,32590,Ew8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32630,Integrability,depend,dependencies,32630,Ew8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40841,Integrability,wrap,wrapt,40841,"_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40869,Integrability,wrap,wrapt-,40869," six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41753,Integrability,wrap,wrapt,41753,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44347,Integrability,wrap,wrapt-,44347,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1240,Modifiability,plugin,plugin,1240,"s per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'h",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15919,Modifiability,Config,Configure,15919,"veLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel packa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26353,Modifiability,config,config,26353,y'; adding 'hailtop/aiotools/fs/stream.py'; adding 'hailtop/auth/__init__.py'; adding 'hailtop/auth/auth.py'; adding 'hailtop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/ha,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26390,Modifiability,config,config,26390,y'; adding 'hailtop/auth/__init__.py'; adding 'hailtop/auth/auth.py'; adding 'hailtop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; addin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26432,Modifiability,config,config,26432,ding 'hailtop/auth/auth.py'; adding 'hailtop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py';,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26472,Modifiability,config,config,26472,iltop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:26479,Modifiability,variab,variables,26479,iltop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:27456,Modifiability,config,config,27456,g.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:27501,Modifiability,config,config,27501,; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:27541,Modifiability,config,config,27541,ltop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:28232,Modifiability,config,config,28232,ailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user install,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:45012,Modifiability,config,config,45012,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9488,Performance,cache,cache-tests,9488,jre/include -I/etc/alternatives/jre/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9521,Performance,cache,cache-tests,9521,F build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/Na,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9545,Performance,cache,cache-tests,9545,; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/NativeBoot.o -o lib/linux-x86-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16823,Performance,cache,cache,16823,"3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:29792,Performance,cache,cached,29792,"te/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none-any.whl (64 kB); Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (58.1.0); Collecting packaging>=19.0; Downloading packaging-23.2-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 18.3 MB/s eta 0:00:00; Collecting tomli>=1.1.0; Downloading tomli-2.0.1-py3-none-any.whl (12 kB); Collecting importlib-metadata>=4.6; Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB); Collecting pyproject_hooks; Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB); Collecting zipp>=0.5; Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB); Installing collected packages: zipp, wheel, tomli, packaging, click, pyproject_hooks, importlib-metadata, build, pip-tools; Successfully installed build-1.0.3 click-8.1.7 importlib-metadata-6.8.0 packaging-23.2 pip-tools-6.13.0 pyproject_hooks-1.0.0 tomli-2.0.1 wheel-0.41.2 zipp-3.17.0. [notice] A new release of pip is available: 23.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:31994,Performance,cache,cached,31994, mktemp; + pinned_no_comments=/tmp/tmp.WRSKGgGEB8; ++ mktemp; + new_pinned_no_comments=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Colle,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32078,Performance,cache,cached,32078,s=/tmp/tmp.C8ggaXDHDt; + PATH=/usr/lib64/qt-3.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/opt/aws/puppet/bin/:/home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32201,Performance,cache,cached,32201,home/hadoop/.local/bin:/home/hadoop/.local/bin; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core=,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32290,Performance,cache,cached,32290,xt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32379,Performance,cache,cached,32379,y dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Coll,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32461,Performance,cache,cached,32461,p-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-n,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32538,Performance,cache,cached,32538, 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32936,Performance,cache,cached,32936,s is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using ca,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33030,Performance,cache,cached,33030,(4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33123,Performance,cache,cached,33123,.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33220,Performance,cache,cached,33220,none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33320,Performance,cache,cached,33320,whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33426,Performance,cache,cached,33426,ing attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manyl,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33518,Performance,cache,cached,33518,o==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33597,Performance,cache,cached,33597,ies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33681,Performance,cache,cached,33681,irements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33744,Performance,cache,cachetools,33744, build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; U,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33769,Performance,cache,cached,33769,us 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33776,Performance,cache,cachetools-,33776,us 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33857,Performance,cache,cached,33857,oml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-an,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:33940,Performance,cache,cached,33940, azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34070,Performance,cache,cached,34070,); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.whl (27 kB); Collecting azure-mgmt-storage==20.1.0; Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34309,Performance,cache,cached,34309,Using cached azure_mgmt_storage-20.1.0-py3-none-any.whl (2.3 MB); Collecting azure-storage-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34398,Performance,cache,cached,34398,e-blob==12.17.0; Using cached azure_storage_blob-12.17.0-py3-none-any.whl (388 kB); Collecting bokeh==3.2.2; Using cached bokeh-3.2.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached googl,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34527,Performance,cache,cached,34527,.2-py3-none-any.whl (7.8 MB); Collecting boto3==1.28.41; Using cached boto3-1.28.41-py3-none-any.whl (135 kB); Collecting botocore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34656,Performance,cache,cached,34656,ore==1.31.41; Using cached botocore-1.31.41-py3-none-any.whl (11.2 MB); Collecting cachetools==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_6,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34747,Performance,cache,cached,34747,ls==5.3.1; Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB); Collecting certifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34833,Performance,cache,cached,34833,ifi==2023.7.22; Using cached certifi-2023.7.22-py3-none-any.whl (158 kB); Collecting cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-com,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:34914,Performance,cache,cached,34914, cffi==1.15.1; Using cached cffi-1.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB); Collecting charset-normalizer==3.2.0; Using cached charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.wh,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35086,Performance,cache,cached,35086,r-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202 kB); Requirement already satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35181,Performance,cache,cached,35181,y satisfied: click==8.1.7 in /home/hadoop/.local/lib/python3.9/site-packages (8.1.7); Collecting commonmark==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35284,Performance,cache,cached,35284,==0.9.1; Using cached commonmark-0.9.1-py2.py3-none-any.whl (51 kB); Collecting contourpy==1.1.0; Using cached contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35391,Performance,cache,cached,35391,ched contourpy-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB); Collecting cryptography==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35499,Performance,cache,cached,35499,hy==41.0.3; Using cached cryptography-41.0.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting m,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35604,Performance,cache,cached,35604,(4.3 MB); Collecting decorator==4.4.2; Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB); Collecting deprecated==1.2.14; Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35745,Performance,cache,cached,35745,precated-1.2.14-py2.py3-none-any.whl (9.6 kB); Collecting dill==0.3.7; Using cached dill-0.3.7-py3-none-any.whl (115 kB); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35862,Performance,cache,cached,35862,B); Collecting frozenlist==1.4.0; Using cached frozenlist-1.4.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (8,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:35966,Performance,cache,cached,35966,anylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB); Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36042,Performance,cache,cached,36042,Collecting google-api-core==2.11.1; Using cached google_api_core-2.11.1-py3-none-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36117,Performance,cache,cached,36117,one-any.whl (120 kB); Collecting google-auth==2.22.0; Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36199,Performance,cache,cached,36199,22.0-py2.py3-none-any.whl (181 kB); Collecting google-auth-oauthlib==0.8.0; Using cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36277,Performance,cache,cached,36277,ing cached google_auth_oauthlib-0.8.0-py2.py3-none-any.whl (19 kB); Collecting google-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-non,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36358,Performance,cache,cached,36358,gle-cloud-core==2.3.3; Using cached google_cloud_core-2.3.3-py2.py3-none-any.whl (29 kB); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36443,Performance,cache,cached,36443,); Collecting google-cloud-storage==2.10.0; Using cached google_cloud_storage-2.10.0-py2.py3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; U,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36534,Performance,cache,cached,36534,y3-none-any.whl (114 kB); Collecting google-crc32c==1.5.0; Using cached google_crc32c-1.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36655,Performance,cache,cached,36655,86_64.manylinux2014_x86_64.whl (32 kB); Collecting google-resumable-media==2.5.0; Using cached google_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Usi,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36745,Performance,cache,cached,36745,oogle_resumable_media-2.5.0-py2.py3-none-any.whl (77 kB); Collecting googleapis-common-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36836,Performance,cache,cached,36836,-protos==1.60.0; Using cached googleapis_common_protos-1.60.0-py2.py3-none-any.whl (227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Colle,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:36917,Performance,cache,cached,36917,(227 kB); Collecting humanize==1.1.0; Using cached humanize-1.1.0-py3-none-any.whl (52 kB); Collecting idna==3.4; Using cached idna-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); C,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37045,Performance,cache,cached,37045,na-3.4-py3-none-any.whl (61 kB); Collecting isodate==0.6.1; Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cach,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37130,Performance,cache,cached,37130,.6.1-py2.py3-none-any.whl (41 kB); Collecting janus==1.0.0; Using cached janus-1.0.0-py3-none-any.whl (6.9 kB); Collecting jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37252,Performance,cache,cached,37252,jinja2==3.1.2; Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB); Collecting jmespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37333,Performance,cache,cached,37333,mespath==1.0.1; Using cached jmespath-1.0.1-py3-none-any.whl (20 kB); Collecting jproperties==2.1.1; Using cached jproperties-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Us,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37454,Performance,cache,cached,37454,es-2.1.1-py2.py3-none-any.whl (17 kB); Collecting markupsafe==2.1.3; Using cached MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37534,Performance,cache,cached,37534,hed MarkupSafe-2.1.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB); Collecting msal==1.23.0; Using cached msal-1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycpar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37661,Performance,cache,cached,37661,1.23.0-py2.py3-none-any.whl (90 kB); Collecting msal-extensions==1.0.0; Using cached msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37747,Performance,cache,cached,37747, msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB); Collecting msrest==0.7.1; Using cached msrest-0.7.1-py3-none-any.whl (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37868,Performance,cache,cached,37868,l (85 kB); Collecting multidict==6.0.4; Using cached multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:37958,Performance,cache,cached,37958,_x86_64.manylinux2014_x86_64.whl (114 kB); Collecting nest-asyncio==1.5.7; Using cached nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38048,Performance,cache,cached,38048,nest_asyncio-1.5.7-py3-none-any.whl (5.3 kB); Collecting numpy==1.25.2; Using cached numpy-1.25.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-no,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38167,Performance,cache,cached,38167,_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB); Collecting oauthlib==3.2.2; Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux201,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38251,Performance,cache,cached,38251,ched oauthlib-3.2.2-py3-none-any.whl (151 kB); Collecting orjson==3.9.5; Using cached orjson-3.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38341,Performance,cache,cached,38341,.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB); Collecting packaging==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Usin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38433,Performance,cache,cached,38433,ing==23.1; Using cached packaging-23.1-py3-none-any.whl (48 kB); Collecting pandas==2.1.0; Using cached pandas-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38555,Performance,cache,cached,38555,cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB); Collecting parsimonious==0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-no,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38643,Performance,cache,cached,38643,0.10.0; Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB); Collecting pillow==10.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38732,Performance,cache,cached,38732,.0.0; Using cached Pillow-10.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38818,Performance,cache,cached,38818,3.3 MB); Collecting plotly==5.16.1; Using cached plotly-5.16.1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38922,Performance,cache,cached,38922, portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39018,Performance,cache,cached,39018,ing protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-an,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39106,Performance,cache,cached,39106,ux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (3,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39227,Performance,cache,cached,39227,yasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39351,Performance,cache,cached,39351,modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39443,Performance,cache,cached,39443,0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39535,Performance,cache,cached,39535,ser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Col,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39608,Performance,cache,cached,39608,llecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39685,Performance,cache,cached,39685,); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39767,Performance,cache,cached,39767,2 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39885,Performance,cache,cached,39885,g python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:39975,Performance,cache,cached,39975,llecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40069,Performance,cache,cached,40069, Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (5,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40151,Performance,cache,cached,40151,64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x8,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40232,Performance,cache,cached,40232,gex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40390,Performance,cache,cached,40390,2 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filen,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40478,Performance,cache,cached,40478,any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a062707668,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40568,Performance,cache,cached,40568,37 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40655,Performance,cache,cached,40655,g s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Instal,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40742,Performance,cache,cached,40742," scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzser",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40862,Performance,cache,cached,40862," six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41027,Performance,cache,cached,41027," Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, huma",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41111,Performance,cache,cached,41111,"B); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41550,Performance,cache,cache,41550,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:42114,Performance,cache,cachetools,42114,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:43160,Performance,cache,cachetools-,43160," yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3tra",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16020,Safety,risk,risk,16020,"ld/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:32268,Safety,timeout,timeout,32268,ompile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.YoVBQEw8XF; WARNING: the legacy dependency resolver is deprecated and will be removed in future versions of pip-tools. The default resolver will be changed to 'backtracking' in pip-tools 7.0.0. Specify --resolver=backtracking to silence this warning.; + cat python/pinned-requirements.txt; + sed /#/d; + sed /#/d; + cat /tmp/tmp.YoVBQEw8XF; + diff /tmp/tmp.WRSKGgGEB8 /tmp/tmp.C8ggaXDHDt; sed '/^pyspark/d' python/pinned-requirements.txt | grep -v -e '^[[:space:]]*#' -e '^$' | tr '\n' '\0' | xargs -0 python3 -m pip install -U; Defaulting to user installation because normal site-packages is not writeable; Collecting aiodns==2.0.0; Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB); Collecting aiohttp==3.8.5; Using cached aiohttp-3.8.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB); Collecting aiosignal==1.3.1; Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB); Collecting async-timeout==4.0.3; Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB); Collecting asyncinit==0.2.4; Using cached asyncinit-0.2.4-py3-none-any.whl (2.8 kB); Collecting attrs==23.1.0; Using cached attrs-23.1.0-py3-none-any.whl (61 kB); Collecting avro==1.11.2; Using cached avro-1.11.2.tar.gz (85 kB); Installing build dependencies: started; Installing build dependencies: finished with status 'done'; Getting requirements to build wheel: started; Getting requirements to build wheel: finished with status 'done'; Preparing metadata (pyproject.toml): started; Preparing metadata (pyproject.toml): finished with status 'done'; Collecting azure-common==1.1.28; Using cached azure_common-1.1.28-py2.py3-none-any.whl (14 kB); Collecting azure-core==1.29.3; Using cached azure_core-1.29.3-py3-none-any.whl (191 kB); Collecting azure-identity==1.14.0; Using cached azure_identity-1.14.0-py3-none-any.whl (160 kB); Collecting azure-mgmt-core==1.4.0; Using cached azure_mgmt_core-1.4.0-py3-none-any.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:42156,Safety,timeout,timeout,42156,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:42925,Safety,timeout,timeout-,42925,"cker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:25127,Security,validat,validators,25127,cloud/aiogoogle/client/bigquery_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/billing_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/compute_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/container_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/iam_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/logging_client.py'; adding 'hailtop/aiocloud/aiogoogle/client/storage_client.py'; adding 'hailtop/aiocloud/common/__init__.py'; adding 'hailtop/aiocloud/common/base_client.py'; adding 'hailtop/aiocloud/common/credentials.py'; adding 'hailtop/aiocloud/common/session.py'; adding 'hailtop/aiogoogle/__init__.py'; adding 'hailtop/aiotools/__init__.py'; adding 'hailtop/aiotools/aio_contextlib.py'; adding 'hailtop/aiotools/copy.py'; adding 'hailtop/aiotools/delete.py'; adding 'hailtop/aiotools/diff.py'; adding 'hailtop/aiotools/local_fs.py'; adding 'hailtop/aiotools/router_fs.py'; adding 'hailtop/aiotools/tasks.py'; adding 'hailtop/aiotools/utils.py'; adding 'hailtop/aiotools/validators.py'; adding 'hailtop/aiotools/weighted_semaphore.py'; adding 'hailtop/aiotools/fs/__init__.py'; adding 'hailtop/aiotools/fs/copier.py'; adding 'hailtop/aiotools/fs/exceptions.py'; adding 'hailtop/aiotools/fs/fs.py'; adding 'hailtop/aiotools/fs/stream.py'; adding 'hailtop/auth/__init__.py'; adding 'hailtop/auth/auth.py'; adding 'hailtop/auth/flow.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:28779,Security,validat,validate,28779,hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collect,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:28824,Security,validat,validate,28824,'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:28833,Security,validat,validate,28833,'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/filesize.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding 'hailtop/utils/rates.py'; adding 'hailtop/utils/rich_progress_bar.py'; adding 'hailtop/utils/serialization.py'; adding 'hailtop/utils/time.py'; adding 'hailtop/utils/utils.py'; adding 'hailtop/utils/validate/__init__.py'; adding 'hailtop/utils/validate/validate.py'; adding 'hail-0.2.124.dist-info/METADATA'; adding 'hail-0.2.124.dist-info/WHEEL'; adding 'hail-0.2.124.dist-info/entry_points.txt'; adding 'hail-0.2.124.dist-info/top_level.txt'; adding 'hail-0.2.124.dist-info/RECORD'; emoving build/bdist.linux-x86_64/wheel; python3 -m pip install 'pip-tools==6.13.0' && bash ../check_pip_requirements.sh python; Defaulting to user installation because normal site-packages is not writeable; Collecting pip-tools==6.13.0; Downloading pip_tools-6.13.0-py3-none-any.whl (53 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.2/53.2 kB 15.7 MB/s eta 0:00:00; Collecting build; Downloading build-1.0.3-py3-none-any.whl (18 kB); Collecting click>=8; Downloading click-8.1.7-py3-none-any.whl (97 kB); ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.9/97.9 kB 32.4 MB/s eta 0:00:00; Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.9/site-packages (from pip-tools==6.13.0) (23.0.1); Collecting wheel; Using cached wheel-0.41.2-py3-none,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:253,Testability,log,logs,253,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:508,Testability,log,logs,508,"@danking - At first glance I do not see any installation of pyspark. * `pip show pyspark` -> WARNING: Package(s) not found: pyspark. * I see mention of `pyspark 3.3.3` in `/hail/hail/python/pinned-requirements.txt` but it seems not installed as per the logs (see below); ```; pyspark==3.3.3; # via -r hail/hail/python/requirements.txt`; ``` . * I do not see any `pyspark` in `/hail/hail/python/hailtop/hailctl/deploy.yaml`. * Checking in `/usr/lib/spark` I see reference of scala 2.12.15 same as in the hail logs; ```sh; $ cat /usr/lib/spark/RELEASE ; Spark 3.3.2-amzn-0.1 built for Hadoop 3.3.3-amzn-3.1; Build flags: -Divy.home=/home/release/.ivy2 -Dsbt.ivy.home=/home/release/.ivy2 -Duser.home=/home/release -Drepo.maven.org= -Dreactor.repo=file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" whic",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:1523,Testability,log,logs,1523,"file:///home/release/.m2/repository -Dhadoop.version=3.3.3-amzn-3.1 -Dyarn.version=3.3.3-amzn-3.1 -Dhive.version=2.3.9-amzn-3 -Dparquet.version=1.12.2-amzn-3 -Dprotobuf.version=2.5.0 -Dfasterxml.jackson.version=2.13.4 -Dfasterxml.jackson.databind.version=2.13.4 -Dcommons.httpclient.version=4.5.9 -Dcommons.httpcore.version=4.4.11 -Daws.java.sdk.version=1.12.446 -Daws.kinesis.client.version=1.12.0 -Daws.kinesis.producer.version=0.12.9 -Dscala.version=2.12.15 -DrecompileMode=all -Dmaven.deploy.plugin.version=2.8.2 -Dmaven.scaladoc.skip -Pyarn -Phadoop-3.2 -Phive -Phive-thriftserver -Psparkr -Pspark-ganglia-lgpl -Pnetlib-lgpl -Pscala-2.12 -Pkubernetes -Pvolcano -Pkinesis-asl -DskipTests; ```; I still did not found why scala is downgraded to 2.12.13. <details><summary>Hail logs</summary>; <p>; # Build Hail #; WARNING: Package(s) not found: hail; REVISION is set to ""13536b531342a263b24a7165bfeec7bd02723e4b"" which is different from old value """"; printf ""13536b531342a263b24a7165bfeec7bd02723e4b"" > env/REVISION; echo 13536b531342a263b24a7165bfeec7bd02723e4b > python/hail/hail_revision; SHORT_REVISION is set to ""13536b531342"" which is different from old value """"; printf ""13536b531342"" > env/SHORT_REVISION; HAIL_PIP_VERSION is set to ""0.2.124"" which is different from old value """"; printf ""0.2.124"" > env/HAIL_PIP_VERSION; echo 0.2.124-13536b531342 > python/hail/hail_version; echo 0.2.124 > python/hail/hail_pip_version; cp -f python/hail/hail_version python/hailtop/hail_version; printf 'hail_version=""0.2.124-13536b531342"";' > python/hail/docs/_static/hail_version.js; printf 'hail_pip_version=""0.2.124""' >> python/hail/docs/_static/hail_version.js; cloud_base is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" which is different from old value """"; printf ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342"" > env/cloud_base; wheel_cloud_path is set to ""gs://hail-30-day/hailctl/dataproc/hadoop-dev/0.2.124-13536b531342/hail-0.2.124-py3-none-any",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5023,Testability,test,testutils,5023," src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I..",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5038,Testability,test,tests,5038," src/main/resources/build-info.properties; echo 'branch=HEAD' >> src/main/resources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I..",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5065,Testability,test,testutils,5065,"sources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5080,Testability,test,tests,5080,"sources/build-info.properties; echo 'date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5098,Testability,test,testutils,5098,"date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux PartitionIterators.cpp -M",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5113,Testability,test,tests,5113,"date=2023-10-19T03:09:40Z' >> src/main/resources/build-info.properties; echo 'sparkVersion=3.3.2' >> src/main/resources/build-info.properties; echo 'hailPipVersion=0.2.124' >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux PartitionIterators.cpp -M",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5316,Testability,test,test,5316," >> src/main/resources/build-info.properties; creating env/HAIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux PartitionIterators.cpp -MG -M -MF build/PartitionIterators.d -MT build/PartitionIterators.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5342,Testability,test,test,5342,"AIL_DEBUG_MODE which does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux PartitionIterators.cpp -MG -M -MF build/PartitionIterators.d -MT build/PartitionIterators.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:5359,Testability,test,test,5359,"does not exist; ELASTIC_MAJOR_VERSION is set to ""7"" which is different from old value """"; printf ""7"" > env/ELASTIC_MAJOR_VERSION; make -C src/main/c prebuilt; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Upcalls.cpp -MG -M -MF build/Upcalls.d -MT build/Upcalls.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux testutils/unit-tests.cpp -MG -M -MF build/testutils/unit-tests.d -MT build/testutils/unit-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux test.cpp -MG -M -MF build/test.d -MT build/test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region_test.cpp -MG -M -MF build/Region_test.d -MT build/Region_test.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Region.cpp -MG -M -MF build/Region.d -MT build/Region.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux PartitionIterators.cpp -MG -M -MF build/PartitionIterators.d -MT build/PartitionIterators.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/inclu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:8245,Testability,Log,Logging,8245,le.d -MT build/NativeModule.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeLongFunc.cpp -MG -M -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeCodeSuite.cpp -MG -M -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeBoot.cpp -MG -M -MF build/NativeBoot.d -MT build/NativeBoot.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Logging.cpp -MG -M -MF build/Logging.d -MT build/Logging.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/al,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:8274,Testability,Log,Logging,8274,c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeLongFunc.cpp -MG -M -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeCodeSuite.cpp -MG -M -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeBoot.cpp -MG -M -MF build/NativeBoot.d -MT build/NativeBoot.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Logging.cpp -MG -M -MF build/Logging.d -MT build/Logging.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decod,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:8294,Testability,Log,Logging,8294,ll -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeLongFunc.cpp -MG -M -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeCodeSuite.cpp -MG -M -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux NativeBoot.cpp -MG -M -MF build/NativeBoot.d -MT build/NativeBoot.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Logging.cpp -MG -M -MF build/Logging.d -MT build/Logging.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9494,Testability,test,tests,9494,jre/include -I/etc/alternatives/jre/include/linux ibs.cpp -MG -M -MF build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9527,Testability,test,tests,9527,F build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/Na,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9551,Testability,test,tests,9551,; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/NativeBoot.o -o lib/linux-x86-,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:11505,Testability,Log,Logging,11505,de/linux build/NativeBoot.o -o lib/linux-x86-64/libboot.so; curl -sSL https://storage.googleapis.com/hail-common/libsimdpp-2.1.tar.gz > libsimdpp-2.1.tar.gz; tar -xzf libsimdpp-2.1.tar.gz; g++ -o build/ibs.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/ibs.d -MT build/ibs.o -c ibs.cpp; g++ -o build/Decoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Decoder.d -MT build/Decoder.o -c Decoder.cpp; g++ -o build/Encoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Encoder.d -MT build/Encoder.o -c Encoder.cpp; g++ -o build/Logging.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Logging.d -MT build/Logging.o -c Logging.cpp; g++ -o build/NativeCodeSuite.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o -c NativeCodeSuite.cp; p; g++ -o build/NativeLongFunc.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o -c NativeLongFunc.cpp; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:11719,Testability,Log,Logging,11719,imdpp-2.1.tar.gz; g++ -o build/ibs.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/ibs.d -MT build/ibs.o -c ibs.cpp; g++ -o build/Decoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Decoder.d -MT build/Decoder.o -c Decoder.cpp; g++ -o build/Encoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Encoder.d -MT build/Encoder.o -c Encoder.cpp; g++ -o build/Logging.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Logging.d -MT build/Logging.o -c Logging.cpp; g++ -o build/NativeCodeSuite.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o -c NativeCodeSuite.cp; p; g++ -o build/NativeLongFunc.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o -c NativeLongFunc.cpp; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -DALL_HEADER_CKSUM=2474410629UL -c NativeModule.cpp -o build/NativeModule.o; g++ -o build/NativePtr.o -ma,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:11739,Testability,Log,Logging,11739,++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/ibs.d -MT build/ibs.o -c ibs.cpp; g++ -o build/Decoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Decoder.d -MT build/Decoder.o -c Decoder.cpp; g++ -o build/Encoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Encoder.d -MT build/Encoder.o -c Encoder.cpp; g++ -o build/Logging.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Logging.d -MT build/Logging.o -c Logging.cpp; g++ -o build/NativeCodeSuite.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o -c NativeCodeSuite.cp; p; g++ -o build/NativeLongFunc.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o -c NativeLongFunc.cpp; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -DALL_HEADER_CKSUM=2474410629UL -c NativeModule.cpp -o build/NativeModule.o; g++ -o build/NativePtr.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:11752,Testability,Log,Logging,11752,-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/ibs.d -MT build/ibs.o -c ibs.cpp; g++ -o build/Decoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Decoder.d -MT build/Decoder.o -c Decoder.cpp; g++ -o build/Encoder.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Encoder.d -MT build/Encoder.o -c Encoder.cpp; g++ -o build/Logging.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Logging.d -MT build/Logging.o -c Logging.cpp; g++ -o build/NativeCodeSuite.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeCodeSuite.d -MT build/NativeCodeSuite.o -c NativeCodeSuite.cp; p; g++ -o build/NativeLongFunc.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeLongFunc.d -MT build/NativeLongFunc.o -c NativeLongFunc.cpp; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -DALL_HEADER_CKSUM=2474410629UL -c NativeModule.cpp -o build/NativeModule.o; g++ -o build/NativePtr.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-stri,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:14904,Testability,Log,Logging,14904,-Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Region.d -MT build/Region.o -c Region.cpp; g++ -o build/Upcalls.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/Upcalls.d -MT build/Upcalls.o -c Upcalls.cpp; g++ -o build/FS.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/FS.d -MT build/FS.o -c FS.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/ibs.o build/Decoder.o build/Encoder.o build/Logging.o build/Na; tiveCodeSuite.o build/NativeLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:15964,Testability,test,tested,15964,"veLongFunc.o build/NativeModule.o build/NativePtr.o build/NativeStatus.o build/ObjectArray.o build/PartitionIterators.o build/Region.o build/Upcalls.o build/FS.o -o lib/linux-x86-64/libhail.so; cp -p -f lib/linux-x86-64/libboot.so lib/linux-x86-64/libhail.so ../../../prebuilt/lib/linux-x86-64/; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; ./gradlew shadowJar -Dscala.version=2.12.15 -Dspark.version=3.3.2 -Delasticsearch.major-version=7; Downloading https://services.gradle.org/distributions/gradle-8.3-bin.zip; ............10%............20%.............30%............40%.............50%............60%.............70%............80%.............90%............100%. Welcome to Gradle 8.3!. Here are the highlights of this release:; - Faster Java compilation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel packa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16745,Testability,test,test,16745,"ation; - Reduced memory usage; - Support for running on Java 20. For more details see https://docs.gradle.org/8.3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16768,Testability,log,log,16768,"3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:27011,Testability,log,login,27011,.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/batch_client/types.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/config/variables.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/initialize.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/utils.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/config/config_variables.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; addi,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:38901,Testability,log,logger,38901,1-py2.py3-none-any.whl (15.6 MB); Collecting portalocker==2.7.0; Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB); Collecting protobuf==3.20.2; Using cached protobuf-3.20.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB); Collecting py4j==0.10.9.5; Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB); Collecting pyasn1==0.5.0; Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB); Collecting pyasn1-modules==0.3.0; Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB); Collecting pycares==4.3.0; Using cached pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB); Collecting pycparser==2.21; Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB); Collecting pygments==2.16.1; Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB); Collecting pyjwt[crypto]==2.8.0; Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB); Collecting python-dateutil==2.8.2; Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB); Collecting python-json-logger==2.0.7; Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB); Collecting pytz==2023.3.post1; Using cached pytz-2023.3.post1-py2.py3-none-any.whl (502 kB); Collecting pyyaml==6.0.1; Using cached PyYAML-6.0.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB); Collecting regex==2023.8.8; Using cached regex-2023.8.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB); Collecting requests==2.31.0; Using cached requests-2.31.0-py3-none-any.whl (62 kB); Collecting requests-oauthlib==1.3.1; Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB); Collecting rich==12.6.0; Using cached rich-12.6.0-py3-none-any.whl (237 kB); Collecting rsa==4.9; Using cached rsa-4.9-py3-none-any.whl (34 kB); Collecting s3transfer==0.6.2; Using cached s3transfer-0.6.2-py3-none-any.whl (79 kB); Collecting scipy==1.11.2; Using cached scipy-1.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.5 MB); Collecting six==1.16.0; Using cac,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:41865,Testability,log,logger,41865,"ylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-logger, pyjwt, pygments, pycparser, pyasn1, protobuf, portalocker, pillow, packaging, orjs; on, oauthlib, numpy, nest-asyncio, multidict, markupsafe, jmespath, idna, humanize, google-crc32c, frozenlist, dill, decorator, charset-normalizer, certifi, cachetools, avro, attrs, asyncinit, async-timeout, yarl, typer, scipy, rsa, rich, requests, python-dateutil, pyasn1-modules, plotly, parsimonious; , jproperties, jinja2, janus, isodate, googleapis-common-protos, google-resumable-media, deprecated, contourpy, cffi, aiosignal, requests-oauthlib, pycares, pandas, google-auth, cryptography, botocore, azure-core, aiohttp, s3transfer, msrest, google-auth-oauthlib, google-api-core, bokeh, azure-storage; -blob, azure-mgmt-core, aiodns, msal, google-cloud-core, boto3, azure-mgmt-storage, msal-extensions, google-cloud-storage, azure-identity; Attempting uninstall: packaging; Found existing installation: packaging 23.2; Uninstalling packaging-23.2:; Successfully uninstalled packaging-23.2; Successfully installed aiodns-2.0.0 aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 asyncinit-0.2.4 attrs-23.1.0 avro-1.11.2 azure-common-1.1.28 azure-core-1.29.3 azure-identity-1.14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cache",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44038,Testability,log,logger-,44038,"14.0 azure-mgmt-core-1.4.0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:16801,Usability,Clear,Clear,16801,"3/release-notes.html. Starting a Gradle Daemon (subsequent builds will be faster). > Configure project :; WARNING: Hail primarily tested with Spark 3.3.0, use other versions at your own risk. > Task :shadedazure:compileJava NO-SOURCE; > Task :shadedazure:processResources NO-SOURCE; > Task :shadedazure:classes UP-TO-DATE; > Task :shadedazure:shadowJar; > Task :compileJava NO-SOURCE; > Task :compileScala; > Task :processResources; > Task :classes; > Task :shadowJar. BUILD SUCCESSFUL in 4m 20s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; WARNING: The wheel package is not available.; WARNING: The wheel package is not available.; installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.124.dist-info/WHEEL; creating 'dist/hail-0.2.124-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; adding 'hail/backend/py4j_backend.py'; adding 'hail/backend/service_backend.py'; adding 'hail/backend/spark_backend.py'; adding 'hail/experimental/__init__.py'; a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:391,Availability,echo,echo,391,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:500,Availability,echo,echo,500,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:611,Availability,echo,echo,611,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:667,Availability,echo,echo,667,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:714,Availability,echo,echo,714,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:792,Availability,echo,echo,792,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:37,Deployability,install,installing,37,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:738,Performance,load,load-spark-env,738,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:773,Performance,load,load-spark-env,773,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:815,Performance,load,load-spark-env,815,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222:22,Usability,clear,clear,22,"@mhebrard. Just to be clear: *after* installing Hail, `/usr/bin/spark-shell --version` now shows `2.12.13` but `pip3 show pyspark` still shows ""Warning: Package(s) not found: pyspark""?. Is `/usr/bin/spark-shell` a symlink? What does it point to? Is `/usr/lib/spark` a symlink? Does it point to the same place? Actually, let's just check a bunch of things:; ```; ls -al /usr/bin/spark-shell; echo $(which spark-shell); ls -al $(which spark-shell); spark-shell --version. ls -al /usr/bin/spark-submit; echo $(which spark-submit); ls -al $(which spark-submit); spark-submit --version. ls -al /usr/bin/spark-class; echo $(which spark-class); ls -al $(which spark-class). echo SPARK_SCALA_VERSION=$SPARK_SCALA_VERSION. echo "">>>>>>>>>> before load-spark-env.sh <<<<<<<<<""; env. load-spark-env.sh. echo "">>>>>>>>>> after load-spark-env.sh <<<<<<<<<""; env. which scala; ls -al $(which scala); cat $(which scala); ```. And one more thing, can you edit `$(which spark-shell)` to add `set -x` then try `spark-shell` and see if there's anything mysterious?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1771296222
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:46,Deployability,install,install,46,"@danking -; Let's compare with & without Hail install; I don't know where to find `load-spark-env.sh` so I only print the env once. ## Without Hail. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```; <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=38; HOSTNAME=ip-192-168-96-172; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 57805 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:518,Deployability,release,release,518,"@danking -; Let's compare with & without Hail install; I don't know where to find `load-spark-env.sh` so I only print the env once. ## Without Hail. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```; <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=38; HOSTNAME=ip-192-168-96-172; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 57805 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:980,Deployability,release,release,980,"ng -; Let's compare with & without Hail install; I don't know where to find `load-spark-env.sh` so I only print the env once. ## Without Hail. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```; <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=38; HOSTNAME=ip-192-168-96-172; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 57805 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11229,Deployability,deploy,deploy,11229, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11310,Deployability,deploy,deploy,11310, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11346,Deployability,deploy,deploy,11346, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11418,Deployability,deploy,deploy,11418, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11493,Deployability,deploy,deploy,11493, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11563,Deployability,deploy,deploy,11563, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11634,Deployability,deploy,deploy,11634, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11715,Deployability,deploy,deploy,11715, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11785,Deployability,deploy,deploy,11785, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:11977,Deployability,install,installed,11977, at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:203); at org.apache.spark.repl.SparkILoop.withSuppressedSettings$1(SparkILoop.scala:189); at org.apache.spark.repl.SparkILoop.startup$1(SparkILoop.scala:201); at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:236); at org.apache.spark.repl.Main$.doMain(Main.scala:78); at org.apache.spark.repl.Main$.main(Main.scala:58); at org.apache.spark.repl.Main.main(Main.scala); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.base/java.lang.reflect.Method.invoke(Method.java:566); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:958); at org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); ```. Nothing strike my attention apart the fact that `$SPARK_SCALA_VERSION` is null and that `scala` in not found by `which` in both scenario (hail installed or not),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:83,Performance,load,load-spark-env,83,"@danking -; Let's compare with & without Hail install; I don't know where to find `load-spark-env.sh` so I only print the env once. ## Without Hail. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```; <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=38; HOSTNAME=ip-192-168-96-172; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 57805 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:1286,Performance,load,load-spark-env,1286,"l 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21; Branch ; Compiled by user release on 2023-07-19T15:12:33Z; Revision ; Url ; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```; <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=38; HOSTNAME=ip-192-168-96-172; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 57805 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:6185,Performance,load,load-spark-env,6185,"operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.21; Branch HEAD; Compiled by user liangchi on 2023-02-11T02:24:04Z; Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6; Url https://github.com/apache/spark; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```. <details><summary>>>>>>>>>>> before load-spark-env.sh <<<<<<<<<</summary>; <p>; ```sh; XDG_SESSION_ID=10; HOSTNAME=ip-192-168-124-160; TERM=xterm-256color; SHELL=/bin/bash; HISTSIZE=1000; SSH_CLIENT=103.37.196.84 60539 22; QTDIR=/usr/lib64/qt-3.3; QTINC=/usr/lib64/qt-3.3/include; SSH_TTY=/dev/pts/0; USER=hadoop; LS_COLORS=rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:3568,Testability,LOG,LOGNAME,3568,=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:; MAIL=/var/spool/mail/hadoop; PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/; AWS_DEFAULT_REGION=ap-southeast-1; PWD=/home/hadoop; JAVA_HOME=/etc/alternatives/jre; LANG=en_US.UTF-8; HISTCONTROL=ignoredups; SHLVL=1; HOME=/home/hadoop; LOGNAME=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 57805 192.168.96.172 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## With Hail (after hail build). ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindin,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:4176,Testability,log,logger,4176,";5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:; MAIL=/var/spool/mail/hadoop; PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/; AWS_DEFAULT_REGION=ap-southeast-1; PWD=/home/hadoop; JAVA_HOME=/etc/alternatives/jre; LANG=en_US.UTF-8; HISTCONTROL=ignoredups; SHLVL=1; HOME=/home/hadoop; LOGNAME=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 57805 192.168.96.172 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## With Hail (after hail build). ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; /usr/bin/spark-shell; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.21; Branch HEAD; Compiled by user liangchi on 2023-02-11T02:24:04Z; Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6; Url https://github.com/apache/spark; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-oper",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:5190,Testability,log,logger,5190,"ation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.21; Branch HEAD; Compiled by user liangchi on 2023-02-11T02:24:04Z; Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6; Url https://github.com/apache/spark; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; /usr/bin/spark-submit; -rwxr-xr-x 1 root root 141 Jul 19 15:54 /usr/bin/spark-submit; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2; /_/; ; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.21; Branch HEAD; Compiled by user liangchi on 2023-02-11T02:24:04Z; Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6; Url https://github.com/apache/spark; Type --help for more information.; ```. ```sh; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; /usr/bin/spark-class; -rwxr-xr-x 1 root root 140 Jul 19 15:54 /usr/bin/spark-class; SPARK_SCALA_VERSION=; ```. <details><summary>>>>>>>>>>> before load-sp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:8468,Testability,LOG,LOGNAME,8468,"=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:; MAIL=/var/spool/mail/hadoop; PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/; AWS_DEFAULT_REGION=ap-southeast-1; PWD=/home/hadoop; JAVA_HOME=/etc/alternatives/jre; LANG=en_US.UTF-8; HISTCONTROL=ignoredups; SHLVL=1; HOME=/home/hadoop; LOGNAME=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 60539 192.168.124.160 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## Debug mode. ```sh; $ set -x; ++ printf '\033]0;%s@%s:%s\007' hadoop ip-192-168-124-160 '~'; $ spark-shell; + spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:9016,Testability,log,logger,9016,"=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:; MAIL=/var/spool/mail/hadoop; PATH=/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/; AWS_DEFAULT_REGION=ap-southeast-1; PWD=/home/hadoop; JAVA_HOME=/etc/alternatives/jre; LANG=en_US.UTF-8; HISTCONTROL=ignoredups; SHLVL=1; HOME=/home/hadoop; LOGNAME=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 60539 192.168.124.160 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## Debug mode. ```sh; $ set -x; ++ printf '\033]0;%s@%s:%s\007' hadoop ip-192-168-124-160 '~'; $ spark-shell; + spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$1(ILoop.scala:914); at scala.tools.nsc.interpreter.ILoop.mkReader$1(ILoop.scala:920); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$4(ILoop.scala:926); at scala.tools.nsc.inte",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:9438,Testability,log,log,9438," SHLVL=1; HOME=/home/hadoop; LOGNAME=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 60539 192.168.124.160 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## Debug mode. ```sh; $ set -x; ++ printf '\033]0;%s@%s:%s\007' hadoop ip-192-168-124-160 '~'; $ spark-shell; + spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$1(ILoop.scala:914); at scala.tools.nsc.interpreter.ILoop.mkReader$1(ILoop.scala:920); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$4(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$an",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:9470,Testability,log,logging,9470,"E=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 60539 192.168.124.160 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## Debug mode. ```sh; $ set -x; ++ printf '\033]0;%s@%s:%s\007' hadoop ip-192-168-124-160 '~'; $ spark-shell; + spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$1(ILoop.scala:914); at scala.tools.nsc.interpreter.ILoop.mkReader$1(ILoop.scala:920); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$4(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:20",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045
https://github.com/hail-is/hail/issues/13837#issuecomment-1772997892:63,Deployability,install,installing,63,"Huh; somehow you received a development version of Spark after installing Hail?. ```; Using Scala version 2.12.13, OpenJDK 64-Bit Server VM, 11.0.21; Branch HEAD; Compiled by user liangchi on 2023-02-11T02:24:04Z; Revision 5103e00c4ce5fcc4264ca9c4df12295d42557af6; Url https://github.com/apache/spark; Type --help for more information.; ```. https://github.com/apache/spark/commit/5103e00c4ce5fcc4264ca9c4df12295d42557af6",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772997892
https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:109,Availability,error,error,109,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581
https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:167,Deployability,install,installin,167,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581
https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:443,Deployability,install,install,443,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581
https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:598,Deployability,install,install-on-cluster,598,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581
https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581:1399,Deployability,install,installed,1399,"@danking I try from the last commin of Hail. That seems to solve the issue of Spark version but not the java error... ```; // Setup EMR + python 3.9 + java 11 without installin hail; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Clone last commit of Hail & install; $ export PATH=$PATH:/home/hadoop/.local/bin; $ cd /tmp; $ git clone --depth 1 https://github.com/broadinstitute/hail.git; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; // Check pyspark; $ pyspark --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/; ; Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21. // Create symlink to hail-all-spark.jar; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python${PYTHON_VERSION}/site-packages/hail/backend /opt/hail/backend; // Launch spark-shell; $ spark-shell; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; ```. Could it be a problem of PATH ? issue with where Hail is installed ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1775200581
https://github.com/hail-is/hail/issues/13837#issuecomment-1777469472:172,Deployability,install,install,172,@danking - Do you have an idea from where this problematic java class should be sourced from ?; I do recall needed to mandle with some symlinks between java directories to install an old version of Hail as JDK was installed properly but some jar from JRE was needed and not present in the JDK directory. ```sh; # for Hail v0.2.32; sudo ln -s /etc/alternatives/java_sdk/include /etc/alternatives/jre/include; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777469472
https://github.com/hail-is/hail/issues/13837#issuecomment-1777469472:214,Deployability,install,installed,214,@danking - Do you have an idea from where this problematic java class should be sourced from ?; I do recall needed to mandle with some symlinks between java directories to install an old version of Hail as JDK was installed properly but some jar from JRE was needed and not present in the JDK directory. ```sh; # for Hail v0.2.32; sudo ln -s /etc/alternatives/java_sdk/include /etc/alternatives/jre/include; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777469472
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:72,Deployability,install,installation,72,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:150,Deployability,configurat,configuration,150,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:321,Deployability,install,installation,321,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:699,Deployability,install,install,699,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:716,Deployability,install,install-on-cluster,716,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782:150,Modifiability,config,configuration,150,"@mhebrard I would expect that `MutableSettings` to come from your Spark installation. I think there are two problems:; 1. For some reason, our gradle configuration is including `MutableSettings`. We should get rid of that, but I haven't yet figured out how to do that.; 2. Normally (1) isn't a problem because your Spark installation appears on the class path before Hail does. It seems to me that this isn't true in your case. This is probably caused by linking the Hail JAR into `/opt`. Is `/opt/hail/backend` on your class path? Why do you link the backend directory into `/opt`? The Hail JAR should be distributed automatically by Spark. You shouldn't need to do anything special after you `pip install` / `make install-on-cluster`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777706782
https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812:229,Deployability,configurat,configurations,229,"@mhebrard can you try applying this diff and then building?. ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index d4bdd879f0..1b65904484 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -100,6 +100,7 @@ configurations {; hailJar.extendsFrom implementation; hailJar {; exclude group: 'org.scala-lang', module: 'scala-library'; + exclude group: 'org.scala-lang', module: 'scala-reflect'; exclude group: 'org.apache.spark'; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812
https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812:229,Modifiability,config,configurations,229,"@mhebrard can you try applying this diff and then building?. ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index d4bdd879f0..1b65904484 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -100,6 +100,7 @@ configurations {; hailJar.extendsFrom implementation; hailJar {; exclude group: 'org.scala-lang', module: 'scala-library'; + exclude group: 'org.scala-lang', module: 'scala-reflect'; exclude group: 'org.apache.spark'; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812
https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812:255,Modifiability,extend,extendsFrom,255,"@mhebrard can you try applying this diff and then building?. ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index d4bdd879f0..1b65904484 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -100,6 +100,7 @@ configurations {; hailJar.extendsFrom implementation; hailJar {; exclude group: 'org.scala-lang', module: 'scala-library'; + exclude group: 'org.scala-lang', module: 'scala-reflect'; exclude group: 'org.apache.spark'; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1777721812
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:144,Availability,error,error,144,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2053,Availability,avail,available,2053,"; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populati",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2143,Availability,avail,available,2143,"""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2233,Availability,avail,available,2233,"4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2735,Availability,avail,available,2735,"ARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:84,Deployability,install,installing,84,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:103,Deployability,Update,Update,103,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:182,Deployability,install,installation,182,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:504,Deployability,install,install-on-cluster,504,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:673,Deployability,install,installation,673,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2338,Deployability,install,installed,2338,"er details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2373,Deployability,configurat,configuration,2373,"er details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3413,Deployability,Configurat,ConfigurationProperties,3413,"erring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:772,Modifiability,config,config,772,"@danking. Here what I have done in my environment ( AWS EMR ); * Create EMR without installing hail; * Update PATH ( this is needed or I get an error with `hailctl not found` at the installation step); ```sh; export PATH=$PATH:/home/hadoop/.local/bin; ```; * Clone latest commit of Hail; ```sh; cd /tmp; git clone --depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2373,Modifiability,config,configuration,2373,"er details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3362,Modifiability,config,configs,3362,"ires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/u",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3413,Modifiability,Config,ConfigurationProperties,3413,"erring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3809,Security,secur,security,3809,"/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.serializer: org.apache.spark.serializer.KryoSerializer; spark.kryo.registrator: is.hail.kryo.HailKryoRegistrator; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3842,Security,secur,security,3842,"/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.serializer: org.apache.spark.serializer.KryoSerializer; spark.kryo.registrator: is.hail.kryo.HailKryoRegistrator; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:4428,Security,secur,security,4428,"/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.serializer: org.apache.spark.serializer.KryoSerializer; spark.kryo.registrator: is.hail.kryo.HailKryoRegistrator; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:4461,Security,secur,security,4461,"/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.serializer: org.apache.spark.serializer.KryoSerializer; spark.kryo.registrator: is.hail.kryo.HailKryoRegistrator; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:1312,Testability,log,logger,1312,"--depth 1 https://github.com/broadinstitute/hail.git; cd hail/hail/; ```; * Edit `build.gradle` and add `exclude group: 'org.scala-lang', module: 'scala-reflect'`; * Build Hail; ```sh; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.2; ```; * Symlink hail-all-spark.jar into /opt ( At the EMR creation step (before hail installation) I edit the `spark-defaults` properties in order to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a954",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:1734,Testability,log,log,1734,"to link `hail-all-spark.jar`... This config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:1766,Testability,log,logging,1766,"s config was needed & works successfuly for an old version of Hail (0.2.60)... can be revisit if not appropriate for recent version; ```sh; sudo mkdir /opt/hail/; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * start pyspark; ```sh; $ pyspark; Python 3.9.18 (main, Oct 25 2023, 05:26:35) ; [GCC 7.3.1 20180712 (Red Hat 7.3.1-17)] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2917,Testability,LOG,LOGGING,2917,"/_/\_\ version 3.3.2-amzn-0.1; /_/. Using Python version 3.9.18 (main, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:2996,Testability,log,log,2996,"ain, Oct 25 2023 05:26:35); Spark context Web UI available at http://ip-192-168-125-39.ap-southeast-1.compute.internal:4040; Spark context available as 'sc' (master = yarn, app id = application_1698211907929_0001).; SparkSession available as 'spark'.; >>> import hail as hl; >>> hl.version(); '0.2.124-e739a95489e4'; hl.init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949:3314,Testability,test,test,3314,".init(sc); pip-installed Hail requires additional configuration options in Spark referring; to the path to the Hail Python module directory HAIL_DIR,; e.g. /path/to/python/site-packages/hail:; spark.jars=HAIL_DIR/backend/hail-all-spark.jar; spark.driver.extraClassPath=HAIL_DIR/backend/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jarRunning on Apache Spark version 3.3.2-amzn-0.1; SparkUI available at http://ip-192-168-110-167.ap-southeast-1.compute.internal:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.124-e739a95489e4; LOGGING: writing to /mnt/tmp/hail/hail/hail-20231025-0729-0.2.124-e739a95489e4.log; >>> mt = hl.balding_nichols_model(n_populations=3, n_samples=500, n_variants=1_000); 2023-10-25 07:29:48.283 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 500 samples, and 1000 variants...; >>> mt.count(); (1000, 500); ```. it seems working in command line using pyspark !. I need to test on jupyter notebook now... FYI the pyspark configs. ```sh ; - Classification: spark-defaults; ConfigurationProperties:; spark.jars: /opt/hail/backend/hail-all-spark.jar; spark.driver.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar; spark.executor.extraClassPath: /opt/hail/backend/hail-all-spark.jar:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1778834949
https://github.com/hail-is/hail/issues/13837#issuecomment-1782294182:75,Deployability,install,install,75,Thanks ! ; I saw that the fix is merged on #13806 v0.2.125 !; I am able to install hail and run it using command line. I do have an issue with jupyter through... working on it,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1782294182
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13842#issuecomment-1769451159
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13844#issuecomment-1769451094
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13845#issuecomment-1768504114
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13846#issuecomment-1768503804
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769458602
https://github.com/hail-is/hail/pull/13852#issuecomment-1769474476:101,Deployability,release,released,101,"We're several months away from Python 3.10. > On Apr 05, 2024 drop support for Python 3.9 (initially released on Oct 05, 2020). https://numpy.org/neps/nep-0029-deprecation_policy.html",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13852#issuecomment-1769474476
https://github.com/hail-is/hail/pull/13853#issuecomment-1775553836:17,Deployability,release,released,17,uvloop 0.19.0 is released; pushing an update to 0.19.0 now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13853#issuecomment-1775553836
https://github.com/hail-is/hail/pull/13853#issuecomment-1775553836:38,Deployability,update,update,38,uvloop 0.19.0 is released; pushing an update to 0.19.0 now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13853#issuecomment-1775553836
https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741:438,Availability,error,error,438,"We should add docs that describe how to do this to:; 1. `hl.default_reference`, obviously; 2. Deprecate the `reference_genome` parameter to `hl.init` and instruct users to use `hl.default_reference`. Inform that this parameter has confusing interactions with ReferenceGenome, so we're removing it.; 3. `hl.ReferenceGenome.__init__` should refer users to that. . I think we should also make a separate PR that improves the `hl.import_vcf` error message. If the backend throws an error like; ```; HailException: Invalid locus '1:249367215' found. Position '249367215' is not within the range [1-249250621] for reference genome 'GRCh37'.; ```; `import_vcf` should catch and wrap with another exception that suggests you use a `reference_genome` parameter or `hl.default_reference`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741
https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741:478,Availability,error,error,478,"We should add docs that describe how to do this to:; 1. `hl.default_reference`, obviously; 2. Deprecate the `reference_genome` parameter to `hl.init` and instruct users to use `hl.default_reference`. Inform that this parameter has confusing interactions with ReferenceGenome, so we're removing it.; 3. `hl.ReferenceGenome.__init__` should refer users to that. . I think we should also make a separate PR that improves the `hl.import_vcf` error message. If the backend throws an error like; ```; HailException: Invalid locus '1:249367215' found. Position '249367215' is not within the range [1-249250621] for reference genome 'GRCh37'.; ```; `import_vcf` should catch and wrap with another exception that suggests you use a `reference_genome` parameter or `hl.default_reference`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741
https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741:444,Integrability,message,message,444,"We should add docs that describe how to do this to:; 1. `hl.default_reference`, obviously; 2. Deprecate the `reference_genome` parameter to `hl.init` and instruct users to use `hl.default_reference`. Inform that this parameter has confusing interactions with ReferenceGenome, so we're removing it.; 3. `hl.ReferenceGenome.__init__` should refer users to that. . I think we should also make a separate PR that improves the `hl.import_vcf` error message. If the backend throws an error like; ```; HailException: Invalid locus '1:249367215' found. Position '249367215' is not within the range [1-249250621] for reference genome 'GRCh37'.; ```; `import_vcf` should catch and wrap with another exception that suggests you use a `reference_genome` parameter or `hl.default_reference`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741
https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741:671,Integrability,wrap,wrap,671,"We should add docs that describe how to do this to:; 1. `hl.default_reference`, obviously; 2. Deprecate the `reference_genome` parameter to `hl.init` and instruct users to use `hl.default_reference`. Inform that this parameter has confusing interactions with ReferenceGenome, so we're removing it.; 3. `hl.ReferenceGenome.__init__` should refer users to that. . I think we should also make a separate PR that improves the `hl.import_vcf` error message. If the backend throws an error like; ```; HailException: Invalid locus '1:249367215' found. Position '249367215' is not within the range [1-249250621] for reference genome 'GRCh37'.; ```; `import_vcf` should catch and wrap with another exception that suggests you use a `reference_genome` parameter or `hl.default_reference`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13856#issuecomment-1771234741
https://github.com/hail-is/hail/issues/13861#issuecomment-1771461424:144,Availability,error,error,144,"There is always a race because `crun` will delete the cgroup once the container completes. Looks like the memory tracking checks for this exact error but not cpu, it would assume it should be both.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13861#issuecomment-1771461424
https://github.com/hail-is/hail/issues/13862#issuecomment-1771508011:1522,Testability,assert,assert,1522,"ssBuilder.scala b/hail/src/main/scala/is/hail/expr/ir/EmitClassBuilder.scala; index 115df824b3..6e5ee81e6a 100644; --- a/hail/src/main/scala/is/hail/expr/ir/EmitClassBuilder.scala; +++ b/hail/src/main/scala/is/hail/expr/ir/EmitClassBuilder.scala; @@ -59,6 +59,35 @@ class EmitModuleBuilder(val ctx: ExecuteContext, val modb: ModuleBuilder) {; new StaticFieldRef(rgField); }; ; + class LoweredReferenceGenome(; + name: SStringPointerValue,; + contigs: SIndexablePointerValue,; + lengths: SIndexablePointerValue,; + xContigs: SIndexablePointerValue,; + yContigs: SIndexablePointerValue,; + mtContigs: SIndexablePointerValue,; + parInterval: SIntervalPointerValue; + ); +; + private val loweredReferences: mutable.Map[String, StaticField[Long]] = mutable.Map.empty; +; + def getLoweredReferenceGenome(cb: EmitCodeBuilder, name: String): LoweredReferenceGenome = {; + loweredReferences.getOrElseUpdate(name, {; + val ecb = genEmitClass[Unit](s""lowered_reference_${name}""); + val rg = ctx.getReference(name); + assert(rg.name == name); + new LoweredReferenceGenome(; + ecb.addLiteral(cb, rg.name, VirtualTypeWithReq.fullyRequired(TString)).asInstanceOf[SStringPointerValue],; + ecb.addLiteral(cb, rg.contigs, VirtualTypeWithReq.fullyRequired(TArray(TString))).asInstanceOf[SIndexablePointerValue],; + ecb.addLiteral(cb, rg.lengths, VirtualTypeWithReq.fullyRequired(TArray(TInt32))).asInstanceOf[SIndexablePointerValue],; + ecb.addLiteral(cb, rg.xContigs, VirtualTypeWithReq.fullyRequired(TSet(TString))).asInstanceOf[SIndexablePointerValue],; + ecb.addLiteral(cb, rg.yContigs, VirtualTypeWithReq.fullyRequired(TSet(TString))).asInstanceOf[SIndexablePointerValue],; + ecb.addLiteral(cb, rg.mtContigs, VirtualTypeWithReq.fullyRequired(TSet(TString))).asInstanceOf[SIndexablePointerValue],; + ecb.addLiteral(cb, Interval(rg.parInput._1, rg.parInput._2), VirtualTypeWithReq.fullyRequired(TInterval(TLocus(rg.name)))).asInstanceOf[SIntervalPointerValue]; + ); + }; + }; +; def referenceGenomes(): IndexedSeq[Re",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13862#issuecomment-1771508011
https://github.com/hail-is/hail/issues/13862#issuecomment-1773407789:11,Deployability,pipeline,pipeline,11,"FWIW, this pipeline was performing these checks perhaps as many as 10 times per genotype, which is obviously unreasonable. Nonetheless, sending the RG along as a literal should improve the speed of these operations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13862#issuecomment-1773407789
https://github.com/hail-is/hail/issues/13862#issuecomment-1773407789:24,Performance,perform,performing,24,"FWIW, this pipeline was performing these checks perhaps as many as 10 times per genotype, which is obviously unreasonable. Nonetheless, sending the RG along as a literal should improve the speed of these operations.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13862#issuecomment-1773407789
https://github.com/hail-is/hail/issues/13863#issuecomment-1788047416:131,Availability,error,errors,131,I think this is a very similar bug: https://github.com/aio-libs/aiomysql/issues/539. Turning off uvloop seemed to get rid of these errors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13863#issuecomment-1788047416
https://github.com/hail-is/hail/issues/13863#issuecomment-1792532420:54,Availability,error,errors,54,"Let's see if #13969 fixes this. If we don't see these errors again over the next week, let's close this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13863#issuecomment-1792532420
https://github.com/hail-is/hail/issues/13864#issuecomment-1785898859:119,Availability,down,downstream,119,I met with Lily and Ruchit. They have more work they need to do to figure out what their use case is and how they want downstream analysts to use the data to figure out how to key their datasets. They'll get back to me once they're ready.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13864#issuecomment-1785898859
https://github.com/hail-is/hail/pull/13870#issuecomment-1775410645:88,Performance,perform,performance,88,"Much better! I understand what's going on now. Just to make sure I understand where the performance improvements are, we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775410645
https://github.com/hail-is/hail/pull/13870#issuecomment-1775410645:198,Performance,queue,queue,198,"Much better! I understand what's going on now. Just to make sure I understand where the performance improvements are, we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775410645
https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156:631,Availability,avail,available,631,"> we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?. No. We have no way to accept only JVM jobs or only Batch jobs, so we either accept all jobs or no jobs. In main, we accept jobs before the JVMs have initialized. We wait for all JVMs to initialize before giving JVMs to any JVM Job. So, concretely, in main and in this PR we *accept* jobs before JVMs are ready; however, in this PR we don't wait for all JVMs to initialize before *running* jobs. There are two improvements in this PR:; 1. If a JVM with the requested number of cores is available, allow the requesting JVMJob to start before the remaining JVMs are initialized.; 2. Rather than starting all the JVMs in parallel, start JVMs serially *and also* start them in the order that they are requested. If we have three waiting JVM Jobs two requesting 1 core and one requesting 4 cores, prefer to start JVMs with 1 and 4 cores to JVMs with 2 or 8 cores. (2) might sound slower (why start serially when we can stat in parallel?) but it appears that 30 JVMs competing for CPU time dramatically slows down average start up time. In both main and this PR it takes about ~25s for all JVMs to be ready; however, in this PR, some jobs can start much sooner than 25s b/c their JVMs are started first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156
https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156:1148,Availability,down,down,1148,"> we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?. No. We have no way to accept only JVM jobs or only Batch jobs, so we either accept all jobs or no jobs. In main, we accept jobs before the JVMs have initialized. We wait for all JVMs to initialize before giving JVMs to any JVM Job. So, concretely, in main and in this PR we *accept* jobs before JVMs are ready; however, in this PR we don't wait for all JVMs to initialize before *running* jobs. There are two improvements in this PR:; 1. If a JVM with the requested number of cores is available, allow the requesting JVMJob to start before the remaining JVMs are initialized.; 2. Rather than starting all the JVMs in parallel, start JVMs serially *and also* start them in the order that they are requested. If we have three waiting JVM Jobs two requesting 1 core and one requesting 4 cores, prefer to start JVMs with 1 and 4 cores to JVMs with 2 or 8 cores. (2) might sound slower (why start serially when we can stat in parallel?) but it appears that 30 JVMs competing for CPU time dramatically slows down average start up time. In both main and this PR it takes about ~25s for all JVMs to be ready; however, in this PR, some jobs can start much sooner than 25s b/c their JVMs are started first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156
https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156:82,Performance,queue,queue,82,"> we don't wait for all JVMs to be intitialized before accepting JVM jobs and the queue is FIFO so we reuse the same JVMs that are warm already?. No. We have no way to accept only JVM jobs or only Batch jobs, so we either accept all jobs or no jobs. In main, we accept jobs before the JVMs have initialized. We wait for all JVMs to initialize before giving JVMs to any JVM Job. So, concretely, in main and in this PR we *accept* jobs before JVMs are ready; however, in this PR we don't wait for all JVMs to initialize before *running* jobs. There are two improvements in this PR:; 1. If a JVM with the requested number of cores is available, allow the requesting JVMJob to start before the remaining JVMs are initialized.; 2. Rather than starting all the JVMs in parallel, start JVMs serially *and also* start them in the order that they are requested. If we have three waiting JVM Jobs two requesting 1 core and one requesting 4 cores, prefer to start JVMs with 1 and 4 cores to JVMs with 2 or 8 cores. (2) might sound slower (why start serially when we can stat in parallel?) but it appears that 30 JVMs competing for CPU time dramatically slows down average start up time. In both main and this PR it takes about ~25s for all JVMs to be ready; however, in this PR, some jobs can start much sooner than 25s b/c their JVMs are started first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13870#issuecomment-1775517156
https://github.com/hail-is/hail/issues/13875#issuecomment-1773441587:61,Testability,Test,Testing,61,"Ah, I've been running into this as well and didn't know why. Testing all the hooks seems reasonable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13875#issuecomment-1773441587
https://github.com/hail-is/hail/pull/13876#issuecomment-1772950616:110,Integrability,message,messages,110,This seems fine to me. I think we should check the worker and driver logs and make sure there's no unexpected messages though before merging.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13876#issuecomment-1772950616
https://github.com/hail-is/hail/pull/13876#issuecomment-1772950616:69,Testability,log,logs,69,This seems fine to me. I think we should check the worker and driver logs and make sure there's no unexpected messages though before merging.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13876#issuecomment-1772950616
https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401:21,Performance,optimiz,optimization,21,"One obvious point of optimization that Dan already identified is the way we were keying our data is causing full shuffles, as we were keying the data by a string variant ID in the form `1-32683987-ACTCTT-A` instead of locus-allele. Changing back to keying on locus-allele fixes this issue for our more straightforward searches, but we have a search that looks for pairs of possible compound heterozygous variants in the same gene, and that still is resulting in 2 full shuffles. I'm a little at a loss for how to fix this, because we are grouping by an unsorted field so I'm not sure how to prevent us from working with an unsorted dataset. The offending code right now is as follows (somewhat simplified for readability):. ```; primary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_ANNOTATION], hl.agg.collect(ch_ht.row)); secondary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_SECONDARY_ANNOTATION], hl.agg.collect(ch_ht.row)); ch_ht = ch_ht.group_by('gene_ids').aggregate(v1=primary_variants, v2=secondary_variants); ch_ht = ch_ht.explode(ch_ht.v1); ch_ht = ch_ht.explode(ch_ht.v2); ch_ht = ch_ht.annotate(grouped_variants=hl.sorted([ch_ht.v1, ch_ht.v2], key=lambda v: (v.locus, v.alleles))); ch_ht = ch_ht.key_by(; locus=ch_ht.grouped_variants[0].locus, ; alleles=ch_ht.grouped_variants[0].alleles,; locus2=ch_ht.grouped_variants[1].locus, ; alleles2=ch_ht.grouped_variants[1].alleles,; ); ch_ht = ch_ht.distinct(); ...; # more filtering and annotating; ...; return ch_ht._key_by_assert_sorted('locus', 'alleles'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401
https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401:694,Usability,simpl,simplified,694,"One obvious point of optimization that Dan already identified is the way we were keying our data is causing full shuffles, as we were keying the data by a string variant ID in the form `1-32683987-ACTCTT-A` instead of locus-allele. Changing back to keying on locus-allele fixes this issue for our more straightforward searches, but we have a search that looks for pairs of possible compound heterozygous variants in the same gene, and that still is resulting in 2 full shuffles. I'm a little at a loss for how to fix this, because we are grouping by an unsorted field so I'm not sure how to prevent us from working with an unsorted dataset. The offending code right now is as follows (somewhat simplified for readability):. ```; primary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_ANNOTATION], hl.agg.collect(ch_ht.row)); secondary_variants = hl.agg.filter(ch_ht[HAS_ALLOWED_SECONDARY_ANNOTATION], hl.agg.collect(ch_ht.row)); ch_ht = ch_ht.group_by('gene_ids').aggregate(v1=primary_variants, v2=secondary_variants); ch_ht = ch_ht.explode(ch_ht.v1); ch_ht = ch_ht.explode(ch_ht.v2); ch_ht = ch_ht.annotate(grouped_variants=hl.sorted([ch_ht.v1, ch_ht.v2], key=lambda v: (v.locus, v.alleles))); ch_ht = ch_ht.key_by(; locus=ch_ht.grouped_variants[0].locus, ; alleles=ch_ht.grouped_variants[0].alleles,; locus2=ch_ht.grouped_variants[1].locus, ; alleles2=ch_ht.grouped_variants[1].alleles,; ); ch_ht = ch_ht.distinct(); ...; # more filtering and annotating; ...; return ch_ht._key_by_assert_sorted('locus', 'alleles'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1776044401
https://github.com/hail-is/hail/issues/13882#issuecomment-1783285545:8,Deployability,update,update,8,"Just to update, when updating to 0.2.125 I discovered a bug :( https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/array.20index.20out.20of.20bounds.20error.20on.20dict.2Eget",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1783285545
https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654:145,Modifiability,enhance,enhancements,145,"we now have our dev test environment running with hail 0.2.126 and this query took ~92 seconds. So faster, but we do still need some performance enhancements. @ehigham let me know what would be helpful for you to get you started on this effort",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654
https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654:133,Performance,perform,performance,133,"we now have our dev test environment running with hail 0.2.126 and this query took ~92 seconds. So faster, but we do still need some performance enhancements. @ehigham let me know what would be helpful for you to get you started on this effort",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654
https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654:20,Testability,test,test,20,"we now have our dev test environment running with hail 0.2.126 and this query took ~92 seconds. So faster, but we do still need some performance enhancements. @ehigham let me know what would be helpful for you to get you started on this effort",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1795785654
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:123,Availability,down,down,123,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:225,Availability,reliab,reliably,225,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:195,Performance,perform,performance,195,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:354,Performance,perform,performance,354,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:280,Testability,log,logs,280,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:411,Testability,log,log,411,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:475,Testability,log,log,475,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779
https://github.com/hail-is/hail/issues/13882#issuecomment-1810939501:385,Availability,avail,available,385,"seqr hail search code is here: https://github.com/broadinstitute/seqr/tree/master/hail_search. Running the aiohttp service is just `python -m hail_search`. Runs on hail 0.2.126. The data you need is `gs://seqr-datasets/v03/GRCh38/SNV_INDEL/runs/manual__2023-11-07T23-31-23.149902+00-00`; For running the service, you need a `DATASETS_DIR` env variable defined, and that data should be available at `$DATASETS_DIR/GRCh38/SNV_INDEL`. Post body for a relatively quick search:; ```; {; ""genome_version"": ""GRCh38"",; ""num_results"": 100,; ""annotations"": {; ""in_frame"": [; ""inframe_insertion"",; ""inframe_deletion""; ],; ""missense"": [; ""stop_lost"",; ""initiator_codon_variant"",; ""start_lost"",; ""protein_altering_variant"",; ""missense_variant""; ],; ""nonsense"": [; ""stop_gained""; ],; ""splice_ai"": ""0.2"",; ""frameshift"": [; ""frameshift_variant""; ],; ""structural"": [],; ""extended_splice_site"": [],; ""essential_splice_site"": [; ""splice_donor_variant"",; ""splice_acceptor_variant""; ],; ""structural_consequence"": [; ""LOF"",; ""DUP_LOF"",; ""INV_SPAN"",; ""COPY_GAIN""; ]; },; ""datasetType"": ""VARIANTS"",; ""pathogenicity"": {; ""hgmd"": [; ""disease_causing""; ],; ""clinvar"": [; ""pathogenic"",; ""likely_pathogenic""; ]; },; ""dataset_type"": ""ALL"",; ""secondary_dataset_type"": null,; ""inheritance_mode"": ""de_novo"",; ""inheritance_filter"": {; ""A"": ""has_alt"",; ""N"": ""ref_ref""; },; ""sample_data"": {; ""SNV_INDEL"": [; {; ""sample_id"": ""RGP_2436_2_D1"",; ""individual_guid"": ""I0097169_rgp_2436_2"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""N""; },; {; ""sample_id"": ""RGP_2436_3_D1"",; ""individual_guid"": ""I0097170_rgp_2436_3"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""A""; },; {; ""sample_id"": ""RGP_2436_1_D1"",; ""individual_guid"": ""I0097168_rgp_2436_1"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""N""; }; ]; },; ""sort"": ""xpos"",; ""sort_metadata"": null,; ""frequencies"": {; ""g1k"": {;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1810939501
https://github.com/hail-is/hail/issues/13882#issuecomment-1810939501:343,Modifiability,variab,variable,343,"seqr hail search code is here: https://github.com/broadinstitute/seqr/tree/master/hail_search. Running the aiohttp service is just `python -m hail_search`. Runs on hail 0.2.126. The data you need is `gs://seqr-datasets/v03/GRCh38/SNV_INDEL/runs/manual__2023-11-07T23-31-23.149902+00-00`; For running the service, you need a `DATASETS_DIR` env variable defined, and that data should be available at `$DATASETS_DIR/GRCh38/SNV_INDEL`. Post body for a relatively quick search:; ```; {; ""genome_version"": ""GRCh38"",; ""num_results"": 100,; ""annotations"": {; ""in_frame"": [; ""inframe_insertion"",; ""inframe_deletion""; ],; ""missense"": [; ""stop_lost"",; ""initiator_codon_variant"",; ""start_lost"",; ""protein_altering_variant"",; ""missense_variant""; ],; ""nonsense"": [; ""stop_gained""; ],; ""splice_ai"": ""0.2"",; ""frameshift"": [; ""frameshift_variant""; ],; ""structural"": [],; ""extended_splice_site"": [],; ""essential_splice_site"": [; ""splice_donor_variant"",; ""splice_acceptor_variant""; ],; ""structural_consequence"": [; ""LOF"",; ""DUP_LOF"",; ""INV_SPAN"",; ""COPY_GAIN""; ]; },; ""datasetType"": ""VARIANTS"",; ""pathogenicity"": {; ""hgmd"": [; ""disease_causing""; ],; ""clinvar"": [; ""pathogenic"",; ""likely_pathogenic""; ]; },; ""dataset_type"": ""ALL"",; ""secondary_dataset_type"": null,; ""inheritance_mode"": ""de_novo"",; ""inheritance_filter"": {; ""A"": ""has_alt"",; ""N"": ""ref_ref""; },; ""sample_data"": {; ""SNV_INDEL"": [; {; ""sample_id"": ""RGP_2436_2_D1"",; ""individual_guid"": ""I0097169_rgp_2436_2"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""N""; },; {; ""sample_id"": ""RGP_2436_3_D1"",; ""individual_guid"": ""I0097170_rgp_2436_3"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""A""; },; {; ""sample_id"": ""RGP_2436_1_D1"",; ""individual_guid"": ""I0097168_rgp_2436_1"",; ""family_guid"": ""F041731_rgp_2436"",; ""project_guid"": ""R0594_rare_genomes_project_gen"",; ""affected"": ""N""; }; ]; },; ""sort"": ""xpos"",; ""sort_metadata"": null,; ""frequencies"": {; ""g1k"": {;",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1810939501
https://github.com/hail-is/hail/issues/13882#issuecomment-1821470558:127,Safety,sanity check,sanity check,127,"In our dev environment the first query runs in 10s, but the second one runs in 77s, if it ran in 20 we'd be fine with it. As a sanity check, the first query should have 3 results and the second should have 85",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821470558
https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905:46,Availability,down,downloaded,46,"Ah the timings were slightly off as I had not downloaded all the data and was using some from `hail_search/fixtures`.; After pulling down the `SNV_INDELS` data, my updated timings are:. | query | results | elapsed |; | ----- | ------- | ------- |; | 0 | 4 | 7s |; | 1 | 83 | 50s |",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905
https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905:133,Availability,down,down,133,"Ah the timings were slightly off as I had not downloaded all the data and was using some from `hail_search/fixtures`.; After pulling down the `SNV_INDELS` data, my updated timings are:. | query | results | elapsed |; | ----- | ------- | ------- |; | 0 | 4 | 7s |; | 1 | 83 | 50s |",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905
https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905:164,Deployability,update,updated,164,"Ah the timings were slightly off as I had not downloaded all the data and was using some from `hail_search/fixtures`.; After pulling down the `SNV_INDELS` data, my updated timings are:. | query | results | elapsed |; | ----- | ------- | ------- |; | 0 | 4 | 7s |; | 1 | 83 | 50s |",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821595905
https://github.com/hail-is/hail/issues/13882#issuecomment-1821636774:184,Testability,test,test,184,"the data should be really deterministic so I'm not sure why those counts are off, but at least those counts and times are more accurate to what we are seeing so probably it means your test environment is reasonable. I would recommend against using the `hail_search/fixtures` data for anything other than running the test suite, its not designed to play nicely with real data",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821636774
https://github.com/hail-is/hail/issues/13882#issuecomment-1821636774:316,Testability,test,test,316,"the data should be really deterministic so I'm not sure why those counts are off, but at least those counts and times are more accurate to what we are seeing so probably it means your test environment is reasonable. I would recommend against using the `hail_search/fixtures` data for anything other than running the test suite, its not designed to play nicely with real data",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821636774
https://github.com/hail-is/hail/issues/13882#issuecomment-1821675042:186,Testability,test,test,186,"> the data should be really deterministic so I'm not sure why those counts are off, but at least those counts and times are more accurate to what we are seeing so probably it means your test environment is reasonable. I guess the exact query isn't important, more the code shape and the kinds of operations hail's doing. Given the timings, it may be more-or-less representative.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821675042
https://github.com/hail-is/hail/issues/13882#issuecomment-1821675629:254,Performance,perform,performance,254,"Dan and I have profiled the second query and have a couple of thoughts. We've identified one source of slowness in the compiler and generated code that relates to how we handle I/O. This is currently under active development and hope will lead to decent performance improvements. The change itself is significant, however, so I can't comment on timelines for when to expect the work to be complete by. There may be some code tweaks that do less work as discussed. I'll have a play with the source code in `hail_search` and report back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1821675629
https://github.com/hail-is/hail/issues/13882#issuecomment-1828333357:487,Performance,perform,performance,487,"The current logic of `key_by` and `distinct` to remove duplicate pairs is actually not properly deduplicating pairs in some cases. Since I know that thats not really the approach we want in the long run I didn't bother figuring out why, and instead tried implementing a version of the code that filters out duplicate pairs before exploding, which should result in less work overall. However, I somehow introduced an extra `Ordering unsorted dataset with network shuffle` and the overall performance of that search got slower by 15 seconds. . Here is the change I made. Let me know if you have a better approach for filtering out duplicates, or if you see any ways to reorganize this code to make it less shuffle-y; https://github.com/broadinstitute/seqr/commit/2e45403efc159b58cec723f86e6de7653d64cf5f",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1828333357
https://github.com/hail-is/hail/issues/13882#issuecomment-1828333357:12,Testability,log,logic,12,"The current logic of `key_by` and `distinct` to remove duplicate pairs is actually not properly deduplicating pairs in some cases. Since I know that thats not really the approach we want in the long run I didn't bother figuring out why, and instead tried implementing a version of the code that filters out duplicate pairs before exploding, which should result in less work overall. However, I somehow introduced an extra `Ordering unsorted dataset with network shuffle` and the overall performance of that search got slower by 15 seconds. . Here is the change I made. Let me know if you have a better approach for filtering out duplicates, or if you see any ways to reorganize this code to make it less shuffle-y; https://github.com/broadinstitute/seqr/commit/2e45403efc159b58cec723f86e6de7653d64cf5f",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1828333357
https://github.com/hail-is/hail/issues/13882#issuecomment-1828689808:314,Availability,error,errors,314,"I've taking a similar approach to try to remove unwanted elements before exploding. Sadly, I haven't seen any noticable improvement. I'm also not sure about correctness as I couldn't get your changes in [2e45403](https://github.com/broadinstitute/seqr/commit/2e45403efc159b58cec723f86e6de7653d64cf5f) to work (got errors about missing `gene_ids`). I saw ~20 fewer results in the second query with the code below. Here's what I wrote based off master. ```python; def _filter_compound_hets(self):; ch_ht = self._ht; if self._is_recessive_search:; ch_ht = ch_ht.filter(ch_ht.comp_het_family_entries.any(hl.is_defined)). # Get possible pairs of variants within the same gene; ch_ht = ch_ht.annotate(gene_ids=self._gene_ids_expr(ch_ht, comp_het=True)); ch_ht = ch_ht.explode(ch_ht.gene_ids). # Filter allowed transcripts to the grouped gene; transcript_annotations = {; k: ch_ht[k].filter(lambda t: t.gene_id == ch_ht.gene_ids); for k in [ALLOWED_TRANSCRIPTS, ALLOWED_SECONDARY_TRANSCRIPTS] if k in ch_ht.row; }; if transcript_annotations:; ch_ht = ch_ht.annotate(**transcript_annotations); primary_filters = self._get_annotation_filters(ch_ht); secondary_filters = self._get_annotation_filters(ch_ht, is_secondary=True). self.unfiltered_comp_het_ht = ch_ht.filter(hl.any(primary_filters + secondary_filters)); if self._has_secondary_annotations and not (primary_filters and secondary_filters):; # In cases where comp het pairs must have different data types, there are no single data type results; return None. primary_variants = hl.agg.filter(hl.any(primary_filters), hl.agg.collect(ch_ht.row)); if secondary_filters:; row_agg = ch_ht.row; if ALLOWED_TRANSCRIPTS in row_agg and ALLOWED_SECONDARY_TRANSCRIPTS in row_agg:; # Ensure main transcripts are properly selected for primary/secondary annotations in variant pairs; row_agg = row_agg.annotate(**{ALLOWED_TRANSCRIPTS: row_agg[ALLOWED_SECONDARY_TRANSCRIPTS]}); secondary_variants = hl.agg.filter(hl.any(secondary_filters), hl.agg.collect(row_agg)); el",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1828689808
https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:197,Availability,down,downstream,197,"Oh yeah, to get my code to work you need to comment out line 778 `gene_id=ch_ht.gene_ids,` in `_annotated_comp_het_variant`. It doesn't break search to be missing that annotation, it just has some downstream display affects that I would need to fix if I actually wanted to use the code, but given the performance hit I wasn't sure it was worth figuring that out as this code may be too slow to use. I was not able to get the code you provided here to run either, but one concern I have with it is that the unique combinations are computed per gene, but if you have a pair of variants that are each in the same 2 genes, you would get the pair twice in the results, one for each gene. The error I get when I run the code you provide is; ```; ""Key type mismatch: cannot index table with given expressions:; Table key: <<<empty key>>>; Index Expressions: locus<GRCh38>, array<str>, set<str>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465
https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:687,Availability,error,error,687," The error I get when I run the code you provide is; ```; ""Key type mismatch: cannot index table with given expressions:; Table key: <<<empty key>>>; Index Expressions: locus<GRCh38>, array<str>, set<str>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465
https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:301,Performance,perform,performance,301,"Oh yeah, to get my code to work you need to comment out line 778 `gene_id=ch_ht.gene_ids,` in `_annotated_comp_het_variant`. It doesn't break search to be missing that annotation, it just has some downstream display affects that I would need to fix if I actually wanted to use the code, but given the performance hit I wasn't sure it was worth figuring that out as this code may be too slow to use. I was not able to get the code you provided here to run either, but one concern I have with it is that the unique combinations are computed per gene, but if you have a pair of variants that are each in the same 2 genes, you would get the pair twice in the results, one for each gene. The error I get when I run the code you provide is; ```; ""Key type mismatch: cannot index table with given expressions:; Table key: <<<empty key>>>; Index Expressions: locus<GRCh38>, array<str>, set<str>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, array<array<struct{GQ: int32, AB: float64, DP: int32, GT: call, sampleId: str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float3",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465
https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465:2504,Security,access,accession,2504," str, sampleType: str, individualGuid: str, familyGuid: str, affected_id: int32}>>, struct{z_score: float32}, struct{region_type_ids: array<int32>}, locus<GRCh37>, str, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, str, int64, struct{PHRED: float32}, struct{alleleId: int32, conflictingPathogenicities: array<struct{pathogenicity_id: int32, count: int32}>, goldStars: int32, pathogenicity_id: int32, assertion_ids: array<int32>}, struct{REVEL_score: float32, VEST4_score: float32, MutPred_score: float32, SIFT_pred_id: int32, Polyphen2_HVAR_pred_id: int32, MutationTaster_pred_id: int32, fathmm_MKL_coding_pred_id: int32}, struct{Eigen_phred: float32}, struct{AF_POPMAX: float32, AF: float32, AC_Adj: int32, AC_Het: int32, AC_Hom: int32, AC_Hemi: int32, AN_Adj: int32}, struct{AF: float32, AN: int32, AC: int32, Hom: int32, AF_POPMAX_OR_GLOBAL: float32, FAF_AF: float32, Hemi: int32}, struct{AF: float32, AN: int32, AC: int32, Hom: int32, AF_POPMAX_OR_GLOBAL: float32, FAF_AF: float32, Hemi: int32}, struct{MPC: float32}, struct{score: float32}, struct{delta_score: float32, splice_consequence_id: int32}, struct{AC: int32, AF: float32, AN: int32, Hom: int32, Het: int32}, struct{accession: str, class_id: int32}, struct{AC: int32, AN: int32, AF: float32, hom: int32}, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, bool, array<struct{amino_acids: str, canonical: int32, codons: str, gene_id: str, hgvsc: str, hgvsp: str, transcript_id: str, biotype_id: int32, consequence_term_ids: array<int32>, is_lof_nagnag: bool, lof_filter_ids: array<int32>, transcript_rank: int32}>, bool, str""; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830257465
https://github.com/hail-is/hail/issues/13882#issuecomment-1830286991:40,Availability,error,error,40,"You'll have to provide me with the full error to help, I don't know where that's coming from. Perhaps I edited another function elsewhere and didn't include it up there. > that are each in the same 2 genes. The same two genes? How can a gene appear twice when you've grouped by the gene id?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830286991
https://github.com/hail-is/hail/issues/13882#issuecomment-1830665552:84,Usability,simpl,simple,84,"Oh I see. Thanks for clarifying - I wasn't sure what that bit did! That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimisation for this query",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1830665552
https://github.com/hail-is/hail/issues/13882#issuecomment-1839225404:114,Usability,feedback,feedback,114,"Next steps:; 1. upload the profile, the `mt.describe()`, metadata.json.gz from the MT/HT to the team chat and get feedback (Chris, Patrick take a look). Decode appears quite slow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839225404
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:326,Availability,avail,available,326,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:145,Integrability,depend,depending,145,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:99,Performance,optimiz,optimization,99,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:183,Performance,optimiz,optimization,183,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:305,Performance,optimiz,optimizaion,305,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525:19,Usability,simpl,simple,19,"> That should be a simple fix, though perhaps at this point not worth it as this is not a fruitful optimization for this query. Agreed, although depending on the time line for a good optimization for this query I may circle back on this, as there is currently a bug in this deduplication so if the actual optimizaion won;t be available for a while it might be worth fixing in the meantime",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1839244525
https://github.com/hail-is/hail/issues/13882#issuecomment-1866888177:54,Usability,resume,resume,54,"Sorry, I've been on my honeymoon and just got back. I resume work on this in the new year. Apologies for the delay.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1866888177
https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829:419,Deployability,release,release,419,"Ok, getting back up to speed on this. There've been a number of changes on either side of this project, so going to give new timings and profiling results for the two queries. Here are mean timings for the two queries, run 5 times, and taking the mean of all but the first. It seems there's been a considerable regression since November on the second query, highlighting our need to get automated benchmark runs in per release (https://github.com/hail-is/hail/issues/14221). | query	| spark |; |-------|-------|; | 0	| 7s |; | 1	| 87s |. Attached are YourKit profiler results of the two queries. 'fast' refers to query 0 and 'slow' to the longer-running query 1.; [seqr-profile-data.zip](https://github.com/hail-is/hail/files/14103185/seqr-profile-data.zip); [seqr-logs.zip](https://github.com/hail-is/hail/files/14104795/seqr-logs.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829
https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829:397,Testability,benchmark,benchmark,397,"Ok, getting back up to speed on this. There've been a number of changes on either side of this project, so going to give new timings and profiling results for the two queries. Here are mean timings for the two queries, run 5 times, and taking the mean of all but the first. It seems there's been a considerable regression since November on the second query, highlighting our need to get automated benchmark runs in per release (https://github.com/hail-is/hail/issues/14221). | query	| spark |; |-------|-------|; | 0	| 7s |; | 1	| 87s |. Attached are YourKit profiler results of the two queries. 'fast' refers to query 0 and 'slow' to the longer-running query 1.; [seqr-profile-data.zip](https://github.com/hail-is/hail/files/14103185/seqr-profile-data.zip); [seqr-logs.zip](https://github.com/hail-is/hail/files/14104795/seqr-logs.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829
https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829:765,Testability,log,logs,765,"Ok, getting back up to speed on this. There've been a number of changes on either side of this project, so going to give new timings and profiling results for the two queries. Here are mean timings for the two queries, run 5 times, and taking the mean of all but the first. It seems there's been a considerable regression since November on the second query, highlighting our need to get automated benchmark runs in per release (https://github.com/hail-is/hail/issues/14221). | query	| spark |; |-------|-------|; | 0	| 7s |; | 1	| 87s |. Attached are YourKit profiler results of the two queries. 'fast' refers to query 0 and 'slow' to the longer-running query 1.; [seqr-profile-data.zip](https://github.com/hail-is/hail/files/14103185/seqr-profile-data.zip); [seqr-logs.zip](https://github.com/hail-is/hail/files/14104795/seqr-logs.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829
https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829:827,Testability,log,logs,827,"Ok, getting back up to speed on this. There've been a number of changes on either side of this project, so going to give new timings and profiling results for the two queries. Here are mean timings for the two queries, run 5 times, and taking the mean of all but the first. It seems there's been a considerable regression since November on the second query, highlighting our need to get automated benchmark runs in per release (https://github.com/hail-is/hail/issues/14221). | query	| spark |; |-------|-------|; | 0	| 7s |; | 1	| 87s |. Attached are YourKit profiler results of the two queries. 'fast' refers to query 0 and 'slow' to the longer-running query 1.; [seqr-profile-data.zip](https://github.com/hail-is/hail/files/14103185/seqr-profile-data.zip); [seqr-logs.zip](https://github.com/hail-is/hail/files/14104795/seqr-logs.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829
https://github.com/hail-is/hail/issues/13882#issuecomment-1917741862:126,Performance,perform,performance,126,"FWIW, I think most of the regression was this PR: https://github.com/broadinstitute/seqr/pull/3792/files. We kind of knew the performance was worse but also we decided that we needed to fix the bug more than we needed performance to be good :/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917741862
https://github.com/hail-is/hail/issues/13882#issuecomment-1917741862:218,Performance,perform,performance,218,"FWIW, I think most of the regression was this PR: https://github.com/broadinstitute/seqr/pull/3792/files. We kind of knew the performance was worse but also we decided that we needed to fix the bug more than we needed performance to be good :/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917741862
https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111:517,Availability,down,down,517,"We recently put in a couple PRs that improve performance on these searches so thought I would update here. They were mostly changes to things upstream of the portion of code we have been focusing on and change how data is initially read in, but the biggest performance gain we got was adding `hl._set_flags(use_new_shuffle='1')`. A lot of the focus was around how we handle searches in multiple data types which has been out of the scope of this work so far, so for the search we've been profiling here its only came down to like 80 seconds, but figured its worth sharing. Hopefully this does not cause to catastrophic of a merge conflict for you guys. https://github.com/broadinstitute/seqr/pull/3873; https://github.com/broadinstitute/seqr/pull/3876",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111
https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111:94,Deployability,update,update,94,"We recently put in a couple PRs that improve performance on these searches so thought I would update here. They were mostly changes to things upstream of the portion of code we have been focusing on and change how data is initially read in, but the biggest performance gain we got was adding `hl._set_flags(use_new_shuffle='1')`. A lot of the focus was around how we handle searches in multiple data types which has been out of the scope of this work so far, so for the search we've been profiling here its only came down to like 80 seconds, but figured its worth sharing. Hopefully this does not cause to catastrophic of a merge conflict for you guys. https://github.com/broadinstitute/seqr/pull/3873; https://github.com/broadinstitute/seqr/pull/3876",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111
https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111:45,Performance,perform,performance,45,"We recently put in a couple PRs that improve performance on these searches so thought I would update here. They were mostly changes to things upstream of the portion of code we have been focusing on and change how data is initially read in, but the biggest performance gain we got was adding `hl._set_flags(use_new_shuffle='1')`. A lot of the focus was around how we handle searches in multiple data types which has been out of the scope of this work so far, so for the search we've been profiling here its only came down to like 80 seconds, but figured its worth sharing. Hopefully this does not cause to catastrophic of a merge conflict for you guys. https://github.com/broadinstitute/seqr/pull/3873; https://github.com/broadinstitute/seqr/pull/3876",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111
https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111:257,Performance,perform,performance,257,"We recently put in a couple PRs that improve performance on these searches so thought I would update here. They were mostly changes to things upstream of the portion of code we have been focusing on and change how data is initially read in, but the biggest performance gain we got was adding `hl._set_flags(use_new_shuffle='1')`. A lot of the focus was around how we handle searches in multiple data types which has been out of the scope of this work so far, so for the search we've been profiling here its only came down to like 80 seconds, but figured its worth sharing. Hopefully this does not cause to catastrophic of a merge conflict for you guys. https://github.com/broadinstitute/seqr/pull/3873; https://github.com/broadinstitute/seqr/pull/3876",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1945174111
https://github.com/hail-is/hail/issues/13882#issuecomment-1947450758:0,Deployability,Update,Updated,0,Updated baseline timings on 61a5d4834 with Hana's updates + `use_new_shuffle=1` on my pc:. ```; --------------------------------------; Timing query 'fast' with 5 repeats.; Initial: 8.920063795001624s ; Mean: 6.641188349500226s; --------------------------------------; Timing query 'slow' with 5 repeats.; Initial: 45.03917969699978s ; Mean: 42.99382913374939s; --------------------------------------; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1947450758
https://github.com/hail-is/hail/issues/13882#issuecomment-1947450758:50,Deployability,update,updates,50,Updated baseline timings on 61a5d4834 with Hana's updates + `use_new_shuffle=1` on my pc:. ```; --------------------------------------; Timing query 'fast' with 5 repeats.; Initial: 8.920063795001624s ; Mean: 6.641188349500226s; --------------------------------------; Timing query 'slow' with 5 repeats.; Initial: 45.03917969699978s ; Mean: 42.99382913374939s; --------------------------------------; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1947450758
https://github.com/hail-is/hail/issues/13902#issuecomment-1781835000:83,Energy Efficiency,reduce,reduce,83,Let's try to reproduce with a CPU heavy workload using 16 cores. Then let's try to reduce CPU and RAM requests to 95% of actual requested.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13902#issuecomment-1781835000
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:106,Availability,Error,Error,106,I got a timeout!; ```; SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:10697,Availability,Error,Error,10697,"d.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). Hail version: 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/com",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:11649,Availability,Error,Error,11649," 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:22240,Availability,Error,Error,22240,s.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). Hail version: 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1907,Energy Efficiency,adapt,adapted,1907,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:2764,Energy Efficiency,adapt,adapted,2764,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:8090,Energy Efficiency,adapt,adapted,8090,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:8947,Energy Efficiency,adapt,adapted,8947,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:13450,Energy Efficiency,adapt,adapted,13450,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:14307,Energy Efficiency,adapt,adapted,14307,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:19633,Energy Efficiency,adapt,adapted,19633,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:20490,Energy Efficiency,adapt,adapted,20490,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:5390,Integrability,protocol,protocol,5390,cher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). java.net.SocketTimeoutException: connect timed out; 	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refres,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:5495,Integrability,protocol,protocol,5495,tException: connect timed out; 	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.Cred,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:5597,Integrability,protocol,protocol,5597,t java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.clou,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:5698,Integrability,protocol,protocol,5698,se/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactor,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:11360,Integrability,wrap,wrapper,11360,"DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). Hail version: 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:16933,Integrability,protocol,protocol,16933,cher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). java.net.SocketTimeoutException: connect timed out; 	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refres,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:17038,Integrability,protocol,protocol,17038,tException: connect timed out; 	at java.base/java.net.PlainSocketImpl.socketConnect(Native Method); 	at java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.Cred,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:17140,Integrability,protocol,protocol,17140,t java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:399); 	at java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.clou,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:17241,Integrability,protocol,protocol,17241,se/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:242); 	at java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:224); 	at java.base/java.net.Socket.connect(Socket.java:591); 	at java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:474); 	at java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:569); 	at java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:242); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:341); 	at java.base/sun.net.www.http.HttpClient.New(HttpClient.java:362); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1242); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1181); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1075); 	at java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1009); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:151); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactor,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:823,Modifiability,config,configure,823,I got a timeout!; ```; SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1907,Modifiability,adapt,adapted,1907,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:2764,Modifiability,adapt,adapted,2764,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:7006,Modifiability,config,configure,7006, com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:8090,Modifiability,adapt,adapted,8090,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:8947,Modifiability,adapt,adapted,8947,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:12366,Modifiability,config,configure,12366,"al_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:13450,Modifiability,adapt,adapted,13450,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:14307,Modifiability,adapt,adapted,14307,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:18549,Modifiability,config,configure,18549, com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory$ComputeCredentialWithRetry.executeRefreshToken(CredentialFactory.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:19633,Modifiability,adapt,adapted,19633,.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:20490,Modifiability,adapt,adapted,20490,al.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:223); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1164,Performance,Cache,Cache,1164,p://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1241,Performance,Cache,Cache,1241,n; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBack,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:7347,Performance,Cache,Cache,7347,com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:7424,Performance,Cache,Cache,7424,); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBack,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:12707,Performance,Cache,Cache,12707,p://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:12784,Performance,Cache,Cache,12784,n; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBack,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:18890,Performance,Cache,Cache,18890,com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:18967,Performance,Cache,Cache,18967,); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBack,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:8,Safety,timeout,timeout,8,I got a timeout!; ```; SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:120,Security,access,access,120,I got a timeout!; ```; SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:1095,Security,access,access,1095,Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:7278,Security,access,access,7278,.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:11663,Security,access,access,11663," 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:12638,Security,access,access,12638,Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:18821,Security,access,access,18821,.java:196); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.api.client.auth.oauth2.Credential.refreshToken(Credential.java:470); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:251); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:507); 	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469); 	at org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174); 	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574); 	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521); 	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540); 	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365); 	at is.hail.io.fs.HadoopFSURL.<init>(HadoopFS.scala:76); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:88); 	at is.hail.io.fs.HadoopFS.parseUrl(HadoopFS.scala:85); 	at is.hail.io.fs.FS.exists(FS.scala:618); 	at is.hail.io.fs.FS.exists$(FS.scala:618); 	at is.hail.io.fs.HadoopFS.exists(HadoopFS.scala:85); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:223); 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:223); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.Exec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:3390,Testability,log,logTime,3390,; 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:9573,Testability,log,logTime,9573,; 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:11447,Testability,test,test,11447,"ttpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run(ServerImpl.java:408); 	at java.base/java.lang.Thread.run(Thread.java:834). Hail version: 0.2.128-ce3ca9c77507; Error summary: SocketTimeoutException: connect timed out; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/py4j_backend.py"", line 223, in _rpc; raise fatal_error_from_java_error_triplet(; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/table.py"", line 2002, in write; Env.backend().execute(; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/test.py"", line 6, in <module>; ht.write('gs://ehigham-hail-tmp/test_hail_in_notebook.ht'); hail.utils.java.FatalError: SocketTimeoutException: connect timed out. Java stack trace:; java.io.IOException: Error getting access token from metadata server at: http://169.254.169.254/computeMetadata/v1/instance/service-accounts/default/token; 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredentialFromMetadataServiceAccount(CredentialFactory.java:254); 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.CredentialFactory.getCredential(CredentialFactory.java:406); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getCredential(GoogleHadoopFileSystemBase.java:1471); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1630); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:1612); 	at com.google.cloud.hadoop",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:14933,Testability,log,logTime,14933,; 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699:21116,Testability,log,logTime,21116,; 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:82); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:80); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange$LinkHandler.handle(ServerImpl.java:692); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Exchange.run(ServerImpl.java:664); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$DefaultExecutor.execute(ServerImpl.java:159); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.handle(ServerImpl.java:442); 	at jdk.httpserver/sun.net.httpserver.ServerImpl$Dispatcher.run,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1973731699
https://github.com/hail-is/hail/issues/13904#issuecomment-1986218258:148,Modifiability,config,configured,148,"after rtfm (https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/master/gcs/README.md#getting-the-connector), seems credentials need to be configured in `core-site.xml`. I don't know where we do this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1986218258
https://github.com/hail-is/hail/issues/13904#issuecomment-1986237607:199,Modifiability,config,config,199,"Indeed, `pyspark/conf/spark-defaults.conf` defines the following:; ```; spark.hadoop.google.cloud.auth.service.account.enable true; spark.hadoop.google.cloud.auth.service.account.json.keyfile $HOME/.config/gcloud/application_default_credentials.json; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13904#issuecomment-1986237607
https://github.com/hail-is/hail/pull/13905#issuecomment-1780008230:61,Deployability,release,release,61,Awaiting confirmation that #13899 is not meant to go in this release,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13905#issuecomment-1780008230
https://github.com/hail-is/hail/pull/13912#issuecomment-1781475256:21,Deployability,release,release,21,WIP until I sort the release.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13912#issuecomment-1781475256
https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654:412,Availability,down,down,412,"> I confirmed that, with this change, #13915 is resolved. In the interest of fixing that for 0.2.125, I'm gonna approve and get it into this release.; > ; > However, I left a comment inline. It seems that the meaning of pathsUsed was always a bit buggy and I think we should kill that tech debt now before it trips us again.; > ; > I'm also still concerned that `test_glob` didn't catch this bug; we should nail down why. We don't catch this in `test_glob` because the matrixread is nested within a `TableKeyByAndAggregate`, which semhash can't handle yet:; ```; 2023-10-26 12:54:40.576 : WARN: Failed to compute SemanticHash: SemanticHash unknown: is.hail.expr.ir.TableKeyByAndAggregate; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654
https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654:141,Deployability,release,release,141,"> I confirmed that, with this change, #13915 is resolved. In the interest of fixing that for 0.2.125, I'm gonna approve and get it into this release.; > ; > However, I left a comment inline. It seems that the meaning of pathsUsed was always a bit buggy and I think we should kill that tech debt now before it trips us again.; > ; > I'm also still concerned that `test_glob` didn't catch this bug; we should nail down why. We don't catch this in `test_glob` because the matrixread is nested within a `TableKeyByAndAggregate`, which semhash can't handle yet:; ```; 2023-10-26 12:54:40.576 : WARN: Failed to compute SemanticHash: SemanticHash unknown: is.hail.expr.ir.TableKeyByAndAggregate; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13919#issuecomment-1781498654
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:312,Deployability,pipeline,pipeline,312,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:262,Security,access,access,262,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:354,Security,access,access,354,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:576,Security,access,access,576,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:671,Security,access,access-token,671,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:447,Testability,test,tested,447,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:645,Testability,log,login,645,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:820,Testability,log,login,820,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:70,Usability,clear,clear,70,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528
https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404:205,Security,access,access-token,205,"Somewhat unrelatedly though, this seems like it would be a natural replacement for our copy-paste token (or identity delegation as the AUS folks do), as you could do the following:. 1. `hailctl auth print-access-token | pbcopy`; 2. On some notebook where you don't have access to your hail identity for some reason, do `hl.init_batch(token=…)` or `hl.ServiceBackend(token=…)`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404
https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404:270,Security,access,access,270,"Somewhat unrelatedly though, this seems like it would be a natural replacement for our copy-paste token (or identity delegation as the AUS folks do), as you could do the following:. 1. `hailctl auth print-access-token | pbcopy`; 2. On some notebook where you don't have access to your hail identity for some reason, do `hl.init_batch(token=…)` or `hl.ServiceBackend(token=…)`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785471404
https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774:43,Security,Access,Access,43,"I don't think the last comment checks out. Access tokens aren't refreshable, right? So you'd have very short-lived access.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774
https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774:115,Security,access,access,115,"I don't think the last comment checks out. Access tokens aren't refreshable, right? So you'd have very short-lived access.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785490774
https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525:322,Deployability,integrat,integration,322,"True. I thought at least for the copy-paste tokens that this would be intentional. Looks like you can get access tokens from GCP that last up to 12 hours, but that could be insufficient for large workloads. If we need something arbitrarily long-lived, our current implementation might be our best bet short of some better integration with OIDC.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525
https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525:322,Integrability,integrat,integration,322,"True. I thought at least for the copy-paste tokens that this would be intentional. Looks like you can get access tokens from GCP that last up to 12 hours, but that could be insufficient for large workloads. If we need something arbitrarily long-lived, our current implementation might be our best bet short of some better integration with OIDC.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525
https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525:106,Security,access,access,106,"True. I thought at least for the copy-paste tokens that this would be intentional. Looks like you can get access tokens from GCP that last up to 12 hours, but that could be insufficient for large workloads. If we need something arbitrarily long-lived, our current implementation might be our best bet short of some better integration with OIDC.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1785516525
https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175:190,Availability,error,error,190,Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175
https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175:24,Deployability,update,update,24,Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175
https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175:196,Integrability,message,message,196,Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1783512175
https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141:192,Availability,error,error,192,> Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141
https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141:26,Deployability,update,update,26,> Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141
https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141:198,Integrability,message,message,198,> Looks like you need to [update the Google Artifact Registry cleanup policies](https://batch.hail.is/batches/8076011/jobs/210) to account for your new image. Instructions to do so are in the error message. Thanks!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13936#issuecomment-1785779141
https://github.com/hail-is/hail/issues/13937#issuecomment-1821482163:10,Deployability,update,update,10,Fix is to update to 2.29.1.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13937#issuecomment-1821482163
https://github.com/hail-is/hail/pull/13939#issuecomment-1785257005:47,Availability,ping,ping,47,"@patrick-schultz OK, I understand now. Can you ping Ed or find someone else to review? Let's get this in post-haste.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13939#issuecomment-1785257005
https://github.com/hail-is/hail/pull/13939#issuecomment-1785433230:160,Availability,down,down,160,I'm a little puzzled by this solution. I feel that we shouldn't be modifying class composition in method calls; the structure of our code seems somewhat upside down. If anything the StagedArrayBuilder should only take a class builder.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13939#issuecomment-1785433230
https://github.com/hail-is/hail/issues/13940#issuecomment-1786375579:165,Availability,error,error,165,"It seems to only occur when I use bp.read_input(..) to localize many files per job. ; Above a certain number of input files (many thousands), I started getting this error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13940#issuecomment-1786375579
https://github.com/hail-is/hail/issues/13940#issuecomment-1834357495:370,Availability,echo,echo,370,"Clarifying for future devs: the Batch.read_input is probably just causing the script to grow large enough that we start using scripts which need to be uploaded separately from the job. Attempting to replicate with; ```. In [6]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. triggers https://github.com/hail-is/hail/issues/14051. I'll try to fix both.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13940#issuecomment-1834357495
https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920:102,Availability,down,down,102,"I like this table much better! However, it's too wide. I don't know exactly the best way to shrink it down, but here's a few off the cuff thoughts:. I don't think I care about ""Live"", I can do that math myself (it's pending + active, right?). Can we shorten Instances to ""I"" and Cores to ""C"" with abbr tags a la `<abbr title=""Instances"">`?. I don't think I care about schedulable instances, for scheduling I really care about cores. I don't think I care about the cores column, right? ~~Isn't that a synonym for ""active cores""?~~ Ah versioning matters. Hmm. Can we maybe just do `XX / YY` and `ZZ%` columns? It's just too wide to quickly scan this table. I think the most important super-heading is ""Schedulable"", what do you think of putting that at the far left of the table?. If we swap ""Spot"" for ""Preemptible"" that will also shrink the width of the table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920
https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920:368,Energy Efficiency,schedul,schedulable,368,"I like this table much better! However, it's too wide. I don't know exactly the best way to shrink it down, but here's a few off the cuff thoughts:. I don't think I care about ""Live"", I can do that math myself (it's pending + active, right?). Can we shorten Instances to ""I"" and Cores to ""C"" with abbr tags a la `<abbr title=""Instances"">`?. I don't think I care about schedulable instances, for scheduling I really care about cores. I don't think I care about the cores column, right? ~~Isn't that a synonym for ""active cores""?~~ Ah versioning matters. Hmm. Can we maybe just do `XX / YY` and `ZZ%` columns? It's just too wide to quickly scan this table. I think the most important super-heading is ""Schedulable"", what do you think of putting that at the far left of the table?. If we swap ""Spot"" for ""Preemptible"" that will also shrink the width of the table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920
https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920:395,Energy Efficiency,schedul,scheduling,395,"I like this table much better! However, it's too wide. I don't know exactly the best way to shrink it down, but here's a few off the cuff thoughts:. I don't think I care about ""Live"", I can do that math myself (it's pending + active, right?). Can we shorten Instances to ""I"" and Cores to ""C"" with abbr tags a la `<abbr title=""Instances"">`?. I don't think I care about schedulable instances, for scheduling I really care about cores. I don't think I care about the cores column, right? ~~Isn't that a synonym for ""active cores""?~~ Ah versioning matters. Hmm. Can we maybe just do `XX / YY` and `ZZ%` columns? It's just too wide to quickly scan this table. I think the most important super-heading is ""Schedulable"", what do you think of putting that at the far left of the table?. If we swap ""Spot"" for ""Preemptible"" that will also shrink the width of the table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920
https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920:700,Energy Efficiency,Schedul,Schedulable,700,"I like this table much better! However, it's too wide. I don't know exactly the best way to shrink it down, but here's a few off the cuff thoughts:. I don't think I care about ""Live"", I can do that math myself (it's pending + active, right?). Can we shorten Instances to ""I"" and Cores to ""C"" with abbr tags a la `<abbr title=""Instances"">`?. I don't think I care about schedulable instances, for scheduling I really care about cores. I don't think I care about the cores column, right? ~~Isn't that a synonym for ""active cores""?~~ Ah versioning matters. Hmm. Can we maybe just do `XX / YY` and `ZZ%` columns? It's just too wide to quickly scan this table. I think the most important super-heading is ""Schedulable"", what do you think of putting that at the far left of the table?. If we swap ""Spot"" for ""Preemptible"" that will also shrink the width of the table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13943#issuecomment-1789625920
https://github.com/hail-is/hail/pull/13943#issuecomment-1792916933:25,Energy Efficiency,schedul,schedulable,25,"Also, ignore getting the schedulable cores backwards.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13943#issuecomment-1792916933
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:170,Availability,fault,fault,170,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:42,Deployability,deploy,deploy,42,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:519,Deployability,deploy,deploy,519,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:815,Deployability,deploy,deploy,815,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:451,Integrability,rout,routing,451,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:499,Integrability,rout,routing,499,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:49,Modifiability,config,config,49,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:526,Modifiability,config,config,526,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616:822,Modifiability,config,config,822,"I don't love what I've had to do with the deploy config stuff. That's in my opinion the most finicky part of this (has already broken multiple times) and it's mostly our fault, because we overload the `namespace` parameter with both identifying the namespace in Kubernetes and signifying whether the environment is prod or not. All I want really is to change the `domain` to a domain and path prefix, and not have the namespace have such an impact on routing. Like what if `namespace` didn't affect routing, but if the deploy config only gave a domain with no path e.g. `hail.is`, we use subdomains so `batch.hail.is`, but if we provided a domain with a path prefix like `internal.hail.is/dgoldste`, we make the batch root `internal.hail.is/dgoldste/batch`?. Alternative: Actually have and use a `base_path` in the deploy config. This would be used in dev and terra environments.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1785575616
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:743,Availability,down,downloader,743,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:1006,Availability,error,errors,1006,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:1193,Availability,error,error,1193,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:1243,Availability,down,downloader,1243,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:550,Deployability,update,update,550,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:883,Integrability,wrap,wraps,883,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715:779,Performance,load,load,779,"@danking , I'm a bit stuck on how to proceed with the credential refreshing. Here's the layout of the problem:. 1. In normal Azure, we accept user-provided SAS tokens. Since they are user-provided, we have no way of obtaining new ones and the onus is on the user to obtain a SAS token for however long they expect to need to use it.; 2. This current design in Terra is to not make the user have to do that, because that seems annoying, and for terra-controlled ABS containers we have an endpoint we can hit to get a SAS token. Ok, but now we need to update our Azure FS infrastructure to refresh a credential if it expires. But, we use the azure client lib and don't control all http requests. For example, for `AzureStorageFS.open`, we call `downloader.readall()` if we want to load the whole file into memory. I went spelunking through their source and looks like `readall` mostly wraps a sequence of range reads, but regardless if we were to use that method we would have to catch credential expiration errors, reset credentials on the blob client and retry hoping that we didn't break any invariants -- I don't want to do that as I wouldn't trust a stream that encountered a non-transient error like that. It could be that getting rid of `downloader.readall` is the only thing we have to worry about, but it makes me uneasy not having control of the http requests we're making to ABS. Do you see a solution other than raking through our `aioazure.fs` and making sure that we only use ""quick"" methods and possibly retrying 401s? It just seems to me like we're going against the grain and even though it feels user-hostile the intention of SAS tokens are to have users own credential expiration.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930482715
https://github.com/hail-is/hail/pull/13944#issuecomment-1930492732:216,Availability,down,downloaders,216,"Stepping back a little bit, there might be a reasonable (if unsatisfying) middle ground. Presumably the operations most at risk are long streams that we always do in chunks anyway, and in that case we can create new downloaders on `AzureReadableStream.read` if the SAS token expires. That would probably solve most of these problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930492732
https://github.com/hail-is/hail/pull/13944#issuecomment-1930492732:123,Safety,risk,risk,123,"Stepping back a little bit, there might be a reasonable (if unsatisfying) middle ground. Presumably the operations most at risk are long streams that we always do in chunks anyway, and in that case we can create new downloaders on `AzureReadableStream.read` if the SAS token expires. That would probably solve most of these problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1930492732
https://github.com/hail-is/hail/pull/13944#issuecomment-1971996799:38,Testability,assert,assert,38,> Hmm. Is the TODO suggesting that we assert the state field is READY in the response?. I handled the other states and removed the TODO,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13944#issuecomment-1971996799
https://github.com/hail-is/hail/pull/13948#issuecomment-1787482245:45,Testability,test,test,45,This PR is passing -- failed on an unrelated test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13948#issuecomment-1787482245
https://github.com/hail-is/hail/pull/13949#issuecomment-1787517445:47,Safety,timeout,timeout,47,Tests failed unrelatedly on `test_ci` due to a timeout on pulling an image.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1787517445
https://github.com/hail-is/hail/pull/13949#issuecomment-1787517445:0,Testability,Test,Tests,0,Tests failed unrelatedly on `test_ci` due to a timeout on pulling an image.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1787517445
https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392:130,Energy Efficiency,monitor,monitoring,130,"Looks like the ops agent [also does logging](https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent) in addition to monitoring. The logging agent we're using now is considered legacy, we should probably switch everything over to this new agent.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392
https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392:36,Testability,log,logging,36,"Looks like the ops agent [also does logging](https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent) in addition to monitoring. The logging agent we're using now is considered legacy, we should probably switch everything over to this new agent.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392
https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392:146,Testability,log,logging,146,"Looks like the ops agent [also does logging](https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent) in addition to monitoring. The logging agent we're using now is considered legacy, we should probably switch everything over to this new agent.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392
https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544:78,Availability,error,error,78,We now mock this test so we've lost the ability to specifically diagnose this error. Hopefully this is useful if a similar bug crops up in the future.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544
https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544:7,Testability,mock,mock,7,We now mock this test so we've lost the ability to specifically diagnose this error. Hopefully this is useful if a similar bug crops up in the future.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544
https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544:17,Testability,test,test,17,We now mock this test so we've lost the ability to specifically diagnose this error. Hopefully this is useful if a similar bug crops up in the future.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13951#issuecomment-2214404544
https://github.com/hail-is/hail/pull/13956#issuecomment-1787480719:187,Testability,benchmark,benchmarking,187,"Hi Chris, would you mind taking a look when you get a chance? I believe you might know the most about the functionality these are exercising. Do the new implementations look ok? Are they benchmarking equivalent functionality?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13956#issuecomment-1787480719
https://github.com/hail-is/hail/pull/13957#issuecomment-1789596118:32,Testability,benchmark,benchmark,32,Can you make the same change to benchmark/Makefile?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13957#issuecomment-1789596118
https://github.com/hail-is/hail/pull/13957#issuecomment-1792680812:34,Testability,benchmark,benchmark,34,> Can you make the same change to benchmark/Makefile?. Sure. I plan to remove wheel generation from benchmark/Makefile as we don't use it anymore.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13957#issuecomment-1792680812
https://github.com/hail-is/hail/pull/13957#issuecomment-1792680812:100,Testability,benchmark,benchmark,100,> Can you make the same change to benchmark/Makefile?. Sure. I plan to remove wheel generation from benchmark/Makefile as we don't use it anymore.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13957#issuecomment-1792680812
https://github.com/hail-is/hail/pull/13957#issuecomment-1795092510:35,Performance,queue,queue,35,Unassigning to get it off of my CI queue. Feel free to reassign when you want me to look at it again.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13957#issuecomment-1795092510
https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741:90,Availability,Ping,Ping,90,The script in question is located at: gs://danking/1_Generate_Variant_Stats_NVXvC_v1.py . Ping me if you need access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741
https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741:110,Security,access,access,110,The script in question is located at: gs://danking/1_Generate_Variant_Stats_NVXvC_v1.py . Ping me if you need access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791061741
https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886:72,Availability,failure,failures,72,Whatever is failing here is likely different from the interval pipeline failures seen in https://github.com/hail-is/hail/issues/13748 and related tickets because GVS team has confirmed that 0.2.126 reduces peak RAM usage from >50GB to 11GB.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886
https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886:63,Deployability,pipeline,pipeline,63,Whatever is failing here is likely different from the interval pipeline failures seen in https://github.com/hail-is/hail/issues/13748 and related tickets because GVS team has confirmed that 0.2.126 reduces peak RAM usage from >50GB to 11GB.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886
https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886:198,Energy Efficiency,reduce,reduces,198,Whatever is failing here is likely different from the interval pipeline failures seen in https://github.com/hail-is/hail/issues/13748 and related tickets because GVS team has confirmed that 0.2.126 reduces peak RAM usage from >50GB to 11GB.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1791064886
https://github.com/hail-is/hail/issues/13960#issuecomment-1802068296:30,Availability,error,error,30,Watching - AoU is seeing this error with 0.2.126,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1802068296
https://github.com/hail-is/hail/issues/13960#issuecomment-1802638976:41,Testability,test,test-case,41,"@daniel-goldstein, here's a much smaller test-case, though the VDS is quite large. You might try this on `gs://neale-bge/bge-wave-1.vds` to see if we can replicate.; ```python3; import hail as hl; hl.init(default_reference='GRCh38', idempotent=True); vds = hl.vds.read_vds(""gs://...""); test_intervals = ['chr13:32355250-32355251']; vds = hl.vds.filter_intervals(; vds,; [hl.parse_locus_interval(x,); for x in test_intervals]); ```. Log statements like; ```; java.net.UnknownHostException: Invalid host name: local host is: ""...-w-1/10.128.0.50""; destination host is: ""...-m.c.terra-vpc-sc-...internal."":8051; ```; suggest to me that the master node is dying, then its removed from DNS, then workers are unable to communicate with it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1802638976
https://github.com/hail-is/hail/issues/13960#issuecomment-1802638976:432,Testability,Log,Log,432,"@daniel-goldstein, here's a much smaller test-case, though the VDS is quite large. You might try this on `gs://neale-bge/bge-wave-1.vds` to see if we can replicate.; ```python3; import hail as hl; hl.init(default_reference='GRCh38', idempotent=True); vds = hl.vds.read_vds(""gs://...""); test_intervals = ['chr13:32355250-32355251']; vds = hl.vds.filter_intervals(; vds,; [hl.parse_locus_interval(x,); for x in test_intervals]); ```. Log statements like; ```; java.net.UnknownHostException: Invalid host name: local host is: ""...-w-1/10.128.0.50""; destination host is: ""...-m.c.terra-vpc-sc-...internal."":8051; ```; suggest to me that the master node is dying, then its removed from DNS, then workers are unable to communicate with it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1802638976
https://github.com/hail-is/hail/issues/13960#issuecomment-1803234894:14,Usability,simpl,simpler,14,"This is a lot simpler, I'll try to run this tomorrow morning.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1803234894
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1192,Availability,avail,avail,1192,"n n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1393,Availability,down,down,1393,"C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1512,Availability,avail,avail,1512,"e {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:2001,Availability,avail,avail,2001,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:2728,Availability,avail,avail,2728,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:3,Deployability,update,update,3,"An update. I'm working with debugging info from the AoU VDS creation cluster. A VDS creation was run using an n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1795,Energy Efficiency,allocate,allocated,1795,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1909,Energy Efficiency,allocate,allocated,1909,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:834,Testability,log,log,834,"An update. I'm working with debugging info from the AoU VDS creation cluster. A VDS creation was run using an n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:864,Testability,log,logs,864,"An update. I'm working with debugging info from the AoU VDS creation cluster. A VDS creation was run using an n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:889,Testability,log,logs,889,"An update. I'm working with debugging info from the AoU VDS creation cluster. A VDS creation was run using an n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:972,Testability,log,logs,972,"An update. I'm working with debugging info from the AoU VDS creation cluster. A VDS creation was run using an n1-highmem-8 driver. The cluster is created by hailctl with no custom driver settings; <details><summary>template for hailctl dataproc start</summary>. [Source](https://github.com/broadinstitute/gatk/blob/ah_var_store/scripts/variantstore/wdl/extract/run_in_hail_cluster.py#L36C1-L48C1). ```; hailctl dataproc start ; --autoscaling-policy={autoscaling_policy}; --worker-machine-type {worker_machine_type}; --region {region}; --project {gcs_project}; --service-account {account}; --num-master-local-ssds 1; --num-worker-local-ssds 1 ; --max-idle=60m; --max-age=1440m; --subnet=projects/{gcs_project}/regions/{region}/subnetworks/subnetwork; {cluster_name}; ```. </details>. I have the driver node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:2461,Testability,log,log,2461,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419
https://github.com/hail-is/hail/issues/13960#issuecomment-1832549389:16,Deployability,pipeline,pipeline,16,"We ran the same pipeline with an n1-highmem-16 driver node and it made it through 50 sample groups (each sample group has ~4000 samples) before crashing. Unfortunately, we do not have the syslogs from this run. We also do not have the Hail log from this run. We do have the stdout/stderr from the Python process. There's not much of value there. The Python process exited with code 256. That doesn't make a lot of sense to me because exit codes should be an unsigned 8-bit integer. On a highmem-16, total RAM is 106,496 MiB. Hail's JVM will use 85,197 MiB. We establish above that the system uses about 9,500 MiB (unclear if it would use more on a larger VM). This all leaves 11,799 MiB for the Python process. That seems extremely generous, but apparently not?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832549389
https://github.com/hail-is/hail/issues/13960#issuecomment-1832549389:240,Testability,log,log,240,"We ran the same pipeline with an n1-highmem-16 driver node and it made it through 50 sample groups (each sample group has ~4000 samples) before crashing. Unfortunately, we do not have the syslogs from this run. We also do not have the Hail log from this run. We do have the stdout/stderr from the Python process. There's not much of value there. The Python process exited with code 256. That doesn't make a lot of sense to me because exit codes should be an unsigned 8-bit integer. On a highmem-16, total RAM is 106,496 MiB. Hail's JVM will use 85,197 MiB. We establish above that the system uses about 9,500 MiB (unclear if it would use more on a larger VM). This all leaves 11,799 MiB for the Python process. That seems extremely generous, but apparently not?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832549389
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:452,Availability,failure,failure,452,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:623,Availability,down,down,623,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:303,Deployability,pipeline,pipelines,303,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1368,Deployability,pipeline,pipeline,1368,"We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:2709,Deployability,release,release,2709,"ogle Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see hailctl's --master-memory-fraction). In Run A (the only run for which we have syslogs), based on the driver's syslog, before Spark starts, the system has already allocated 8500 MiB to Linux/Google/Dataproc daemons. Moreover, the actual RAM of the system (as reported by the earlyoom daemon) is 52223 MiB (51 GiB, 1GiB less than Google advertises for n1-highmem-8). Assuming these daemons never release their memory, all our user code must fit in 43723 MiB. Since the JVM's max heap is 42598 MiB, Python (and indeed, anything else on the system) is limited to allocating 1125 MiB. I assume that an n1-highmem-16 uses the same amount of memory for system daemons, so I'd expect just over ten GiB that is used neither by system daemons nor the JVM. Assuming that's right, I can't explain why the oomkiller killed the JVM in Run B.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1147,Energy Efficiency,Monitor,Monitoring,1147," loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:2477,Energy Efficiency,allocate,allocated,2477,"ogle Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see hailctl's --master-memory-fraction). In Run A (the only run for which we have syslogs), based on the driver's syslog, before Spark starts, the system has already allocated 8500 MiB to Linux/Google/Dataproc daemons. Moreover, the actual RAM of the system (as reported by the earlyoom daemon) is 52223 MiB (51 GiB, 1GiB less than Google advertises for n1-highmem-8). Assuming these daemons never release their memory, all our user code must fit in 43723 MiB. Since the JVM's max heap is 42598 MiB, Python (and indeed, anything else on the system) is limited to allocating 1125 MiB. I assume that an n1-highmem-16 uses the same amount of memory for system daemons, so I'd expect just over ten GiB that is used neither by system daemons nor the JVM. Assuming that's right, I can't explain why the oomkiller killed the JVM in Run B.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:20,Integrability,message,message,20,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1026,Testability,log,log,1026,"ve summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1073,Testability,log,logs,1073,"ve summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:967,Usability,simpl,simple,967,"crossposting from a message I sent to the variants team. ---. #### executive summary. Excess JVM memory use is almost certainly not the issue. I've taken a close look at the import_gvs.py loop and the related Hail Python code. No obvious accumulation of RAM use. AFAICT, the oomkiller keeps killing the pipelines. We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the drive",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1264,Usability,clear,clear,1264,"We need to stop this because the oomkiller (a) acts before the JVM GC can free things and (b) prevents us from getting JVM diagnostics on failure. We control the JVM's max heap with hailctl's --master-memory-fraction (default is 0.8 for 80% of the master machine type's advertised RAM). I suggest we set this down to 0.6 and continue using an n1-highmem-16 driver.; If Hail is (incorrectly) accumulating garbage memory per-group, we'll have a better chance diagnosing that with a running JVM instead of one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:1822,Usability,clear,clear,1822,"one that's been SIGKILL'ed. To understand what's going on, we gotta see what is using RAM in the n1-highmem-16 case. If I could SSH to the cluster, a simple solution is a screen with top -s 300 -n 100 >memory.log (I'd guess no more than 500KiB per hour of logs) and retrieve that file if the cluster fails. If we could get Google Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see hailctl's --master-memory-fraction). In Run A (the only run for which we have syslogs), based on the driver's syslog, before Spark starts, the system has already allocated 8500 MiB to Linux/Google/Dataproc daemons. Moreover, the actual RAM of the system (as reported by the earlyoom daemon) is 52223 MiB (51 GiB, 1GiB less than Google advertises for n1-highmem-8). Assuming these daemons never release their memory, all our user code must fit in 43723 MiB. Since the JVM's max heap is 42598 MiB, Python",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:840,Availability,down,down,840,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:1914,Availability,echo,echo,1914,"unately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2081,Availability,avail,avail,2081,"unately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2183,Availability,avail,available,2183,"'s memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory setti",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2431,Availability,avail,available,2431,"mem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:3538,Availability,avail,available,3538,"al: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry from our local scientific community is that many of them have transitioned to Query-on-Batch where we have exact and total control over the memory available to the driver and the workers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:463,Deployability,release,released,463,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:994,Deployability,upgrade,upgraded,994," fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2492,Energy Efficiency,allocate,allocates,2492,"1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry from our local scientific community is that many of them have transitioned to Query-on-Batch where we have exact a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:3074,Energy Efficiency,reduce,reduces,3074,"al: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry from our local scientific community is that many of them have transitioned to Query-on-Batch where we have exact and total control over the memory available to the driver and the workers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:2733,Safety,safe,safe,2733,"al: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: All done; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. Notice:; 1. The total memory available on the machine is less than 52 GiB (= 53,248 MiB), indeed it is a full 1025 MiB below the advertised amount.; 2. Once all the components of the Dataproc cluster have started (but before any Hail Query jobs are submitted) the total memory available is already depleted to 42760 MiB. Recall that Hail allocates 41 GiB (= 41,984 MiB) to its JVM. This leaves the Python process and all other daemons on the system only 776 MiB of excess RAM. For reference `python3 -c 'import hail'` needs 206 MiB. ---. We must address this situation. It seems safe to assume that the system daemons will use a constant 9.5 GiB of RAM. Moreover the advertised RAM amount is at least 1 GiB larger than reality. I propose:; 1. The driver memory calculation in `hailctl dataproc` should take the advertised RAM amount, subtract 10.5 GiB, and then use 90% of the remaining value. For an n1-highmem-8, that reduces our allocation from 41 GiB to 37 GiB yielding an additional 4GiB to Python and deamon memory fluctuations.; 2. AoU RWB needs to review its memory settings for Spark driver nodes to ensure that the JVM is set to an appropriate maximum heap size. For what it's worth, I think the reason we didn't get an outcry from our local scientific community is that many of them have transitioned to Query-on-Batch where we have exact and total control over the memory available to the driver and the workers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:291,Testability,log,log,291,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:316,Testability,log,log,316,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:385,Usability,simpl,simply,385,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790
https://github.com/hail-is/hail/issues/13960#issuecomment-1836845812:147,Integrability,message,message,147,This ticket is complete when:. - [x] We merge a PR that modifies the driver memory setting for hailctl dataproc start as described in the previous message. https://github.com/hail-is/hail/pull/14066; - [x] We have received confirmation from the AoU RWB team that the Spark driver heap size is set in a manner that leaves abundant RAM for Python and daemon memory fluctuations.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836845812
https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445:5,Deployability,patch,patch,5,"This patch and the contents of #13970 was sufficient to successfully run `make -C hail install SPARK_VERSION=3.4.0` (but is incompatible with Spark 3.3). ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index 1b65904484..d1feb0e578 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -40,7 +40,7 @@ tasks.withType(JavaCompile) {; }; ; project.ext {; - breezeVersion = ""1.1""; + breezeVersion = ""2.1.0""; ; sparkVersion = System.getProperty(""spark.version"", ""3.3.0""); ; diff --git a/hail/src/main/scala/is/hail/HailContext.scala b/hail/src/main/scala/is/hail/HailContext.scala; index 4e4063378b..4d2f9056a5 100644; --- a/hail/src/main/scala/is/hail/HailContext.scala; +++ b/hail/src/main/scala/is/hail/HailContext.scala; @@ -113,10 +113,10 @@ object HailContext {; ; {; import breeze.linalg._; - import breeze.linalg.operators.{BinaryRegistry, OpMulMatrix}; + import breeze.linalg.operators.{BinaryRegistry, HasOps, OpMulMatrix}; ; implicitly[BinaryRegistry[DenseMatrix[Double], Vector[Double], OpMulMatrix.type, DenseVector[Double]]].register(; - DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD); + HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD); }; ; theContext = new HailContext(backend, branchingFactor, optimizerIterations); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445
https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445:87,Deployability,install,install,87,"This patch and the contents of #13970 was sufficient to successfully run `make -C hail install SPARK_VERSION=3.4.0` (but is incompatible with Spark 3.3). ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index 1b65904484..d1feb0e578 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -40,7 +40,7 @@ tasks.withType(JavaCompile) {; }; ; project.ext {; - breezeVersion = ""1.1""; + breezeVersion = ""2.1.0""; ; sparkVersion = System.getProperty(""spark.version"", ""3.3.0""); ; diff --git a/hail/src/main/scala/is/hail/HailContext.scala b/hail/src/main/scala/is/hail/HailContext.scala; index 4e4063378b..4d2f9056a5 100644; --- a/hail/src/main/scala/is/hail/HailContext.scala; +++ b/hail/src/main/scala/is/hail/HailContext.scala; @@ -113,10 +113,10 @@ object HailContext {; ; {; import breeze.linalg._; - import breeze.linalg.operators.{BinaryRegistry, OpMulMatrix}; + import breeze.linalg.operators.{BinaryRegistry, HasOps, OpMulMatrix}; ; implicitly[BinaryRegistry[DenseMatrix[Double], Vector[Double], OpMulMatrix.type, DenseVector[Double]]].register(; - DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD); + HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD); }; ; theContext = new HailContext(backend, branchingFactor, optimizerIterations); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445
https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445:1214,Performance,optimiz,optimizerIterations,1214,"This patch and the contents of #13970 was sufficient to successfully run `make -C hail install SPARK_VERSION=3.4.0` (but is incompatible with Spark 3.3). ```diff; diff --git a/hail/build.gradle b/hail/build.gradle; index 1b65904484..d1feb0e578 100644; --- a/hail/build.gradle; +++ b/hail/build.gradle; @@ -40,7 +40,7 @@ tasks.withType(JavaCompile) {; }; ; project.ext {; - breezeVersion = ""1.1""; + breezeVersion = ""2.1.0""; ; sparkVersion = System.getProperty(""spark.version"", ""3.3.0""); ; diff --git a/hail/src/main/scala/is/hail/HailContext.scala b/hail/src/main/scala/is/hail/HailContext.scala; index 4e4063378b..4d2f9056a5 100644; --- a/hail/src/main/scala/is/hail/HailContext.scala; +++ b/hail/src/main/scala/is/hail/HailContext.scala; @@ -113,10 +113,10 @@ object HailContext {; ; {; import breeze.linalg._; - import breeze.linalg.operators.{BinaryRegistry, OpMulMatrix}; + import breeze.linalg.operators.{BinaryRegistry, HasOps, OpMulMatrix}; ; implicitly[BinaryRegistry[DenseMatrix[Double], Vector[Double], OpMulMatrix.type, DenseVector[Double]]].register(; - DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD); + HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD); }; ; theContext = new HailContext(backend, branchingFactor, optimizerIterations); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13971#issuecomment-1792870445
https://github.com/hail-is/hail/issues/13971#issuecomment-1876070344:173,Deployability,release,release-,173,We will be skipping Spark 3.4.x and jumping to Spark 3.5.x because Google Dataproc has skipped to 3.5.x. https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.2,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13971#issuecomment-1876070344
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:673,Availability,error,error,673,"#### Summary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:772,Availability,error,error,772,"#### Summary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:856,Availability,error,error,856,"#### Summary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:995,Availability,error,error,995,"ary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""B",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1041,Availability,error,errors,1041,"ary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""B",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1120,Availability,error,error,1120,"280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBuff",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1413,Availability,error,error,1413,"here is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1460,Availability,failure,failure,1460,", we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:65",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:2157,Availability,Error,Error,2157,"e broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.ensure(InputBuffers.scala:385) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readByte(InputBuffers.scala:403) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac0",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:4017,Availability,Error,Error,4017,.hail.io.LEB128InputBuffer.skipInt(InputBuffers.scala:260) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at __C796collect_distributed_array_table_native_writer.__m872SKIP_o_int32(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m869INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m868INPLACE_DECODE_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_r_array_of_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m867DECODE_r_struct_of_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32ENDEND_TO_SBaseStructPointer(Unknown Source) ~[?:?]; ```. Error for run 2; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readBytes(InputBuffers.scala:444) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.LEB128InputBuffer.readBytes(InputBuffers.scala:253) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at __C816collect_distributed_array_table_native_writer.__m893INPLACE_DECODE_o_binary_TO_o_string(Unknown Source) ~[?:?]; 	at __C816collect_distributed_array_table_native_writer.__m889INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32A,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:207,Deployability,pipeline,pipeline,207,"#### Summary. It has happened twice. The failing partition is different in each run. 1. 49340 https://batch.hail.is/batches/8069235/jobs/51280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:2244,Safety,detect,detected,2244,"plementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.ensure(InputBuffers.scala:385) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readByte(InputBuffers.scala:403) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.LEB128InputBuffer.readByte(InputBuffers.scala:220) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.LEB128InputBuffer.skipInt(InputBuffers.scala:260) ~[gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at __C796collect_distributed_array_table_native_",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:4103,Safety,detect,detected,4103,gs:__hail-query-ger0g_jars_fcaafc533ec130ae210b152afa81c0b5ac04592b.jar.jar:0.0.1-SNAPSHOT]; 	at __C796collect_distributed_array_table_native_writer.__m872SKIP_o_int32(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m869INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m868INPLACE_DECODE_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_r_array_of_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at __C796collect_distributed_array_table_native_writer.__m867DECODE_r_struct_of_r_array_of_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32ENDEND_TO_SBaseStructPointer(Unknown Source) ~[?:?]; ```. Error for run 2; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:655) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.BlockingInputBuffer.readBytes(InputBuffers.scala:444) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.LEB128InputBuffer.readBytes(InputBuffers.scala:253) ~[gs:__hail-query-ger0g_jars_ee77707f4fab22b1c253321b082a70aff3f44d1c.jar.jar:0.0.1-SNAPSHOT]; 	at __C816collect_distributed_array_table_native_writer.__m893INPLACE_DECODE_o_binary_TO_o_string(Unknown Source) ~[?:?]; 	at __C816collect_distributed_array_table_native_writer.__m889INPLACE_DECODE_o_struct_of_o_int32ANDo_int32ANDo_int32ANDo_binaryANDo_array_of_o_int32END_TO_o_struct_of_o_callANDo_int32ANDo_stringANDo_array_of_o_int32END(Unknown Source) ~[?:?]; 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1077,Testability,log,logic,1077,"280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBuff",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1146,Testability,log,logic,1146,"280; 2. 25997 https://batch.hail.is/batches/8083195/jobs/27937. The pipeline runs two table collects to get sample information, then converts the matrix table to a table of ndarrays of the value `hl.int(hl.is_defined(mt.GT))`. The entries are getting subsetted, so there is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBuff",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1393,Testability,Log,Log,1393,"here is skipping going on. In both cases, we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623:1424,Testability,Log,Log,1424,", we are decoding the entry array when the corrupted block is discovered. In the first case, we are skipping an int (must be RGQ based on the etype and type). In the second case, we are decoding a string (must be FT). Since the error happens on a seemingly arbitrary partition, it seems likely this is related to our transient error handling. Both runs use a version of Hail after we fixed the broken transient error handling in GoogleStorageFS (run 1 used fcaafc533e, run 2 used 0.2.126 / ee77707f4f). ---. #### Path forward. If it *is* a transient error, we need to fix how we handle transient errors. Maybe our position handling logic is wrong? If it is *not* a transient error, maybe our skipping logic is wrong? FT appears immediately after RGQ and we know RGQ is getting skipped. Our implementation of `seek` for the compressed block buffers looks sketchy to me, but we're using PartitionNativeReader which does no seeking. Action items:; 1. Log every transient error.; 2. Log the file name and the offset on failure. ---. #### Debugging information. EType:; ```; +EBaseStruct{; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[; EBaseStruct{; GT:EInt32,; GQ:EInt32,; RGQ:EInt32,; FT:EBinary,; AD:EArray[EInt32]}]}; ```; (zipped) Type:; ```; Struct{; locus:Locus(GRCh38),; alleles:Array[String],; filters:Set[String],; info:Struct{; AC:Array[Int32]},; `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[; Struct{; GT:Call,; GQ:Int32,; FT:String,; AD:Array[Int32]}]}; ```; Source buffer spec:; ```; {""name"":""LEB128BufferSpec"",""child"":; {""name"":""BlockingBufferSpec"",""blockSize"":65536,""child"":; {""name"":""ZstdBlockBufferSpec"",""blockSize"":65536,""child"":; {""name"":""StreamBlockBufferSpec""}}}}; ```; Error for run 1.; ```; Caused by: com.github.luben.zstd.ZstdException: Corrupted block detected; 	at com.github.luben.zstd.ZstdDecompressCtx.decompressByteArray(ZstdDecompressCtx.java:157) ~[zstd-jni-1.5.2-1.jar:1.5.2-1]; 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:65",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834181623
https://github.com/hail-is/hail/issues/13979#issuecomment-1834228219:30,Deployability,pipeline,pipeline,30,I've asked Wenhan to run this pipeline with a JAR that has extra debugging information enabled https://github.com/hail-is/hail/compare/main...danking:hail:debug-13979.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834228219
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:27,Availability,failure,failure,27,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:149,Availability,error,errors,149,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:211,Availability,error,errors,211,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:256,Availability,error,error,256,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:387,Availability,error,error,387,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:937,Energy Efficiency,allocate,allocated,937,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:1283,Energy Efficiency,allocate,allocated,1283,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:114,Integrability,message,message,114,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:234,Integrability,message,message,234,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:864,Performance,cache,cache,864,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:1210,Performance,cache,cache,1210,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:1715,Security,hash,hash,1715,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:110,Testability,log,log,110,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:167,Testability,log,log,167,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:466,Usability,learn,learn,466,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385
https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845:54,Availability,Failure,Failures,54,We tried updated to zstd-jni 1.5.5-11 from 1.5.5-2. 4 Failures. [6873](https://batch.hail.is/batches/8093977/jobs/6873) execute(...)_stage2_table_native_writer_job4933	Failed		13s 631ms	$0.0001; [7157](https://batch.hail.is/batches/8093977/jobs/7157) execute(...)_stage2_table_native_writer_job5217	Failed		15s 919ms	$0.0001; [8854](https://batch.hail.is/batches/8093977/jobs/8854) execute(...)_stage2_table_native_writer_job6914	Failed		1 minute 12s	$0.0006; [12795](https://batch.hail.is/batches/8093977/jobs/12795) execute(...)_stage2_table_native_writer_job10855	Failed		21s 305ms	$0.0002,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845
https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845:9,Deployability,update,updated,9,We tried updated to zstd-jni 1.5.5-11 from 1.5.5-2. 4 Failures. [6873](https://batch.hail.is/batches/8093977/jobs/6873) execute(...)_stage2_table_native_writer_job4933	Failed		13s 631ms	$0.0001; [7157](https://batch.hail.is/batches/8093977/jobs/7157) execute(...)_stage2_table_native_writer_job5217	Failed		15s 919ms	$0.0001; [8854](https://batch.hail.is/batches/8093977/jobs/8854) execute(...)_stage2_table_native_writer_job6914	Failed		1 minute 12s	$0.0006; [12795](https://batch.hail.is/batches/8093977/jobs/12795) execute(...)_stage2_table_native_writer_job10855	Failed		21s 305ms	$0.0002,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843738845
https://github.com/hail-is/hail/issues/13979#issuecomment-1843765049:29,Availability,error,error,29,"In the latter two cases, the error does not come from zstd decompression. It comes later during region allocation and using isHet on a Call with ploidy 3. When zstd does notice a decompression issue, it's always immediately after a read. In this case, immediately after a read of the entries data, but in the past we've seen reads of other MTs/HTs. Note that the entries are the bulk of the bytes, so if there's something that's rare in terms of bytes processed, we're just much more likely to see it in the entries.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843765049
https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744:121,Availability,down,download,121,"Let's compare 8093951-8854 to 8093977-8854. The latter is a failed task (partition 6914) the former is successful. We'll download the logs and make toss away some debug info that changed between the experiments. ```; cat log | rg StreamBlockInputBuffer: | sed 's/bytes.*//' > newlog; ```. Since the latter failed, the log obviously ends earlier, but there are *no differences* (besides timestamps) in the size of the blocks read from GCS. Since these block sizes are read from the input stream, this is pretty good evidence that the bytes aren't corrupted up until now. ```; # git diff --no-index --word-diff good bad ; ...; 2023-12-06 [-19:47:11.500-]{+21:39:00.885+} StreamBlockInputBuffer: INFO: reading 2081[-2023-12-06 19:47:11.531 StreamBlockInputBuffer: INFO: reading 2499-]; ```. The decompressed data size is the same: 65536. It's worth noting this is a relatively small compressed buffer after a series of much larger compressed buffers. This one is 2081 and the immediately previous one is 14675. Most of the ones before this are also in the 14k range. ---. Same experiment on job 7157 again shows no differences in bytes read before the exception occurs. ```; 2023-12-06 [-19:45:18.693-]{+21:36:52.116+} StreamBlockInputBuffer: INFO: reading 17923 ; 2023-12-06 [-19:45:18.809-]{+21:36:52.388+} StreamBlockInputBuffer: INFO: reading 17843[-2023-12-06 19:45:18.810 StreamBlockInputBuffer: INFO: reading 17657-]; [-2023-12-06 19:45:18.811 StreamBlockInputBuffer: INFO: reading 17646-]; ```. The network reads are identical other than the size of the first read. That first read is the serialized function. I'm not that surprised it differs in size between different commits of Hail. The byte counting is done in our code. If we're counting bytes correctly, then it seems like we're reading the same series of chunks from GCS. . ```; GoogleStorageFS$: INFO: read 1755052 (0 of 1755052) oldbb(0, 8388608) newbb(0, 1755052); GoogleStorageFS$: INFO: read 8388608 (62604 of 58870664) oldbb(0, 8388",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744
https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744:134,Testability,log,logs,134,"Let's compare 8093951-8854 to 8093977-8854. The latter is a failed task (partition 6914) the former is successful. We'll download the logs and make toss away some debug info that changed between the experiments. ```; cat log | rg StreamBlockInputBuffer: | sed 's/bytes.*//' > newlog; ```. Since the latter failed, the log obviously ends earlier, but there are *no differences* (besides timestamps) in the size of the blocks read from GCS. Since these block sizes are read from the input stream, this is pretty good evidence that the bytes aren't corrupted up until now. ```; # git diff --no-index --word-diff good bad ; ...; 2023-12-06 [-19:47:11.500-]{+21:39:00.885+} StreamBlockInputBuffer: INFO: reading 2081[-2023-12-06 19:47:11.531 StreamBlockInputBuffer: INFO: reading 2499-]; ```. The decompressed data size is the same: 65536. It's worth noting this is a relatively small compressed buffer after a series of much larger compressed buffers. This one is 2081 and the immediately previous one is 14675. Most of the ones before this are also in the 14k range. ---. Same experiment on job 7157 again shows no differences in bytes read before the exception occurs. ```; 2023-12-06 [-19:45:18.693-]{+21:36:52.116+} StreamBlockInputBuffer: INFO: reading 17923 ; 2023-12-06 [-19:45:18.809-]{+21:36:52.388+} StreamBlockInputBuffer: INFO: reading 17843[-2023-12-06 19:45:18.810 StreamBlockInputBuffer: INFO: reading 17657-]; [-2023-12-06 19:45:18.811 StreamBlockInputBuffer: INFO: reading 17646-]; ```. The network reads are identical other than the size of the first read. That first read is the serialized function. I'm not that surprised it differs in size between different commits of Hail. The byte counting is done in our code. If we're counting bytes correctly, then it seems like we're reading the same series of chunks from GCS. . ```; GoogleStorageFS$: INFO: read 1755052 (0 of 1755052) oldbb(0, 8388608) newbb(0, 1755052); GoogleStorageFS$: INFO: read 8388608 (62604 of 58870664) oldbb(0, 8388",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744
https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744:221,Testability,log,log,221,"Let's compare 8093951-8854 to 8093977-8854. The latter is a failed task (partition 6914) the former is successful. We'll download the logs and make toss away some debug info that changed between the experiments. ```; cat log | rg StreamBlockInputBuffer: | sed 's/bytes.*//' > newlog; ```. Since the latter failed, the log obviously ends earlier, but there are *no differences* (besides timestamps) in the size of the blocks read from GCS. Since these block sizes are read from the input stream, this is pretty good evidence that the bytes aren't corrupted up until now. ```; # git diff --no-index --word-diff good bad ; ...; 2023-12-06 [-19:47:11.500-]{+21:39:00.885+} StreamBlockInputBuffer: INFO: reading 2081[-2023-12-06 19:47:11.531 StreamBlockInputBuffer: INFO: reading 2499-]; ```. The decompressed data size is the same: 65536. It's worth noting this is a relatively small compressed buffer after a series of much larger compressed buffers. This one is 2081 and the immediately previous one is 14675. Most of the ones before this are also in the 14k range. ---. Same experiment on job 7157 again shows no differences in bytes read before the exception occurs. ```; 2023-12-06 [-19:45:18.693-]{+21:36:52.116+} StreamBlockInputBuffer: INFO: reading 17923 ; 2023-12-06 [-19:45:18.809-]{+21:36:52.388+} StreamBlockInputBuffer: INFO: reading 17843[-2023-12-06 19:45:18.810 StreamBlockInputBuffer: INFO: reading 17657-]; [-2023-12-06 19:45:18.811 StreamBlockInputBuffer: INFO: reading 17646-]; ```. The network reads are identical other than the size of the first read. That first read is the serialized function. I'm not that surprised it differs in size between different commits of Hail. The byte counting is done in our code. If we're counting bytes correctly, then it seems like we're reading the same series of chunks from GCS. . ```; GoogleStorageFS$: INFO: read 1755052 (0 of 1755052) oldbb(0, 8388608) newbb(0, 1755052); GoogleStorageFS$: INFO: read 8388608 (62604 of 58870664) oldbb(0, 8388",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744
https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744:318,Testability,log,log,318,"Let's compare 8093951-8854 to 8093977-8854. The latter is a failed task (partition 6914) the former is successful. We'll download the logs and make toss away some debug info that changed between the experiments. ```; cat log | rg StreamBlockInputBuffer: | sed 's/bytes.*//' > newlog; ```. Since the latter failed, the log obviously ends earlier, but there are *no differences* (besides timestamps) in the size of the blocks read from GCS. Since these block sizes are read from the input stream, this is pretty good evidence that the bytes aren't corrupted up until now. ```; # git diff --no-index --word-diff good bad ; ...; 2023-12-06 [-19:47:11.500-]{+21:39:00.885+} StreamBlockInputBuffer: INFO: reading 2081[-2023-12-06 19:47:11.531 StreamBlockInputBuffer: INFO: reading 2499-]; ```. The decompressed data size is the same: 65536. It's worth noting this is a relatively small compressed buffer after a series of much larger compressed buffers. This one is 2081 and the immediately previous one is 14675. Most of the ones before this are also in the 14k range. ---. Same experiment on job 7157 again shows no differences in bytes read before the exception occurs. ```; 2023-12-06 [-19:45:18.693-]{+21:36:52.116+} StreamBlockInputBuffer: INFO: reading 17923 ; 2023-12-06 [-19:45:18.809-]{+21:36:52.388+} StreamBlockInputBuffer: INFO: reading 17843[-2023-12-06 19:45:18.810 StreamBlockInputBuffer: INFO: reading 17657-]; [-2023-12-06 19:45:18.811 StreamBlockInputBuffer: INFO: reading 17646-]; ```. The network reads are identical other than the size of the first read. That first read is the serialized function. I'm not that surprised it differs in size between different commits of Hail. The byte counting is done in our code. If we're counting bytes correctly, then it seems like we're reading the same series of chunks from GCS. . ```; GoogleStorageFS$: INFO: read 1755052 (0 of 1755052) oldbb(0, 8388608) newbb(0, 1755052); GoogleStorageFS$: INFO: read 8388608 (62604 of 58870664) oldbb(0, 8388",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744
https://github.com/hail-is/hail/pull/13980#issuecomment-1798843967:69,Deployability,deploy,deployed,69,I'm putting the WIP tag on until we get the batch database migration deployed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13980#issuecomment-1798843967
https://github.com/hail-is/hail/pull/13985#issuecomment-1804259410:175,Performance,Concurren,Concurrent,175,"@jigold https://dev.mysql.com/doc/refman/8.0/en/innodb-online-ddl-operations.html#online-ddl-primary-key-operations. Operation | Instant | In Place | Rebuilds Table | Permits Concurrent DML | Only Modifies Metadata; -- | -- | -- | -- | -- | --; Adding a primary key	|No | Yes* | Yes* | Yes | No; Dropping a primary key	|No | No | Yes | No | No; Dropping a primary key and adding another	|No | Yes | Yes | Yes | No. So, replacing the primary key can be done inplace while allowing data manipulation on the table. It sounds like we should use the syntax:; ```; ALTER TABLE tbl_name DROP PRIMARY KEY, ADD PRIMARY KEY (column), ALGORITHM=INPLACE, LOCK=NONE;; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13985#issuecomment-1804259410
https://github.com/hail-is/hail/pull/13985#issuecomment-1809137525:0,Testability,Test,Tests,0,Tests are passing now!!!! Ready for review. Remember this is stacked on another PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13985#issuecomment-1809137525
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:4,Availability,error,error,4,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2226,Availability,error,error,2226,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:379,Modifiability,Plugin,Plugins,379,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:639,Modifiability,Plugin,Plugins,639,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:722,Modifiability,Plugin,Plugins,722,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:805,Modifiability,Plugin,Plugins,805,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:891,Modifiability,Plugin,Plugins,891,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:977,Modifiability,Plugin,Plugins,977,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:1063,Modifiability,Plugin,Plugins,1063,"rring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:1879,Modifiability,plugin,plugin,1879,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:1922,Modifiability,Plugin,Plugins,1922,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2129,Modifiability,Plugin,Plugins,2129,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2288,Modifiability,Plugin,Plugins,2288,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2371,Modifiability,Plugin,Plugins,2371,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2454,Modifiability,Plugin,Plugins,2454,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2540,Modifiability,Plugin,Plugins,2540,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2626,Modifiability,Plugin,Plugins,2626,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:2712,Modifiability,Plugin,Plugins,2712,"4.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241.; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:1731,Performance,cache,cache,1731,"p/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/vep_data//human_ancestor.fa.gz,conservation_file:/vep_data//loftee.sql', '--dir_plugins', '/vep/ensembl-vep/Plugins/', '--dir_cache', '/vep_data/', '-o', 'STDOUT'] failed with non-zero exit status -9; VEP error output:; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224:18,Testability,log,log,18,"The error about a log file is an unfortunate red herring, the main container appears to fail. `/vep/vep` is returning exit code -9 but providing no further debug information. We need to assess who is generating the -9. Based on the contents of `docker/hailgenetics/vep/grch38/95/Dockerfile`, `/vep/vep` appears to be; ```; #!/bin/bash; export PERL5LIB=$PERL5LIB:/vep/ensembl-vep/Plugins/; exec perl /vep/ensembl-vep/vep \""\$@\""""; ```; It seems likely that `/vep/esnembl-vep/vep` is returning exit code -9. We need to determine under what conditions that happens. Main container output:; ```; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /vep/ensembl-vep/Plugins/splice_site_scan.pl line 241. Traceback (most recent call last):; File ""/hail-vep/vep.py"", line 218, in <module>; main(action, consequence, tolerate_parse_error, block_size, input_file, output_file, part_id, vep_cmd); File ""/hail-vep/vep.py"", line 199, in main; results = run_vep(vep_cmd, input_file, block_size, consequence, tolerate_parse_error, part_id, os.environ); File ""/hail-vep/vep.py"", line 127, in run_vep; raise ValueError(f'VEP command {vep_cmd} failed with non-zero exit status {proc.returncode}\n'; ValueError: VEP command ['/vep/vep', '--input_file', '/io/input', '--format', 'vcf', '--json', '--everything', '--allele_number', '--no_stats', '--cache', '--offline', '--minimal', '--assembly', 'GRCh38', '--fasta', '/vep_data//homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz', '--plugin', 'LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:/vep_data//gerp_conservation_scores.homo_sapiens.GRCh38.bw",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1802287224
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:74,Availability,down,downloaded,74,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:208,Availability,failure,failure,208,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:227,Availability,failure,failure,227,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:39,Testability,test,test,39,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:1974,Testability,test,test,1974," chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows much more slowly. https://batch.hail.is/batches/8089322/jobs/3; ```; chr1	10122	.	A	C	128.00	AC0	AC=0;AN=90064;AF=0.00000e+00;lcr;variant_type=snv;n_alt_alleles=1;ReadPosRankSum=-6.69000e-01;MQRankSum=-1.58200e+00;RAW_MQ=1.86842e+05;DP=119;MQ_DP=137;VarDP=119;MQ=3.69298e+01;QD=1.07563e+00;FS=2.34212e+00;SB=281,217,5,6;InbreedingCoeff=-1.46711e-05;AS_VQSLOD=-6.44890e+00;NEGATIVE_TRAIN_SITE;culprit=AS_QD;SOR=6.72000e-01;AC_asj_female=0;AN_asj_female=1182;AF_asj_female=0.00000e+00;nhomalt_asj_female=0;AC_eas_female=0;AN_eas_female=878;AF_eas_female=0.00000e+00;nhomalt_eas_female=0;AC_afr_male=0;AN_afr_male=11652;AF_afr_male=0.00000e+00;nhomalt_afr_male=0;AC_female=0;AN_female=45840;AF_female=0.00000e+00;nhomalt_female=0;AC_fin_male=0;AN_fin_male=5562;AF_fin_male=0.00000e+00;nhomalt_fin_male=0;AC_oth_female=0;AN_oth_female=702;AF_oth_female=0.00000e+00;nhomalt_oth_female=0;AC_ami=0;AN_ami=488;AF_ami=0.00000e+00;nhomalt_ami=0;AC_oth=0;AN_oth=1340;AF_ot",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:240,Usability,clear,clearly,240,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:257,Availability,down,download,257,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:327,Deployability,release,release-,327,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:479,Deployability,update,update,479,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:293,Performance,cache,cache,293,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:103,Testability,test,test,103,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145:44,Usability,learn,learned,44,"@jigold OK, so here's the summary of what I learned:. We don't have tabix files for GRCh38 and we only test on small positions. Many large positions without tabix files seems to cause a problem for VEP (and make it slow, unsurprisingly). Fix seems to be to download the *indexed* homo_sapiens cache https://ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/ and upload that to our QoB VEP bucket. I presume you copied from the data we use in Dataproc? If yes, we should update that to also have tabix files. Also, in Dataproc, we use highmem machines for VEP. We should change _service_vep to also use highmem machines. <details><summary>Listing the tabix files for GRCh38 and GRCh37</summary>. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch38-us-central1/homo_sapiens/95_GRCh38/\*/\*.tbi; CommandException: One or more URLs matched no objects.; ```. ```; (base) dking@wm28c-761 /tmp % gsutil ls gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/\*/\*.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/1/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/10/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/11/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/12/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/13/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/14/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/15/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/16/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/17/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/18/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/19/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapiens/85_GRCh37/2/all_vars.gz.tbi; gs://hail-qob-vep-grch37-us-central1/homo_sapi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830868145
https://github.com/hail-is/hail/issues/13989#issuecomment-1830874506:39,Testability,test,test,39,"This ticket is complete when:; - [ ] A test is added using the VCF provided by Julia.; - [ ] We have tabixed GRCh38 data in the QoB bucket and also in each Dataproc location: us, eu, aus-sydney. I've removed the highmem requirement from this list. I'm not convinced that, if we fix the tabix issue, we will need highmem machines.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830874506
https://github.com/hail-is/hail/issues/13989#issuecomment-1832737456:697,Deployability,release,release-,697,"Thanks for figuring this out! For dataproc, the startup script runs the code below the first time the data is used to generate the index for GRCh37 only. I ran the same dummy VEP command when I generated the QoB data for GRCh37. But we don't do this in GRCh38 on dataproc, so I didn't run this command for QoB as well. The fix is to add something similar as below to the GRCh38 dataproc script and then independently fix the QoB data for GRCh38. ```; # Run VEP on the 1-variant VCF to create fasta.index file -- caution do not make fasta.index file writeable afterwards!; cat /vep_data/loftee_data/1var.vcf | docker run -i -v /vep_data:/root/.vep \; ${VEP_DOCKER_IMAGE} \; perl /vep/ensembl-tools-release-85/scripts/variant_effect_predictor/variant_effect_predictor.pl \; --format vcf \; --json \; --everything \; --allele_number \; --no_stats \; --cache --offline \; --minimal \; --assembly ${ASSEMBLY} \; -o STDOUT; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1832737456
https://github.com/hail-is/hail/issues/13989#issuecomment-1832737456:849,Performance,cache,cache,849,"Thanks for figuring this out! For dataproc, the startup script runs the code below the first time the data is used to generate the index for GRCh37 only. I ran the same dummy VEP command when I generated the QoB data for GRCh37. But we don't do this in GRCh38 on dataproc, so I didn't run this command for QoB as well. The fix is to add something similar as below to the GRCh38 dataproc script and then independently fix the QoB data for GRCh38. ```; # Run VEP on the 1-variant VCF to create fasta.index file -- caution do not make fasta.index file writeable afterwards!; cat /vep_data/loftee_data/1var.vcf | docker run -i -v /vep_data:/root/.vep \; ${VEP_DOCKER_IMAGE} \; perl /vep/ensembl-tools-release-85/scripts/variant_effect_predictor/variant_effect_predictor.pl \; --format vcf \; --json \; --everything \; --allele_number \; --no_stats \; --cache --offline \; --minimal \; --assembly ${ASSEMBLY} \; -o STDOUT; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1832737456
https://github.com/hail-is/hail/issues/13989#issuecomment-1832748615:23,Modifiability,config,configured,23,"Actually, v95 might be configured differently, so we do need to do something else...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1832748615
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:237,Modifiability,rewrite,rewrite,237,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:92,Testability,log,logic,92,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:445,Testability,assert,assert,445,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:521,Testability,assert,assertion,521,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:640,Testability,assert,assert,640,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:653,Testability,assert,assert,653,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:666,Testability,assert,assert,666,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:753,Testability,assert,assertions,753,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:38,Usability,simpl,simplicity,38,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:115,Usability,simpl,simplified,115,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:298,Usability,simpl,simplify,298,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400:509,Usability,clear,clear,509,"> This has significantly improved the simplicity of the parser, so much so that much of the logic therein could be simplified further, though I think that's beyond the scope of this change. Agreed. But as my follow up will be a complete rewrite of the parser, I definitely don't want to do more to simplify the current one. > I like the separation of type-checking and parsing, however I'd prefer in your implementations of `typecheck` that you assert one thing at a time. That way when things fail, it'll be clear which assertion was fired (ie if `(a && b && c)` fails, you don't know if it's `a` or `b` or `c`, whereas; > ; > ```scala; > assert(a); > assert(b); > assert(c); > ```; > ; > would give you that information. Good suggestion. I only moved assertions here, didn't add any new ones, but I don't mind splitting up some that I moved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/13990#issuecomment-1809203400
https://github.com/hail-is/hail/issues/13993#issuecomment-1969996616:63,Availability,avail,available,63,Need more information. Please re-open when more information is available!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13993#issuecomment-1969996616
https://github.com/hail-is/hail/issues/13996#issuecomment-1804219578:183,Deployability,install,installed,183,"This specifically pertains to the *cgroup* of the user container. This command will probably *not* work inside the user container's mount namespace as 1. they wouldn't have `gcsfuse` installed and 2. we don't give them the capabilities necessary to set up a FUSE mount. `nsenter` should allow us to invoke `gcsfuse` inside the user's cgroup to attribute any memory usage to the user and not as part of the batch container. The tricky bit is that currently we run `gcsfuse`/`blobfuse` before the container is created. Because `crun` currently creates/destroys the cgroup, it does not yet exist when these mounts are set up. It *might* be possible to use [OCI hooks](https://github.com/opencontainers/runtime-spec/blob/main/config.md#prestart) to run `gcsfuse`/`blobfuse` after the container and corresponding cgroup is created but before user code is run.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13996#issuecomment-1804219578
https://github.com/hail-is/hail/issues/13996#issuecomment-1804219578:722,Modifiability,config,config,722,"This specifically pertains to the *cgroup* of the user container. This command will probably *not* work inside the user container's mount namespace as 1. they wouldn't have `gcsfuse` installed and 2. we don't give them the capabilities necessary to set up a FUSE mount. `nsenter` should allow us to invoke `gcsfuse` inside the user's cgroup to attribute any memory usage to the user and not as part of the batch container. The tricky bit is that currently we run `gcsfuse`/`blobfuse` before the container is created. Because `crun` currently creates/destroys the cgroup, it does not yet exist when these mounts are set up. It *might* be possible to use [OCI hooks](https://github.com/opencontainers/runtime-spec/blob/main/config.md#prestart) to run `gcsfuse`/`blobfuse` after the container and corresponding cgroup is created but before user code is run.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13996#issuecomment-1804219578
https://github.com/hail-is/hail/issues/13998#issuecomment-1834317436:86,Integrability,message,message,86,I squashed this in https://github.com/hail-is/hail/pull/14057; more details in the PR message.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/13998#issuecomment-1834317436
https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207:377,Deployability,install,installed,377,"```; (py311) jigold@wm349-8c4 hail % gcloud artifacts repositories set-cleanup-policies hail \; --project=hail-vdc \; --location=us \; --policy=/Users/jigold/projects/hail/infra/gcp-broad/gcp-ar-cleanup-policy.txt \; --no-dry-run; WARNING: Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up. If you have a compatible Python interpreter installed, you can use it by setting; the CLOUDSDK_PYTHON environment variable to point to it. Updated repository [hail].; Dry run is disabled.; ```. I checked the UI and it seems correct now.; <img width=""420"" alt=""Screenshot 2023-11-15 at 7 50 06 AM"" src=""https://github.com/hail-is/hail/assets/1693348/630f0481-c24a-4e41-9350-ef091cc62b1b"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207
https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207:472,Deployability,Update,Updated,472,"```; (py311) jigold@wm349-8c4 hail % gcloud artifacts repositories set-cleanup-policies hail \; --project=hail-vdc \; --location=us \; --policy=/Users/jigold/projects/hail/infra/gcp-broad/gcp-ar-cleanup-policy.txt \; --no-dry-run; WARNING: Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up. If you have a compatible Python interpreter installed, you can use it by setting; the CLOUDSDK_PYTHON environment variable to point to it. Updated repository [hail].; Dry run is disabled.; ```. I checked the UI and it seems correct now.; <img width=""420"" alt=""Screenshot 2023-11-15 at 7 50 06 AM"" src=""https://github.com/hail-is/hail/assets/1693348/630f0481-c24a-4e41-9350-ef091cc62b1b"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207
https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207:447,Modifiability,variab,variable,447,"```; (py311) jigold@wm349-8c4 hail % gcloud artifacts repositories set-cleanup-policies hail \; --project=hail-vdc \; --location=us \; --policy=/Users/jigold/projects/hail/infra/gcp-broad/gcp-ar-cleanup-policy.txt \; --no-dry-run; WARNING: Python 3.5-3.7 will be deprecated on August 8th, 2023. Please use Python version 3.8 and up. If you have a compatible Python interpreter installed, you can use it by setting; the CLOUDSDK_PYTHON environment variable to point to it. Updated repository [hail].; Dry run is disabled.; ```. I checked the UI and it seems correct now.; <img width=""420"" alt=""Screenshot 2023-11-15 at 7 50 06 AM"" src=""https://github.com/hail-is/hail/assets/1693348/630f0481-c24a-4e41-9350-ef091cc62b1b"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14001#issuecomment-1812482207
https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604:299,Availability,error,error,299,"Adding a simple reproducible example. ```python; ht = hl.Table.from_pandas(pd.DataFrame({""variant"":['chr1:123:C:T']})); ht = ht.key_by(**hl.parse_variant(ht.variant)); pd_table = ht.to_pandas(); pd_table.to_pickle(os.path.join(bucket, 'test.pkl')); ```. The two examples below do not cause the same error. ; ```python; ht = hl.Table.from_pandas(pd.DataFrame({""foo"":['bar']})); ht = hl.Table.from_pandas(pd.DataFrame({""foo"":[1, 2, 3]})); ```. Hope this helps.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604
https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604:236,Testability,test,test,236,"Adding a simple reproducible example. ```python; ht = hl.Table.from_pandas(pd.DataFrame({""variant"":['chr1:123:C:T']})); ht = ht.key_by(**hl.parse_variant(ht.variant)); pd_table = ht.to_pandas(); pd_table.to_pickle(os.path.join(bucket, 'test.pkl')); ```. The two examples below do not cause the same error. ; ```python; ht = hl.Table.from_pandas(pd.DataFrame({""foo"":['bar']})); ht = hl.Table.from_pandas(pd.DataFrame({""foo"":[1, 2, 3]})); ```. Hope this helps.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604
https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604:9,Usability,simpl,simple,9,"Adding a simple reproducible example. ```python; ht = hl.Table.from_pandas(pd.DataFrame({""variant"":['chr1:123:C:T']})); ht = ht.key_by(**hl.parse_variant(ht.variant)); pd_table = ht.to_pandas(); pd_table.to_pickle(os.path.join(bucket, 'test.pkl')); ```. The two examples below do not cause the same error. ; ```python; ht = hl.Table.from_pandas(pd.DataFrame({""foo"":['bar']})); ht = hl.Table.from_pandas(pd.DataFrame({""foo"":[1, 2, 3]})); ```. Hope this helps.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1808416604
https://github.com/hail-is/hail/issues/14004#issuecomment-1813149330:680,Safety,avoid,avoid,680,"> This suggests to me that the dataframe created by hail maintains reference to hail objects and pandas is attempting to recreate these objects when unpickling. I suspect this is not intentional. Hi @anh151, you are correct that `to_pandas` is creating dataframes that contain hail objects. In your example, the hail type in question is the [`Locus`](https://hail.is/docs/0.2/genetics/hail.genetics.Locus.html#locus), but we also have a couple auxiliary classes like `Interval` and `Call` that could end up in the pandas table. I see how this can be unintuitive especially with your point of round-tripping through CSV (which uses the `str` of the object by default and thus will avoid the class lookup on read), but I hesitate to call it unintentional. I'll broach this question with the team as to what would be the least confusing behavior, but I suspect many users are using `to_pandas` results in the same hail session in which case it might be expected to get small hail objects in their result. In the meantime, you can look at the schema of your resultant table and translate within pandas to your desired representation, i.e. convert Locus entries to dicts.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1813149330
https://github.com/hail-is/hail/issues/14004#issuecomment-1813182236:28,Usability,feedback,feedback,28,"Sounds good. Thanks for the feedback. If it requires a significant effort to modify the code base to remove this behavior or if the change is not desired, it may be worth including a warning/info section describing this behavior in the documentation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14004#issuecomment-1813182236
https://github.com/hail-is/hail/pull/14005#issuecomment-1874171278:20,Performance,cache,cache,20,Ensuring consistent cache keys across builds is challenging. We have to at least move the build-info file out of the JAR but there seemed to be other minor inconsistencies too,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14005#issuecomment-1874171278
https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472:242,Performance,load,load,242,"Here's an implementation of a *split* SVCF-VCF courtesy of Tim P:; ```python3; import hail as hl. from constants import *. hl.init(log='/tmp/hail.log'). vds = hl.vds.read_vds(vds_path). hl.get_reference('GRCh38').add_sequence(get_fasta()). # load metadata structure from arbitrary input GVCF; metadata = hl.get_vcf_metadata(gvcf_paths[0]); metadata['format']['LEN'] = {; 'Description': 'Reference block length',; 'Number': '1',; 'Type': 'Integer',; }. # create reference VCF; rd = vds.reference_data; rd = rd.key_rows_by(locus=rd.locus, alleles=[rd.locus.sequence_context()]); rd = rd.transmute_entries(LEN=rd.END - rd.locus.position + 1); hl.export_vcf(rd, reference_svcr_vcf_path, metadata=metadata,; tabix=True). # create variant VCF; vd = vds.variant_data. # recode gvcf_info struct to top-level fields for compatibility with VCF format limitations; info_fields = list(vd.gvcf_info); mt = vd.transmute_entries(**{f'INFO_{x}': vd.gvcf_info[x] for x in info_fields}). # recode boolean info fields as integers to support VCF spec; bool_fields = [fd for fd in mt.entry if mt[fd].dtype == hl.tbool]; mt = mt.transmute_entries(**{fd: hl.int(mt[fd]) for fd in bool_fields}). def transform_number(number):; if number in {'A', 'R', 'G'}:; return f'LOCAL_{number}'; return number. for info_fd in info_fields:; info = metadata['info'][info_fd]; if info['Type'] == 'Flag':; info['Type'] = 'Integer'; info['Number'] = '1'; metadata['format'][f'INFO_{info_fd}'] = info. for d in metadata['format'].values():; d['Number'] = transform_number(d.get('Number')). hl.export_vcf(mt, variant_svcr_vcf_path, metadata=metadata,; tabix=True); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472
https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472:131,Testability,log,log,131,"Here's an implementation of a *split* SVCF-VCF courtesy of Tim P:; ```python3; import hail as hl. from constants import *. hl.init(log='/tmp/hail.log'). vds = hl.vds.read_vds(vds_path). hl.get_reference('GRCh38').add_sequence(get_fasta()). # load metadata structure from arbitrary input GVCF; metadata = hl.get_vcf_metadata(gvcf_paths[0]); metadata['format']['LEN'] = {; 'Description': 'Reference block length',; 'Number': '1',; 'Type': 'Integer',; }. # create reference VCF; rd = vds.reference_data; rd = rd.key_rows_by(locus=rd.locus, alleles=[rd.locus.sequence_context()]); rd = rd.transmute_entries(LEN=rd.END - rd.locus.position + 1); hl.export_vcf(rd, reference_svcr_vcf_path, metadata=metadata,; tabix=True). # create variant VCF; vd = vds.variant_data. # recode gvcf_info struct to top-level fields for compatibility with VCF format limitations; info_fields = list(vd.gvcf_info); mt = vd.transmute_entries(**{f'INFO_{x}': vd.gvcf_info[x] for x in info_fields}). # recode boolean info fields as integers to support VCF spec; bool_fields = [fd for fd in mt.entry if mt[fd].dtype == hl.tbool]; mt = mt.transmute_entries(**{fd: hl.int(mt[fd]) for fd in bool_fields}). def transform_number(number):; if number in {'A', 'R', 'G'}:; return f'LOCAL_{number}'; return number. for info_fd in info_fields:; info = metadata['info'][info_fd]; if info['Type'] == 'Flag':; info['Type'] = 'Integer'; info['Number'] = '1'; metadata['format'][f'INFO_{info_fd}'] = info. for d in metadata['format'].values():; d['Number'] = transform_number(d.get('Number')). hl.export_vcf(mt, variant_svcr_vcf_path, metadata=metadata,; tabix=True); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472
https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472:146,Testability,log,log,146,"Here's an implementation of a *split* SVCF-VCF courtesy of Tim P:; ```python3; import hail as hl. from constants import *. hl.init(log='/tmp/hail.log'). vds = hl.vds.read_vds(vds_path). hl.get_reference('GRCh38').add_sequence(get_fasta()). # load metadata structure from arbitrary input GVCF; metadata = hl.get_vcf_metadata(gvcf_paths[0]); metadata['format']['LEN'] = {; 'Description': 'Reference block length',; 'Number': '1',; 'Type': 'Integer',; }. # create reference VCF; rd = vds.reference_data; rd = rd.key_rows_by(locus=rd.locus, alleles=[rd.locus.sequence_context()]); rd = rd.transmute_entries(LEN=rd.END - rd.locus.position + 1); hl.export_vcf(rd, reference_svcr_vcf_path, metadata=metadata,; tabix=True). # create variant VCF; vd = vds.variant_data. # recode gvcf_info struct to top-level fields for compatibility with VCF format limitations; info_fields = list(vd.gvcf_info); mt = vd.transmute_entries(**{f'INFO_{x}': vd.gvcf_info[x] for x in info_fields}). # recode boolean info fields as integers to support VCF spec; bool_fields = [fd for fd in mt.entry if mt[fd].dtype == hl.tbool]; mt = mt.transmute_entries(**{fd: hl.int(mt[fd]) for fd in bool_fields}). def transform_number(number):; if number in {'A', 'R', 'G'}:; return f'LOCAL_{number}'; return number. for info_fd in info_fields:; info = metadata['info'][info_fd]; if info['Type'] == 'Flag':; info['Type'] = 'Integer'; info['Number'] = '1'; metadata['format'][f'INFO_{info_fd}'] = info. for d in metadata['format'].values():; d['Number'] = transform_number(d.get('Number')). hl.export_vcf(mt, variant_svcr_vcf_path, metadata=metadata,; tabix=True); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472
https://github.com/hail-is/hail/pull/14015#issuecomment-1814589546:70,Energy Efficiency,monitor,monitoring,70,This should be the right way to turn it off: https://cloud.google.com/monitoring/settings/disable#disable-oagent. I think any small amount of data is from the VM startup time before we shut it off in the startup script,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14015#issuecomment-1814589546
https://github.com/hail-is/hail/pull/14016#issuecomment-1834642128:25,Integrability,rout,routes,25,TODO for myself. Any new routes we add need to have a test added to `test_authorized_users_only()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14016#issuecomment-1834642128
https://github.com/hail-is/hail/pull/14016#issuecomment-1834642128:54,Testability,test,test,54,TODO for myself. Any new routes we add need to have a test added to `test_authorized_users_only()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14016#issuecomment-1834642128
https://github.com/hail-is/hail/pull/14018#issuecomment-1888002011:154,Performance,cache,cache,154,"In the spirit of spreading out review burden a bit, I'm gonna pick up review for this PR. I'll be sure to read up on all the stacked conversations so I'm cache'd in before I review this one. I'll stick a review on here and you can dismiss when this is ready for a look :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14018#issuecomment-1888002011
https://github.com/hail-is/hail/pull/14024#issuecomment-1846221998:83,Deployability,update,updated,83,replaced by https://github.com/hail-is/hail/pull/14084; everything else is already updated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14024#issuecomment-1846221998
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14027#issuecomment-1830488767
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14028#issuecomment-1830488695
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14029#issuecomment-1830488648
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14030#issuecomment-1830488614
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14031#issuecomment-1830488589
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14032#issuecomment-1830488547
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14046#issuecomment-1831146555
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14047#issuecomment-1831146473
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:93,Availability,avail,available,93,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:40,Deployability,release,release,40,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:129,Deployability,update,updates,129,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:327,Deployability,patch,patch,327,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:333,Deployability,release,releases,333,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:456,Deployability,configurat,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:204,Integrability,depend,dependabot,204,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:247,Integrability,depend,dependabot,247,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:348,Integrability,depend,dependency,348,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:482,Integrability,depend,dependency-updates,482,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:456,Modifiability,config,configuration-options-for-dependency-updates,456,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:549,Modifiability,config,config,549,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:425,Security,secur,security,425,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383:447,Security,secur,security,447,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file. If you change your mind, just re-open this PR and I'll resolve any conflicts on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14048#issuecomment-1831146383
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:330,Availability,error,error,330,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:945,Availability,avail,available,945,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:218,Deployability,install,installing-it-on-a-single-computer,218,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:264,Deployability,install,installed,264,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:354,Deployability,install,install,354,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:1353,Integrability,wrap,wrapper,1353,"so like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: INFO: Running Hail version 0.2.127-d18228b9bc5b; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:702,Performance,load,load,702,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:1793,Performance,load,loads,1793,"so like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: INFO: Running Hail version 0.2.127-d18228b9bc5b; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:791,Testability,log,logger,791,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:1081,Testability,LOG,LOGGING,1081,"so like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: INFO: Running Hail version 0.2.127-d18228b9bc5b; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:1106,Testability,log,log,1106,"so like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: INFO: Running Hail version 0.2.127-d18228b9bc5b; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:1891,Testability,Log,Log,1891,"so like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: INFO: Running Hail version 0.2.127-d18228b9bc5b; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076
https://github.com/hail-is/hail/issues/14051#issuecomment-1833938619:219,Security,expose,expose,219,"Possibly related: https://github.com/erdewit/nest_asyncio/issues/22#issuecomment-1300570745. If Ben W is using asyncio in *his* code, it seems likely we'll end up with unpatched tasks. If this is the problem, we should expose an async implementation of hailtop.batch that he can use.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1833938619
https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993:176,Availability,echo,echo,176,"Simple replication:; ```. In [6]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993
https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993:0,Usability,Simpl,Simple,0,"Simple replication:; ```. In [6]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834356993
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:1366,Availability,echo,echo,1366,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:432,Deployability,configurat,configuration,432,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:651,Deployability,configurat,configuration,651,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:432,Modifiability,config,configuration,432,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:619,Modifiability,config,config,619,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:651,Modifiability,config,configuration,651,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467:718,Modifiability,config,config,718,"This seems to do it:; ```. In [1]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(32):; ...: j = b.new_job(); ...: j.command(f'cat >/dev/null {"" "".join(b.read_input(""gs://danking/foo.vcf"") for _ in range(1000))}'); ...: b.run(); /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/batch/backend.py:786: UserWarning: Using an image ubuntu:22.04 from Docker Hub. Jobs may fail due to Docker Hub rate limits.; warnings.warn(f'Using an image {image} from Docker Hub. '. https://batch.hail.is/batches/8090821 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 33/33 0:00:00 0:01:37; batch 8090821 complete: success; Out[1]: <hailtop.batch_client.client.Batch at 0x1086d1bd0>. In [2]: import hailtop.batch as hb; ...: b = hb.Batch(backend=hb.ServiceBackend()); ...: for _ in range(300):; ...: j = b.new_job(); ...: j.command(f'echo {""a"" * 11 * 1024}'); ...: b.run(); ```. Perhaps related to creating a fresh service backend?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834376467
https://github.com/hail-is/hail/issues/14051#issuecomment-1834378001:9,Availability,reliab,reliably,9,Hmm. Not reliably.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14051#issuecomment-1834378001
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:128,Availability,error,error,128,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:584,Availability,robust,robust,584,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:32,Testability,test,tests,32,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:71,Testability,test,tests,71,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:147,Testability,test,test,147,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:241,Testability,test,test,241,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:355,Testability,test,test,355,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:439,Testability,test,test,439,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:567,Testability,test,test,567,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100:616,Testability,test,test,616,"We weren't actually running the tests in QoB previously. I enabled the tests in #14062, but they all still passed even with the error. ```; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_default_arguments; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float64; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_0_and_1; PASSED test/hail/methods/relatedness/test_identity_by_descent.py::test_ibd_does_not_error_with_dummy_maf_float32; ```. My guess is our test suite isn't robust enough. I don't think we test with any family relationships -- all unrelated samples.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14052#issuecomment-1839163100
https://github.com/hail-is/hail/pull/14056#issuecomment-1877749195:502,Deployability,Deploy,DeployConfig,502,"> Inside the cluster, folks no longer need tokens, right? Can we delete all the -tokens secrets?. Clients from before the OAuth change still expect the `tokens.json` file to exist in the job container. So we can only delete these once we drop support for tokens on the server. > It seems to me that this change should also delete hailtop/auth/tokens.py and all uses of it. Clients should unconditionally use OAuth2 now. I think removing client-side token support entirely removes the remaining uses of DeployConfig.default_namespace. This is correct and I'm happy to do this. Do you want me to add that to this change or make a separate PR? I might prefer a separate PR as I will need to come up with a solution for copy-paste tokens which use `tokens.py`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14056#issuecomment-1877749195
https://github.com/hail-is/hail/pull/14056#issuecomment-1877749736:133,Usability,feedback,feedback,133,> Or maybe this should be called [base_path](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/base)?. Also would appreciate feedback on the naming if you have any,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14056#issuecomment-1877749736
https://github.com/hail-is/hail/pull/14056#issuecomment-1879295919:135,Deployability,deploy,deploy,135,> elimination of default_namespace. This is also unfortunately tricky :/// as clients require `default_namespace` exist in container's deploy config,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14056#issuecomment-1879295919
https://github.com/hail-is/hail/pull/14056#issuecomment-1879295919:142,Modifiability,config,config,142,> elimination of default_namespace. This is also unfortunately tricky :/// as clients require `default_namespace` exist in container's deploy config,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14056#issuecomment-1879295919
https://github.com/hail-is/hail/pull/14059#issuecomment-1836781021:96,Security,access,access,96,"This also means all jobs need to be using a recent version of Hail so that they know how to use access tokens, right? Which version started supporting that?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14059#issuecomment-1836781021
https://github.com/hail-is/hail/pull/14059#issuecomment-1841779614:241,Deployability,update,updated,241,"Not in our batch jobs, but we do use tokens to submit on behalf of different users, eg: https://github.com/populationgenomics/analysis-runner/blob/d7f6d8fa5b61ac20f9952c50ee9ce27bd0ba5974/server/main.py#L105. So outside yes, but inside - we updated hail batch and I'm pretty confident it's using Oauth.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14059#issuecomment-1841779614
https://github.com/hail-is/hail/issues/14067#issuecomment-1839682395:34,Usability,guid,guide-analysis,34,@daniel-goldstein Let's put it at guide-analysis.hail.is.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14067#issuecomment-1839682395
https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943:50,Deployability,release,release-,50,"AFAICT, FASTAs live at:; ```; ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna_index/; ```; whereas the VEP cache lives at; ```; ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/homo_sapiens_merged_vep_95_GRCh38.tar.gz; ```; These seem to be two distinct sources of data, so my inclination is to not move the FASTAs inside the cache folder. That seems likely to cause confusion for ourselves in the future. Seems very reasonable to have `gs://bucket/cache/95_GRCh38/homo_sapiens_merged/...` and `gs://bucket/fasta/95_GRCh38/homo_sapiens/...`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943
https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943:154,Deployability,release,release-,154,"AFAICT, FASTAs live at:; ```; ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna_index/; ```; whereas the VEP cache lives at; ```; ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/homo_sapiens_merged_vep_95_GRCh38.tar.gz; ```; These seem to be two distinct sources of data, so my inclination is to not move the FASTAs inside the cache folder. That seems likely to cause confusion for ourselves in the future. Seems very reasonable to have `gs://bucket/cache/95_GRCh38/homo_sapiens_merged/...` and `gs://bucket/fasta/95_GRCh38/homo_sapiens/...`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943
https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943:113,Performance,cache,cache,113,"AFAICT, FASTAs live at:; ```; ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna_index/; ```; whereas the VEP cache lives at; ```; ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/homo_sapiens_merged_vep_95_GRCh38.tar.gz; ```; These seem to be two distinct sources of data, so my inclination is to not move the FASTAs inside the cache folder. That seems likely to cause confusion for ourselves in the future. Seems very reasonable to have `gs://bucket/cache/95_GRCh38/homo_sapiens_merged/...` and `gs://bucket/fasta/95_GRCh38/homo_sapiens/...`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943
https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943:342,Performance,cache,cache,342,"AFAICT, FASTAs live at:; ```; ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna_index/; ```; whereas the VEP cache lives at; ```; ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/homo_sapiens_merged_vep_95_GRCh38.tar.gz; ```; These seem to be two distinct sources of data, so my inclination is to not move the FASTAs inside the cache folder. That seems likely to cause confusion for ourselves in the future. Seems very reasonable to have `gs://bucket/cache/95_GRCh38/homo_sapiens_merged/...` and `gs://bucket/fasta/95_GRCh38/homo_sapiens/...`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943
https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943:465,Performance,cache,cache,465,"AFAICT, FASTAs live at:; ```; ftp.ensembl.org/pub/release-95/fasta/homo_sapiens/dna_index/; ```; whereas the VEP cache lives at; ```; ftp.ensembl.org/pub/release-95/variation/indexed_vep_cache/homo_sapiens_merged_vep_95_GRCh38.tar.gz; ```; These seem to be two distinct sources of data, so my inclination is to not move the FASTAs inside the cache folder. That seems likely to cause confusion for ourselves in the future. Seems very reasonable to have `gs://bucket/cache/95_GRCh38/homo_sapiens_merged/...` and `gs://bucket/fasta/95_GRCh38/homo_sapiens/...`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846193943
https://github.com/hail-is/hail/pull/14071#issuecomment-1846195135:77,Deployability,upgrade,upgrade,77,"That said, fixing dataproc with minimal changes seems best to me. If/when we upgrade to a newer VEP version we can change to a more sensible structure then.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1846195135
https://github.com/hail-is/hail/pull/14071#issuecomment-1875981027:15,Testability,test,test,15,I also need to test this on dataproc.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1875981027
https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531:408,Deployability,release,release,408,"The new tar file is now in all VEP replicates for dataproc. The only change is it uses the indexed cache files and the tar file has the word ""_indexed"" in it. Otherwise, it should have the same contents / file structure as the non-indexed tar file that is there currently. I tested this as best as I could, but it would be prudent to give ourselves time when releasing this in case there is a problem in the release script.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531
https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531:99,Performance,cache,cache,99,"The new tar file is now in all VEP replicates for dataproc. The only change is it uses the indexed cache files and the tar file has the word ""_indexed"" in it. Otherwise, it should have the same contents / file structure as the non-indexed tar file that is there currently. I tested this as best as I could, but it would be prudent to give ourselves time when releasing this in case there is a problem in the release script.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531
https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531:275,Testability,test,tested,275,"The new tar file is now in all VEP replicates for dataproc. The only change is it uses the indexed cache files and the tar file has the word ""_indexed"" in it. Otherwise, it should have the same contents / file structure as the non-indexed tar file that is there currently. I tested this as best as I could, but it would be prudent to give ourselves time when releasing this in case there is a problem in the release script.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1881444531
https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042:28,Deployability,release,release,28,"AFAICT, you didn't edit the release.sh script; do I misunderstand what you're worried about?. Can you run the dataproc tests via dev deploy and post the batch links here? I think this should do it. ```; hailctl dev deploy --branch jigold/fix-vep-grch38-cache -s test_dataproc-38 -s test_dataproc-37; ```. If those pass then I'm confident `vep-GRCh38.sh` is correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042
https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042:133,Deployability,deploy,deploy,133,"AFAICT, you didn't edit the release.sh script; do I misunderstand what you're worried about?. Can you run the dataproc tests via dev deploy and post the batch links here? I think this should do it. ```; hailctl dev deploy --branch jigold/fix-vep-grch38-cache -s test_dataproc-38 -s test_dataproc-37; ```. If those pass then I'm confident `vep-GRCh38.sh` is correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042
https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042:215,Deployability,deploy,deploy,215,"AFAICT, you didn't edit the release.sh script; do I misunderstand what you're worried about?. Can you run the dataproc tests via dev deploy and post the batch links here? I think this should do it. ```; hailctl dev deploy --branch jigold/fix-vep-grch38-cache -s test_dataproc-38 -s test_dataproc-37; ```. If those pass then I'm confident `vep-GRCh38.sh` is correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042
https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042:253,Performance,cache,cache,253,"AFAICT, you didn't edit the release.sh script; do I misunderstand what you're worried about?. Can you run the dataproc tests via dev deploy and post the batch links here? I think this should do it. ```; hailctl dev deploy --branch jigold/fix-vep-grch38-cache -s test_dataproc-38 -s test_dataproc-37; ```. If those pass then I'm confident `vep-GRCh38.sh` is correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042
https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042:119,Testability,test,tests,119,"AFAICT, you didn't edit the release.sh script; do I misunderstand what you're worried about?. Can you run the dataproc tests via dev deploy and post the batch links here? I think this should do it. ```; hailctl dev deploy --branch jigold/fix-vep-grch38-cache -s test_dataproc-38 -s test_dataproc-37; ```. If those pass then I'm confident `vep-GRCh38.sh` is correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1883942042
https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981:89,Deployability,release,release,89,I was just concerned that I hadn't tested dataproc after the changes and didn't want the release to fail. There wasn't anything about the actual release I changed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981
https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981:145,Deployability,release,release,145,I was just concerned that I hadn't tested dataproc after the changes and didn't want the release to fail. There wasn't anything about the actual release I changed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981
https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981:35,Testability,test,tested,35,I was just concerned that I hadn't tested dataproc after the changes and didn't want the release to fail. There wasn't anything about the actual release I changed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981
https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081:112,Deployability,deploy,deploying,112,"This is largely working, but IIRC was facing some bug in Azure. I would start by re-running the tests, then dev deploying and running any failing tests yourself.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081
https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081:96,Testability,test,tests,96,"This is largely working, but IIRC was facing some bug in Azure. I would start by re-running the tests, then dev deploying and running any failing tests yourself.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081
https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081:146,Testability,test,tests,146,"This is largely working, but IIRC was facing some bug in Azure. I would start by re-running the tests, then dev deploying and running any failing tests yourself.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14076#issuecomment-2239861081
https://github.com/hail-is/hail/pull/14086#issuecomment-1887439034:120,Deployability,release,released,120,I will not wait for #14113. It's a really important improvement but there's also many bug fixes in here that need to be released.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14086#issuecomment-1887439034
https://github.com/hail-is/hail/pull/14086#issuecomment-1887561566:24,Deployability,release,release,24,Dataproc passed on this release. https://ci.hail.is/batches/8105133 as of 5f793639264adf0990a2189dd6d34ba67d049b9f which is based on 1a5f4851149a84fd210c694053fb5c593cf27d07 in hi/main.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14086#issuecomment-1887561566
https://github.com/hail-is/hail/pull/14087#issuecomment-1847877295:20,Testability,test,test,20,"@chrisvittal ; ```; test/hail/conftest.py:10: in <module>; from hail import current_backend, init, reset_global_randomness; /usr/local/lib/python3.9/dist-packages/hail/__init__.py:54: in <module>; from . import vds # noqa: E402; /usr/local/lib/python3.9/dist-packages/hail/vds/__init__.py:1: in <module>; from . import combiner; /usr/local/lib/python3.9/dist-packages/hail/vds/combiner/__init__.py:2: in <module>; from .variant_dataset_combiner import new_combiner, load_combiner, VariantDatasetCombiner, VDSMetadata; /usr/local/lib/python3.9/dist-packages/hail/vds/combiner/variant_dataset_combiner.py:15: in <module>; from hail.vds import VariantDataset; E ImportError: cannot import name 'VariantDataset' from partially initialized module 'hail.vds' (most likely due to a circular import) (/usr/local/lib/python3.9/dist-packages/hail/vds/__init__.py); =========================== short test summary info ============================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14087#issuecomment-1847877295
https://github.com/hail-is/hail/pull/14087#issuecomment-1847877295:889,Testability,test,test,889,"@chrisvittal ; ```; test/hail/conftest.py:10: in <module>; from hail import current_backend, init, reset_global_randomness; /usr/local/lib/python3.9/dist-packages/hail/__init__.py:54: in <module>; from . import vds # noqa: E402; /usr/local/lib/python3.9/dist-packages/hail/vds/__init__.py:1: in <module>; from . import combiner; /usr/local/lib/python3.9/dist-packages/hail/vds/combiner/__init__.py:2: in <module>; from .variant_dataset_combiner import new_combiner, load_combiner, VariantDatasetCombiner, VDSMetadata; /usr/local/lib/python3.9/dist-packages/hail/vds/combiner/variant_dataset_combiner.py:15: in <module>; from hail.vds import VariantDataset; E ImportError: cannot import name 'VariantDataset' from partially initialized module 'hail.vds' (most likely due to a circular import) (/usr/local/lib/python3.9/dist-packages/hail/vds/__init__.py); =========================== short test summary info ============================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14087#issuecomment-1847877295
https://github.com/hail-is/hail/pull/14091#issuecomment-1856210907:134,Testability,test,tests,134,@daniel-goldstein sorry can you re-approve? I got angry at the flakiness of the event loop and considered rewriting some of the batch tests that are particularly bad offenders but then thought better of it and just retried.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14091#issuecomment-1856210907
https://github.com/hail-is/hail/pull/14093#issuecomment-1852287669:251,Availability,echo,echo,251,"On an n1-highmem-8, this is the RAM in use after startup. About 200MiB lower overhead than [the last time I did this](https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790).; ```; Dec 12 15:20:34 dk-m post-hdfs-startup-script[10260]: + echo 'All done'; Dec 12 15:20:34 dk-m post-hdfs-startup-script[10260]: All done; Dec 12 15:20:42 dk-m earlyoom[6529]: mem avail: 42959 of 52223 MiB (82.26%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14093#issuecomment-1852287669
https://github.com/hail-is/hail/pull/14093#issuecomment-1852287669:373,Availability,avail,avail,373,"On an n1-highmem-8, this is the RAM in use after startup. About 200MiB lower overhead than [the last time I did this](https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790).; ```; Dec 12 15:20:34 dk-m post-hdfs-startup-script[10260]: + echo 'All done'; Dec 12 15:20:34 dk-m post-hdfs-startup-script[10260]: All done; Dec 12 15:20:42 dk-m earlyoom[6529]: mem avail: 42959 of 52223 MiB (82.26%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14093#issuecomment-1852287669
https://github.com/hail-is/hail/pull/14093#issuecomment-1852290763:25,Testability,test,tested,25,Native code still works (tested by running `hl.identity_by_descent`).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14093#issuecomment-1852290763
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:1052,Energy Efficiency,Meter,MeteredStream,1052,.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:1071,Energy Efficiency,Meter,MeteredStream,1071,ag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9351,Energy Efficiency,Meter,MeteredStream,9351,.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9370,Energy Efficiency,Meter,MeteredStream,9370,Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:1206,Integrability,protocol,protocol,1206,(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$Unbuffered,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:2708,Integrability,Synchroniz,SynchronizedBufferedReadableByteChannel,2708,e.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:31) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:81) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedReadableByteChannel.read(StorageByteChannels.java:84) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageReadChannel.read(BaseStorageReadChannel.java:105) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$1.readHandlingRequesterPays(GoogleStorageFS.scala:216) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$1.fill(GoogleStorageFS.scala:245) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FSSeekableInputStream.read(FS.scala:168) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.DataInputStream.re,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9505,Integrability,protocol,protocol,9505,[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$Unbuffered,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:11007,Integrability,Synchroniz,SynchronizedBufferedReadableByteChannel,11007,e.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:31) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:81) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedReadableByteChannel.read(StorageByteChannels.java:84) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageReadChannel.read(BaseStorageReadChannel.java:105) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$1.readHandlingRequesterPays(GoogleStorageFS.scala:216) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$1.fill(GoogleStorageFS.scala:245) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.FSSeekableInputStream.read(FS.scala:168) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.DataInputStream.re,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:6928,Performance,concurren,concurrent,6928,t java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:7183,Performance,concurren,concurrent,7183,-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392];,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:7276,Performance,concurren,concurrent,7276,dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:7374,Performance,concurren,concurrent,7374,ackend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:7479,Performance,concurren,concurrent,7479,38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decryp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:15227,Performance,concurren,concurrent,15227,a.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:15482,Performance,concurren,concurrent,15482,a.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:15575,Performance,concurren,concurrent,15575,a.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:15673,Performance,concurren,concurrent,15673,a.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:15778,Performance,concurren,concurrent,15778,a.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2355) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2213) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1669) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:503) ~[?:1.8.0_392]; 	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:461) ~[?:1.8.0_392]; 	at is.hail.backend.service.Worker$.$anonfun$main$4(Worker.scala:136) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:657) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$3(Worker.scala:135) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$2(Worker.scala:134) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.$anonfun$map$1(Try.scala:255) ~[scala-library-2.12.15.jar:?]; 	at scala.util.Success.map(Try.scala:213) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:97,Security,secur,security,97,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:175,Security,secur,security,175,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:262,Security,secur,security,262,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:349,Security,secur,security,349,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:436,Security,secur,security,436,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:516,Security,secur,security,516,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:599,Security,secur,security,599,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:697,Security,secur,security,697,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:724,Security,access,access,724,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:782,Security,secur,security,782,A stack trace for posterity:; ```; Caused by: javax.net.ssl.SSLException: Tag mismatch!; 	at sun.security.ssl.Alert.createSSLException(Alert.java:133) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8416,Security,secur,security,8416,romise.scala:33) ~[scala-library-2.12.15.jar:?]; 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64) ~[scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8532,Security,secur,security,8532,scala-library-2.12.15.jar:?]; 	... 3 more; Caused by: javax.crypto.AEADBadTagException: Tag mismatch!; 	at com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8639,Security,secur,security,8639,com.sun.crypto.provider.GaloisCounterMode.decryptFinal(GaloisCounterMode.java:620) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.Ne,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8735,Security,secur,security,8735,ider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.finalNoPadding(CipherCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_j,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8815,Security,secur,security,8815,rCore.java:1116) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SN,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8898,Security,secur,security,8898,erCore.fillOutputBuffer(CipherCore.java:1053) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:8996,Security,secur,security,8996,.provider.CipherCore.doFinal(CipherCore.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$Scattering,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9023,Security,access,access,9023,Core.java:941) ~[sunjce_provider.jar:1.8.0_392]; 	at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteC,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:9081,Security,secur,security,9081,at com.sun.crypto.provider.AESCipher.engineDoFinal(AESCipher.java:491) ~[sunjce_provider.jar:1.8.0_392]; 	at javax.crypto.CipherSpi.bufferCrypt(CipherSpi.java:779) ~[?:1.8.0_392]; 	at javax.crypto.CipherSpi.engineDoFinal(CipherSpi.java:730) ~[?:1.8.0_392]; 	at javax.crypto.Cipher.doFinal(Cipher.java:2463) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLCipher$T12GcmReadCipherGenerator$GcmReadCipher.decrypt(SSLCipher.java:1606) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:262) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dki,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352
https://github.com/hail-is/hail/pull/14097#issuecomment-1881181045:31,Deployability,upgrade,upgrade,31,@danking Looks like we need to upgrade `pytest_asyncio`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14097#issuecomment-1881181045
https://github.com/hail-is/hail/issues/14099#issuecomment-1858099553:18,Deployability,install,install,18,Mitigation: `pip3 install 'ipython<8.17'`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14099#issuecomment-1858099553
https://github.com/hail-is/hail/pull/14100#issuecomment-1858589110:76,Testability,test,test,76,Need to also double check the number for `n_ready` is correct with a better test case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14100#issuecomment-1858589110
https://github.com/hail-is/hail/issues/14102#issuecomment-1860989511:66,Availability,error,error,66,"Hey @seanjosephjurgens !. Sorry you're running into trouble. This error message is bad. See https://github.com/hail-is/hail/issues/13346 for that bug. The real issue here is VCF INFO fields like:; ```; AS_BaseQRankSum=0.000,.,0.100,0.500; ```; The VCF spec doesn't explicitly permit missing values as elements of INFO or FORMAT fields. It does permit the whole field to be missing a la `FIELD=.` but `FIELD=1,.,1` or `FIELD=.,.,.` are not explicitly permitted. In particular, `FIELD=.` could mean ""this field is missing"" or ""this field is not-missing, it is a one-element array containing one missing value"". The fix is to use `hl.import_vcf(..., array_elements_required=False)`. When that is true, Hail will parse `1,.,1` as `[1, NA, 1]`. Be forewarned: Hail treats `FIELD=.` as a missing field, not an array with one missing element.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14102#issuecomment-1860989511
https://github.com/hail-is/hail/issues/14102#issuecomment-1860989511:72,Integrability,message,message,72,"Hey @seanjosephjurgens !. Sorry you're running into trouble. This error message is bad. See https://github.com/hail-is/hail/issues/13346 for that bug. The real issue here is VCF INFO fields like:; ```; AS_BaseQRankSum=0.000,.,0.100,0.500; ```; The VCF spec doesn't explicitly permit missing values as elements of INFO or FORMAT fields. It does permit the whole field to be missing a la `FIELD=.` but `FIELD=1,.,1` or `FIELD=.,.,.` are not explicitly permitted. In particular, `FIELD=.` could mean ""this field is missing"" or ""this field is not-missing, it is a one-element array containing one missing value"". The fix is to use `hl.import_vcf(..., array_elements_required=False)`. When that is true, Hail will parse `1,.,1` as `[1, NA, 1]`. Be forewarned: Hail treats `FIELD=.` as a missing field, not an array with one missing element.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14102#issuecomment-1860989511
https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756:43,Modifiability,refactor,refactor,43,"@danking Curious for your thoughts on this refactor. I was getting pretty turned around myself with the various credential classes and I think this is closer to what we want in a keyless world. Ideally the batch worker should just be able to request credentials (in the form of an access token) for a given identity with just the identity's ID. LMK if you're in favor of this or not, or if you would like to see it folded into the metadata server PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756
https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756:281,Security,access,access,281,"@danking Curious for your thoughts on this refactor. I was getting pretty turned around myself with the various credential classes and I think this is closer to what we want in a keyless world. Ideally the batch worker should just be able to request credentials (in the form of an access token) for a given identity with just the identity's ID. LMK if you're in favor of this or not, or if you would like to see it folded into the metadata server PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1879054756
https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738:28,Performance,optimiz,optimizing,28,"Ya you're right, I was over-optimizing trying to share credentials between jobs of the same user. Just kept it as 1:1 jobs to credentials and it got a lot simpler. I changed the key to the job id because using the name of the identity would cause collisions between jobs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738
https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738:155,Usability,simpl,simpler,155,"Ya you're right, I was over-optimizing trying to share credentials between jobs of the same user. Just kept it as 1:1 jobs to credentials and it got a lot simpler. I changed the key to the job id because using the name of the identity would cause collisions between jobs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14125#issuecomment-1881179738
https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070:442,Modifiability,config,config,442,"There's a pretty sizeable amount of changes that had to be made manually, so the merge conflicts might be a lot more painful with this one than https://github.com/hail-is/hail/pull/14119; not sure if that's a case for delaying this or not. I think many of those manual changes could also be made using the `--unsafe-fixes` flag to `ruff`, but it seemed better to try doing them manually to try and avoid introducing too many issues. The lint config changes, automatic changes from `ruff`, and manual changes required to make the `ruff` check pass are split into separate commits, so hopefully that will make the review easier",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070
https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070:309,Safety,unsafe,unsafe-fixes,309,"There's a pretty sizeable amount of changes that had to be made manually, so the merge conflicts might be a lot more painful with this one than https://github.com/hail-is/hail/pull/14119; not sure if that's a case for delaying this or not. I think many of those manual changes could also be made using the `--unsafe-fixes` flag to `ruff`, but it seemed better to try doing them manually to try and avoid introducing too many issues. The lint config changes, automatic changes from `ruff`, and manual changes required to make the `ruff` check pass are split into separate commits, so hopefully that will make the review easier",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070
https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070:398,Safety,avoid,avoid,398,"There's a pretty sizeable amount of changes that had to be made manually, so the merge conflicts might be a lot more painful with this one than https://github.com/hail-is/hail/pull/14119; not sure if that's a case for delaying this or not. I think many of those manual changes could also be made using the `--unsafe-fixes` flag to `ruff`, but it seemed better to try doing them manually to try and avoid introducing too many issues. The lint config changes, automatic changes from `ruff`, and manual changes required to make the `ruff` check pass are split into separate commits, so hopefully that will make the review easier",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883315070
https://github.com/hail-is/hail/pull/14128#issuecomment-1883347616:56,Safety,unsafe,unsafe-fixes,56,"putting this back in the WIP stack while i try using `--unsafe-fixes` and see if it differs from the manual changes significantly, and break out the manual fixes into separate commits based on which rule they address",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883347616
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:343,Modifiability,variab,variable,343,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:38,Safety,unsafe,unsafe-fixes,38,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:547,Security,hash,hashable,547,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:120,Testability,assert,assert,120,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:161,Testability,assert,assert,161,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:199,Testability,assert,assert,199,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355:85,Usability,feedback,feedback,85,"looks like the differences between `--unsafe-fixes` and my manual edits based on the feedback the linter gave were:; * `assert <boolean value> == True` becomes `assert <boolean value> is True`, not `assert <boolean value>`; * `if <value> == foo or <value> == bar` becomes `if <value> in (foo, bar)`, not `if <value> in {foo, bar}`; * `<unused variable> = foo` becomes `foo` instead of being deleted outright. those seem fine, though i think the manual version of the latter two is better in the cases where i had added it, as i only used sets for hashable types and deleted things that didn't have side effects, afaik",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14128#issuecomment-1883396355
https://github.com/hail-is/hail/pull/14131#issuecomment-1883560111:170,Modifiability,extend,extend,170,"okay @daniel-goldstein https://github.com/hail-is/hail/pull/14132 replaces just the formatting/format checking with `ruff`, and i'll make another PR once that goes in to extend the `ruff` linting to the `hail` folder. thanks so much for your help on this! :)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14131#issuecomment-1883560111
https://github.com/hail-is/hail/pull/14132#issuecomment-1883692445:280,Modifiability,config,configs,280,"Interesting, [PEP 8](https://peps.python.org/pep-0008/#string-quotes) does have an opinion about triple-quoted strings. FWIW, I'm happy to go stricter in the future and allow string normalization and all that (assuming other folks are on board), but I appreciate you aligning the configs for this PR!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14132#issuecomment-1883692445
https://github.com/hail-is/hail/pull/14132#issuecomment-1883771570:35,Deployability,update,updated,35,"fixed up the dev requirements, and updated the pre-commit hook, and in the process realized i had only run `ruff format` on files that are checked by `make check-all`, so also ran it at the root of the repo, as the hook will run there. EDIT: i misunderstood how the pre-commit hooks work, and apparently it only runs them on the files you have changed, but i think it's still worth it to format across the repo, not just in the places we check with `make check-all`; and also, i personally was a grump and never used the pre-commit hooks, but now that i've had to test them out for this, i have seen the light ⚡. also i personally would love if our quotes were consistent as well! i'll ask on zulip how ppl feel about that",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14132#issuecomment-1883771570
https://github.com/hail-is/hail/pull/14132#issuecomment-1883771570:564,Testability,test,test,564,"fixed up the dev requirements, and updated the pre-commit hook, and in the process realized i had only run `ruff format` on files that are checked by `make check-all`, so also ran it at the root of the repo, as the hook will run there. EDIT: i misunderstood how the pre-commit hooks work, and apparently it only runs them on the files you have changed, but i think it's still worth it to format across the repo, not just in the places we check with `make check-all`; and also, i personally was a grump and never used the pre-commit hooks, but now that i've had to test them out for this, i have seen the light ⚡. also i personally would love if our quotes were consistent as well! i'll ask on zulip how ppl feel about that",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14132#issuecomment-1883771570
https://github.com/hail-is/hail/pull/14138#issuecomment-1887634816:174,Testability,test,test-resources,174,"Sent this to you, Ed, since, IIRC, you experienced broken uploads in the past due to our bad copy implementation. If you could clone this and try; ```; rm hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; ```; that'd be most appreciated!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887634816
https://github.com/hail-is/hail/pull/14138#issuecomment-1887634816:219,Testability,test,test-resources,219,"Sent this to you, Ed, since, IIRC, you experienced broken uploads in the past due to our bad copy implementation. If you could clone this and try; ```; rm hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; ```; that'd be most appreciated!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887634816
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:821,Availability,Error,Error,821,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:995,Availability,Error,Error,995,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:1152,Availability,failure,failure,1152,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:1100,Deployability,install,installed,1100,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:1141,Integrability,depend,dependency,1141,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:760,Safety,timeout,timeout,760,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:104,Testability,test,test-resources,104,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:149,Testability,test,test-resources,149,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:303,Testability,test,test,303,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:331,Testability,test,test-ezlis,331,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:354,Testability,test,test-resources,354,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:369,Testability,test,test,369,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:444,Testability,test,test-ezlis,444,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:467,Testability,test,test-resources,467,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:560,Testability,test,test,560,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:592,Testability,test,test-ezlis,592,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:615,Testability,test,test-resources,615,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:630,Testability,test,test,630,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:699,Testability,test,test-ezlis,699,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:722,Testability,test,test-resources,722,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:979,Testability,test,test-resources,979,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:2051,Availability,Error,Error,2051,"irectory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```; What am I missing?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:15,Deployability,install,installed,15,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:1463,Performance,load,loads,1463,"irectory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```; What am I missing?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:1570,Performance,load,loads,1570,"irectory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```; What am I missing?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:723,Safety,timeout,timeout,723,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:66,Testability,test,test-resources,66,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:111,Testability,test,test-resources,111,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:266,Testability,test,test,266,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:294,Testability,test,test-ezlis,294,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:317,Testability,test,test-resources,317,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:332,Testability,test,test,332,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:407,Testability,test,test-ezlis,407,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:430,Testability,test,test-resources,430,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:523,Testability,test,test,523,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:555,Testability,test,test-ezlis,555,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:578,Testability,test,test-resources,578,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:593,Testability,test,test,593,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:662,Testability,test,test-ezlis,662,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:685,Testability,test,test-resources,685,"With `hailtop` installed, I get:; ```; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources ; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163:2035,Testability,test,test-resources,2035,"irectory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; Traceback (most recent call last):; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 211, in <module>; asyncio.run(main()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/asyncio/runners.py"", line 44, in run; return loop.run_until_complete(main); File ""uvloop/loop.pyx"", line 1517, in uvloop.loop.Loop.run_until_complete; File ""/home/edmund/.local/src/hail/hail/python/hailtop/aiotools/copy.py"", line 182, in main; files = json.loads(args.files); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/__init__.py"", line 346, in loads; return _default_decoder.decode(s); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 337, in decode; obj, end = self.raw_decode(s, idx=_w(s, 0).end()); File ""/home/edmund/.pyenv/versions/3.9.17/lib/python3.9/json/decoder.py"", line 355, in raw_decode; raise JSONDecodeError(""Expecting value"", s, err.value) from None; json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```; What am I missing?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887744163
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:386,Testability,test,test,386,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:418,Testability,test,test-ezlis,418,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:440,Testability,test,test-resources,440,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:455,Testability,test,test,455,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:522,Testability,test,test-ezlis,522,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:544,Testability,test,test-resources,544,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728
https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238:34,Availability,echo,echo,34,"e.g.; ```; # cat Makefile; foo:; 	echo '[ \; hello \; '; # make foo; echo '[ \; hello \; '; [ hello ; ```. If you create such a Makefile and run Make do you see `[ hello ` echo'd or do you see something else, possibly including newlines?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238
https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238:69,Availability,echo,echo,69,"e.g.; ```; # cat Makefile; foo:; 	echo '[ \; hello \; '; # make foo; echo '[ \; hello \; '; [ hello ; ```. If you create such a Makefile and run Make do you see `[ hello ` echo'd or do you see something else, possibly including newlines?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238
https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238:172,Availability,echo,echo,172,"e.g.; ```; # cat Makefile; foo:; 	echo '[ \; hello \; '; # make foo; echo '[ \; hello \; '; [ hello ; ```. If you create such a Makefile and run Make do you see `[ hello ` echo'd or do you see something else, possibly including newlines?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889782238
https://github.com/hail-is/hail/pull/14138#issuecomment-1889786055:18,Integrability,depend,dependency,18,"Good catch on the dependency issue, that should be fixed now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889786055
https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303:614,Availability,echo,echo,614,"According to the makefile documentation https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html:; ```; Notice how the backslash/newline pair was removed inside the string quoted with double quotes (""…""), ; but not from the string quoted with single quotes ('…'). This is the way the default shell (/bin/sh) ; handles backslash/newline pairs. If you specify a different shell in your makefiles it may treat them differently.; ```. Seems you (or `brew`) may have configured `make` to use something other than `/bin/sh`.; Quick way to verify:. ```Makefile; .PHONY: print-shell; print-shell:; 	@echo $(SHELL); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303
https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303:484,Modifiability,config,configured,484,"According to the makefile documentation https://www.gnu.org/software/make/manual/html_node/Splitting-Recipe-Lines.html:; ```; Notice how the backslash/newline pair was removed inside the string quoted with double quotes (""…""), ; but not from the string quoted with single quotes ('…'). This is the way the default shell (/bin/sh) ; handles backslash/newline pairs. If you specify a different shell in your makefiles it may treat them differently.; ```. Seems you (or `brew`) may have configured `make` to use something other than `/bin/sh`.; Quick way to verify:. ```Makefile; .PHONY: print-shell; print-shell:; 	@echo $(SHELL); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1890075303
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1069,Availability,error,error,1069,"EDIT2:. OK, so, I'm not sure when this behavior changed but Make 4.0 wants a `\` to indicate that the recipe continues on the next line *but also* passes that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less leg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1448,Availability,echo,echo,1448," recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Fr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:2443,Deployability,release,release,2443,"ill get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Free Software Foundation, Inc.; ```. Looks like this was an intentionally backwards incompatible change [in Make 4.0](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.0&id=52191d9d613819a77a321ad6c3ab16e1bc73c381#n18) which removed the POSIX-compatible behavior on which our Makefile relies:; ```; * WARNING: Backward-incompatibility!; If .POSIX is specified, then make adheres to the POSIX backslash/newline; handling requirements, which introduces the following changes to the; standard backslash/newline handling in non-recipe lines:; * Any trailing space before the backslash is preserved; * Each backslash/newline (plus subsequent whitespace) is converted to a; single space; ```. They seem to have [broken the behavior in order to fix something else](https://git.savannah.gnu.org/cgit/make.git/commit/?id=391456a) and then added a [`.POSIX`](https://git.savannah.gnu.org/cgit/make.git/commit/?id=88f1bc8) escape hatch for Makefiles that want POSIX compatibility. For the Ma",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:666,Modifiability,variab,variable,666,"EDIT2:. OK, so, I'm not sure when this behavior changed but Make 4.0 wants a `\` to indicate that the recipe continues on the next line *but also* passes that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less leg",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1179,Modifiability,variab,variable,1179,"sses that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1201,Modifiability,variab,variable,1201,"sses that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1346,Modifiability,rewrite,rewrite,1346," recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Fr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1591,Modifiability,variab,variables,1591," recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Fr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1623,Modifiability,Variab,Variable,1623," recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Fr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1765,Modifiability,variab,variable,1765,"ne rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Free Software Foundation, Inc.; ```. Looks like this was an intentionally backwards incompatible change [in Make 4.0](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.0&id=52191d9d613819a77a321ad6c3ab16e1bc73c381#n18) which removed the POSIX-compatible be",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1885,Modifiability,variab,variable,1885,"This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Free Software Foundation, Inc.; ```. Looks like this was an intentionally backwards incompatible change [in Make 4.0](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.0&id=52191d9d613819a77a321ad6c3ab16e1bc73c381#n18) which removed the POSIX-compatible behavior on which our Makefile relies:; ```; * WARNING: Backward-incompatibility!; If .POSIX is specified, then make adheres to the POSIX backslash/newli",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:4087,Modifiability,variab,variable,4087,"3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Free Software Foundation, Inc.; ```. Looks like this was an intentionally backwards incompatible change [in Make 4.0](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.0&id=52191d9d613819a77a321ad6c3ab16e1bc73c381#n18) which removed the POSIX-compatible behavior on which our Makefile relies:; ```; * WARNING: Backward-incompatibility!; If .POSIX is specified, then make adheres to the POSIX backslash/newline; handling requirements, which introduces the following changes to the; standard backslash/newline handling in non-recipe lines:; * Any trailing space before the backslash is preserved; * Each backslash/newline (plus subsequent whitespace) is converted to a; single space; ```. They seem to have [broken the behavior in order to fix something else](https://git.savannah.gnu.org/cgit/make.git/commit/?id=391456a) and then added a [`.POSIX`](https://git.savannah.gnu.org/cgit/make.git/commit/?id=88f1bc8) escape hatch for Makefiles that want POSIX compatibility. For the Makefile I shared above, I get equivalent behavior with and without a `.POSIX:` fake target. I suspect Make 4.x treats them differently. In particular, the problem is not the shell, it's our Makes behaving differently. Make 3 replaces `\\\n` with ` ` before calling the shell whereas Make 4 appears to preserve the `\\\n` to the shell (regardless of the presence of quotes in either case). In particular, Make 4 appears to treat recipe lines differently from how it treats all other lines in Makefiles. I don't like the noise of the backslash-quotes. The end of the doc page you linked suggests using a Make variable when you intentionally want normal Makefile backslash-newline interpretation. That feels a bit too clever. Let's try just demanding POSIX-compatibility. I've pushed that change. Can you give it a try?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:2129,Testability,test,tested,2129,"g, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 and Make 4.4.1. The first EDIT and the original comment follow for context. ---. EDIT: Nope, I still appear to be wrong. Hold on. ---. I have bash 3.2.57; ```; (base) dking@wm28c-761 /tmp % make print-shell; /bin/sh; (base) dking@wm28c-761 /tmp % /bin/sh --version; GNU bash, version 3.2.57(1)-release (arm64-apple-darwin22); Copyright (C) 2007 Free Software Foundation, Inc.; ```. Looks like this was an intentionally backwards incompatible change [in Make 4.0](https://git.savannah.gnu.org/cgit/make.git/tree/NEWS?h=4.0&id=52191d9d613819a77a321ad6c3ab16e1bc73c381#n18) which removed the POSIX-compatible behavior on which our Makefile relies:; ```; * WARNING: Backward-incompatibility!; If .POSIX is specified, then make adheres to the POSIX backslash/newline; handling requirements, which introduces the following changes to the; standard backslash/newline handling in non-recipe lines:; * Any trailing space before the backslash is preserved; * Each backslash/newline (plus subsequen",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324:1080,Usability,simpl,simple,1080,"sses that backslash and newline to the shell. In Make 3.81, the `\` was also required but the newline and backslash *are not passed* to the shell. In other words: in 3.81, backslash-newline is always replaced with a space and in 4.0, backslash-newline is replaced with a space *except on recipe lines in which case it is necessary to indicate the recipe continues but it is also passed literally to the shell*. The docs page you linked directly addresses our use case and suggests we put the command inside of a make variable (thus triggering normal backslash-newline rules rather than the special recipe line rules). > Sometimes you want to split a long line inside of single quotes, but you don’t want the backslash/newline to appear in the quoted content. This is often the case when passing scripts to languages such as Perl, where extraneous backslashes inside the script can change its meaning or even be a syntax error. One simple way of handling this is to place the quoted string, or even the entire command, into a make variable then use the variable in the recipe. In this situation the newline quoting rules for makefiles will be used, and the backslash/newline will be removed. If we rewrite our example above using this method:; > ; > ```; > HELLO = 'hello \; > world'; > ; > all : ; @echo $(HELLO); > ```; > ; > we will get output like this:; > ; > ```; > hello world; > ```; >; > If you like, you can also use target-specific variables (see [Target-specific Variable Values](https://www.gnu.org/software/make/manual/html_node/Target_002dspecific.html)) to obtain a tighter correspondence between the variable and the recipe that uses it. It seems to me like there are not any great choices. Putting the JSON into a Make variable seems too magical and likely to confuse a newbie editing this file. Using escaped double quotes is less legible than literal JSON. Putting the whole JSON array on one line is quite long. I guess we can go with double quotes for now. I tested on Make 3.81 a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1894411324
https://github.com/hail-is/hail/pull/14147#issuecomment-1912321464:255,Safety,avoid,avoid,255,"@chrisvittal: Ed has already used mill on his machine, and helped with the PR. It would be great to both get your eyes on the changes, as well as checking out the branch and testing the setup instructions above (I've been using a seperate git worktree to avoid clobbering my gradle based intellij project).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1912321464
https://github.com/hail-is/hail/pull/14147#issuecomment-1912321464:174,Testability,test,testing,174,"@chrisvittal: Ed has already used mill on his machine, and helped with the PR. It would be great to both get your eyes on the changes, as well as checking out the branch and testing the setup instructions above (I've been using a seperate git worktree to avoid clobbering my gradle based intellij project).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1912321464
https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793:272,Availability,down,downstream,272,"Ok, I think I sorted out the make->mill dependency propagation. Any real target which invokes mill to build it now depends on a target `FORCE` which is always out-of-date, so mill is always invoked. But mill will not change the modification time if it doesn't need to, so downstream targets aren't forced to be run. For example, we have targets; ```; FORCE:. SHADOW_JAR := out/assembly.dest/out.jar; $(SHADOW_JAR): FORCE; 	$(mill) assembly. PYTHON_JAR := python/hail/backend/hail-all-spark.jar; $(PYTHON_JAR): $(SHADOW_JAR); 	cp -f $(SHADOW_JAR) $@. .PHONY: python-jar; python-jar: $(PYTHON_JAR); ```. If I remove the python jar and invoke make, it runs mill then copies:; ```; ❯ rm python/hail/backend/hail-all-spark.jar. ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If run again, mill is invoked to check for changes, but as the jar doesn't change it isn't copied again:; ```; ❯ make python-jar; bash millw assembly; [105/110] memory.resources; ```. If I change some scala sources, the jar is updated and copied:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If I change some scala sources in a way that doesn't actually affect the jar, such as modifying comments, mill is smart enough to not change the jar, so it won't be copied again:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 1 Scala source to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [105/110] memory.resources; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793
https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793:1234,Deployability,update,updated,1234,"Ok, I think I sorted out the make->mill dependency propagation. Any real target which invokes mill to build it now depends on a target `FORCE` which is always out-of-date, so mill is always invoked. But mill will not change the modification time if it doesn't need to, so downstream targets aren't forced to be run. For example, we have targets; ```; FORCE:. SHADOW_JAR := out/assembly.dest/out.jar; $(SHADOW_JAR): FORCE; 	$(mill) assembly. PYTHON_JAR := python/hail/backend/hail-all-spark.jar; $(PYTHON_JAR): $(SHADOW_JAR); 	cp -f $(SHADOW_JAR) $@. .PHONY: python-jar; python-jar: $(PYTHON_JAR); ```. If I remove the python jar and invoke make, it runs mill then copies:; ```; ❯ rm python/hail/backend/hail-all-spark.jar. ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If run again, mill is invoked to check for changes, but as the jar doesn't change it isn't copied again:; ```; ❯ make python-jar; bash millw assembly; [105/110] memory.resources; ```. If I change some scala sources, the jar is updated and copied:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If I change some scala sources in a way that doesn't actually affect the jar, such as modifying comments, mill is smart enough to not change the jar, so it won't be copied again:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 1 Scala source to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [105/110] memory.resources; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793
https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793:40,Integrability,depend,dependency,40,"Ok, I think I sorted out the make->mill dependency propagation. Any real target which invokes mill to build it now depends on a target `FORCE` which is always out-of-date, so mill is always invoked. But mill will not change the modification time if it doesn't need to, so downstream targets aren't forced to be run. For example, we have targets; ```; FORCE:. SHADOW_JAR := out/assembly.dest/out.jar; $(SHADOW_JAR): FORCE; 	$(mill) assembly. PYTHON_JAR := python/hail/backend/hail-all-spark.jar; $(PYTHON_JAR): $(SHADOW_JAR); 	cp -f $(SHADOW_JAR) $@. .PHONY: python-jar; python-jar: $(PYTHON_JAR); ```. If I remove the python jar and invoke make, it runs mill then copies:; ```; ❯ rm python/hail/backend/hail-all-spark.jar. ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If run again, mill is invoked to check for changes, but as the jar doesn't change it isn't copied again:; ```; ❯ make python-jar; bash millw assembly; [105/110] memory.resources; ```. If I change some scala sources, the jar is updated and copied:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If I change some scala sources in a way that doesn't actually affect the jar, such as modifying comments, mill is smart enough to not change the jar, so it won't be copied again:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 1 Scala source to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [105/110] memory.resources; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793
https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793:115,Integrability,depend,depends,115,"Ok, I think I sorted out the make->mill dependency propagation. Any real target which invokes mill to build it now depends on a target `FORCE` which is always out-of-date, so mill is always invoked. But mill will not change the modification time if it doesn't need to, so downstream targets aren't forced to be run. For example, we have targets; ```; FORCE:. SHADOW_JAR := out/assembly.dest/out.jar; $(SHADOW_JAR): FORCE; 	$(mill) assembly. PYTHON_JAR := python/hail/backend/hail-all-spark.jar; $(PYTHON_JAR): $(SHADOW_JAR); 	cp -f $(SHADOW_JAR) $@. .PHONY: python-jar; python-jar: $(PYTHON_JAR); ```. If I remove the python jar and invoke make, it runs mill then copies:; ```; ❯ rm python/hail/backend/hail-all-spark.jar. ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If run again, mill is invoked to check for changes, but as the jar doesn't change it isn't copied again:; ```; ❯ make python-jar; bash millw assembly; [105/110] memory.resources; ```. If I change some scala sources, the jar is updated and copied:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 10 Scala sources to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [110/110] assembly; cp -f out/assembly.dest/out.jar python/hail/backend/hail-all-spark.jar; ```. If I change some scala sources in a way that doesn't actually affect the jar, such as modifying comments, mill is smart enough to not change the jar, so it won't be copied again:; ```; ❯ make python-jar; bash millw assembly; [95/110] compile; [info] compiling 1 Scala source to /Users/pschulz/hail/mill-worktree/hail/out/compile.dest/classes ...; [info] done compiling; [105/110] memory.resources; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930325793
https://github.com/hail-is/hail/pull/14147#issuecomment-1930447429:23,Integrability,depend,dependencies,23,"So I just put back the dependencies on `native-lib-prebuilt`. Since that just calls make recursively, it would probably be better to let mill invoke make, but I didn't want to deal with that, and this is a pretty uncommon use case (I think).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930447429
https://github.com/hail-is/hail/pull/14147#issuecomment-1930537252:25,Integrability,depend,dependencies,25,"> So I just put back the dependencies on `native-lib-prebuilt`. Since that just calls make recursively, it would probably be better to let mill invoke make, but I didn't want to deal with that, and this is a pretty uncommon use case (I think). That's sane to me, and avoids needing to deal with the make jobserver at the mill level. Feel free to un-WIP this whenever you're ready to merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930537252
https://github.com/hail-is/hail/pull/14147#issuecomment-1930537252:267,Safety,avoid,avoids,267,"> So I just put back the dependencies on `native-lib-prebuilt`. Since that just calls make recursively, it would probably be better to let mill invoke make, but I didn't want to deal with that, and this is a pretty uncommon use case (I think). That's sane to me, and avoids needing to deal with the make jobserver at the mill level. Feel free to un-WIP this whenever you're ready to merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14147#issuecomment-1930537252
https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704:53,Safety,unsafe,unsafe-fixes,53,"i went through and manually fixed everything that `--unsafe-fixes` had initially addressed (after undoing the unsafe fixes, obv), and i broke all my changes up into separate commits based on which linter rule they were addressing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704
https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704:110,Safety,unsafe,unsafe,110,"i went through and manually fixed everything that `--unsafe-fixes` had initially addressed (after undoing the unsafe fixes, obv), and i broke all my changes up into separate commits based on which linter rule they were addressing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704
https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704:98,Usability,undo,undoing,98,"i went through and manually fixed everything that `--unsafe-fixes` had initially addressed (after undoing the unsafe fixes, obv), and i broke all my changes up into separate commits based on which linter rule they were addressing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14150#issuecomment-1894479704
https://github.com/hail-is/hail/pull/14150#issuecomment-1998147422:175,Safety,avoid,avoid,175,"closing in favor of https://github.com/hail-is/hail/pull/14415, which starts from scratch on the current `main` and applies all the temporarily-ignored ruff rules manually to avoid bugs being introduced by automatic fixes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14150#issuecomment-1998147422
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:751,Availability,FAILURE,FAILURES,751,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:424,Modifiability,config,configfile,424,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:448,Modifiability,plugin,plugins,448,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:74,Safety,avoid,avoid,74,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:470,Safety,timeout,timeout-,470,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:149,Testability,test,test,149,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:158,Testability,assert,assert,158,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:228,Testability,test,test,228,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:863,Testability,test,test,863,"Ah yeah good point I forgot about that. You have to construct a string to avoid truncation a la:; ```; (base) dking@wm28c-761 /tmp % cat foo.py; def test():; assert False, 'b' * 1000; =========================================== test session starts ============================================; (base) dking@wm28c-761 /tmp % pytest foo.py; platform darwin -- Python 3.10.9, pytest-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:925,Testability,test,test,925,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:936,Testability,assert,assert,936,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:964,Testability,Assert,AssertionError,964,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:1984,Testability,assert,assert,1984,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:2008,Testability,Assert,AssertionError,2008,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:2072,Testability,test,test,2072,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:2149,Testability,test,test,2149,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019:2156,Testability,Assert,AssertionError,2156,"st-7.4.3, pluggy-1.3.0; rootdir: /private/tmp; configfile: pytest.ini; plugins: xdist-2.5.0, timeout-2.2.0, instafail-0.5.0, devtools-0.12.2, asyncio-0.21.1, timestamper-0.0.9, metadata-3.0.0, html-1.22.1, anyio-4.2.0, forked-1.6.0, accept-0.1.9, image-diff-0.0.11; asyncio: mode=strict; collected 1 item . foo.py F [100%]. ================================================= FAILURES =================================================; ___________________________________________________ test ___________________________________________________. def test():; > assert False, 'b' * 1000; E AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb; E assert False. foo.py:2: AssertionError; ========================================= short test summary info ==========================================; FAILED foo.py::test - AssertionError: bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb...; ============================================ 1 failed in 0.05s =============================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14151#issuecomment-1889800019
https://github.com/hail-is/hail/issues/14154#issuecomment-1889761766:35,Deployability,release,release,35,This should probably not be in the release script. It should just run on every deploy. The original PR's title suggested this was our intention https://github.com/hail-is/hail/pull/13703,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14154#issuecomment-1889761766
https://github.com/hail-is/hail/issues/14154#issuecomment-1889761766:79,Deployability,deploy,deploy,79,This should probably not be in the release script. It should just run on every deploy. The original PR's title suggested this was our intention https://github.com/hail-is/hail/pull/13703,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14154#issuecomment-1889761766
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:43,Deployability,release,released,43,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:345,Deployability,release,releases,345,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:383,Deployability,release,release,383,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:391,Deployability,upgrade,upgrades,391,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:500,Modifiability,enhance,enhancements,500,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582:471,Security,access,access,471,"My team is pretty excited about hail being released with support for Spark 3.5. One thing I noticed is that it looks like the plan is to [restrict to Spark 3.5.0](https://github.com/hail-is/hail/pull/14158/files#diff-7e9fff5f09cc109665f7fe9baa107affaac24f5dc5a0aa8bc3769221a4c6c328R53) - would it be possible to allow some wiggle room for minor releases? Spark has been beginning to release upgrades much more often than in the past, so restricting to 3.5.0 will prevent access to bug fixes, feature enhancements, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1900997582
https://github.com/hail-is/hail/pull/14158#issuecomment-1922339476:29,Integrability,message,message,29,@zyd14 that's just a warning message printed during compilation. The requirements.txt file [accepts any 3.5.x version](https://github.com/hail-is/hail/pull/14158/files#diff-c4e24762fa3ba8e53670cc9aba74121ade8ac055942738bde9c951fc0514561aR14).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1922339476
https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910:107,Deployability,deploy,deploy,107,"Since the dataproc tests only run on main commits (not on every PR commit, due to cost), I submitted a dev deploy to test the latest commit to this branch against dataproc: https://ci.hail.is/batches/8119055. ```; hailctl dev deploy -b danking/hail:dataproc-2.2 -s test_dataproc-37 -s test_dataproc-38; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910
https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910:226,Deployability,deploy,deploy,226,"Since the dataproc tests only run on main commits (not on every PR commit, due to cost), I submitted a dev deploy to test the latest commit to this branch against dataproc: https://ci.hail.is/batches/8119055. ```; hailctl dev deploy -b danking/hail:dataproc-2.2 -s test_dataproc-37 -s test_dataproc-38; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910
https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910:19,Testability,test,tests,19,"Since the dataproc tests only run on main commits (not on every PR commit, due to cost), I submitted a dev deploy to test the latest commit to this branch against dataproc: https://ci.hail.is/batches/8119055. ```; hailctl dev deploy -b danking/hail:dataproc-2.2 -s test_dataproc-37 -s test_dataproc-38; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910
https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910:117,Testability,test,test,117,"Since the dataproc tests only run on main commits (not on every PR commit, due to cost), I submitted a dev deploy to test the latest commit to this branch against dataproc: https://ci.hail.is/batches/8119055. ```; hailctl dev deploy -b danking/hail:dataproc-2.2 -s test_dataproc-37 -s test_dataproc-38; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1924204910
https://github.com/hail-is/hail/pull/14158#issuecomment-1927618210:13,Deployability,deploy,deploy,13,Previous dev deploy passed. Rebased on main and submitted a new dev deploy: https://ci.hail.is/batches/8120683,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1927618210
https://github.com/hail-is/hail/pull/14158#issuecomment-1927618210:68,Deployability,deploy,deploy,68,Previous dev deploy passed. Rebased on main and submitted a new dev deploy: https://ci.hail.is/batches/8120683,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1927618210
https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516:17,Deployability,deploy,deploy,17,"And here's a dev deploy that runs the dataproc tests. Don't approve until these tests pass! We don't run them on ordinary PRs because they're expensive and slow. We do run them on main commits. For this PR, the chance of having broken dataproc is high enough that we should ensure the tests pass before merging into main. https://ci.hail.is/batches/8121061",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516
https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516:47,Testability,test,tests,47,"And here's a dev deploy that runs the dataproc tests. Don't approve until these tests pass! We don't run them on ordinary PRs because they're expensive and slow. We do run them on main commits. For this PR, the chance of having broken dataproc is high enough that we should ensure the tests pass before merging into main. https://ci.hail.is/batches/8121061",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516
https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516:80,Testability,test,tests,80,"And here's a dev deploy that runs the dataproc tests. Don't approve until these tests pass! We don't run them on ordinary PRs because they're expensive and slow. We do run them on main commits. For this PR, the chance of having broken dataproc is high enough that we should ensure the tests pass before merging into main. https://ci.hail.is/batches/8121061",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516
https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516:285,Testability,test,tests,285,"And here's a dev deploy that runs the dataproc tests. Don't approve until these tests pass! We don't run them on ordinary PRs because they're expensive and slow. We do run them on main commits. For this PR, the chance of having broken dataproc is high enough that we should ensure the tests pass before merging into main. https://ci.hail.is/batches/8121061",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1930642516
https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352:54,Deployability,install,install-gcs-connector,54,"Delay merging until https://github.com/broadinstitute/install-gcs-connector/pull/6 is merged. Without that PR, users will not have access to a version of the GCS Hadoop connector that does not use tons of memory in JVM 11.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352
https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352:131,Security,access,access,131,"Delay merging until https://github.com/broadinstitute/install-gcs-connector/pull/6 is merged. Without that PR, users will not have access to a version of the GCS Hadoop connector that does not use tons of memory in JVM 11.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1931024352
https://github.com/hail-is/hail/pull/14158#issuecomment-1932835714:16,Deployability,deploy,deploy,16,Rebased and dev deploy kicked off: https://ci.hail.is/batches/8122588,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1932835714
https://github.com/hail-is/hail/pull/14158#issuecomment-1932836017:34,Deployability,install,install-gcs-connector,34,https://github.com/broadinstitute/install-gcs-connector/pull/6 is merged.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1932836017
https://github.com/hail-is/hail/pull/14158#issuecomment-1959922243:83,Integrability,wrap,wrap,83,@patrick-schultz @ehigham I'm abdicating responsibility for this. I've too much to wrap up in the next five work days. It looks like there's a mill issue currently. Otherwise I think it should be ready to merge.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1959922243
https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:133,Availability,failure,failure,133,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844
https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:370,Deployability,configurat,configuration,370,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844
https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:370,Modifiability,config,configuration,370,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844
https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:439,Modifiability,config,configure,439,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844
https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:235,Testability,test,test,235,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844
https://github.com/hail-is/hail/pull/14158#issuecomment-1961689398:126,Deployability,INSTALL,INSTALL,126,"Matt S fortuitously asked a question that lead me to https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md , so I'm trying that now. That might be the last necessary fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961689398
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1005,Availability,error,errors,1005,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1561,Availability,Error,Error,1561,"o pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:317,Deployability,configurat,configuration,317,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:416,Deployability,INSTALL,INSTALL,416,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:868,Deployability,update,updated,868,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:3197,Energy Efficiency,adapt,adapted,3197,"rce (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:2142); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:759); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:1277); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:162); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.FS.glob(FS.scala:402); E 	at is.hail.io.fs.FS.glob$(FS.scala:402); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1(HadoopFS.scala:154); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1$adapted(HadoopFS.scala:153). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1048,Integrability,message,message,1048,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1298,Integrability,message,message,1298,"p connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.Go",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:317,Modifiability,config,configuration,317,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:3197,Modifiability,adapt,adapted,3197,"rce (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:2142); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:759); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:1277); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:162); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.FS.glob(FS.scala:402); E 	at is.hail.io.fs.FS.glob$(FS.scala:402); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1(HadoopFS.scala:154); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1$adapted(HadoopFS.scala:153). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1139,Security,access,access,1139,"hat hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1389,Security,access,access,1389,"/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1567,Security,access,accessing,1567,"o pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:147,Testability,test,tests,147,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:634,Testability,test,test,634,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:796,Testability,test,test-requester-pays-,796,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:1587,Testability,test,test-requester-pays-,1587,"o pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStat",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236
https://github.com/hail-is/hail/pull/14158#issuecomment-2050442437:124,Deployability,update,update,124,"> I'm good with this, just one minor request, and a resolution on @daniel-goldstein 's question above.; > ; > Also, need to update the hail version in the changelog text. Sorry, missed that bit about the changelog",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-2050442437
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:75,Deployability,release,release,75,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:113,Deployability,release,release,113,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:164,Deployability,Release,Released,164,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:256,Deployability,release,releases,256,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:290,Deployability,Update,Update,290,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:301,Deployability,release,release,301,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203:352,Deployability,release,release,352,"The recent PR #14086 was added to for a month before it was merged and the release made on Jan 12th. However the release date listed in the changelog remained the `Released 2023-12-08` date on which the PR was initiated. If there is a checklist for making releases, it may be worth adding “Update the release date in _change_log.md_ before merging the release PR” to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14161#issuecomment-1891099203
https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580:245,Deployability,deploy,deploy,245,Just to make sure I understand -- the variable rename is to make sure it is clear that `HAIL_PRODUCTION_DOMAIN` means something different than `HAIL_DOMAIN` and is only applicable for CI? This is because the other services will have the correct deploy config?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580
https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580:38,Modifiability,variab,variable,38,Just to make sure I understand -- the variable rename is to make sure it is clear that `HAIL_PRODUCTION_DOMAIN` means something different than `HAIL_DOMAIN` and is only applicable for CI? This is because the other services will have the correct deploy config?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580
https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580:252,Modifiability,config,config,252,Just to make sure I understand -- the variable rename is to make sure it is clear that `HAIL_PRODUCTION_DOMAIN` means something different than `HAIL_DOMAIN` and is only applicable for CI? This is because the other services will have the correct deploy config?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580
https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580:76,Usability,clear,clear,76,Just to make sure I understand -- the variable rename is to make sure it is clear that `HAIL_PRODUCTION_DOMAIN` means something different than `HAIL_DOMAIN` and is only applicable for CI? This is because the other services will have the correct deploy config?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898843580
https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090:210,Deployability,deploy,deploy,210,"Yes, CI generates the config for gateway which needs the root domain name tied to the cluster, e.g. `hail.is` or `azure.hail.is`. But if it uses the environment variable name `HAIL_DOMAIN`, it will clobber the deploy config field `domain` in test namespaces which should be `internal.hail.is` not `hail.is`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090
https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090:22,Modifiability,config,config,22,"Yes, CI generates the config for gateway which needs the root domain name tied to the cluster, e.g. `hail.is` or `azure.hail.is`. But if it uses the environment variable name `HAIL_DOMAIN`, it will clobber the deploy config field `domain` in test namespaces which should be `internal.hail.is` not `hail.is`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090
https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090:161,Modifiability,variab,variable,161,"Yes, CI generates the config for gateway which needs the root domain name tied to the cluster, e.g. `hail.is` or `azure.hail.is`. But if it uses the environment variable name `HAIL_DOMAIN`, it will clobber the deploy config field `domain` in test namespaces which should be `internal.hail.is` not `hail.is`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090
https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090:217,Modifiability,config,config,217,"Yes, CI generates the config for gateway which needs the root domain name tied to the cluster, e.g. `hail.is` or `azure.hail.is`. But if it uses the environment variable name `HAIL_DOMAIN`, it will clobber the deploy config field `domain` in test namespaces which should be `internal.hail.is` not `hail.is`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090
https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090:242,Testability,test,test,242,"Yes, CI generates the config for gateway which needs the root domain name tied to the cluster, e.g. `hail.is` or `azure.hail.is`. But if it uses the environment variable name `HAIL_DOMAIN`, it will clobber the deploy config field `domain` in test namespaces which should be `internal.hail.is` not `hail.is`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/14164#issuecomment-1898947090
https://github.com/hail-is/hail/issues/14166#issuecomment-1896447300:9,Availability,down,downgrade,9,"For now, downgrade:; ```; pip3 install 'ipython<8.17'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14166#issuecomment-1896447300
https://github.com/hail-is/hail/issues/14166#issuecomment-1896447300:31,Deployability,install,install,31,"For now, downgrade:; ```; pip3 install 'ipython<8.17'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14166#issuecomment-1896447300
https://github.com/hail-is/hail/issues/14168#issuecomment-1897619805:0,Deployability,Update,Update,0,"Update: when I tested with chr1 with 32355811 variants at local computer using singularity instead of docker with 200g spark memory, it also failed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897619805
https://github.com/hail-is/hail/issues/14168#issuecomment-1897619805:15,Testability,test,tested,15,"Update: when I tested with chr1 with 32355811 variants at local computer using singularity instead of docker with 200g spark memory, it also failed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897619805
https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087:172,Performance,load,loading-a-plink-file,172,"Although the test is still running now, I am pretty sure the following solution solved the problem. ```; #https://discuss.hail.is/t/i-get-a-negativearraysizeexception-when-loading-a-plink-file/899. export PYSPARK_SUBMIT_ARGS=""--driver-java-options '-XX:hashCode=0' --conf 'spark.executor.extraJavaOptions=-XX:hashCode=0' pyspark-shell"". ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087
https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087:253,Security,hash,hashCode,253,"Although the test is still running now, I am pretty sure the following solution solved the problem. ```; #https://discuss.hail.is/t/i-get-a-negativearraysizeexception-when-loading-a-plink-file/899. export PYSPARK_SUBMIT_ARGS=""--driver-java-options '-XX:hashCode=0' --conf 'spark.executor.extraJavaOptions=-XX:hashCode=0' pyspark-shell"". ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087
https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087:309,Security,hash,hashCode,309,"Although the test is still running now, I am pretty sure the following solution solved the problem. ```; #https://discuss.hail.is/t/i-get-a-negativearraysizeexception-when-loading-a-plink-file/899. export PYSPARK_SUBMIT_ARGS=""--driver-java-options '-XX:hashCode=0' --conf 'spark.executor.extraJavaOptions=-XX:hashCode=0' pyspark-shell"". ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087
https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087:13,Testability,test,test,13,"Although the test is still running now, I am pretty sure the following solution solved the problem. ```; #https://discuss.hail.is/t/i-get-a-negativearraysizeexception-when-loading-a-plink-file/899. export PYSPARK_SUBMIT_ARGS=""--driver-java-options '-XX:hashCode=0' --conf 'spark.executor.extraJavaOptions=-XX:hashCode=0' pyspark-shell"". ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1897770087
https://github.com/hail-is/hail/issues/14168#issuecomment-1904412205:1084,Usability,feedback,feedback,1084,"Hey @shengqh !. Yeah, this is a bug in Kryo, a serialization library used by Spark, which cannot handle the size of data you're producing. This is partly a deficiency in Hail: we assume that PLINK files are relatively small, in particular that the number of variants is small. This issue was supposedly resolved in Spark 2.4.0+ and 3.0.0+ by https://github.com/apache/spark/commit/3e033035a3c0b7d46c2ae18d0d322d4af3808711 . You appear to be running Apache Spark version 3.3.2, so I'm surprised you encountered this. Can you confirm which version of the Kryo JAR you have in your environment?. Can you also share a bit of information about this PLINK file? `import_plink` could obviously be modified to support 30M+ variant PLINK files, but I'd like to understand better why such large PLINK files exist. Do you expect these files to continue to grow in size? Do other consumers of these PLINK files want one PLINK file per chromosome? Would it be possible to generate many PLINK files per chromosome such that all the PLINK files have roughly the same size in bytes?. Thanks for your feedback and help improving Hail!. Related issue: https://github.com/hail-is/hail/issues/5564 .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1904412205
https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993:679,Testability,test,tested,679,"@danking:. > Hey @shengqh !; > ; > Yeah, this is a bug in Kryo, a serialization library used by Spark, which cannot handle the size of data you're producing.; > ; > This is partly a deficiency in Hail: we assume that PLINK files are relatively small, in particular that the number of variants is small.; > ; > This issue was supposedly resolved in Spark 2.4.0+ and 3.0.0+ by [apache/spark@3e03303](https://github.com/apache/spark/commit/3e033035a3c0b7d46c2ae18d0d322d4af3808711) . You appear to be running Apache Spark version 3.3.2, so I'm surprised you encountered this. Can you confirm which version of the Kryo JAR you have in your environment?. I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. > ; > Can you also share a bit of information about this PLINK file? `import_plink` could obviously be modified to support 30M+ variant PLINK files, but I'd like to understand better why such large PLINK files exist. Do you expect these files to continue to grow in size? Do other consumers of these PLINK files want one PLINK file per chromosome? Would it be possible to generate many PLINK files per chromosome such that all the PLINK files have roughly the same size in bytes?. We have a 35K cohort. The VCF format of chr1 is 2.4T. So we prefer to deliver plink bed format and hail matrix. And, the cohort will continue to grow in future. I will prefer to keep one file per chromosome. For large cohort, which format do you prefer? Hail matrix or Hail VDS?. > ; > Thanks for your feedback and help improving Hail!; > ; > Related issue: #5564 .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993
https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993:1562,Usability,feedback,feedback,1562,"@danking:. > Hey @shengqh !; > ; > Yeah, this is a bug in Kryo, a serialization library used by Spark, which cannot handle the size of data you're producing.; > ; > This is partly a deficiency in Hail: we assume that PLINK files are relatively small, in particular that the number of variants is small.; > ; > This issue was supposedly resolved in Spark 2.4.0+ and 3.0.0+ by [apache/spark@3e03303](https://github.com/apache/spark/commit/3e033035a3c0b7d46c2ae18d0d322d4af3808711) . You appear to be running Apache Spark version 3.3.2, so I'm surprised you encountered this. Can you confirm which version of the Kryo JAR you have in your environment?. I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. > ; > Can you also share a bit of information about this PLINK file? `import_plink` could obviously be modified to support 30M+ variant PLINK files, but I'd like to understand better why such large PLINK files exist. Do you expect these files to continue to grow in size? Do other consumers of these PLINK files want one PLINK file per chromosome? Would it be possible to generate many PLINK files per chromosome such that all the PLINK files have roughly the same size in bytes?. We have a 35K cohort. The VCF format of chr1 is 2.4T. So we prefer to deliver plink bed format and hail matrix. And, the cohort will continue to grow in future. I will prefer to keep one file per chromosome. For large cohort, which format do you prefer? Hail matrix or Hail VDS?. > ; > Thanks for your feedback and help improving Hail!; > ; > Related issue: #5564 .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1904727993
https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526:473,Deployability,pipeline,pipeline,473,"> We have a 35K cohort. The VCF format of chr1 is 2.4T. Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" (samtools/hts-specs#434) and ""reference blocks"" (samtools/hts-specs#435). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF. What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. ---. > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526
https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526:957,Integrability,depend,depends,957,"> We have a 35K cohort. The VCF format of chr1 is 2.4T. Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" (samtools/hts-specs#434) and ""reference blocks"" (samtools/hts-specs#435). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF. What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. ---. > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526
https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526:1588,Performance,load,loading,1588,"> We have a 35K cohort. The VCF format of chr1 is 2.4T. Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" (samtools/hts-specs#434) and ""reference blocks"" (samtools/hts-specs#435). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF. What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. ---. > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526
https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526:1085,Testability,test,tested,1085,"> We have a 35K cohort. The VCF format of chr1 is 2.4T. Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" (samtools/hts-specs#434) and ""reference blocks"" (samtools/hts-specs#435). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF. What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. ---. > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11. Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1922048526
https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344:589,Deployability,pipeline,pipeline,589,"> > We have a 35K cohort. The VCF format of chr1 is 2.4T.; > ; > Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" ([samtools/hts-specs#434](https://github.com/samtools/hts-specs/pull/434)) and ""reference blocks"" ([samtools/hts-specs#435](https://github.com/samtools/hts-specs/pull/435)). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF.; > ; > What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. Looks like VDS is a better solution than HailMatrix. However, we got the joint call result as vcf alreay. Can VDS Combiner read joint call VCF and then save it as VDS format? I cannot find any example to transfer VCF to VDS. Thanks. > ; > > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11.; > ; > Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement fo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344
https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344:1073,Integrability,depend,depends,1073," a 35K cohort. The VCF format of chr1 is 2.4T.; > ; > Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" ([samtools/hts-specs#434](https://github.com/samtools/hts-specs/pull/434)) and ""reference blocks"" ([samtools/hts-specs#435](https://github.com/samtools/hts-specs/pull/435)). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF.; > ; > What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. Looks like VDS is a better solution than HailMatrix. However, we got the joint call result as vcf alreay. Can VDS Combiner read joint call VCF and then save it as VDS format? I cannot find any example to transfer VCF to VDS. Thanks. > ; > > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11.; > ; > Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344
https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344:1945,Performance,load,loading,1945," a 35K cohort. The VCF format of chr1 is 2.4T.; > ; > Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" ([samtools/hts-specs#434](https://github.com/samtools/hts-specs/pull/434)) and ""reference blocks"" ([samtools/hts-specs#435](https://github.com/samtools/hts-specs/pull/435)). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF.; > ; > What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. Looks like VDS is a better solution than HailMatrix. However, we got the joint call result as vcf alreay. Can VDS Combiner read joint call VCF and then save it as VDS format? I cannot find any example to transfer VCF to VDS. Thanks. > ; > > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11.; > ; > Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344
