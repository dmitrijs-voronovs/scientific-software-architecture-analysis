id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1107:253,usability,tool,tools,253,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:353,usability,tool,tools,353,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:630,usability,tool,toolkit,630,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:641,usability,perform,perform,641,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:860,usability,perform,perform,860,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1005,usability,document,documentation,1005,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1350,usability,tool,tool,1350,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1108:422,availability,error,error,422,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:153,deployability,contain,contains,153,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,deployability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:515,deployability,modul,module,515,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1478,deployability,version,version,1478,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:162,integrability,batch,batch,162,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,integrability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:361,integrability,batch,batch,361,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1478,integrability,version,version,1478,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,interoperability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,modifiability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:515,modifiability,modul,module,515,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:631,modifiability,pac,packages,631,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:897,modifiability,pac,packages,897,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1101,modifiability,pac,packages,1101,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1478,modifiability,version,version,1478,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:162,performance,batch,batch,162,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:215,performance,perform,performing,215,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:361,performance,batch,batch,361,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:422,performance,error,error,422,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:568,performance,time,time,568,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,reliability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:422,safety,error,error,422,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:488,safety,input,input-,488,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:515,safety,modul,module,515,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,security,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:241,testability,integr,integration,241,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:444,testability,Trace,Traceback,444,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:215,usability,perform,performing,215,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:422,usability,error,error,422,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:488,usability,input,input-,488,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:647,usability,tool,tools,647,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:913,usability,tool,tools,913,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1117,usability,tool,tools,1117,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/issues/1108:1503,usability,help,help,1503,"Ingest with BBKNN; Hi there! Thanks for adding the ingest method to scanpy! I was wondering what would be the suggested approach when the reference data contains batch effects that should be removed before actually performing the asymmetric integration with a query dataset. I tried to use the neighbors structure returned by BBKNN (which correctly adjusts for batch effects), but the 'metric' object is missing. Here the error:. ```. KeyError Traceback (most recent call last). <ipython-input-22-a805d117788e> in <module>. ----> 1 sc.tl.ingest(adata, adata_ref, obs='time', embedding_method='umap'). /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, inplace, **kwargs). 115 labeling_method = labeling_method * len(obs). 116 . --> 117 ing = Ingest(adata_ref). 118 ing.fit(adata). 119 . /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata). 268 . 269 if 'neighbors' in adata.uns:. --> 270 self._init_neighbors(adata). 271 . 272 if 'X_umap' in adata.obsm:. /opt/conda/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata). 229 else:. 230 dist_args = (). --> 231 dist_func = named_distances[adata.uns['neighbors']['params']['metric']]. 232 self._random_init, self._tree_init = make_initialisations(dist_func, dist_args). 233 self._search = make_initialized_nnd_search(dist_func, dist_args). KeyError: 'metric'. ```. I'm running scanpy version 1.4.5.post2. Any help would be highly appreciated!! Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1108
https://github.com/scverse/scanpy/pull/1109:219,availability,error,errors,219,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:172,energy efficiency,heat,heatmap,172,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:441,modifiability,layer,layer,441,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:540,modifiability,layer,layer,540,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:798,modifiability,layer,layers,798,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:805,modifiability,layer,layer,805,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:219,performance,error,errors,219,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:214,safety,test,test,214,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:219,safety,error,errors,219,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:6,testability,Simpl,Simplify,6,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:69,testability,simpl,simplification,69,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:214,testability,test,test,214,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:704,testability,assert,assert,704,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:935,testability,assert,assert,935,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:6,usability,Simpl,Simplify,6,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:69,usability,simpl,simplification,69,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1109:219,usability,error,errors,219,"[WIP] Simplify plotting; @flying-sheep This is generally the kind of simplification I was hoping we could do with plotting. . It's not much, and is more about the dotplot, heatmap, etc. plotting methods. Also, the test errors I was running into are still happening. Another example would using a function to choose representations of X the same way for each function. Something like:. ```python. def _choose_obs_rep(adata, *, use_raw=False, layer=None, obsm=None, obsp=None):. """""". Choose array aligned with obs annotation. """""". is_layer = layer is not None. is_raw = use_raw is not False. is_obsm = obsm is not None. is_obsp = obsp is not None. choices_made = sum((is_layer, is_raw, is_obsm, is_obsp)). assert choices_made <= 1. if choices_made == 0:. return adata.X. elif is_layer:. return adata.layers[layer]. elif use_raw:. return adata.raw.X. elif is_obsm:. return adata.obsm[obsm]. elif is_obsp:. return adata.obsp[obsp]. else:. assert False, (. ""That was unexpected. Please report this bug at:\n\n\t"". "" https://github.com/theislab/scanpy/issues"". ). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1109
https://github.com/scverse/scanpy/pull/1110:72,integrability,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1110
https://github.com/scverse/scanpy/pull/1110:72,modifiability,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1110
https://github.com/scverse/scanpy/pull/1110:72,security,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1110
https://github.com/scverse/scanpy/pull/1111:72,integrability,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111
https://github.com/scverse/scanpy/pull/1111:72,modifiability,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111
https://github.com/scverse/scanpy/pull/1111:72,security,configur,configurable,72,"Change the default number of nearest neighbors search in Ingest; It was configurable with the default `k=10` before, now it uses n_neighbors from `sc.tl.neighbors`. As discussed with @falexwolf .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1111
https://github.com/scverse/scanpy/pull/1113:16,availability,error,error,16,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/pull/1113:31,deployability,stack,stackoverflow,31,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/pull/1113:16,performance,error,error,16,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/pull/1113:233,performance,cach,caches,233,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/pull/1113:16,safety,error,error,16,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/pull/1113:16,usability,error,error,16,"try fixing h5py error; https://stackoverflow.com/questions/51593527/oserror-unable-to-open-file-unable-to-open-file. /edit: that was not it. Ill set up a Python 3.7 venv and look if I can reproduce it locally. /edit: nope, cleaning caches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1113
https://github.com/scverse/scanpy/issues/1114:23,availability,error,error,23,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:169,availability,error,errors,169,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:264,availability,error,errors,264,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:819,availability,error,error,819,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:907,availability,Error,Error,907,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1998,availability,error,error,1998,"-------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:112,deployability,updat,update,112,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1910,deployability,modul,module,1910,"output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2239,deployability,scale,scale,2239,"ries(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a fra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3327,deployability,Version,Versions,3327,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3360,deployability,log,logging,3360,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1162,energy efficiency,core,core,1162,"ting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_vio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1316,energy efficiency,core,core,1316,"nes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1533,energy efficiency,core,core,1533,"ethod='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2239,energy efficiency,scale,scale,2239,"ries(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a fra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2530,energy efficiency,core,core,2530,"/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2743,energy efficiency,core,core,2743,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2984,energy efficiency,core,core,2984,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3327,integrability,Version,Versions,3327,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:597,interoperability,share,sharey,597,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1146,modifiability,pac,packages,1146," multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1300,modifiability,pac,packages,1300,"`sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1517,modifiability,pac,packages,1517,", 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1910,modifiability,modul,module,1910,"output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2096,modifiability,pac,packages,2096,"nt call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueErro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2239,modifiability,scal,scale,2239,"ries(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a fra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2514,modifiability,pac,packages,2514,"ackages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2727,modifiability,pac,packages,2727,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2968,modifiability,pac,packages,2968,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3327,modifiability,Version,Versions,3327,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:23,performance,error,error,23,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:169,performance,error,errors,169,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:264,performance,error,errors,264,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:819,performance,error,error,819,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:907,performance,Error,Error,907,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1998,performance,error,error,1998,"-------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:2239,performance,scale,scale,2239,"ries(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a fra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:23,safety,error,error,23,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:112,safety,updat,update,112,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:169,safety,error,errors,169,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:264,safety,error,errors,264,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:819,safety,error,error,819,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:907,safety,Error,Error,907,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1070,safety,Except,Exception,1070,"ion of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1260,safety,except,except,1260," errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1667,safety,Except,Exception,1667,"mes'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_sl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1720,safety,Except,Exception,1720,":1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1788,safety,except,exception,1788,"vals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1807,safety,except,exception,1807,"#gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 319",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1883,safety,input,input-,1883,". ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1910,safety,modul,module,1910,"output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1998,safety,error,error,1998,"-------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3068,safety,except,except,3068,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3360,safety,log,logging,3360,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:112,security,updat,update,112,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3360,security,log,logging,3360,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1080,testability,Trace,Traceback,1080,"t the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1839,testability,Trace,Traceback,1839,"roups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3360,testability,log,logging,3360,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:23,usability,error,error,23,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:49,usability,clear,clear,49,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:169,usability,error,errors,169,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:264,usability,error,errors,264,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:376,usability,minim,minimal,376,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:819,usability,error,error,819,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:907,usability,Error,Error,907,"sc.pl.matrixplot index error; <!-- Please give a clear and concise description of what the bug is: -->. Since I update to scanpy==1.4.5.1 I am getting multiple plotting errors. `sc.pl.rank_genes_groups() and sc.pl.violin()` are still working fine but I am getting errors in the rank_genes functions like `sc.pl.rank_genes_groups_violin(`) and `sc.pl.tracksplot()`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ##still working fine. sc.tl.rank_genes_groups(adata, 'louvain', method='wilcoxon'). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names', 'pvals']}).head(5). ##gives error. sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 er",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1883,usability,input,input-,1883,". ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:1998,usability,error,error,1998,"-------------------------------------------------------------------. Exception Traceback (most recent call last). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3169 try:. -> 3170 value = Series(value). 3171 except:. ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in __init__(self, data, index, dtype, name, copy, fastpath). 273 data = _sanitize_array(data, index, dtype, copy,. --> 274 raise_cast_failure=True). 275 . ~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py in _sanitize_array(data, index, dtype, copy, raise_cast_failure). 4160 if isinstance(data, np.ndarray):. -> 4161 raise Exception('Data must be 1-dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/issues/1114:3485,usability,learn,learn,3485,"dimensional'). 4162 else:. Exception: Data must be 1-dimensional. During handling of the above exception, another exception occurred:. ValueError Traceback (most recent call last). <ipython-input-23-ccdbf8b7836c> in <module>. ----> 1 sc.pl.rank_genes_groups_violin(adata, groups='2', n_genes=8) ## 200316 error fix later, also when I run the entire script from the start. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_violin(adata, groups, n_genes, gene_names, gene_symbols, use_raw, key, split, scale, strip, jitter, size, ax, show, save). 727 if issparse(X_col): X_col = X_col.toarray().flatten(). 728 new_gene_names.append(g). --> 729 df[g] = X_col. 730 df['hue'] = adata.obs[groups_key].astype(str).values. 731 if reference == 'rest':. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in __setitem__(self, key, value). 3114 else:. 3115 # set column. -> 3116 self._set_item(key, value). 3117 . 3118 def _setitem_slice(self, key, value):. ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _set_item(self, key, value). 3188 """""". 3189 . -> 3190 self._ensure_valid_index(value). 3191 value = self._sanitize_column(key, value). 3192 NDFrame._set_item(self, key, value). ~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py in _ensure_valid_index(self, value). 3170 value = Series(value). 3171 except:. -> 3172 raise ValueError('Cannot set a frame with no defined index '. 3173 'and a value that cannot be converted to a '. 3174 'Series'). ValueError: Cannot set a frame with no defined index and a value that cannot be converted to a Series. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.23.0 scikit-learn==0.21.3 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1. scvelo==0.1.25 scanpy==1.4.5.1 anndata==0.7.1 loompy==3.0.6 numpy==1.18.1 scipy==1.4.1 matplotlib==3.1.3 sklearn==0.21.3 pandas==0.23.0 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1114
https://github.com/scverse/scanpy/pull/1117:299,availability,cluster,clustering,299,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:93,deployability,depend,dependency,93,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:299,deployability,cluster,clustering,299,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:381,deployability,API,APIs,381,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:81,energy efficiency,Current,Currently,81,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:497,energy efficiency,current,currently,497,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:93,integrability,depend,dependency,93,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:381,integrability,API,APIs,381,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:381,interoperability,API,APIs,381,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:93,modifiability,depend,dependency,93,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:93,safety,depend,dependency,93,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:93,testability,depend,dependency,93,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1117:72,usability,support,support,72,"CITE-seq improvements; This is a bit of a catch all to improve cite-seq support. Currently a dependency of https://github.com/theislab/scanpy-tutorials/pull/14. I'll write a bit more about this after some sleep. The main goals here are:. * Implement analysis functions for cite-seq data (like joint clustering, geometric mean normalization, etc.). * Improve generality of existing APIs. Basically, if the antibody counts are in obsm, we should be able to apply most functions to that. This is not currently the case.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1117
https://github.com/scverse/scanpy/pull/1118:213,safety,test,test,213,"pp.neighbors saves to obsp and uses key_added argument; It is now possible to have several neighbors graphs in adata. For example,. ```py. sc.pp.neighbors(adata). sc.pp.neighbors(adata, use_rep='some', key_added='test'). sc.pp.neighbors(adata, use_rep='some1', key_added='test1'). sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'). sc.tl.diffmap(adata, neighbors_key='test1'). ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/pull/1118:357,safety,test,test,357,"pp.neighbors saves to obsp and uses key_added argument; It is now possible to have several neighbors graphs in adata. For example,. ```py. sc.pp.neighbors(adata). sc.pp.neighbors(adata, use_rep='some', key_added='test'). sc.pp.neighbors(adata, use_rep='some1', key_added='test1'). sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'). sc.tl.diffmap(adata, neighbors_key='test1'). ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/pull/1118:213,testability,test,test,213,"pp.neighbors saves to obsp and uses key_added argument; It is now possible to have several neighbors graphs in adata. For example,. ```py. sc.pp.neighbors(adata). sc.pp.neighbors(adata, use_rep='some', key_added='test'). sc.pp.neighbors(adata, use_rep='some1', key_added='test1'). sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'). sc.tl.diffmap(adata, neighbors_key='test1'). ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/pull/1118:357,testability,test,test,357,"pp.neighbors saves to obsp and uses key_added argument; It is now possible to have several neighbors graphs in adata. For example,. ```py. sc.pp.neighbors(adata). sc.pp.neighbors(adata, use_rep='some', key_added='test'). sc.pp.neighbors(adata, use_rep='some1', key_added='test1'). sc.pp.neighbors(adata, key_added='test2'). sc.tl.umap(adata, neighbors_key='test'). sc.tl.diffmap(adata, neighbors_key='test1'). ```. and so on.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1118
https://github.com/scverse/scanpy/pull/1119:36,security,control,control,36,"Print info about the real number of control genes in scoring function; Since we sample ctrl_size many genes from each bin, total number of genes is a function of n_bins and ctrl_size but total number, but hard to calculate since multiple genes can fall into the same bin. This PR just prints total number of control genes to inform the user.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1119
https://github.com/scverse/scanpy/pull/1119:308,security,control,control,308,"Print info about the real number of control genes in scoring function; Since we sample ctrl_size many genes from each bin, total number of genes is a function of n_bins and ctrl_size but total number, but hard to calculate since multiple genes can fall into the same bin. This PR just prints total number of control genes to inform the user.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1119
https://github.com/scverse/scanpy/pull/1119:36,testability,control,control,36,"Print info about the real number of control genes in scoring function; Since we sample ctrl_size many genes from each bin, total number of genes is a function of n_bins and ctrl_size but total number, but hard to calculate since multiple genes can fall into the same bin. This PR just prints total number of control genes to inform the user.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1119
https://github.com/scverse/scanpy/pull/1119:308,testability,control,control,308,"Print info about the real number of control genes in scoring function; Since we sample ctrl_size many genes from each bin, total number of genes is a function of n_bins and ctrl_size but total number, but hard to calculate since multiple genes can fall into the same bin. This PR just prints total number of control genes to inform the user.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1119
https://github.com/scverse/scanpy/pull/1119:336,usability,user,user,336,"Print info about the real number of control genes in scoring function; Since we sample ctrl_size many genes from each bin, total number of genes is a function of n_bins and ctrl_size but total number, but hard to calculate since multiple genes can fall into the same bin. This PR just prints total number of control genes to inform the user.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1119
https://github.com/scverse/scanpy/issues/1120:10,interoperability,specif,specific,10,"Highlight specific cells based on hard gene expression cut-offs; Dear Scanpy team, . In the UMAP plot, I would like to highlight all cells that for instance have and CD3G expression > 2 and CD4 expression < 3. Cells that do not fulfill these two criteria would for instance be dark blue, while those that do are yellow. How would I go about doing this? . I have tried to follow your advice from: https://github.com/theislab/scanpy/issues/532 . However, this is not exactly what I would wish to do and I am to unfamiliar with the design of the adata object to fix this myself. Could you point me in the right direction? Kind regards, . Laurenz De Cock.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1120
https://github.com/scverse/scanpy/issues/1120:77,security,team,team,77,"Highlight specific cells based on hard gene expression cut-offs; Dear Scanpy team, . In the UMAP plot, I would like to highlight all cells that for instance have and CD3G expression > 2 and CD4 expression < 3. Cells that do not fulfill these two criteria would for instance be dark blue, while those that do are yellow. How would I go about doing this? . I have tried to follow your advice from: https://github.com/theislab/scanpy/issues/532 . However, this is not exactly what I would wish to do and I am to unfamiliar with the design of the adata object to fix this myself. Could you point me in the right direction? Kind regards, . Laurenz De Cock.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1120
https://github.com/scverse/scanpy/issues/1121:787,availability,error,error,787,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:888,availability,error,error,888,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:348,deployability,depend,dependency,348,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:376,deployability,version,version,376,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:948,deployability,instal,installing,948,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1045,deployability,depend,dependecies,1045,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:28,energy efficiency,load,load,28,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:743,energy efficiency,load,load,743,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:348,integrability,depend,dependency,348,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:376,integrability,version,version,376,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1045,integrability,depend,dependecies,1045,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:348,modifiability,depend,dependency,348,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:376,modifiability,version,version,376,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1045,modifiability,depend,dependecies,1045,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:28,performance,load,load,28,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:154,performance,time,time,154,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:574,performance,perform,performing,574,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:743,performance,load,load,743,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:787,performance,error,error,787,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:888,performance,error,error,888,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:348,safety,depend,dependency,348,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:787,safety,error,error,787,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:888,safety,error,error,888,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1045,safety,depend,dependecies,1045,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:348,testability,depend,dependency,348,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1045,testability,depend,dependecies,1045,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:85,usability,clear,clear,85,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:259,usability,learn,learn,259,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:304,usability,learn,learn,304,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:317,usability,learn,learn,317,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:574,usability,perform,performing,574,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:787,usability,error,error,787,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:888,usability,error,error,888,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:966,usability,learn,learn,966,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1121:1032,usability,learn,learn,1032,"ImportError: dlopen: cannot load any more object with static TLS; <!-- Please give a clear and concise description of what the bug is: -->. I've had hard time in figuring this out. This is not a problem of scanpy directly but apparently is related to [scikit-learn 0.21 series](https://github.com/scikit-learn/scikit-learn/issues/14485) which is a dependency of latest scanpy version (1.4.6). Also related to [this comment in pytorch](https://github.com/pytorch/pytorch/issues/2575#issuecomment-523657178). My issue is that I'm using, in addition to scanpy, another library performing a dl_import with static TLS. . So if I issue. ```python. import scanpy as sc. import graph_tool.all as gt. ```. I get. ```python. ImportError: dlopen: cannot load any more object with static TLS . ```. error and I'm not able to use the second library. Reversing the order of the imports raises the same error and I'm not able to use `scanpy`. The issue is solved installing scikit-learn 0.20.4 (the last of 0.20 series). What are the exact scikit-learn 0.21.2 dependecies in scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1121
https://github.com/scverse/scanpy/issues/1122:75,availability,error,error,75,"BBKNN and ingest; Hi all! I want to use ingest after BBKNN but it gives an error related to the metric. If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/issues/1122:124,modifiability,paramet,parameter,124,"BBKNN and ingest; Hi all! I want to use ingest after BBKNN but it gives an error related to the metric. If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/issues/1122:75,performance,error,error,75,"BBKNN and ingest; Hi all! I want to use ingest after BBKNN but it gives an error related to the metric. If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/issues/1122:75,safety,error,error,75,"BBKNN and ingest; Hi all! I want to use ingest after BBKNN but it gives an error related to the metric. If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/issues/1122:75,usability,error,error,75,"BBKNN and ingest; Hi all! I want to use ingest after BBKNN but it gives an error related to the metric. If I add the metric parameter to the neighbors dict I have no more problems, but it is true only if the metric is euclidean. . Is it possible to have the metric always reported in the BBKNN neighbors dict? And to use ingest with different metrics?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1122
https://github.com/scverse/scanpy/pull/1123:731,deployability,version,version,731,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:723,energy efficiency,current,current,723,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:731,integrability,version,version,731,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:695,modifiability,scenario,scenario,695,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:731,modifiability,version,version,731,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:291,performance,perform,performance,291,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:563,performance,Perform,Performancewise,563,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:739,reliability,doe,doesn,739,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:280,safety,test,tested,280,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:280,testability,test,tested,280,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:259,usability,custom,custom,259,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:291,usability,perform,performance,291,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:468,usability,user,user-images,468,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:563,usability,Perform,Performancewise,563,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1123:800,usability,user,user-images,800,"Fix pl.paga with pie charts; Hi everyone,. at the moment, pie charts for paga are a bit brittle, see https://github.com/theislab/cellrank/issues/25. This pull request is an attempt to fix it. Rather than using `ax.pie`, it's just a bunch of scatterplots with custom markers. I've tested the performance. ```python. foo = {i: {c.to_hex(cm.viridis(_)): 0.001 for _ in range(255)} for i in range(8)}. sc.pl.paga(adata, color=foo, colorbar=False). ```. ![currect](https://user-images.githubusercontent.com/46717574/77180766-ad339b80-6aca-11ea-9a85-617ad122d140.png). Performancewise, it takes about ~14 seconds to produce the plot with the proposed changes,. ~4s, but I consider that the worst-case scenario. More importantly, current version doesn't produce a correct plot, see below:. ![buggy](https://user-images.githubusercontent.com/46717574/77180621-7f4e5700-6aca-11ea-8c78-25fbba8f7c98.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1123
https://github.com/scverse/scanpy/pull/1124:41,energy efficiency,Current,Currently,41,"Fix `n_pcs` usage if `use_rep=='X_pca'`; Currently. ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep='X_pca'). ```. and . ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep=None). ```. yield different results, because the former uses all 50 PCs while the latter uses the user-defined 30 PCs. Now, both ways, it accounts for the user-defined 30 PCs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1124
https://github.com/scverse/scanpy/pull/1124:399,usability,user,user-defined,399,"Fix `n_pcs` usage if `use_rep=='X_pca'`; Currently. ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep='X_pca'). ```. and . ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep=None). ```. yield different results, because the former uses all 50 PCs while the latter uses the user-defined 30 PCs. Now, both ways, it accounts for the user-defined 30 PCs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1124
https://github.com/scverse/scanpy/pull/1124:456,usability,user,user-defined,456,"Fix `n_pcs` usage if `use_rep=='X_pca'`; Currently. ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep='X_pca'). ```. and . ```. sc.pp.pca(adata, n_comps=50). neighbors = sc.Neighbors(adata). neighbors.compute_neighbors(n_pcs=30, use_rep=None). ```. yield different results, because the former uses all 50 PCs while the latter uses the user-defined 30 PCs. Now, both ways, it accounts for the user-defined 30 PCs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1124
https://github.com/scverse/scanpy/issues/1125:399,availability,Error,Error,399,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:658,availability,error,error,658,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:884,availability,Error,Error,884,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:322,deployability,releas,release,322,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:330,deployability,version,version,330,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:601,deployability,version,version,601,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1133,deployability,modul,module,1133,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1365,deployability,log,logg,1365,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1828,deployability,Version,Versions,1828,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1861,deployability,log,logging,1861,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:330,integrability,version,version,330,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:405,integrability,messag,message,405,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:601,integrability,version,version,601,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:664,integrability,messag,message,664,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1828,integrability,Version,Versions,1828,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:297,interoperability,coordinat,coordinates,297,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:405,interoperability,messag,message,405,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:664,interoperability,messag,message,664,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:330,modifiability,version,version,330,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:525,modifiability,pac,packages,525,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:601,modifiability,version,version,601,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1133,modifiability,modul,module,1133,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1828,modifiability,Version,Versions,1828,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:399,performance,Error,Error,399,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:658,performance,error,error,658,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:884,performance,Error,Error,884,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:399,safety,Error,Error,399,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:658,safety,error,error,658,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:884,safety,Error,Error,884,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1106,safety,input,input-,1106,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1133,safety,modul,module,1133,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1365,safety,log,logg,1365,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1861,safety,log,logging,1861,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1365,security,log,logg,1365,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1861,security,log,logging,1861,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1062,testability,Trace,Traceback,1062,"se give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louva",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1365,testability,log,logg,1365,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1861,testability,log,logging,1861,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:77,usability,clear,clear,77,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:399,usability,Error,Error,399,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:483,usability,User,Users,483,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:658,usability,error,error,658,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:751,usability,minim,minimal,751,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:884,usability,Error,Error,884,"AttributeError: 'AnnData' object has no attribute 'obsp'; <!-- Please give a clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1106,usability,input,input-,1106,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:1186,usability,tool,tools,1186,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/issues/1125:2007,usability,learn,learn,2007,"clear and concise description of what the bug is: -->. I'm using the ""scvelo"" https://scvelo.readthedocs.io/getting_started.html for scRNA data analysis. It underlying called ""scanpy"" function ""umap"" for calculating the coordinates. I tried the release version ""scanpy-1.4.4.post1-py_0"". It can not be imported to Python. Error message: ""ImportError: cannot import name '_Metric' from 'scanpy.neighbors' (/Users/shuzhe/anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py)"". I finally switch to the developing version for ""scanpy"". When I run ""umap"", it gives me the error message below. I'm wondering what the "".obsp"" is and how it is generated. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. scv.tl.umap(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-22-391fc8667646> in <module>. ----> 1 scv.tl.umap(adata). ~/scanpy/scanpy/tools/_umap.py in umap(adata, min_dist, spread, n_components, maxiter, alpha, gamma, negative_sample_rate, init_pos, random_state, a, b, copy, method, neighbors_key). 125 start = logg.info('computing UMAP'). 126 . --> 127 neighbors = NeighborsView(adata, neighbors_key). 128 . 129 if ('params' not in neighbors. ~/scanpy/scanpy/_utils.py in __init__(self, adata, key). 667 self._dists_key = self._neighbors_dict['distances_key']. 668 . --> 669 if self._conns_key in adata.obsp:. 670 self._connectivities = adata.obsp[self._conns_key]. 671 if self._dists_key in adata.obsp:. AttributeError: 'AnnData' object has no attribute 'obsp'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.7.dev26+gc255fa10 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.21.2 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1125
https://github.com/scverse/scanpy/pull/1127:402,deployability,contain,containing,402,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:440,deployability,contain,containing,440,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:760,deployability,updat,update,760,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1641,deployability,log,logfoldchange,1641,"core and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1832,deployability,Updat,Update,1832,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2189,deployability,log,log,2189,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2524,deployability,stack,stackedviolin,2524,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2665,deployability,Updat,Update,2665,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2690,deployability,Updat,Update,2690,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2710,deployability,Updat,Update,2710,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:909,energy efficiency,current,current,909,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2437,energy efficiency,Adapt,Adapt,2437,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2468,energy efficiency,model,model,2468,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2481,energy efficiency,Adapt,Adapt,2481,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2487,energy efficiency,heat,heatmap,2487,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2505,energy efficiency,model,model,2505,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2518,energy efficiency,Adapt,Adapt,2518,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2548,energy efficiency,model,model,2548,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1309,integrability,filter,filter,1309,"been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.github",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1410,integrability,filter,filter,1410,"the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2437,integrability,Adapt,Adapt,2437,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2481,integrability,Adapt,Adapt,2481,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2518,integrability,Adapt,Adapt,2518,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2437,interoperability,Adapt,Adapt,2437,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2481,interoperability,Adapt,Adapt,2481,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2518,interoperability,Adapt,Adapt,2518,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:620,modifiability,paramet,parameter,620,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:672,modifiability,paramet,parameter,672,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:818,modifiability,paramet,parameters,818,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1701,modifiability,paramet,parameters,1701,"ps` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2437,modifiability,Adapt,Adapt,2437,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2481,modifiability,Adapt,Adapt,2481,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2518,modifiability,Adapt,Adapt,2518,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:760,safety,updat,update,760,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:799,safety,avoid,avoid,799,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1641,safety,log,logfoldchange,1641,"core and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1832,safety,Updat,Update,1832,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2189,safety,log,log,2189,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2665,safety,Updat,Update,2665,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2690,safety,Updat,Update,2690,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2697,safety,test,tests,2697,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2710,safety,Updat,Update,2710,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:760,security,updat,update,760,"[WIP] Dotplot (aka bubble plot) improvements; This PR addresses issues from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1641,security,log,logfoldchange,1641,"core and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1832,security,Updat,Update,1832,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2189,security,log,log,2189,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2468,security,model,model,2468,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2505,security,model,model,2505,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2548,security,model,model,2548,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2573,security,modif,modifications,2573,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2665,security,Updat,Update,2665,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2690,security,Updat,Update,2690,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2710,security,Updat,Update,2710,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1641,testability,log,logfoldchange,1641,"core and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2189,testability,log,log,2189,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2697,testability,test,tests,2697,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1064,usability,user,user-images,1064," from #562 #1103. Here is a list of changes for `sc.pl.dotplot` and also for `sc.pl.rank_genes_groups_dotplot`:. * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1175,usability,user,user-images,1175,". * Colorbar and dot size legends had been improved. Now is also possible to set a title for them. * The dotplot functionality has been separated from the main function. This allows to take any two pandas dataFrames, one containing the color values and other containing the size to be plotted. * A new dotplot style is added, in which a background square is colored according to the colormap instead of the dot. The style can be chosen as parameter. * Now p-values, score and in general any parameter from `sc.rank_genes_groups` can be plotted. * `swap_axes` has been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:1752,usability,feedback,feedback,1752,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/pull/1127:2294,usability,user,user-images,2294,"s been added. * **update**: method chaining was added to avoid explosion of parameters as suggested in #956. The caveat is that a different name is needed to keep the current functionality of `sc.pl.dotplot`. Now is possible to do `sc.pl.DotPlot(adata, ....).add_dendrogram(size=1.2).swap_axes().show()`. ![image](https://user-images.githubusercontent.com/4964309/77526545-13ce0600-6e8b-11ea-996a-3d548f52f200.png). ![image](https://user-images.githubusercontent.com/4964309/77529251-8c36c600-6e8f-11ea-8446-c1dd18374cd4.png). Open issues:. * we need a better way to filter the output from rank_genes_groups (and I would also consider a better name). One option is to filter while plotting. * to correctly plot the results from `sc.tl.rank_genes_groups` is better to report the results for all genes (`n_genes`). The default is to keep the top 100 genes per group. Thus, for many genes, the pvalue, logfoldchange etc in other groups is not saved. * added new parameters, for some I would be happy to have some feedback. One is `style` that has two options `square color` and `dot color`. **Update**. The following is now possible (notice the method chaining):. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], 'B-cell': ['CD79A', 'CD79B', 'MS4A1'], 'myeloid': ['CST3', 'LYZ']}. sc.pl.DotPlot(adata, markers, groupby='bulk_labels') \. .add_totals(sort='descending', size=1.2) \. .legend(color_title='log(UMI count+1)', width=1.6)\. .style(color_map='RdBu_r', dot_min=0.3)\. .show(). ```. ![image](https://user-images.githubusercontent.com/4964309/77777939-889e6d00-7050-11ea-842e-cf2a11739df6.png). TODO:. - [x] Remove small secondary ticks. - [x] Adapt matrixplot to new object model. - [ ] Adapt heatmap to object model. - [x] Adapt stackedviolin to object model. - [ ] Incorporate modifications from #1116 . - [x] Fix call from rank_genes_groups. - [x] 'black' code. - [x] Update docstrings. - [ ] Update tests. - [ ] Update tutorial and readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1127
https://github.com/scverse/scanpy/issues/1128:60,deployability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,integrability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:100,integrability,coupl,couple,100,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:892,integrability,compon,components,892,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,interoperability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:892,interoperability,compon,components,892,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,modifiability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:100,modifiability,coupl,couple,100,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:892,modifiability,compon,components,892,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,reliability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:597,reliability,doe,does,597,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,security,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:392,security,modif,modified,392,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:735,security,modif,modified,735,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:774,security,modif,modifications,774,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:60,testability,integr,integrate,60,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/issues/1128:100,testability,coupl,couple,100,"Issues with ingest; Hi all,. I am trying to use `ingest` to integrate different datasets. I found a couple of issues. - `ingest` requires that the `var_names` are the same in the reference and the new object. I can select the intersection between the datasets; however, it requires that the genes are in the same order `if not ref_var_names.equals(new_var_names)`. I think this `if` could be modified using `set` (e.g., `len(set(ref_var_names).difference(set(new_var_names))) == 0`). I tried to order the `.var` dataframe, but the `.X` remains the same. In such a way, the expression of the genes does not correspond to the correct one. I can generate a dataframe and recreate the `.X`, but it could be very nice that the `.X` will be modified according to `.var` or `.obs` modifications (i.e., ordering). . - although it is possible to set `embedding_method=umap`, `ingest` requires the PCA components. I used autoencoders instead of PCA, and I cannot run `ingest` only considering the UMAP. Can you fix it? . Thank you in advance. Best,. Andrea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1128
https://github.com/scverse/scanpy/pull/1130:35,availability,down,downloading,35,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2368,availability,down,download,2368,"f2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See htt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2499,availability,down,download,2499,"backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:143,deployability,instal,installed,143,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:198,deployability,modul,module,198,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:224,deployability,depend,dependency,224,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:888,deployability,modul,module,888,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2994,deployability,contain,container,2994,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3326,deployability,updat,update,3326,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3460,deployability,updat,update,3460,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:224,integrability,depend,dependency,224,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1274,integrability,filter,filter,1274,". sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:198,modifiability,modul,module,198,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:224,modifiability,depend,dependency,224,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:495,modifiability,pac,packages,495,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:888,modifiability,modul,module,888,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:979,modifiability,pac,packages,979,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1456,modifiability,pac,packages,1456,"nvs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1860,modifiability,pac,packages,1860,"put-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2230,modifiability,pac,packages,2230,"ues.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameErr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2467,modifiability,pac,packages,2467,"/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2779,modifiability,pac,packages,2779,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3148,modifiability,pac,packages,3148,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1566,performance,cach,cache,1566,"e: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:1971,performance,cach,cache,1971,"site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:205,reliability,doe,does,205,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:198,safety,modul,module,198,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:224,safety,depend,dependency,224,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:766,safety,except,exception,766,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:785,safety,except,exception,785,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:862,safety,input,input-,862,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:888,safety,modul,module,888,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3220,safety,except,except,3220,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3326,safety,updat,update,3326,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3460,safety,updat,update,3460,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3326,security,updat,update,3326,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:3460,security,updat,update,3460,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:224,testability,depend,dependency,224,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:412,testability,Trace,Traceback,412,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:818,testability,Trace,Traceback,818,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:2596,testability,unit,unit,2596,"url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning, **kwargs). 489 else:. 490 ext = is_valid_filename(filename, return_ext=True). --> 491 is_present = check_datafile_present_and_download(. 492 filename,. 493 backup_url=backup_url,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in check_datafile_present_and_download(path, backup_url). 745 path.parent.mkdir(parents=True). 746 . --> 747 download(backup_url, path). 748 return True. 749 . ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in download(url, path). 722 . 723 path.parent.mkdir(parents=True, exist_ok=True). --> 724 with tqdm(unit='B', unit_scale=True, miniters=1, desc=path.name) as t:. 725 def update_to(b=1, bsize=1, tsize=None):. 726 if tsize is not None:. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in __init__(self, *args, **kwargs). 206 unit_scale = 1 if self.unit_scale is True else self.unit_scale or 1. 207 total = self.total * unit_scale if self.total else self.total. --> 208 self.container = self.status_printer(. 209 self.fp, total, self.desc, self.ncols). 210 self.sp = self.display. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 101 except NameError:. 102 # #187 #451 #558. --> 103 raise ImportError(. 104 ""FloatProgress not found. Please update jupyter and ipywidgets."". 105 "" See https://ipywidgets.readthedocs.io/en/stable"". ImportError: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:67,usability,progress,progress,67,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:160,usability,progress,progressbar,160,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:612,usability,progress,progress,612,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:626,usability,statu,status,626,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/pull/1130:862,usability,input,input-,862,"Use tqdm instead of tqdm.auto when downloading datasets; Using the progress bar from tqdm.auto causes a `ImportError` when `ipywidgets` is not installed. . The progressbar from the top level `tqdm` module does not have this dependency. . Repex: . ```python. import scanpy as sc. sc.datasets.moignard15(). ```. Output: . ```. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/tqdm/notebook.py in status_printer(_, total, desc, ncols). 97 else: # No total? Show info style bar with no progress tqdm status. ---> 98 pbar = IProgress(min=0, max=1). 99 pbar.value = 1. NameError: name 'IProgress' is not defined. During handling of the above exception, another exception occurred:. ImportError Traceback (most recent call last). <ipython-input-5-ec5b1e8cd660> in <module>. ----> 1 sc.datasets.moignard15(). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/datasets/__init__.py in moignard15(). 108 filename = settings.datasetdir / 'moignard15/nbt.3154-S3.xlsx'. 109 backup_url = 'http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx'. --> 110 adata = sc.read(filename, sheet='dCt_values.txt', backup_url=backup_url). 111 # filter out 4 genes as in Haghverdi et al. (2016). 112 gene_subset = ~np.in1d(adata.var_names, ['Eif2b1', 'Mrpl19', 'Polr2a', 'Ubc']). ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, **kwargs). 92 filename = Path(filename) # allow passing strings. 93 if is_valid_filename(filename):. ---> 94 return _read(. 95 filename, backed=backed, sheet=sheet, ext=ext,. 96 delimiter=delimiter, first_column_names=first_column_names,. ~/anaconda3/envs/test_scanpy/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, suppress_cache_warning",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1130
https://github.com/scverse/scanpy/issues/1131:41,availability,failur,failures,41,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:424,availability,error,error,424,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5400,availability,error,error,5400,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5709,availability,error,error,5709,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:41,deployability,fail,failures,41,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:266,deployability,Fail,Failed,266,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1124,deployability,Fail,Failed,1124,"ts.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1257,deployability,Fail,Failed,1257,"rror: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1569,deployability,modul,module,1569,"is, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2423,deployability,Version,Versions,2423,"n was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3235,deployability,Version,Versions,3235,"ttribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4047,deployability,Version,Versions,4047,"e in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4859,deployability,Version,Versions,4859,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5551,deployability,Fail,Failed,5551,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2423,integrability,Version,Versions,2423,"n was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2466,integrability,wrap,wrapper,2466,"eption:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3235,integrability,Version,Versions,3235,"ttribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3278,integrability,wrap,wrapper,3278,"s=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4047,integrability,Version,Versions,4047,"e in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4090,integrability,wrap,wrapper,4090,"e(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4859,integrability,Version,Versions,4859,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4902,integrability,wrap,wrapper,4902,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2466,interoperability,wrapper,wrapper,2466,"eption:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3278,interoperability,wrapper,wrapper,3278,"s=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4090,interoperability,wrapper,wrapper,4090,"e(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4902,interoperability,wrapper,wrapper,4902,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1569,modifiability,modul,module,1569,"is, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2169,modifiability,layer,layers,2169,"a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2184,modifiability,layer,layers,2184,"pe {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Ce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:2423,modifiability,Version,Versions,2423,"n was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:3235,modifiability,Version,Versions,3235,"ttribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4047,modifiability,Version,Versions,4047,"e in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:4859,modifiability,Version,Versions,4859,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:41,performance,failur,failures,41,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:424,performance,error,error,424,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:613,performance,disk,disk,613,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5400,performance,error,error,5400,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5709,performance,error,error,5709,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:41,reliability,fail,failures,41,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:266,reliability,Fail,Failed,266,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1124,reliability,Fail,Failed,1124,"ts.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1257,reliability,Fail,Failed,1257,"rror: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5551,reliability,Fail,Failed,5551,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:424,safety,error,error,424,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:964,safety,except,except,964,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:971,safety,Except,Exception,971,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1419,safety,except,exception,1419,"error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/V",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1467,safety,except,exception,1467,"random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1543,safety,input,input-,1543,"we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1569,safety,modul,module,1569,"is, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5400,safety,error,error,5400,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5709,safety,error,error,5709,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:645,testability,trace,traceback,645,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:773,testability,Trace,Traceback,773,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1499,testability,Trace,Traceback,1499,"l.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positiona",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:424,usability,error,error,424,"Passing a RandomState instance can cause failures to save; ```python. import scanpy as sc. import numpy as np. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). pbmc.write(""tmp.h5ad'). ```. ```pytb. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. It looks like we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:1543,usability,input,input-,1543,"we'll have to not write this, or figure out how to represent it on disk. <details>. <summary> Full traceback </summary>. ```pytb. ---------------------------------------------------------------------------. NotImplementedError Traceback (most recent call last). ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 187 try:. --> 188 return func(elem, key, val, *args, **kwargs). 189 except Exception as e:. ~/github/anndata/anndata/_io/h5ad.py in write_not_implemented(f, key, value, dataset_kwargs). 144 raise NotImplementedError(. --> 145 f""Failed to write value for {key}, "". 146 f""since a writer for type {type(value)} has not been implemented yet."". NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. The above exception was the direct cause of the following exception:. NotImplementedError Traceback (most recent call last). <ipython-input-2-1dd6b1c7e996> in <module>. 4 pbmc = sc.datasets.pbmc68k_reduced(). 5 sc.tl.umap(pbmc, random_state=np.random.RandomState(10)). ----> 6 pbmc.write(""tmp.h5ad""). ~/github/anndata/anndata/_core/anndata.py in write_h5ad(self, filename, compression, compression_opts, force_dense, as_dense). 1988 compression_opts=compression_opts,. 1989 force_dense=force_dense,. -> 1990 as_dense=as_dense,. 1991 ). 1992 . ~/github/anndata/anndata/_io/h5ad.py in write_h5ad(filepath, adata, force_dense, as_dense, dataset_kwargs, **kwargs). 110 write_attribute(f, ""varp"", adata.varp, dataset_kwargs=dataset_kwargs). 111 write_attribute(f, ""layers"", adata.layers, dataset_kwargs=dataset_kwargs). --> 112 write_attribute(f, ""uns"", adata.uns, dataset_kwargs=dataset_kwargs). 113 if adata.isbacked:. 114 adata.file.open(filepath, ""r+""). /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5400,usability,error,error,5400,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/issues/1131:5709,usability,error,error,5709,"ype({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/h5ad.py in write_mapping(f, key, value, dataset_kwargs). 284 def write_mapping(f, key, value, dataset_kwargs=MappingProxyType({})):. 285 for sub_key, sub_value in value.items():. --> 286 write_attribute(f, f""{key}/{sub_key}"", sub_value, dataset_kwargs=dataset_kwargs). 287 . 288 . /usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/functools.py in wrapper(*args, **kw). 838 '1 positional argument'). 839 . --> 840 return dispatch(args[0].__class__)(*args, **kw). 841 . 842 funcname = getattr(func, '__name__', 'singledispatch function'). ~/github/anndata/anndata/_io/h5ad.py in write_attribute_h5ad(f, key, value, *args, **kwargs). 124 if key in f:. 125 del f[key]. --> 126 _write_method(type(value))(f, key, value, *args, **kwargs). 127 . 128 . ~/github/anndata/anndata/_io/utils.py in func_wrapper(elem, key, val, *args, **kwargs). 193 f""Above error raised while writing key {key!r} of {type(elem)}"". 194 f"" from {parent}."". --> 195 ) from e. 196 . 197 return func_wrapper. NotImplementedError: Failed to write value for uns/umap/params/random_state, since a writer for type <class 'numpy.random.mtrand.RandomState'> has not been implemented yet. Above error raised while writing key 'uns/umap/params/random_state' of <class 'h5py._hl.files.File'> from /. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1131
https://github.com/scverse/scanpy/pull/1132:171,interoperability,specif,specifying,171,More flexible umap; This PR lets user choose the connectivity matrix passed to UMAP for layout. Two arguments have been added to the umap function for this:. * `obsp` for specifying the connectivity matrix in `obsp`. * `key_added` for choosing the key name in `obsm`. Still need to reorganize the arguments for `sc.tl.umap` so the more used ones are documented first.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1132
https://github.com/scverse/scanpy/pull/1132:33,usability,user,user,33,More flexible umap; This PR lets user choose the connectivity matrix passed to UMAP for layout. Two arguments have been added to the umap function for this:. * `obsp` for specifying the connectivity matrix in `obsp`. * `key_added` for choosing the key name in `obsm`. Still need to reorganize the arguments for `sc.tl.umap` so the more used ones are documented first.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1132
https://github.com/scverse/scanpy/pull/1132:350,usability,document,documented,350,More flexible umap; This PR lets user choose the connectivity matrix passed to UMAP for layout. Two arguments have been added to the umap function for this:. * `obsp` for specifying the connectivity matrix in `obsp`. * `key_added` for choosing the key name in `obsm`. Still need to reorganize the arguments for `sc.tl.umap` so the more used ones are documented first.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1132
https://github.com/scverse/scanpy/issues/1133:753,availability,cluster,cluster,753,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:753,deployability,cluster,cluster,753,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:269,energy efficiency,heat,heatmap,269,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:43,integrability,transform,transformed,43,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:43,interoperability,transform,transformed,43,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:136,performance,perform,performs,136,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:490,performance,perform,perform,490,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:651,reliability,doe,does,651,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:763,safety,input,input,763,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:136,usability,perform,performs,136,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:490,usability,perform,perform,490,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:763,usability,input,input,763,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1133:803,usability,help,help,803,"PAGA connectivity score; Hi. I am recently transformed Seurat object to scanpy and use it for further pseudotime analysis (PAGA) and it performs really well. . But I have three question here:. 1) I am wondering if anybody here knows how to make PAGA connectivity score heatmap (ref: Popescu et al, 2019, Nature) which shows connections strength between partitions. I've tried dendrogram in scanpy (pl.coorelation.matrix) but we'd like to try more. . 2) And also if anyone knows if we could perform differential expression on the partitions by PAGA to find the marker gene along the potential path? 3) PAGA generated a pie chart in every partition But does anyone know whether I could acquire the real percentage of the pie representing different Seurat cluster I input? Thanks in advance for everyone's help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1133
https://github.com/scverse/scanpy/issues/1134:24,availability,consist,consistent,24,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:115,availability,cluster,cluster,115,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:140,availability,consist,consistent,140,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:156,availability,cluster,cluster,156,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:220,availability,cluster,clusters,220,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:549,availability,cluster,clusters,549,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:700,availability,cluster,clusters,700,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:885,availability,cluster,cluster,885,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:115,deployability,cluster,cluster,115,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:156,deployability,cluster,cluster,156,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:220,deployability,cluster,clusters,220,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:549,deployability,cluster,clusters,549,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:700,deployability,cluster,clusters,700,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:885,deployability,cluster,cluster,885,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:41,integrability,sub,subsetting,41,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:91,integrability,sub,subsetting,91,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:411,integrability,sub,subplots,411,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:24,usability,consist,consistent,24,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:140,usability,consist,consistent,140,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:290,usability,user,user-images,290,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/issues/1134:784,usability,user,user-images,784,"Color palette should be consistent after subsetting (with multiple axes per figure); After subsetting the anndata, cluster colors should be consistent with cluster class. . ```python. sc.pl.umap(adata_spatial, color = [""clusters""], palette=sc.pl.palettes.default_28). ```. ![image](https://user-images.githubusercontent.com/25887487/77832090-c2946f80-7133-11ea-8ec1-f8011a2d4c19.png). ```python. fig, axs = plt.subplots(1,2, figsize=(8,5)). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Anterior"", :], . color=""clusters"", . show = False,. ax = axs[0]). sc.pl.umap(. adata_spatial[adata_spatial.obs.library_id == ""V1_Mouse_Brain_Sagittal_Posterior"", :], . color=""clusters"", . show = False,. ax = axs[1]). plt.tight_layout(). ```. ![image](https://user-images.githubusercontent.com/25887487/77832119-f5d6fe80-7133-11ea-95bb-9e1ed9eea1cd.png). Maybe cluster colors should be stored as dictionary with class labels as keys? Or is there another way to achieve this that I am not familiar with ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1134
https://github.com/scverse/scanpy/pull/1135:51,deployability,scale,scale,51,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:136,deployability,scale,scaled,136,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:51,energy efficiency,scale,scale,51,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:136,energy efficiency,scale,scaled,136,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:424,interoperability,format,formats,424,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:51,modifiability,scal,scale,51,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:136,modifiability,scal,scaled,136,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:51,performance,scale,scale,51,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:136,performance,scale,scaled,136,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:273,testability,simpl,simplify,273,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/pull/1135:273,usability,simpl,simplify,273,"Store mean and std in annotations when calling `pp.scale`, only accept AnnData; This should allow people to reconstruct count data from scaled values. Moving away from accepting numpy arrrays and sparse matrices in the preprocessing functions has always been on my mind to simplify the code. Nobody is passing anything different from an AnnData. In the very early days of Scanpy, I thought it'd be nice to also accept other formats of data matrices.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1135
https://github.com/scverse/scanpy/issues/1136:262,availability,Error,Error,262,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:14,deployability,instal,installed,14,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:362,deployability,Version,Versions,362,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:395,deployability,log,logging,395,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:362,integrability,Version,Versions,362,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:362,modifiability,Version,Versions,362,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:262,performance,Error,Error,262,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:262,safety,Error,Error,262,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:395,safety,log,logging,395,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:395,security,log,logging,395,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:395,testability,log,logging,395,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:75,usability,clear,clear,75,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:145,usability,minim,minimal,145,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/issues/1136:262,usability,Error,Error,262,"Scanpy cant't installed in two environment in anaconda; <!-- Please give a clear and concise description of what the bug is: -->. ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1136
https://github.com/scverse/scanpy/pull/1137:79,safety,test,tests,79,change uns structure for spatial (#1105); Fix uns structure in read visium and tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1137
https://github.com/scverse/scanpy/pull/1137:79,testability,test,tests,79,change uns structure for spatial (#1105); Fix uns structure in read visium and tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1137
https://github.com/scverse/scanpy/pull/1138:141,availability,state,state,141,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:152,deployability,manag,managed,152,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:377,deployability,contain,contains,377,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:152,energy efficiency,manag,managed,152,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:141,integrability,state,state,141,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:152,safety,manag,managed,152,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/pull/1138:299,usability,close,close,299,"fix uns structure in read_visium; Hi @ivirshup, so I made a mistake with squash and rebase and basically had all the history in a pretty bad state. . I managed to revert everything to the first squash, and this should be it. This PR is essentially #1105, but with correct history. Also, this should close the scanpy/spatial branch, which should NOT be merged since that branch contains the messed up history after the rebase. Sorry again for that...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1138
https://github.com/scverse/scanpy/issues/1139:608,availability,error,error,608,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:0,interoperability,Incompatib,Incompatible,0,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:134,modifiability,paramet,parameters,134,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:608,performance,error,error,608,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:580,reliability,doe,doesn,580,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:608,safety,error,error,608,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/issues/1139:608,usability,error,error,608,"Incompatible function get.rank_genes_groups_df ; <!-- What kind of feature would you like to request? -->. - [ x] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. ... It happened to me that when I use the function `sc.tl.rank_genes_groups(adata, groupby='groups_r0.2', key_added='rank_genes_r0.2')` the key `rank_genes_r0.2` is added to the attribute `.uns`. However, when I want to extract the coloumn `groups_r0.2` using the function `sc.get.rank_genes_groups_df(adata, group=""0"",key='rank_genes_r0.2')` it doesn't work because of the error in ` d[k] = adata.uns[""rank_genes_groups""][k][group]` the suggestion is to change the `rank_genes_groups` to `key`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1139
https://github.com/scverse/scanpy/pull/1140:4,availability,robust,robust,4,add robust installation instructions again; These were removed in https://github.com/theislab/scanpy/commit/fddb710258b816629f8c8feb9c01f2b75b8a6ebf#diff-548eb9ce4cac8e13a1238ad703272931.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140
https://github.com/scverse/scanpy/pull/1140:11,deployability,instal,installation,11,add robust installation instructions again; These were removed in https://github.com/theislab/scanpy/commit/fddb710258b816629f8c8feb9c01f2b75b8a6ebf#diff-548eb9ce4cac8e13a1238ad703272931.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140
https://github.com/scverse/scanpy/pull/1140:4,reliability,robust,robust,4,add robust installation instructions again; These were removed in https://github.com/theislab/scanpy/commit/fddb710258b816629f8c8feb9c01f2b75b8a6ebf#diff-548eb9ce4cac8e13a1238ad703272931.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140
https://github.com/scverse/scanpy/pull/1140:4,safety,robust,robust,4,add robust installation instructions again; These were removed in https://github.com/theislab/scanpy/commit/fddb710258b816629f8c8feb9c01f2b75b8a6ebf#diff-548eb9ce4cac8e13a1238ad703272931.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1140
https://github.com/scverse/scanpy/issues/1141:180,availability,cluster,clusters,180,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:536,availability,sli,slightly,536,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:180,deployability,cluster,clusters,180,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1787,deployability,Version,Versions,1787,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:45,integrability,sub,subsets,45,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:125,integrability,sub,subsetted,125,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:282,integrability,sub,subsets,282,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:416,integrability,sub,subsets,416,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1787,integrability,Version,Versions,1787,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1787,modifiability,Version,Versions,1787,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:536,reliability,sli,slightly,536,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:348,security,ident,identical,348,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:251,usability,behavi,behaving,251,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:623,usability,guidanc,guidance,623,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:891,usability,user,user-images,891,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1182,usability,user,user-images,1182,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1423,usability,user,user-images,1423,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1687,usability,user,user-images,1687,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1141:1894,usability,learn,learn,1894,"Distorted UMAP aspect ratio in certain adata subsets; Hi,. I seem to be running into a problem where UMAP projections for my subsetted adata appear distorted, but only for certain clusters. I'm not sure if this is actually a bug or if the function is behaving properly. Oddly, some subsets appear 'undistorted' such that their UMAP projections are identical to that of the original unsubsetted adata. However, other subsets appear distorted compared to the original unsubsetted adata, such that their aspect ratios seem to have changed slightly. Please see below. Is this a bug or am I not passing the correct options? Any guidance would be greatly appreciated, and my apologies if this belongs in the community thread. ## Distorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['2','3','4','5','6','7','8','9'])`. ![image](https://user-images.githubusercontent.com/56206488/78223316-49c34980-748c-11ea-8f96-171c39444d87.png). `ec = adata[adata.obs['louvain_r0.8_sub1'].isin(['2','3','4','5','6','7','8','9']),:].copy()`. `sc.pl.umap(ec, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223415-711a1680-748c-11ea-8a02-b02c5701d911.png). ## Undistorted example ##. `sc.pl.umap(adata, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy, groups=['11'])`. ![image](https://user-images.githubusercontent.com/56206488/78223506-9a3aa700-748c-11ea-9608-f4fa8ba4e34c.png). `tc = adata[adata.obs['louvain_r0.8_sub1'].isin(['11']),:].copy()`. `sc.pl.umap(tc, color='louvain_r0.8_sub1', palette=sc.pl.palettes.vega_20_scanpy)`. ![image](https://user-images.githubusercontent.com/56206488/78223568-b9d1cf80-748c-11ea-93f8-0d0e9138f0bf.png). #### Versions:. scanpy==1.4.4.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.3.0 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Best,. Seth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1141
https://github.com/scverse/scanpy/issues/1142:987,availability,error,error,987,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1682,availability,error,error,1682,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:18,deployability,instal,installation,18,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:233,deployability,instal,install,233,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:341,deployability,fail,failed,341,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:426,deployability,fail,failed,426,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:585,deployability,fail,failed,585,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:779,deployability,fail,failed,779,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:931,deployability,instal,installed,931,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1143,deployability,fail,failed,1143,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1228,deployability,fail,failed,1228,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1387,deployability,fail,failed,1387,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1581,deployability,fail,failed,1581,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1842,deployability,instal,installed,1842,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1979,deployability,instal,installed,1979,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:679,interoperability,conflict,conflicts,679,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:702,interoperability,incompatib,incompatible,702,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:821,interoperability,specif,specifications,821,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:853,interoperability,incompatib,incompatible,853,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1481,interoperability,conflict,conflicts,1481,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1504,interoperability,incompatib,incompatible,1504,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1733,interoperability,specif,specifications,1733,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1765,interoperability,incompatib,incompatible,1765,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:272,modifiability,pac,package,272,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:524,modifiability,pac,package,524,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:715,modifiability,pac,packages,715,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1074,modifiability,pac,package,1074,"culation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1326,modifiability,pac,package,1326,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1517,modifiability,pac,packages,1517,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:987,performance,error,error,987,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1015,performance,time,time,1015," installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1682,performance,error,error,1682,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:341,reliability,fail,failed,341,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:426,reliability,fail,failed,426,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:585,reliability,fail,failed,585,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:779,reliability,fail,failed,779,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1143,reliability,fail,failed,1143,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1228,reliability,fail,failed,1228,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1387,reliability,fail,failed,1387,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1581,reliability,fail,failed,1581,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:987,safety,error,error,987,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1682,safety,error,error,1682,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:2041,safety,compl,completely,2041,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:2041,security,compl,completely,2041,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:987,usability,error,error,987,"Issues with conda installation; So this is possibly related to #1136 (pure speculation  ). Basically, on a Vm with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1142:1682,usability,error,error,1682,"with ubuntu 18:. ```. conda create -n temp_env_scanpy. conda activate temp_env_scanpy. (temp_env_scanpy) giov@vm:~$ conda install -c bioconda scanpy. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: -. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/linux-64::__cuda==9.1=0. Your installed CUDA driver is: 9.1. ```. Interestingly, this error is not thrown all the time, e.g. in a VM centos 7 without cuda:. ```. Collecting package metadata (current_repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: failed with initial frozen solve. Retrying with flexible solve. Solving environment: \. Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed. UnsatisfiableError:. ```. Another student working with me had the same issue in windows. His error was:. ```. UnsatisfiableError: The following specifications were found to be incompatible with your CUDA driver:. - feature:/win-64::__cuda==10.2=0. Your installed CUDA driver is: 10.2. ```. But on a mac, no problem at all. In all situations, I have at least another environment with scanpy installed. In all cases, conda was `4.8.3`. I cannot rule out completely the possibility that my conda in those 2 vms are messed up.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1142
https://github.com/scverse/scanpy/issues/1143:366,availability,error,error,366,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1201,availability,Error,Error,1201,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:187,deployability,version,version,187,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:232,deployability,version,version,232,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:720,deployability,version,versions,720,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1283,deployability,Version,Versions,1283,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1316,deployability,log,logging,1316,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:187,integrability,version,version,187,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:232,integrability,version,version,232,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:720,integrability,version,versions,720,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:836,integrability,batch,batch,836,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:885,integrability,batch,batch,885,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:984,integrability,batch,batch,984,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1086,integrability,batch,batch,1086,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1283,integrability,Version,Versions,1283,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:878,interoperability,format,format,878,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:977,interoperability,format,format,977,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1079,interoperability,format,format,1079,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:187,modifiability,version,version,187,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:232,modifiability,version,version,232,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:486,modifiability,pac,packages,486,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:720,modifiability,version,versions,720,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1283,modifiability,Version,Versions,1283,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:366,performance,error,error,366,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:836,performance,batch,batch,836,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:885,performance,batch,batch,885,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:984,performance,batch,batch,984,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1086,performance,batch,batch,1086,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1201,performance,Error,Error,1201,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:366,safety,error,error,366,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1201,safety,Error,Error,1201,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1316,safety,log,logging,1316,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1316,security,log,logging,1316,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:0,testability,Assert,AssertionError,0,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:383,testability,Assert,AssertionError,383,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1316,testability,log,logging,1316,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:92,usability,clear,clear,92,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:366,usability,error,error,366,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:451,usability,USER,USER,451,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:742,usability,minim,minimal,742,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1143:1201,usability,Error,Error,1201,"AssertionError: Sizes of partitioned, $174.6 do not match on .../_qc.py; <!-- Please give a clear and concise description of what the bug is: -->. Running Python 3.7 on Jupyter lab, with version 1.4.6 and also with 1.4.4.post1 (the version my friend can successfully run). When creating an AnnData object, and trying to run calculate_qc_metrics, I get the following error:. ```pytb. AssertionError: Sizes of partitioned, $174.6 do not match on /home/$USER/miniconda3/lib/python3.7/site-packages/scanpy/preprocessing/_qc.py (397). ```. What I find most interesting, is that the adata.X object is a **CSR** matrix, whereas for my friend whose code works, adata.X is a **SparseCSRView**. Why is this the case? (same scanpy versions). <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. batch='pool1'. adata = sc.read_mtx(folder.format(batch)+'matrix.mtx'). adata = adata.transpose(). adata.obs['barcodes'] = pd.read_csv(folder.format(batch)+'barcodes.tsv', sep = '\t', header = None).values. adata.var_names = pd.read_csv(folder.format(batch)+'features.tsv', sep = '\t', header = None)[0].values. sc.pp.calculate_qc_metrics(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ... **EDIT: Creating another environment with Python 3.6.1 fixes the issue... What could be wrong?**",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1143
https://github.com/scverse/scanpy/issues/1144:282,availability,error,error,282,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:423,availability,error,error,423,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:558,availability,error,error,558,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:597,availability,error,error,597,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:54,deployability,build,builds,54,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:117,deployability,build,builds,117,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:251,deployability,fail,failing,251,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:334,deployability,build,builds,334,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:416,deployability,build,builds,416,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:401,energy efficiency,current,current,401,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:282,performance,error,error,282,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:423,performance,error,error,423,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:558,performance,error,error,558,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:597,performance,error,error,597,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:251,reliability,fail,failing,251,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:448,reliability,doe,does,448,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:282,safety,error,error,282,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:423,safety,error,error,423,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:558,safety,error,error,558,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:597,safety,error,error,597,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:282,usability,error,error,282,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:423,usability,error,error,423,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:558,usability,error,error,558,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1144:597,usability,error,error,597,"Better CI for docs; @flying-sheep @falexwolf . . [Doc builds are broken](https://readthedocs.com/projects/icb-scanpy/builds/310089/) ... again. This really has to be part of the CI process. It should be implemented in a way where the CI marks a PR as failing if read the docs would error. I see two options:. * Get the readthedocs CI builds (which we can ask them about). * Figure out how to make our current travis builds error like read the docs does. @giovp I don't believe you can mark keys within a dictionary as attributes. I think that's causing this error:. ```python. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/readwrite.py:docstring of scanpy.read_visium:38:py:attr reference target not found: anndata.AnnData.uns['spatial']['library_id']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1144
https://github.com/scverse/scanpy/issues/1146:96,availability,sli,slightly,96,"Conda doesn't have scanpy>=1.4.5?; https://bioconda.github.io/recipes/scanpy/README.html. Also, slightly related but it seems like Rapids has dropped pip support.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146
https://github.com/scverse/scanpy/issues/1146:6,reliability,doe,doesn,6,"Conda doesn't have scanpy>=1.4.5?; https://bioconda.github.io/recipes/scanpy/README.html. Also, slightly related but it seems like Rapids has dropped pip support.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146
https://github.com/scverse/scanpy/issues/1146:96,reliability,sli,slightly,96,"Conda doesn't have scanpy>=1.4.5?; https://bioconda.github.io/recipes/scanpy/README.html. Also, slightly related but it seems like Rapids has dropped pip support.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146
https://github.com/scverse/scanpy/issues/1146:154,usability,support,support,154,"Conda doesn't have scanpy>=1.4.5?; https://bioconda.github.io/recipes/scanpy/README.html. Also, slightly related but it seems like Rapids has dropped pip support.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1146
https://github.com/scverse/scanpy/issues/1147:35,availability,Error,Error,35,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:280,availability,error,error,280,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:490,availability,down,down,490,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1015,availability,Error,Error,1015,"_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1262,availability,error,errors,1262," 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2616,availability,state,state,2616,"nst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2751,availability,state,state,2751," _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3050,availability,state,state,3050,"ody(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3070,availability,state,state,3070," typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3164,availability,state,state,3164,". -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3333,availability,state,state,3333,"rom, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3424,availability,state,state,3424,"ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4142,availability,state,state,4142,"ry.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4229,availability,state,state,4229,"aise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During hand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4251,availability,state,state,4251,". 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4334,availability,state,state,4334,"e). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4952,availability,error,error,4952," 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5090,availability,error,error,5090,"packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5115,availability,error,error,5115,"es.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6843,availability,error,errors,6843,"ayer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.Typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7367,availability,error,errors,7367,"ib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7833,availability,error,errors,7833,"except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8127,availability,error,error,8127,", **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8624,availability,state,state,8624," if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8652,availability,state,state,8652,"l. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8891,availability,state,state,8891,"naconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9066,availability,state,state,9066,"9 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9180,availability,avail,available,9180,"not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9331,availability,state,state,9331,"pe, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9351,availability,state,state,9351,"ibrary, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9456,availability,state,state,9456,"ype, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9698,availability,state,state,9698,"mpile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (Tru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9840,availability,state,state,9840,"ompile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10853,availability,state,state,10853,":. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10946,availability,state,state,10946,"r_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10968,availability,state,state,10968,"compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11014,availability,state,state,11014,"_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11034,availability,state,state,11034," **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11117,availability,state,state,11117,"e_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_contex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12561,availability,error,errors,12561,"naconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13111,availability,error,error,13111,"context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13136,availability,error,error,13136,""" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2394,deployability,pipelin,pipeline,2394,"es\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4185,deployability,pipelin,pipeline,4185,"tion = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4514,deployability,Modul,Module,4514,"ock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4562,deployability,modul,module,4562,"urn func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4846,deployability,modul,module,4846," finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5010,deployability,Fail,Failed,5010,"unc(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 fo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5034,deployability,pipelin,pipeline,5034,"if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(perce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5375,deployability,modul,module,5375,"r.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8383,deployability,pipelin,pipeline,8383,"rg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8495,deployability,pipelin,pipeline,8495,"eturn_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9190,deployability,pipelin,pipelines,9190,"nd not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10902,deployability,pipelin,pipeline,10902,"~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11927,deployability,build,builder,11927,"ing().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12967,deployability,Fail,Failed,12967,"ower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12991,deployability,pipelin,pipeline,12991,"275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13031,deployability,Fail,Failed,13031,"site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13055,deployability,pipelin,pipeline,13055,"ing.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14339,deployability,instal,installing,14339,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14405,deployability,instal,installing,14405,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14434,deployability,Version,Versions,14434,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14467,deployability,log,logging,14467,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2394,integrability,pipelin,pipeline,2394,"es\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2616,integrability,state,state,2616,"nst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2751,integrability,state,state,2751," _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3050,integrability,state,state,3050,"ody(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3070,integrability,state,state,3070," typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3164,integrability,state,state,3164,". -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3333,integrability,state,state,3333,"rom, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, st",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3424,integrability,state,state,3424,"ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4142,integrability,state,state,4142,"ry.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4185,integrability,pipelin,pipeline,4185,"tion = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4229,integrability,state,state,4229,"aise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During hand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4251,integrability,state,state,4251,". 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4334,integrability,state,state,4334,"e). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5034,integrability,pipelin,pipeline,5034,"if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(perce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8383,integrability,pipelin,pipeline,8383,"rg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8495,integrability,pipelin,pipeline,8495,"eturn_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8624,integrability,state,state,8624," if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8652,integrability,state,state,8652,"l. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8891,integrability,state,state,8891,"naconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9066,integrability,state,state,9066,"9 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. --->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9190,integrability,pipelin,pipelines,9190,"nd not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9331,integrability,state,state,9331,"pe, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9351,integrability,state,state,9351,"ibrary, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9456,integrability,state,state,9456,"ype, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9698,integrability,state,state,9698,"mpile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (Tru",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9840,integrability,state,state,9840,"ompile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10853,integrability,state,state,10853,":. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10902,integrability,pipelin,pipeline,10902,"~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10946,integrability,state,state,10946,"r_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10968,integrability,state,state,10968,"compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11014,integrability,state,state,11014,"_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11034,integrability,state,state,11034," **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11117,integrability,state,state,11117,"e_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_contex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12991,integrability,pipelin,pipeline,12991,"275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13055,integrability,pipelin,pipeline,13055,"ing.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Bl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14434,integrability,Version,Versions,14434,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:441,interoperability,conflict,conflict,441,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4838,interoperability,bind,binding,4838,"er() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4964,interoperability,format,format,4964,"ck(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1247,modifiability,pac,packages,1247,"ook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1392,modifiability,pac,packages,1392,"r se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1571,modifiability,pac,packages,1571,"e necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lif",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1718,modifiability,pac,packages,1718,">. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1989,modifiability,pac,packages,1989,"t out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2214,modifiability,pac,packages,2214," last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2508,modifiability,pac,packages,2508,"st(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2686,modifiability,pac,packages,2686,"eturn. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2842,modifiability,pac,packages,2842,", flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2969,modifiability,pac,packages,2969,"conda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3114,modifiability,pac,packages,3114,", has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_pass",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3283,modifiability,pac,packages,3283,"rgs, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3464,modifiability,pac,packages,3464,"ifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lower",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3646,modifiability,pac,packages,3646,"le_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3887,modifiability,pac,packages,3887,". 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4093,modifiability,pac,packages,4093,"aconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4285,modifiability,pac,packages,4285,"es\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4448,modifiability,pac,packages,4448,"a3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4514,modifiability,Modul,Module,4514,"ock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4562,modifiability,modul,module,4562,"urn func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4598,modifiability,pac,packages,4598,"_acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4820,modifiability,pac,packages,4820,"303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4838,modifiability,bind,binding,4838,"er() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4846,modifiability,modul,module,4846," finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5375,modifiability,modul,module,5375,"r.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5468,modifiability,pac,packages,5468,"py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5579,modifiability,layer,layer,5579,"conda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5742,modifiability,pac,packages,5742,"e_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5845,modifiability,layer,layer,5845,"dule.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6132,modifiability,pac,packages,6132,"ed with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6378,modifiability,pac,packages,6378,". ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6662,modifiability,pac,packages,6662," --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anacon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6967,modifiability,pac,packages,6967,"egment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7202,modifiability,pac,packages,7202,"364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7446,modifiability,pac,packages,7446,"18 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7679,modifiability,pac,packages,7679,"cher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7912,modifiability,pac,packages,7912,"y with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8247,modifiability,pac,packages,8247,"). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8558,modifiability,pac,packages,8558,"> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 ra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8811,modifiability,pac,packages,8811,"_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9006,modifiability,pac,packages,9006,"=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9234,modifiability,pac,packages,9234,"lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9406,modifiability,pac,packages,9406,"ypingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9648,modifiability,pac,packages,9648,"state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9927,modifiability,pac,packages,9927,"lf._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLower",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10162,modifiability,pac,packages,10162,"lerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10522,modifiability,pac,packages,10522,"elf._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10804,modifiability,pac,packages,10804,"8 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11068,modifiability,pac,packages,11068," return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in low",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11348,modifiability,pac,packages,11348,"2 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11582,modifiability,pac,packages,11582,"te). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11831,modifiability,pac,packages,11831,"in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12039,modifiability,pac,packages,12039,"s). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12546,modifiability,pac,packages,12546,"wer(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12790,modifiability,pac,packages,12790,"of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13273,modifiability,pac,packages,13273,"conda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13685,modifiability,pac,packages,13685,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13791,modifiability,pac,packages,13791,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13897,modifiability,pac,packages,13897,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14003,modifiability,pac,packages,14003,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14109,modifiability,pac,packages,14109,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14234,modifiability,pac,packages,14234,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14434,modifiability,Version,Versions,14434,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:35,performance,Error,Error,35,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:280,performance,error,error,280,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1015,performance,Error,Error,1015,"_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1262,performance,error,errors,1262," 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4952,performance,error,error,4952," 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5090,performance,error,error,5090,"packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5115,performance,error,error,5115,"es.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5604,performance,parallel,parallel,5604,"umba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def insp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5873,performance,parallel,parallel,5873,"mir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6843,performance,error,errors,6843,"ayer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.Typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7367,performance,error,errors,7367,"ib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7833,performance,error,errors,7833,"except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8127,performance,error,error,8127,", **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12561,performance,error,errors,12561,"naconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13111,performance,error,error,13111,"context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13136,performance,error,error,13136,""" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5010,reliability,Fail,Failed,5010,"unc(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 fo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9180,reliability,availab,available,9180,"not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12967,reliability,Fail,Failed,12967,"ower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13031,reliability,Fail,Failed,13031,"site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13483,reliability,pra,prange,13483,"*unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:35,safety,Error,Error,35,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:280,safety,error,error,280,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1015,safety,Error,Error,1015,"_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1262,safety,error,errors,1262," 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1346,safety,except,except,1346,"trained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4514,safety,Modul,Module,4514,"ock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4562,safety,modul,module,4562,"urn func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4846,safety,modul,module,4846," finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4952,safety,error,error,4952," 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5090,safety,error,error,5090,"packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5115,safety,error,error,5115,"es.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5250,safety,except,exception,5250,"e['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5269,safety,except,exception,5269,"3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5348,safety,input,input-,5348,"ata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5375,safety,modul,module,5375,"r.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6836,safety,except,except,6836,"_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6843,safety,error,errors,6843,"ayer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.Typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7360,safety,except,except,7360,"onda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7367,safety,error,errors,7367,"ib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7826,safety,except,except,7826,"). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7833,safety,error,errors,7833,"except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8127,safety,error,error,8127,", **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9180,safety,avail,available,9180,"not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12427,safety,except,except,12427,"4 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12509,safety,except,exception,12509,"197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12561,safety,error,errors,12561,"naconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13111,safety,error,error,13111,"context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13136,safety,error,error,13136,""" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14467,safety,log,logging,14467,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6623,security,sign,signature,6623,"op=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9180,security,availab,available,9180,"not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10985,security,sign,signature,10985," **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11004,security,sign,signature,11004,"_acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14467,security,log,logging,14467,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1191,testability,Trace,Traceback,1191," using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:2739,testability,assert,assert,2739,"parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class). 614 return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,. --> 615 lifted_from=lifted_from). 616 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(self, func_ir, lifted, lifted_from). 340 FixupArgs().run_pass(self.state). --> 341 return self._compile_ir(). 342 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_ir(self). 399 assert self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with Sim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3739,testability,Simpl,SimpleTimer,3739," self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3833,testability,Simpl,SimpleTimer,3833,"te-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4882,testability,context,context,4882,"-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5304,testability,Trace,Traceback,5304,"ses.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8879,testability,assert,assert,8879,"ey] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10317,testability,Simpl,SimpleTimer,10317,"un(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10411,testability,Simpl,SimpleTimer,10411,"mba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12288,testability,context,contextlib,12288,"ython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\prep",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12333,testability,trace,traceback,12333,"\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12411,testability,trace,traceback,12411,"o is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14467,testability,log,logging,14467,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:35,usability,Error,Error,35,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:61,usability,clear,clear,61,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:280,usability,error,error,280,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:642,usability,minim,minimal,642,"sc.pp.calculate_qc_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1015,usability,Error,Error,1015,"_metrics Runtime Error; <!-- Please give a clear and concise description of what the bug is: -->. (Python & GitHub novice here, apologies in advance.). Running through a tutorial using the 10xGenomics 3K PBMC dataset in Jupyter Notebook on Windows 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:1262,usability,error,errors,1262," 10, caught an error at sc.pp.calculate_qc_metrics. Based on a quick look with my untrained eyes, this may not be a scanpy issue per se so much as an underlying data structure conflict issue in numba and/or llvmlite? Trimmed down code I used to reach that point (the skipped steps, in ellipses, don't seem to be necessary, but I may still have a few extras there):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import pandas as pd. import numpy as np. import matplotlib.pyplot as plt. ... adata = sc.read_10x_mtx(""/PBMC_10X/""). ... adata_10x = sc.read_10x_mtx(""/PBMC_10X/""). ... sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ```. That spat out:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. RuntimeError Traceback (most recent call last). ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 716 try:. --> 717 yield. 718 except NumbaError as e:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_inst(self, inst). 475 if isinstance(inst, _class):. --> 476 func(self, inst). 477 return. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _lower_parfor_parallel(lowerer, parfor). 240 lowerer, parfor, typemap, typingctx, targetctx, flags, {},. --> 241 bool(alias_map), index_var_typ, parfor.races). 242 numba.parfor.sequential_parfor_lowering = False. ~\anaconda3\lib\site-packages\numba\npyufunc\parfor.py in _create_gufunc_for_parfor_body(lowerer, parfor, typemap, typingctx, targetctx, flags, locals, has_aliases, index_var_typ, races). 1168 flags,. -> 1169 locals). 1170 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_ir(typingctx,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3739,usability,Simpl,SimpleTimer,3739," self.state.func_ir is not None. --> 400 return self._compile_core(). 401 . ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.par",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:3833,usability,Simpl,SimpleTimer,3833,"te-packages\numba\compiler.py in _compile_core(self). 372 if is_final_pipeline:. --> 373 raise e. 374 else:. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4899,usability,close,close,4899,"compiler_machinery.py in check(func, compiler_state). 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:4952,usability,error,error,4952," 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 pro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5090,usability,error,error,5090,"packages\numba\typed_passes.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5115,usability,error,error,5115,"es.py in run_pass(self, state). 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:5348,usability,input,input-,5348,"ata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 231 # Materialize LLVM Module. --> 232 self.library.add_ir_module(self.module). 233 . ~\anaconda3\lib\site-packages\numba\targets\codegen.py in add_ir_module(self, ir_module). 200 ir = cgutils.normalize_ir_text(str(ir_module)). --> 201 ll_module = ll.parse_assembly(ir). 202 ll_module.name = ir_module.name. ~\anaconda3\lib\site-packages\llvmlite\binding\module.py in parse_assembly(llvmir, context). 25 mod.close(). ---> 26 raise RuntimeError(""LLVM IR parsing error\n{0}"".format(errmsg)). 27 return mod. RuntimeError: Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. During handling of the above exception, another exception occurred:. LoweringError Traceback (most recent call last). <ipython-input-21-b19e785cf655> in <module>. ----> 1 sc.pp.calculate_qc_metrics(adata_10x, inplace = True). ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, parallel). 281 percent_top=percent_top,. 282 inplace=inplace,. --> 283 X=X,. 284 ). 285 var_metrics = describe_var(. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:6843,usability,error,errors,6843,"ayer, use_raw, inplace, X, parallel). 107 if percent_top:. 108 percent_top = sorted(percent_top). --> 109 proportions = top_segment_proportions(X, percent_top). 110 for i, n in enumerate(percent_top):. 111 obs_metrics[f""pct_{expr_type}_in_top_{n}_{var_type}""] = (. ~\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py in top_segment_proportions(mtx, ns). 364 mtx = csr_matrix(mtx). 365 return top_segment_proportions_sparse_csr(. --> 366 mtx.data, mtx.indptr, np.array(ns, dtype=np.int). 367 ). 368 else:. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.Typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7367,usability,error,errors,7367,"ib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 418 e.patch_message('\n'.join((str(e).rstrip(), help_msg))). 419 # ignore the FULL_TRACEBACKS config, this needs reporting! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7567,usability,statu,status,7567,"g! --> 420 raise e. 421 . 422 def inspect_llvm(self, signature=None):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7631,usability,statu,status,7631,"one):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_for_args(self, *args, **kws). 351 argtypes.append(self.typeof_pyval(a)). 352 try:. --> 353 return self.compile(tuple(argtypes)). 354 except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lift",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:7833,usability,error,errors,7833,"except errors.ForceLiteralArg as e:. 355 # Received request for compiler re-entry with the list of arguments. ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:8127,usability,error,error,8127,", **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, sig). 766 self._cache_misses[sig] += 1. 767 try:. --> 768 cres = self._compiler.compile(args, return_type). 769 except errors.ForceLiteralArg as e:. 770 def folded(args, kws):. ~\anaconda3\lib\site-packages\numba\dispatcher.py in compile(self, args, return_type). 75 . 76 def compile(self, args, return_type):. ---> 77 status, retval = self._compile_cached(args, return_type). 78 if status:. 79 return retval. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_cached(self, args, return_type). 89 . 90 try:. ---> 91 retval = self._compile_core(args, return_type). 92 except errors.TypingError as e:. 93 self._failed_cache[key] = e. ~\anaconda3\lib\site-packages\numba\dispatcher.py in _compile_core(self, args, return_type). 107 args=args, return_type=return_type,. 108 flags=flags, locals=self.locals,. --> 109 pipeline_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:9072,usability,statu,status,9072,"line_class=self.pipeline_class). 110 # Check typing error if object mode is used. 111 if cres.typing_error is not None and not flags.enable_pyobject:. ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class). 549 pipeline = pipeline_class(typingctx, targetctx, library,. 550 args, return_type, flags, locals). --> 551 return pipeline.compile_extra(func). 552 . 553 . ~\anaconda3\lib\site-packages\numba\compiler.py in compile_extra(self, func). 329 self.state.lifted = (). 330 self.state.lifted_from = None. --> 331 return self._compile_bytecode(). 332 . 333 def compile_ir(self, func_ir, lifted=(), lifted_from=None):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_bytecode(self). 391 """""". 392 assert self.state.func_ir is None. --> 393 return self._compile_core(). 394 . 395 def _compile_ir(self):. ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 371 self.state.status.fail_reason = e. 372 if is_final_pipeline:. --> 373 raise e. 374 else:. 375 raise CompilerError(""All available pipelines exhausted""). ~\anaconda3\lib\site-packages\numba\compiler.py in _compile_core(self). 362 res = None. 363 try:. --> 364 pm.run(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10317,usability,Simpl,SimpleTimer,10317,"un(self.state). 365 if self.state.cr is not None:. 366 break. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:10411,usability,Simpl,SimpleTimer,10411,"mba\compiler_machinery.py in run(self, state). 345 (self.pipeline_name, pass_desc). 346 patched_exception = self._patch_error(msg, e). --> 347 raise patched_exception. 348 . 349 def dependency_analysis(self):. ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in run(self, state). 336 pass_inst = _pass_registry.get(pss).pass_inst. 337 if isinstance(pass_inst, CompilerPass):. --> 338 self._runPass(idx, pass_inst, state). 339 else:. 340 raise BaseException(""Legacy pass in use""). ~\anaconda3\lib\site-packages\numba\compiler_lock.py in _acquire_compile_lock(*args, **kwargs). 30 def _acquire_compile_lock(*args, **kwargs):. 31 with self:. ---> 32 return func(*args, **kwargs). 33 return _acquire_compile_lock. 34 . ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in _runPass(self, index, pss, internal_state). 300 mutated |= check(pss.run_initialization, internal_state). 301 with SimpleTimer() as pass_time:. --> 302 mutated |= check(pss.run_pass, internal_state). 303 with SimpleTimer() as finalize_time:. 304 mutated |= check(pss.run_finalizer, internal_state). ~\anaconda3\lib\site-packages\numba\compiler_machinery.py in check(func, compiler_state). 273 . 274 def check(func, compiler_state):. --> 275 mangled = func(compiler_state). 276 if mangled not in (True, False):. 277 msg = (""CompilerPass implementations should return True/False. "". ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:11783,usability,Close,Close,11783,"naconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 405 . 406 # TODO: Pull this out into the pipeline. --> 407 NativeLowering().run_pass(state). 408 lowered = state['cr']. 409 signature = typing.signature(state.return_type, *state.args). ~\anaconda3\lib\site-packages\numba\typed_passes.py in run_pass(self, state). 347 lower = lowering.Lower(targetctx, library, fndesc, interp,. 348 metadata=metadata). --> 349 lower.lower(). 350 if not flags.no_cpython_wrapper:. 351 lower.create_cpython_wrapper(flags.release_gil). ~\anaconda3\lib\site-packages\numba\lowering.py in lower(self). 193 if self.generator_info is None:. 194 self.genlower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12434,usability,Stop,StopIteration,12434,"ower = None. --> 195 self.lower_normal_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12472,usability,Stop,StopIteration,12472,"_function(self.fndesc). 196 else:. 197 self.genlower = self.GeneratorLower(self). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:12561,usability,error,errors,12561,"naconda3\lib\site-packages\numba\lowering.py in lower_normal_function(self, fndesc). 246 # Init argument values. 247 self.extract_function_arguments(). --> 248 entry_block_tail = self.lower_function_body(). 249 . 250 # Close tail of entry block. ~\anaconda3\lib\site-packages\numba\lowering.py in lower_function_body(self). 271 bb = self.blkmap[offset]. 272 self.builder.position_at_end(bb). --> 273 self.lower_block(block). 274 . 275 self.post_lower(). ~\anaconda3\lib\site-packages\numba\lowering.py in lower_block(self, block). 286 with new_error_context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13111,usability,error,error,13111,"context('lowering ""{inst}"" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13136,usability,error,error,13136,""" at {loc}', inst=inst,. 287 loc=self.loc, errcls_=defaulterrcls):. --> 288 self.lower_inst(inst). 289 self.post_block(block). 290 . ~\anaconda3\lib\contextlib.py in __exit__(self, type, value, traceback). 128 value = type(). 129 try:. --> 130 self.gen.throw(type, value, traceback). 131 except StopIteration as exc:. 132 # Suppress StopIteration *unless* it's the same exception that. ~\anaconda3\lib\site-packages\numba\errors.py in new_error_context(fmt_, *args, **kwargs). 723 from numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13645,usability,User,Users,13645,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13751,usability,User,Users,13751,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13857,usability,User,Users,13857,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:13963,usability,User,Users,13963,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14069,usability,User,Users,14069,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14194,usability,User,Users,14194,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1147:14589,usability,learn,learn,14589,"m numba import config. 724 tb = sys.exc_info()[2] if config.FULL_TRACEBACKS else None. --> 725 six.reraise(type(newerr), newerr, tb). 726 . 727 . ~\anaconda3\lib\site-packages\numba\six.py in reraise(tp, value, tb). 667 if value.__traceback__ is not tb:. 668 raise value.with_traceback(tb). --> 669 raise value. 670 . 671 else:. LoweringError: Failed in nopython mode pipeline (step: nopython mode backend). Failed in nopython mode pipeline (step: nopython mode backend). LLVM IR parsing error. <string>:4053:36: error: '%.2725' defined with type 'i64' but expected 'i32'. %"".2726"" = icmp eq i32 %"".2724"", %"".2725"". ^. File ""..\..\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py"", line 399:. def top_segment_proportions_sparse_csr(data, indptr, ns):. <source elided>. partitioned = np.zeros((indptr.size - 1, maxidx), dtype=data.dtype). for i in numba.prange(indptr.size - 1):. ^. [1] During: lowering ""id=13[LoopNest(index_variable = parfor_index.260, range = (0, $122binary_subtract.5, 1))]{130: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399)>, 400: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (405)>, 402: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (406)>, 276: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (403)>, 318: <ir.Block at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (404)>}Var(parfor_index.260, _qc.py:399)"" at C:\Users\lyciansarpedon\anaconda3\lib\site-packages\scanpy\preprocessing\_qc.py (399). ```. Unlikely to be related, but this was after I had issues installing scanpy from conda (as in #1142), which I got around by installing through pip. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1147
https://github.com/scverse/scanpy/issues/1148:479,deployability,Version,Versions,479,"sc.pl.spatial plots vertically flipped spots when `img_key=None`; sc.pl.spatial plots vertically flipped spots when `sc.pl.spatial(..., img_key=None)`. Try comparing these in your lymph node demo notebook. ```python. # Plot orientation correct. sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',. color=['total_counts', 'n_genes_by_counts']). # Now spots are flipped. sc.pl.spatial(adata, img_key = None, cmap='magma',. color=['total_counts', 'n_genes_by_counts']). ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1148
https://github.com/scverse/scanpy/issues/1148:479,integrability,Version,Versions,479,"sc.pl.spatial plots vertically flipped spots when `img_key=None`; sc.pl.spatial plots vertically flipped spots when `sc.pl.spatial(..., img_key=None)`. Try comparing these in your lymph node demo notebook. ```python. # Plot orientation correct. sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',. color=['total_counts', 'n_genes_by_counts']). # Now spots are flipped. sc.pl.spatial(adata, img_key = None, cmap='magma',. color=['total_counts', 'n_genes_by_counts']). ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1148
https://github.com/scverse/scanpy/issues/1148:479,modifiability,Version,Versions,479,"sc.pl.spatial plots vertically flipped spots when `img_key=None`; sc.pl.spatial plots vertically flipped spots when `sc.pl.spatial(..., img_key=None)`. Try comparing these in your lymph node demo notebook. ```python. # Plot orientation correct. sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',. color=['total_counts', 'n_genes_by_counts']). # Now spots are flipped. sc.pl.spatial(adata, img_key = None, cmap='magma',. color=['total_counts', 'n_genes_by_counts']). ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1148
https://github.com/scverse/scanpy/issues/1148:581,usability,learn,learn,581,"sc.pl.spatial plots vertically flipped spots when `img_key=None`; sc.pl.spatial plots vertically flipped spots when `sc.pl.spatial(..., img_key=None)`. Try comparing these in your lymph node demo notebook. ```python. # Plot orientation correct. sc.pl.spatial(adata, img_key = ""hires"", cmap='magma',. color=['total_counts', 'n_genes_by_counts']). # Now spots are flipped. sc.pl.spatial(adata, img_key = None, cmap='magma',. color=['total_counts', 'n_genes_by_counts']). ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.17.3 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.10.2 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1148
https://github.com/scverse/scanpy/issues/1150:901,availability,cluster,cluster,901,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:667,deployability,instal,installed,667,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:901,deployability,cluster,cluster,901,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:990,integrability,wrap,wrap,990,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1305,integrability,wrap,wrapper,1305,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1305,interoperability,wrapper,wrapper,1305,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:31,modifiability,paramet,parameter,31,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:144,modifiability,paramet,parameters,144,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:421,modifiability,pac,package,421,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:775,modifiability,paramet,parameter,775,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1086,modifiability,paramet,parameters,1086,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1280,modifiability,paramet,parameters,1280,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1513,performance,time,time,1513,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:785,security,expos,exposed,785,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1226,security,modif,modify,1226,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1483,security,polic,policar,1483,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:226,testability,simpl,simple,226,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:218,usability,tool,tool,218,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:226,usability,simpl,simple,226,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:242,usability,tool,tool,242,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:290,usability,tool,tools,290,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:390,usability,tool,tools,390,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:979,usability,tool,tools,979,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1034,usability,user,user,1034,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1150:1590,usability,tool,tools,1590,"turn on the existing `n_iter=` parameter in multicore tsne; <!-- What kind of feature would you like to request? -->. - [X] Additional function parameters / changed functionality / changed defaults? - [X] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [X] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. t-SNE is an interative algorithm, and takes numerous iterations to converge, particularly on larger datasets. For example, if MulticoreTSNE is installed, it accepts `n_iter=30000` as opposed to the default `n_iter=1000`. It would be nice to have this parameter exposed. For larger datasets of say 200K cells, 1000 iterations isn't enough to fully converge to its final compact cluster shapes. . Alternatively, is it possible to pass in a kwargs to scanpy tools that wrap other algorithms, so that the advanced user can flexibly look up [additional MulticoreTSNE parameters](https://github.com/DmitryUlyanov/Multicore-TSNE/blob/62dedde52469f3a0aeb22fdd7bce2538f17f77ef/MulticoreTSNE/__init__.py#L55) to modify, without needing to exhaustively enumerate all parameters in the scanpy wrapper? Finally, it would be even better to have the faster FFT-based tsne to generalize to millions of cells, the most recent re-implementation being https://github.com/pavlin-policar/openTSNE. In the mean time, one has to overwrite the `.X_tsne` attribute after running these other tools separately.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1150
https://github.com/scverse/scanpy/issues/1151:30,availability,error,error,30,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:345,availability,Error,Error,345,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:312,deployability,scale,scale,312,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:593,deployability,modul,module,593,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:616,deployability,scale,scale,616,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:673,deployability,scale,scale,673,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:878,deployability,log,logic,878,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1122,deployability,stack,stacklevel,1122,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1208,deployability,Version,Versions,1208,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1241,deployability,log,logging,1241,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:312,energy efficiency,scale,scale,312,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:616,energy efficiency,scale,scale,616,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:673,energy efficiency,scale,scale,673,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1273,energy efficiency,Current,Current,1273,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1208,integrability,Version,Versions,1208,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:312,modifiability,scal,scale,312,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:593,modifiability,modul,module,593,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:616,modifiability,scal,scale,616,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:673,modifiability,scal,scale,673,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1208,modifiability,Version,Versions,1208,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:30,performance,error,error,30,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:312,performance,scale,scale,312,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:345,performance,Error,Error,345,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:616,performance,scale,scale,616,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:673,performance,scale,scale,673,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:30,safety,error,error,30,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:345,safety,Error,Error,345,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:567,safety,input,input-,567,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:593,safety,modul,module,593,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:878,safety,log,logic,878,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1241,safety,log,logging,1241,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:878,security,log,logic,878,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1241,security,log,logging,1241,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:523,testability,Trace,Traceback,523,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:878,testability,log,logic,878,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:1241,testability,log,logging,1241,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:30,usability,error,error,30,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:182,usability,minim,minimal,182,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:345,usability,Error,Error,345,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1151:567,usability,input,input-,567,"new AnnData `.is_view` causes error.; PR #1056 added the new `is_view` property. Yet, some anndata, including those in the `sc.datasets` do not have this attribute set. . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. adata = sc.datasets.pbmc3k(). sc.pp.scale(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-5-d1141fe2ca57> in <module>. ----> 1 sc.pp.scale(adata). /scanpy/scanpy/preprocessing/_simple.py in scale(data, zero_center, max_value, copy). 910 if isinstance(data, AnnData):. 911 adata = data.copy() if copy else data. --> 912 view_to_actual(adata). 913 # need to add the following here to make inplace logic work. 914 if zero_center and issparse(adata.X):. /scanpy/scanpy/_utils.py in view_to_actual(adata). 377 . 378 def view_to_actual(adata):. --> 379 if adata.is_view:. 380 warnings.warn(. 381 ""Revieved a view of an AnnData. Making a copy."", stacklevel=2,. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > Current scanpy master branch.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1151
https://github.com/scverse/scanpy/issues/1152:315,deployability,log,logfoldchanges,315,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:370,deployability,modul,modularity,370,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:370,integrability,modular,modularity,370,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:16,modifiability,paramet,parameterized,16,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:370,modifiability,modul,modularity,370,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:393,modifiability,paramet,parameterization,393,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:457,modifiability,paramet,parameter,457,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:353,reliability,doe,does,353,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:315,safety,log,logfoldchanges,315,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:370,safety,modul,modularity,370,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:315,security,log,logfoldchanges,315,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:315,testability,log,logfoldchanges,315,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1152:370,testability,modula,modularity,370,"Making `scores` parameterized; https://github.com/theislab/scanpy/blob/2a7fb7cdf56ff44ef6338c7dba3b84b4b32d216c/scanpy/plotting/_tools/__init__.py#L286. `scanpy.pl.rank_genes_groups()` by default presents the `scores` from `adata.uns['rank_genes']['scores']`. However, why is it not possible to change to `scores` `logfoldchanges`. The code at line 286 does not use any modularity or possible parameterization. A possible change would be to introduce a new parameter `plotby`, which corresponds to `adata.uns['rank_genes'][f'{plotby}']` or similar. . I do realize that it is easy to extract the relevant data and plot them by myself. However, there is value in making it easier to choose what to exactly plot from the `rank_genes_groups`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1152
https://github.com/scverse/scanpy/issues/1153:47,availability,error,error,47,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:151,availability,error,error,151,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:320,availability,error,error,320,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:933,availability,Error,Error,933,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:958,availability,Error,Error,958,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1197,availability,replic,replicate,1197,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1315,availability,error,error,1315,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:231,deployability,log,logarithmizing,231,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1415,deployability,modul,module,1415,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1905,deployability,Version,Versions,1905,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:464,energy efficiency,current,current,464,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:749,integrability,Sub,Subbing,749,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1905,integrability,Version,Versions,1905,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1415,modifiability,modul,module,1415,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1559,modifiability,pac,packages,1559,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1685,modifiability,pac,packages,1685,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1905,modifiability,Version,Versions,1905,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:47,performance,error,error,47,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:105,performance,perform,performing,105,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:151,performance,error,error,151,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:320,performance,error,error,320,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:933,performance,Error,Error,933,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:958,performance,Error,Error,958,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1315,performance,error,error,1315,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:47,safety,error,error,47,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:151,safety,error,error,151,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:231,safety,log,logarithmizing,231,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:320,safety,error,error,320,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:731,safety,test,test,731,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:933,safety,Error,Error,933,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:958,safety,Error,Error,958,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1315,safety,error,error,1315,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1415,safety,modul,module,1415,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:231,security,log,logarithmizing,231,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:231,testability,log,logarithmizing,231,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:731,testability,test,test,731,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1342,testability,Trace,Traceback,1342,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:47,usability,error,error,47,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:105,usability,perform,performing,105,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:151,usability,error,error,151,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:320,usability,error,error,320,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:933,usability,Error,Error,933,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:958,usability,Error,Error,958,"scanpy.pp.log1p with backed h5ad produces copy error; I am fairly new with using scanpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:1315,usability,error,error,1315,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1153:2007,usability,learn,learn,2007,"anpy, and so I may be performing this incorrectly. I encountered an error when trying to create a backed AnnData object from an h5ad file, and then logarithmizing the data matrix within the object using scanpy.pp.log1p. However I get an error within the AnnData object code because the preprocessing/_simple.py script is not passing a filename in the copy() function. Right now my current workaround is to create the AnnData object as non-backed, do the log1p, and then create a ""filename"" property to the AnnData object afterwards to make it backed for other scanpy functions. ### Example. ```python. import scanpy as sc. dataset_path = ""/path/to/test/data.h5ad"" # Subbing out actual filenames for data. adata = sc.read_h5ad(dataset_path, backed='r'). print(adata) # To ensure there is a backed filepath. adata.raw = sc.pp.log1p(adata, copy=True) # Error is here. ```. #### Error output. ```pytb. # I printed the AnnData object to ensure it was backed. AnnData object with n_obs  n_vars = 4166  16852 backed at '/tmp/1b12dde9-1762-7564-8fbd-1b07b750505f.h5ad'. obs: 'cell_type', 'barcode', 'tSNE_1', 'tSNE_2', 'replicate', 'louvain', 'n_genes', 'percent_mito', 'n_counts'. var: 'gene_symbol', 'n_cells'. obsm: 'X_tsne'. # Actual error after calling log1p. Traceback (most recent call last):. File ""log1p_test.cgi"", line 129, in <module>. main(). File ""log1p_test.cgi"", line 81, in main. adata.raw = sc.pp.log1p(adata, copy=True). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 292, in log1p. data = data.copy(). File ""/opt/Python-3.7.3/lib/python3.7/site-packages/anndata/_core/anndata.py"", line 1457, in copy. ""To copy an AnnData object in backed mode, "". ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. ```. #### Versions:. scanpy==1.4.6 anndata==0.7.1 umap==0.3.10 numpy==1.16.3 scipy==1.4.1 pandas==0.24.2 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1153
https://github.com/scverse/scanpy/issues/1154:558,availability,Error,Error,558,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:859,deployability,modul,module,859,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2210,deployability,Version,Versions,2210,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2243,deployability,log,logging,2243,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:306,energy efficiency,optim,optimal,306,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2210,integrability,Version,Versions,2210,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:859,modifiability,modul,module,859,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:1080,modifiability,pac,packages,1080,"ption of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:1467,modifiability,pac,packages,1467,"e'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you ple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:1816,modifiability,pac,packages,1816,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2210,modifiability,Version,Versions,2210,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:558,performance,Error,Error,558,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:558,safety,Error,Error,558,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:832,safety,input,input-,832,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:859,safety,modul,module,859,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2243,safety,log,logging,2243,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2243,security,log,logging,2243,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:788,testability,Trace,Traceback,788,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2243,testability,log,logging,2243,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:60,usability,clear,clear,60,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:167,usability,minim,minimal,167,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:558,usability,Error,Error,558,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:832,usability,input,input-,832,"'tuple' object has no attribute 'tocsr'; <!-- Please give a clear and concise description of what the bug is: -->. 'tuple' object has no attribute 'tocsr'. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... # neighborhood graph of cells (determine optimal number of PCs here). sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). # compute UMAP. sc.tl.umap(adata). # tSNE. tsne = TSNE( n_jobs=20 ). adata.obsm['X_tsne'] = tsne.fit_transform( adata.X ). adata.write( f_anndata_path ). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matri",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2375,usability,learn,learn,2375,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1154:2475,usability,help,help,2475,"is code block (if applicable, else delete the block): -->. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 30. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-38-e2dd1fe70ab9> in <module>. 6 sc.settings.n_jobs = 15. 7 with parallel_backend('threading', n_jobs=20):. ----> 8 sc.pp.neighbors(adata, n_neighbors=15, n_pcs=30). 9 . 10 #sc.settings.n_jobs = 15. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 93 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 94 method=method, metric=metric, metric_kwds=metric_kwds,. ---> 95 random_state=random_state,. 96 ). 97 adata.uns['neighbors'] = {}. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 681 knn_distances,. 682 self._adata.shape[0],. --> 683 self.n_neighbors,. 684 ). 685 # overwrite the umap connectivities if method is 'gauss'. ~/miniconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/neighbors/__init__.py in compute_connectivities_umap(knn_indices, knn_dists, n_obs, n_neighbors, set_op_mix_ratio, local_connectivity). 322 distances = get_sparse_matrix_from_indices_distances_umap(knn_indices, knn_dists, n_obs, n_neighbors). 323 . --> 324 return distances, connectivities.tocsr(). 325 . 326 . AttributeError: 'tuple' object has no attribute 'tocsr'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.4.0 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. > ... Could you please help me resolve it? I looked up older issues but could not find solution to this. Thank you very much",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1154
https://github.com/scverse/scanpy/issues/1155:129,availability,cluster,clusters,129,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/issues/1155:129,deployability,cluster,clusters,129,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/issues/1155:157,integrability,sub,subset,157,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/issues/1155:256,integrability,sub,subset,256,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/issues/1155:453,integrability,sub,subset,453,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/issues/1155:197,modifiability,paramet,parameter,197,"sc.pl.rank_genes_groups_heatmap colorbar order; sc.pl.rank_genes_groups() was desgined to display all the groups(such as all the clusters). When plot only a subset of the groups using the 'groups' parameter, the color bar would not change according to the subset groups, the orders are confused. here is the warning:. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. Then how to disply only a subset of the groups?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1155
https://github.com/scverse/scanpy/pull/1156:18,modifiability,refact,refactoring,18,"rank_genes_groups refactoring 2nd try; Related to 1), 2) of [this](https://github.com/theislab/scanpy/issues/723#issuecomment-526079225). Replaces https://github.com/theislab/scanpy/pull/1081",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156
https://github.com/scverse/scanpy/pull/1156:18,performance,refactor,refactoring,18,"rank_genes_groups refactoring 2nd try; Related to 1), 2) of [this](https://github.com/theislab/scanpy/issues/723#issuecomment-526079225). Replaces https://github.com/theislab/scanpy/pull/1081",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1156
https://github.com/scverse/scanpy/issues/1157:414,availability,error,error,414,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1116,availability,Error,Error,1116,"s trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,deployability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,deployability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,deployability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1688,deployability,modul,module,1688,"='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manif",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3398,deployability,Version,Versions,3398,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3431,deployability,log,logging,3431,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,integrability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,integrability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,integrability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1950,integrability,standardiz,standardization,1950,"```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3398,integrability,Version,Versions,3398,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,interoperability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,interoperability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,interoperability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1950,interoperability,standard,standardization,1950,"```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,modifiability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,modifiability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,modifiability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1688,modifiability,modul,module,1688,"='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manif",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1863,modifiability,pac,packages,1863,"- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:2164,modifiability,pac,packages,2164," delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:2527,modifiability,pac,packages,2527,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:2837,modifiability,pac,packages,2837,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3140,modifiability,pac,packages,3140,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3398,modifiability,Version,Versions,3398,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:414,performance,error,error,414,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1116,performance,Error,Error,1116,"s trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1395,performance,time,time,1395,"ept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,reliability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,reliability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,reliability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:744,reliability,doe,does,744,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:414,safety,error,error,414,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1116,safety,Error,Error,1116,"s trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1661,safety,input,input-,1661,". sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1688,safety,modul,module,1688,"='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manif",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3431,safety,log,logging,3431,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,security,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,security,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,security,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3431,security,log,logging,3431,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:145,testability,integr,integration,145,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:279,testability,integr,integrated,279,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:520,testability,integr,integrate,520,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1617,testability,Trace,Traceback,1617,"ternal as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:3431,testability,log,logging,3431,". RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). 1117 . 1118 if update_manifold:. -> 1119 edm = ut.calc_nnm(g_weighted, k, distance). 1120 self.adata.uns[""nnm""] = edm. 1121 EDM = edm.copy(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in calc_nnm(g_weighted, k, distance). 448 if g_weighted.shape[0] > 8000:. 449 # only uses cosine. --> 450 nnm, dists = nearest_neighbors(g_weighted, n_neighbors=k, metric=distance). 451 EDM = gen_sparse_knn(nnm, dists). 452 EDM = EDM.tocsr(). ~/anaconda3/lib/python3.7/site-packages/samalg/utilities.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, seed, low_memory). 175 leaf_array=leaf_array,. 176 n_iters=n_iters,. --> 177 verbose=False,. 178 ). 179 . TypeError: some keyword arguments unexpected. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:56,usability,clear,clear,56,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:414,usability,error,error,414,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:875,usability,minim,minimal,875,"TypeError in scanpy.external.tl.sam; <!-- Please give a clear and concise description of what the bug is: -->. Hi, I was trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1116,usability,Error,Error,1116,"s trying to apply the SAM integration on a merged dataset of three example dataset from 10x homepage, in an attempt to compare the result to the PAGA and bbknn integrated umap. I got a successful run on one of the PBMC dataset with no reprocessing. However in any other case I kept bump into an error:. TypeError: some keyword arguments unexpected. Here is the record. On the other hand, if I want to integrate bbknn with SAM, do I just apply bbknn after the run of SAM like this? ////. import scanpy.external as sce. sam_obj = sce.tl.sam(adata). sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1157:1661,usability,input,input-,1661,". sc.pl.umap(sam_obj, color='Sample') . bbknn.bbknn(adata,batch_key='Sample'). #does this change the umap? or do I need to make another call of tl.umap? sc.pl.umap(sam_obj, color='Sample') . ////. i. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. import scanpy.external as sce. for adata in adatalist:. sam_obj = sce.tl.sam(adata). sce.pl.sam(adata,projection='X_umap'). <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ... Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.016564277393631113. Iteration: 1, Convergence: 0.01278454723440345. Computing the UMAP embedding... Elapsed time: 50.534051179885864 seconds. Self-assembling manifold. Running SAM. RUNNING SAM. Iteration: 0, Convergence: 0.022868878389371346. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-17-4514ae92b370> in <module>. 1 import scanpy.external as sce. 2 for adata in adatalist:. ----> 3 sam_obj = sce.tl.sam(adata). 4 sce.pl.sam(adata,projection='X_umap'). ~/.local/lib/python3.7/site-packages/scanpy/external/tl/_sam.py in sam(adata, max_iter, num_norm_avg, k, distance, standardization, weight_pcs, sparse_pca, n_pcs, n_genes, projection, inplace, verbose). 216 projection=projection,. 217 sparse_pca=sparse_pca,. --> 218 verbose=verbose,. 219 ). 220 . ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in run(self, max_iter, verbose, projection, stopping_condition, num_norm_avg, k, distance, preprocessing, npcs, n_genes, weight_PCs, sparse_pca, proj_kwargs). 1014 . 1015 W, wPCA_data, EDM, = self.calculate_nnm(. -> 1016 n_genes, preprocessing, npcs, nnas, weight_PCs, sparse_pca,. 1017 ). 1018 new = W. ~/anaconda3/lib/python3.7/site-packages/samalg/__init__.py in calculate_nnm(self, n_genes, preprocessing, npcs, num_norm_avg, weight_PCs, sparse_pca, update_manifold). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1157
https://github.com/scverse/scanpy/issues/1158:301,availability,cluster,clusters,301,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:390,availability,cluster,clusters,390,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:479,availability,cluster,clusters,479,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:569,availability,down,download,569,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:301,deployability,cluster,clusters,301,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:390,deployability,cluster,clusters,390,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:479,deployability,cluster,clusters,479,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:48,integrability,sub,subplots,48,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:144,integrability,sub,subplots,144,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:225,integrability,sub,subplots,225,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:18,reliability,doe,does,18,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1158:587,usability,user,user-images,587,"scanpy.pl.spatial does not work properly in plt.subplots; I have spatial annotations for multiple datasets and want to put them in the same plt.subplots framework. Only the last one gets the markers. ```python. fig, ax = plt.subplots(1,3, figsize=(20,6)). sc.pl.spatial(adata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[0], show=False). sc.pl.spatial(bdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[1], show=False). sc.pl.spatial(cdata, img_key=""hires"", color=""clusters"", size=1.5, ax=ax[2], show=False). plt.tight_layout(pad=3.0). plt.show(). ```. ![download](https://user-images.githubusercontent.com/37935731/78901496-64765f00-7a46-11ea-83ba-56dc16ff5e14.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1158
https://github.com/scverse/scanpy/issues/1159:93,availability,cluster,cluster,93,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:158,availability,cluster,clusters,158,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:207,availability,cluster,clusters,207,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:254,availability,cluster,clusters,254,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:360,availability,cluster,cluster,360,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:405,availability,cluster,clusters,405,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:93,deployability,cluster,cluster,93,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:158,deployability,cluster,clusters,158,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:207,deployability,cluster,clusters,207,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:254,deployability,cluster,clusters,254,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:360,deployability,cluster,cluster,360,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:405,deployability,cluster,clusters,405,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:32,energy efficiency,heat,heatmap,32,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:175,energy efficiency,heat,heatmap,175,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:0,integrability,sub,subsampling,0,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:283,integrability,sub,subsampling,283,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/issues/1159:376,usability,user,user-defined,376,"subsampling cells number; sc.pl.heatmap and the related functions plot all the cells of each cluster at default. Sometimes cell number differ a lot among the clusters, so the heatmap becomes unblanced, some clusters take a lot of space, while some small clusters becomes unclear. So subsampling is necessary to sample an equal. number of data points from each cluster using a user-defined threshold while clusters lower than the threshold keep the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1159
https://github.com/scverse/scanpy/pull/1161:174,availability,cluster,clusters,174,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/pull/1161:576,availability,cluster,clusters,576,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/pull/1161:174,deployability,cluster,clusters,174,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/pull/1161:576,deployability,cluster,clusters,576,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/pull/1161:233,usability,user,user-images,233,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/pull/1161:383,usability,behavi,behaviour,383,"Add ylabel option to violin; This PR adds option to add y-label to violin plot, see below:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced'], groupby='clusters',. ylabel=['foo', 'bar']). ```. ![violin](https://user-images.githubusercontent.com/46717574/79081535-a2150980-7d1e-11ea-85a6-ac682f06737a.png). `ylabel` is by default `None`, preserving the original behaviour. Also fixes an issue when there are duplicate keys and `groupby != None`, such as:. ```python. sc.pl.violin(adata, ['initial_size', 'initial_size_spliced', 'initial_size'],. groupby='clusters'). ```. Previously, it created a figure with 3 axes, now are only 2 (order of keys is being preserved).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1161
https://github.com/scverse/scanpy/issues/1163:282,deployability,api,apidocs,282,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:325,deployability,api,api,325,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,deployability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,deployability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:657,energy efficiency,Current,Currently,657,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:282,integrability,api,apidocs,282,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:325,integrability,api,api,325,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:528,integrability,topic,topic,528,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,integrability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,integrability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:282,interoperability,api,apidocs,282,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:325,interoperability,api,api,325,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:559,interoperability,coordinat,coordinate,559,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,interoperability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,interoperability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:7,modifiability,extens,extension,7,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:117,modifiability,extens,extension,117,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:694,modifiability,extens,extension,694,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,modifiability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,modifiability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:239,performance,content,content,239,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:843,performance,network,networks,843,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,reliability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,reliability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,security,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:843,security,network,networks,843,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,security,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:719,testability,integr,integration,719,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:855,testability,integr,integration,855,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1163:168,usability,learn,learn,168,"Scanpy extension for single-cell TCR data; Hi, . we developed [scirpy](https://github.com/icbi-lab/scirpy), a scanpy extension to analyse single-cell TCR data. You can learn more about the project in our [preprint](https://www.biorxiv.org/content/10.1101/2020.04.10.035865v1), the [apidocs](https://icbi-lab.github.io/scirpy/api.html) and the [tutorial](https://icbi-lab.github.io/scirpy/tutorials/tutorial_3k_tcr.html). . Since I heard that some people around here (@davidsebfischer, @b-schubert) are really interested in this topic, I created this issue to coordinate efforts. I would love to work together with you guys to take this to the next level. . Currently, some ideas of mine are. * extension to BCR data. * integration with @davidsebfischer's [tcellmatch](https://github.com/theislab/tcellmatch) as a distance metric for clonotype networks. * integration with epitope databases. Let me know what you think! . Best, . Gregor . CC @ffinotello, @szabogtamas, @mlist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1163
https://github.com/scverse/scanpy/issues/1164:18,availability,error,errors,18,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:151,availability,error,errors,151,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:490,availability,Error,Error,490,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:783,deployability,fail,failed,783,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1981,deployability,fail,failed,1981,"mbat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed ty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2975,deployability,fail,failed,2975,"l"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anacon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4573,deployability,Version,Versions,4573,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4606,deployability,log,logging,4606,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4573,integrability,Version,Versions,4573,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:626,modifiability,pac,packages,626,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:951,modifiability,pac,packages,951,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1055,modifiability,pac,packages,1055,"ive a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1445,modifiability,pac,packages,1445,"ombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1549,modifiability,pac,packages,1549," block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/e",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1821,modifiability,pac,packages,1821," array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2137,modifiability,pac,packages,2137,", g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2389,modifiability,pac,packages,2389,"ome/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <so",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2583,modifiability,pac,packages,2583,"py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /hom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2815,modifiability,pac,packages,2815,"e-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:3143,modifiability,pac,packages,3143,"canpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../ana",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:3247,modifiability,pac,packages,3247,"01) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:3637,modifiability,pac,packages,3637,"ba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:3741,modifiability,pac,packages,3741,".func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-lear",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4013,modifiability,pac,packages,4013,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4185,modifiability,pac,packages,4185,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4445,modifiability,pac,packages,4445,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4573,modifiability,Version,Versions,4573,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:18,performance,error,errors,18,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:151,performance,error,errors,151,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:490,performance,Error,Error,490,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:783,reliability,fail,failed,783,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:1981,reliability,fail,failed,1981,"mbat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed ty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:2975,reliability,fail,failed,2975,"l"" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True, but has lifted loops. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 270:. @numba.jit. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anacon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:18,safety,error,errors,18,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:151,safety,error,errors,151,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:490,safety,Error,Error,490,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4606,safety,log,logging,4606,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4606,security,log,logging,4606,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4606,testability,log,logging,4606,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:18,usability,error,errors,18,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:65,usability,clear,clear,65,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:151,usability,error,errors,151,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:213,usability,minim,minimal,213,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:490,usability,Error,Error,490,"Combat processing errors/warnings in console; <!-- Please give a clear and concise description of what the bug is: -->. Console outputs a long list of errors/warnings when running scanpy.pp.combat(). . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataCombat = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataCombat). sc.pp.pca(adataCombat, svd_solver='arpack'). sc.pp.combat(adataCombat, key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inferen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1164:4741,usability,learn,learn,4741,"ckages/scanpy/preprocessing/_combat.py:269: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""_it_sol"" failed type inference due to: Cannot unify array(float64, 2d, C) and array(float64, 1d, C) for 'sum2', defined at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (311). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 311:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. g_new = (t2*n*g_hat + d_old*g_bar) / (t2*n + d_old). sum2 = s_data - g_new.reshape((g_new.shape[0], 1)) @ np.ones((1, s_data.shape[1])). ^. [1] During: typing of assignment at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py (313). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 313:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. sum2 = sum2 ** 2. sum2 = sum2.sum(axis=1). ^. @numba.jit. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/compiler.py:742: NumbaWarning: Function ""_it_sol"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py"", line 305:. def _it_sol(s_data, g_hat, d_hat, g_bar, t2, a, b, conv=0.0001) -> Tuple[float, float]:. <source elided>. change = 1. count = 0. ^. self.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:235: RuntimeWarning: divide by zero encountered in true_divide. b_prior[i],. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1164
https://github.com/scverse/scanpy/issues/1166:267,availability,error,error,267,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:479,availability,Error,Error,479,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:958,availability,cluster,clustermap,958,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:25,deployability,updat,updating,25,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:139,deployability,upgrad,upgraded,139,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:291,deployability,modul,module,291,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:629,deployability,modul,module,629,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:746,deployability,modul,module,746,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:901,deployability,modul,module,901,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:958,deployability,cluster,clustermap,958,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1177,deployability,modul,module,1177,"onment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1335,deployability,modul,module,1335,". <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2190,deployability,modul,module,2190," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2381,deployability,modul,module,2381," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2443,deployability,modul,module,2443," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:7,energy efficiency,load,load,7,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:208,energy efficiency,load,load,208,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:986,energy efficiency,heat,heatmap,986,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:139,modifiability,upgrad,upgraded,139,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:217,modifiability,pac,package,217,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:291,modifiability,modul,module,291,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:629,modifiability,modul,module,629,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:703,modifiability,pac,packages,703,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:746,modifiability,modul,module,746,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:850,modifiability,pac,packages,850,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:901,modifiability,modul,module,901,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1125,modifiability,pac,packages,1125,">. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1177,modifiability,modul,module,1177,"onment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1288,modifiability,pac,packages,1288,"odule 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1335,modifiability,modul,module,1335,". <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1446,modifiability,pac,packages,1446,"t scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1623,modifiability,pac,packages,1623," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1776,modifiability,pac,packages,1776," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2046,modifiability,pac,package,2046," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2128,modifiability,pac,packages,2128," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2190,modifiability,modul,module,2190," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2320,modifiability,pac,packages,2320," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2381,modifiability,modul,module,2381," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2443,modifiability,modul,module,2443," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:7,performance,load,load,7,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:208,performance,load,load,208,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:267,performance,error,error,267,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:479,performance,Error,Error,479,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:25,safety,updat,updating,25,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:267,safety,error,error,267,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:291,safety,modul,module,291,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:479,safety,Error,Error,479,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:629,safety,modul,module,629,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:746,safety,modul,module,746,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:901,safety,modul,module,901,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1177,safety,modul,module,1177,"onment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:1335,safety,modul,module,1335,". <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2190,safety,modul,module,2190," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2381,safety,modul,module,2381," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:2443,safety,modul,module,2443," block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_gtk3agg.py"", line 4, in <module>. from . import backend_agg, backend_cairo, backend_gtk3. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/backends/backend_cairo.py"", line 15, in <module>. if cairo.version_info < (1, 11, 0):. AttributeError: module 'cairo' has no attribute 'version_info'. >>> . ```. I have scanpy==1.4.6, matplotlib==3.1.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:25,security,updat,updating,25,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:565,testability,Trace,Traceback,565,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:77,usability,clear,clear,77,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:267,usability,error,error,267,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:351,usability,minim,minimal,351,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1166:479,usability,Error,Error,479,"cannot load scanpy after updating to 1.4.6 via miniconda; <!-- Please give a clear and concise description of what the bug is: -->. I have upgraded to scanpy 1.4.6 in a conda environment. Since then I cannot load the package into python, as it gives me the following error: `AttributeError: module 'cairo' has no attribute 'version_info'`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/__init__.py"", line 38, in <module>. from . import plotting as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import scatter, violin, ranking, clustermap, stacked_violin, heatmap, dotplot, matrixplot, tracksplot, dendrogram, correlation_matrix. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/scanpy/plotting/_anndata.py"", line 16, in <module>. from matplotlib import pyplot as pl. File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 2349, in <module>. switch_backend(rcParams[""backend""]). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/__init__.py"", line 833, in __getitem__. plt.switch_backend(rcsetup._auto_backend_sentinel). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 204, in switch_backend. switch_backend(candidate). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/site-packages/matplotlib/pyplot.py"", line 221, in switch_backend. backend_mod = importlib.import_module(backend_name). File ""/home/tsztank/.miniconda3/envs/brandeis/lib/python3.7/importlib/__init__.py"", line 127, in import_module",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1166
https://github.com/scverse/scanpy/issues/1167:219,availability,error,error,219,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:802,availability,Error,Error,802,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1860,availability,error,error,1860,"he block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2708,availability,state,state,2708,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3305,availability,state,state,3305,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4302,availability,error,error,4302,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5150,availability,state,state,5150,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5747,availability,state,state,5747,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6744,availability,error,error,6744,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7592,availability,state,state,7592,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8189,availability,state,state,8189,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9186,availability,error,error,9186,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10034,availability,state,state,10034,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10631,availability,state,state,10631,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11628,availability,error,error,11628,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12476,availability,state,state,12476,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13073,availability,state,state,13073,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14070,availability,error,error,14070,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14918,availability,state,state,14918,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15515,availability,state,state,15515,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16512,availability,error,error,16512,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17360,availability,state,state,17360,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17957,availability,state,state,17957,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18954,availability,error,error,18954,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19802,availability,state,state,19802,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20399,availability,state,state,20399,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21801,availability,state,state,21801,"ages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22450,availability,state,state,22450,"ckages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24578,availability,state,state,24578,"y/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25307,availability,state,state,25307,"/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26723,availability,state,state,26723,"] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27452,availability,state,state,27452,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1297,deployability,fail,failed,1297,"a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3739,deployability,fail,failed,3739,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6181,deployability,fail,failed,6181,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8623,deployability,fail,failed,8623,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11065,deployability,fail,failed,11065,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13507,deployability,fail,failed,13507,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15949,deployability,fail,failed,15949,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18391,deployability,fail,failed,18391,"anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20949,deployability,fail,failed,20949,"ack from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-ba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:23480,deployability,fail,failed,23480,"rrection vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.z",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25667,deployability,fail,failed,25667,"ject_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27560,deployability,modul,module,27560,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28170,deployability,Version,Versions,28170,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28203,deployability,log,logging,28203,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22662,energy efficiency,schedul,scheduled,22662,"ine 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2708,integrability,state,state,2708,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3305,integrability,state,state,3305,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5150,integrability,state,state,5150,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5747,integrability,state,state,5747,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7592,integrability,state,state,7592,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8189,integrability,state,state,8189,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10034,integrability,state,state,10034,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10631,integrability,state,state,10631,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12476,integrability,state,state,12476,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13073,integrability,state,state,13073,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14918,integrability,state,state,14918,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15515,integrability,state,state,15515,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17360,integrability,state,state,17360,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17957,integrability,state,state,17957,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19802,integrability,state,state,19802,"t an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20399,integrability,state,state,20399,"is=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20682,integrability,batch,batch,20682,".7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20717,integrability,batch,batch,20717,"ine 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_j",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21801,integrability,state,state,21801,"ages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22450,integrability,state,state,22450,"ckages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24578,integrability,state,state,24578,"y/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25307,integrability,state,state,25307,"/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25398,integrability,batch,batch,25398,"1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26723,integrability,state,state,26723,"] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27452,integrability,state,state,27452,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28170,integrability,Version,Versions,28170,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:938,modifiability,pac,packages,938,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1158,modifiability,pac,packages,1158,"orrect()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1466,modifiability,paramet,parameterized,1466,"key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1628,modifiability,pac,packages,1628,"'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1815,modifiability,pac,packages,1815,"his code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2124,modifiability,pac,packages,2124,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2210,modifiability,pac,packages,2210,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2417,modifiability,pac,packages,2417,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2599,modifiability,pac,packages,2599,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:2783,modifiability,pac,packages,2783,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3196,modifiability,pac,packages,3196,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3380,modifiability,pac,packages,3380,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3600,modifiability,pac,packages,3600,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3908,modifiability,paramet,parameterized,3908," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4070,modifiability,pac,packages,4070,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4257,modifiability,pac,packages,4257,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4566,modifiability,pac,packages,4566,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4652,modifiability,pac,packages,4652,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4859,modifiability,pac,packages,4859,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5041,modifiability,pac,packages,5041,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5225,modifiability,pac,packages,5225,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5638,modifiability,pac,packages,5638,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5822,modifiability,pac,packages,5822,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6042,modifiability,pac,packages,6042,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6350,modifiability,paramet,parameterized,6350," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6512,modifiability,pac,packages,6512,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6699,modifiability,pac,packages,6699,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7008,modifiability,pac,packages,7008,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7094,modifiability,pac,packages,7094,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7301,modifiability,pac,packages,7301,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7483,modifiability,pac,packages,7483,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:7667,modifiability,pac,packages,7667,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8080,modifiability,pac,packages,8080,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8264,modifiability,pac,packages,8264,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8484,modifiability,pac,packages,8484,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8792,modifiability,paramet,parameterized,8792," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8954,modifiability,pac,packages,8954,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9141,modifiability,pac,packages,9141,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9450,modifiability,pac,packages,9450,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9536,modifiability,pac,packages,9536,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9743,modifiability,pac,packages,9743,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9925,modifiability,pac,packages,9925,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10109,modifiability,pac,packages,10109,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10522,modifiability,pac,packages,10522,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10706,modifiability,pac,packages,10706,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10926,modifiability,pac,packages,10926,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11234,modifiability,paramet,parameterized,11234," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11396,modifiability,pac,packages,11396,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11583,modifiability,pac,packages,11583,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11892,modifiability,pac,packages,11892,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11978,modifiability,pac,packages,11978,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12185,modifiability,pac,packages,12185,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12367,modifiability,pac,packages,12367,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12551,modifiability,pac,packages,12551,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:12964,modifiability,pac,packages,12964,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13148,modifiability,pac,packages,13148,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13368,modifiability,pac,packages,13368,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13676,modifiability,paramet,parameterized,13676," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13838,modifiability,pac,packages,13838,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14025,modifiability,pac,packages,14025,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14334,modifiability,pac,packages,14334,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14420,modifiability,pac,packages,14420,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14627,modifiability,pac,packages,14627,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14809,modifiability,pac,packages,14809,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:14993,modifiability,pac,packages,14993,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15406,modifiability,pac,packages,15406,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15590,modifiability,pac,packages,15590,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:15810,modifiability,pac,packages,15810,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16118,modifiability,paramet,parameterized,16118," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16280,modifiability,pac,packages,16280,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16467,modifiability,pac,packages,16467,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16776,modifiability,pac,packages,16776,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:16862,modifiability,pac,packages,16862,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17069,modifiability,pac,packages,17069,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17251,modifiability,pac,packages,17251,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17435,modifiability,pac,packages,17435,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:17848,modifiability,pac,packages,17848,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised fr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18032,modifiability,pac,packages,18032,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18252,modifiability,pac,packages,18252,"ges/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""..",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18560,modifiability,paramet,parameterized,18560," compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18722,modifiability,pac,packages,18722,"ml#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:18909,modifiability,pac,packages,18909,"), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19218,modifiability,pac,packages,19218,"nvs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19304,modifiability,pac,packages,19304,"is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/uti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19511,modifiability,pac,packages,19511,"Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19693,modifiability,pac,packages,19693,"canpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:19877,modifiability,pac,packages,19877,"s/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20290,modifiability,pac,packages,20290,"n3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20474,modifiability,pac,packages,20474,"3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:20800,modifiability,pac,packages,20800,"ate.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. sta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21094,modifiability,pac,packages,21094,"isit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information vi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21180,modifiability,pac,packages,21180,"f-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21451,modifiability,pac,packages,21451,"lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). Starting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21640,modifiability,pac,packages,21640,"ting MNN correct iteration. Reference batch: 0. Step 1 of 11: processing batch 1. Looking for MNNs... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:88: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:21876,modifiability,pac,packages,21876,"t mode WITHOUT looplifting enabled because Function ""find_mutual_nn"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (94). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22289,modifiability,pac,packages,22289,"= []. for index_2 in range(data2.shape[0]):. ^. @jit((float32[:, :], float32[:, :], int8, int8, int8)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""find_mutual_nn"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anacon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22557,modifiability,pac,packages,22557,"without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:22972,modifiability,pac,packages,22972,"pilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 94:. def find_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:23328,modifiability,pac,packages,23328,"d_mutual_nn(data1, data2, k1, k2, n_jobs):. <source elided>. mutual_2 = []. for index_2 in range(data2.shape[0]):. ^. state.func_ir.loc)). Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/ir_utils.py:2041: NumbaPendingDeprecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:23602,modifiability,pac,packages,23602,"ecationWarning: . Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'mnn2' of function 'compute_correction'. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:23964,modifiability,pac,packages,23964,"ite-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24144,modifiability,pac,packages,24144,"pe[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24337,modifiability,pac,packages,24337,"y/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function compute_correction failed at nopython mode lowering due to: iterating over 2D array. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:24653,modifiability,pac,packages,24653,"tion(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. [1] During: lowering ""$80for_iter.1 = iternext(value=$phi80.0)"" at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25066,modifiability,pac,packages,25066,"2[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25513,modifiability,pac,packages,25513,"]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25812,modifiability,pac,packages,25812,"cted, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:25899,modifiability,pac,packages,25899,"numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26289,modifiability,pac,packages,26289,"2, vect):. ^. state.func_ir.loc)). Adjusting variance... Applying correction... Step 2 of 11: processing batch 2. Looking for MNNs... Computing correction vectors... /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mn",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26482,modifiability,pac,packages,26482,"/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:102: NumbaWarning: . Compilation is falling back to object mode WITHOUT looplifting enabled because Function ""compute_correction"" failed type inference due to: non-precise type pyobject. [1] During: typing of argument at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (mo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:26798,modifiability,pac,packages,26798,"n3.7/site-packages/mnnpy/utils.py (107). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. @jit(float32[:, :](float32[:, :], float32[:, :], int32[:], int32[:], float32[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27211,modifiability,pac,packages,27211,"2[:, :], float32)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""compute_correction"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.prin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27560,modifiability,modul,module,27560,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27701,modifiability,pac,packages,27701,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:27844,modifiability,pac,packages,27844,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28015,modifiability,pac,packages,28015,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:28170,modifiability,Version,Versions,28170,"led in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 107:. def compute_correction(data1, data2, mnn1, mnn2, data2_or_raw2, sigma):. <source elided>. vect_reduced = np.zeros((data2.shape[0], vect.shape[1]), dtype=np.float32). for index, ve in zip(mnn2, vect):. ^. state.func_ir.loc)). Traceback (most recent call last):. File ""<ipython-input-2-111b3b404a99>"", line 7, in <module>. batch_categories=['1','2','3','4','5','6','7','8','9','10','11','12']). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/external/pp/_mnn_correct.py"", line 154, in mnn_correct. **kwargs,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 126, in mnn_correct. svd_mode=svd_mode, do_concatenate=do_concatenate, **kwargs). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/mnn.py"", line 182, in mnn_correct. new_batch_in, sigma). IndexError: arrays used as indices must be of integer (or boolean) type. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. >scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:219,performance,error,error,219,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:802,performance,Error,Error,802,"mnn_correct gives several Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Funct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1020,performance,parallel,parallel,1020,"l Numba warnings and IndexError; <!-- Please give a clear and concise description of what the bug is: -->. Running ```sc.external.pp.mnn_correct()``` outputs abundant Numba warnings and an Index error when reaches Step2 (of 11) during Computing correction vectors... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. adataMNN = sc.read_h5ad(results_file). sc.pp.highly_variable_genes(adataMNN, batch_key = 'sample'). var_select = adataMNN.var.highly_variable_nbatches > 1. var_genesMNN = var_select.index[var_select]. datasets = [adataMNN[adataMNN.obs['sample'] == sa].copy() for sa in adataMNN.obs['sample'].cat.categories]. sc.external.pp.mnn_correct(*datasets, var_subset=var_genesMNN, batch_key='sample'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:1860,performance,error,error,1860,"he block): -->. ```. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:3462,performance,parallel,parallel,3462,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:4302,performance,error,error,4302,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:5904,performance,parallel,parallel,5904,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:6744,performance,error,error,6744,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:8346,performance,parallel,parallel,8346,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:9186,performance,error,error,9186,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:10788,performance,parallel,parallel,10788,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:11628,performance,error,error,11628,"state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x7f637ad4ca70>). [2] During: typing of call at /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py (16). File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 16:. def l2_norm(in_matrix):. return np.linalg.norm(x=in_matrix, axis=1). ^. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
https://github.com/scverse/scanpy/issues/1167:13230,performance,parallel,parallel,13230,"rning: Function ""l2_norm"" was compiled in object mode without forceobj=True. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/object_mode_passes.py:188: NumbaDeprecationWarning: . Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour. For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit. File ""../../../anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py"", line 15:. @jit(float32[:](float32[:, :]), nogil=True). def l2_norm(in_matrix):. ^. state.func_ir.loc)). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: Code running in object mode won't allow parallel execution despite nogil=True. @jit(float32[:](float32[:, :]), nogil=True). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/mnnpy/utils.py:14: NumbaWarning: . Compilation is falling back to object mode WITH looplifting enabled because Function ""l2_norm"" failed type inference due to: Invalid use of Function(<function norm at 0x7f637ad4ca70>) with argument(s) of type(s): (axis=Literal[int](1), x=array(float32, 2d, A)). * parameterized. In definition 0:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. In definition 1:. TypeError: norm_impl() got an unexpected keyword argument 'x'. raised from /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/numba/typing/templates.py:539. This error is usually caused by passing an argument of a type that is unsupported by the named function. [1] During: resolving callee type: Function(<function norm at 0x",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1167
